
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.8">
    
    
      
        <title>Adaptive Self-Supervision Algorithms for Physics-Informed Neural Networks 物理信息神经网络的自适应自监督算法 - Nanxi Gu</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.815d1a91.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../paper.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#adaptive-self-supervision-algorithms-for-physics-informed-neural-networks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Nanxi Gu" class="md-header__button md-logo" aria-label="Nanxi Gu" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Nanxi Gu
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Adaptive Self-Supervision Algorithms for Physics-Informed Neural Networks <br> 物理信息神经网络的自适应自监督算法
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Nanxi Gu" class="md-nav__button md-logo" aria-label="Nanxi Gu" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Nanxi Gu
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        模型
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../Songs/" class="md-nav__link">
        歌词
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    Abstract 摘要
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    1. Introduction 介绍
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-related-work" class="md-nav__link">
    2. Related Work 相关工作
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-methods" class="md-nav__link">
    3. Methods 方法
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-experiments" class="md-nav__link">
    4. Experiments 实验
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-conclusions" class="md-nav__link">
    5. Conclusions 结论
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reference" class="md-nav__link">
    Reference 参考文献
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="adaptive-self-supervision-algorithms-for-physics-informed-neural-networks">Adaptive Self-Supervision Algorithms for Physics-Informed Neural Networks <br> 物理信息神经网络的自适应自监督算法</h1>
<ul>
<li>作者: Shashank Subramanian | Robert M. Kirby | Michael W. Mahoney | Amir Gholami</li>
<li>机构:</li>
<li>时间: 2022-07-08</li>
<li>预印: <a href="http://arxiv.org/abs/2207.04084">arXiv:2207.04084v1</a></li>
<li>领域:</li>
<li>标签: #PINN #开源</li>
<li>引用: 29 篇</li>
<li>代码: <a href="https://github.com/ShashankSubramanian/adaptive-selfsupervision-pinns">Github</a></li>
</ul>
<h2 id="abstract">Abstract 摘要</h2>
<p><model>Physics-informed neural networks (PINNs)</model> incorporate physical knowledge from the problem domain as a soft constraint on the loss function, but recent work has shown that this can lead to optimization difficulties. Here, we study the impact of the location of the collocation points on the trainability of these models. We find that the vanilla PINN performance can be significantly boosted by adapting the location of the collocation points as training proceeds. Specifically, we propose a novel adaptive collocation scheme which progressively allocates more collocation points (without increasing their number) to areas where the model is making higher errors (based on the gradient of the loss function in the domain). This, coupled with a judicious restarting of the training during any optimization stalls (by simply resampling the collocation points in order to adjust the loss landscape) leads to better estimates for the prediction error. We present results for several problems, including a 2D Poisson and diffusion-advection system with different forcing functions. We find that training vanilla PINNs for these problems can result in up to 70% prediction error in the solution, especially in the regime of low collocation points. In contrast, our adaptive schemes can achieve up to an order of magnitude smaller error, with similar computational complexity as the baseline.
Furthermore, we find that the adaptive methods consistently perform on-par or slightly better than vanilla PINN method, even for large collocation point regimes. The code for all the experiments has been open sourced and available at Github.</p>
<h2 id="1-introduction">1. Introduction 介绍</h2>
<h2 id="2-related-work">2. Related Work 相关工作</h2>
<p>There has been a large body of work studying PINNs [5,7,9,18,20,21,30] and the challenges associated with their training [6,11,24–27]. The work of [25] notes these challenges and proposes a loss scaling method to resolve the training difficulty. Similar to this approach, some works have treated the problem as a multi-objective optimization and tune the weights of the different loss terms[2,29]. A more formal approach was suggested in [13] where the weights are learned by solving a minimax　optimization problem that ascends in the loss weight space and descends in the model parameter space. This approach was extended in [15] to shift the focus of the weights from the loss terms to the training data points instead, and the minimax forces the optimization to pay attention to specific regions of the domain. However,minimax optimization problems are known to be hard to optimize and introduce additional complexity and computational expense. Furthermore, it has been shown that using curriculum or sequence-to-sequence learning can ameliorate the training difficulty with PINNs [11]. More recently, the work of [24] shows that incorporating causality in time can help training for time-dependent PDEs.
There is also recent work that studies the role of the collocation points. For instance, [22] refines the collocation point set without learnable weights. They propose an auxiliary NN that acts as a generative model to sample new collocation points that mimic the PDE residual. However, the auxiliary network also has to be trained in tandem with the PINN. The work of [14] proposes an adaptive collocation scheme where the points are densely sampled uniformly and trained for some number of iterations. Then the set is extended by adding points in increasing rank order of PDE residuals to refine in certain locations (of sharp fronts,for example) and the model is retrained. However, this method can increase the computational overhead,as the number of collocation points is progressively increased. Furthermore, in <sup id="fnref:8"><a class="footnote-ref" href="#fn:8">1</a></sup> the authors show that the latter approach can lead to excessive clustering of points throughout training. To address this, instead they propose to add points based on an underlying density function defined by the PDE residual. Both these schemes keep the original collocation set (the low residual points) and increase the training dataset sizes as the optimization proceeds.
Unlike the work of [8,14], we focus on using gradient of the loss function, instead of the nominal loss value,as the proxy to guide the adaptive resampling of the collocation points. We show that this approach leads to better localization of the collocation points, especially for problems with sharp features. Furthermore, we incorporate a novel cosine-annealing scheme, which progressively incorporates adaptive sampling as training proceeds. Importantly, we also keep the number of collocation points the same. Not only does this not increase the computational overhead, but this is also easier to implement as well．</p>
<h2 id="3-methods">3. Methods 方法</h2>
<p>In PINNs, we use a feedforward NN, denoted <span class="arithmatex">\(NN(\pmb{x};\theta)\)</span>, that is parameterized by weights and biases, <span class="arithmatex">\(\theta\)</span>, takes as input values for coordinate points, <span class="arithmatex">\(\pmb{x}\)</span>, and outputs the solution value <span class="arithmatex">\(u(\pmb{x})\in\mathbb{R}\)</span> at these points. As described in Section 1, the model parameters <span class="arithmatex">\(\theta\)</span> are optimized through the loss function:</p>
<div class="arithmatex">\[
    \min_{\theta}\mathcal{L}_{\mathcal{B}} + \lambda_{\mathcal{F}}\mathcal{L}_{\mathcal{F}}. \tag{3.1}
\]</div>
<h2 id="4-experiments">4. Experiments 实验</h2>
<h2 id="5-conclusions">5. Conclusions 结论</h2>
<h2 id="reference">Reference 参考文献</h2>
<p>Rafael Bischof and Michael Kraus. Multi-objective loss balancing for physics-informed deep learning.
arXiv preprint arXiv:2110.09813, 2021.</p>
<p>[3] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.</p>
<p>[4] Steven L Brunton, Bernd R Noack, and Petros Koumoutsakos. Machine learning for fluid mechanics.
Annual Review of Fluid Mechanics, 52:477–508, 2020.</p>
<p>[5] Yuyao Chen, Lu Lu, George Em Karniadakis, and Luca Dal Negro. Physics-informed neural networks for inverse problems in nano-optics and metamaterials. Optics express, 28(8):11618–11633, 2020.</p>
<p>[6] C. Edwards. Neural networks learn to speed up simulations. Communications of the ACM, 65(5):27–29,2022.</p>
<p>[7] Nicholas Geneva and Nicholas Zabaras. Modeling the dynamics of pde systems with physics-constrained deep auto-regressive networks. Journal of Computational Physics, 403:109056, 2020.</p>
<p>[9] Xiaowei Jin, Shengze Cai, Hui Li, and George Em Karniadakis. Nsfnets (navier-stokes flow nets): Physics-informed neural networks for the incompressible navier-stokes equations. Journal of Computational Physics, 426:109951, 2021.</p>
<p>[10] George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang.
Physics-informed machine learning. Nature Reviews Physics, 3(6):422–440, 2021.</p>
<p>[11] Aditi Krishnapriyan, Amir Gholami, Shandian Zhe, Robert Kirby, and Michael W Mahoney. Charac-terizing possible failure modes in physics-informed neural networks. Advances in Neural Information Processing Systems, 34, 2021.</p>
<p>[12] Isaac E Lagaris, Aristidis Likas, and Dimitrios I Fotiadis. Artificial neural networks for solving ordinary and partial differential equations. IEEE transactions on neural networks, 9(5):987–1000, 1998.</p>
<p>[13] Dehao Liu and Yan Wang. A dual-dimer method for training physics-constrained neural networks with minimax architecture. Neural Networks, 136:112–125, 2021.</p>
<p>[14] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. Deepxde: A deep learning library for solving differential equations. SIAM Review, 63(1):208–228, 2021.</p>
<p>[15] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft attention mechanism. arXiv preprint arXiv:2009.04544, 2020.</p>
<p>[16] Christopher Rackauckas, Yingbo Ma, Julius Martensen, Collin Warner, Kirill Zubov, Rohit Supekar,Dominic Skinner, Ali Ramadhan, and Alan Edelman. Universal differential equations for scientific machine learning. arXiv preprint arXiv:2001.04385, 2020.</p>
<p>[17]  Maziar Raissi, Paris Perdikaris, and George E Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational Physics, 378:686–707, 2019.</p>
<p>[18] Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations. Science, 367(6481):1026–1030, 2020.</p>
<p>[19] Amuthan A Ramabathiran and Prabhu Ramachandran. Spinn: Sparse, physics-based, and partially interpretable neural networks for pdes. Journal of Computational Physics, 445:110600, 2021.</p>
<p>[20] Francisco Sahli Costabal, Yibo Yang, Paris Perdikaris, Daniel E Hurtado, and Ellen Kuhl. Physics-informed neural networks for cardiac activation mapping. Frontiers in Physics, 8:42, 2020.</p>
<p>[21] Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial differential equations. Journal of computational physics, 375:1339–1364, 2018.</p>
<p>[22] Kejun Tang, Xiaoliang Wan, and Chao Yang. Das: A deep adaptive sampling method for solving partial differential equations. arXiv preprint arXiv:2112.14038, 2021.</p>
<p>[23] Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev, Sven Giesselbach, Raoul Heese,Birgit Kirsch, Julius Pfrommer, Annika Pick, Rajkumar Ramamurthy, et al. Informed machine learning–a taxonomy and survey of integrating knowledge into learning systems. arXiv preprint arXiv:1903.12394,2019.</p>
<p>[24] Sifan Wang, Shyam Sankaran, and Paris Perdikaris. Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404, 2022.Adaptive Self-supervision Algorithms for Physics-informed Neural Networks1.</p>
<p>[25] Sifan Wang, Yujun Teng, and Paris Perdikaris. Understanding and mitigating gradient pathologies in physics-informed neural networks. arXiv preprint arXiv:2001.04536, 2020.</p>
<p>[26] Sifan Wang, Hanwen Wang, and Paris Perdikaris. On the eigenvector bias of fourier feature networks:From regression to solving multi-scale pdes with physics-informed neural networks. arXiv preprint arXiv:2012.10047, 2020.</p>
<p>[27] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why pinns fail to train: A neural tangent kernel perspective. arXiv preprint arXiv:2007.14527, 2020.</p>
<p>[28] Jared Willard, Xiaowei Jia, Shaoming Xu, Michael Steinbach, and Vipin Kumar. Integrating physics-based modeling with machine learning: A survey. arXiv preprint arXiv:2003.04919, 2020.</p>
<p>[29] Zixue Xiang, Wei Peng, Xiaohu Zheng, Xiaoyu Zhao, and Wen Yao. Self-adaptive loss balanced physics-informed neural networks for the incompressible navier-stokes equations. arXiv preprint arXiv:2104.06217,2021.</p>
<p>[30] Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, and Paris Perdikaris. Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data. Journal of Computational Physics, 394:56–81, 2019.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:8">
<p>John Hanna, Jose V Aguado, Sebastien Comas-Cardona, Ramzi Askri, and Domenico Borzacchiello.
Residual-based adaptivity for two-phase flow simulation in porous media using physics-informed neural networks. arXiv preprint arXiv:2109.14290, 2021.&#160;<a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.d6c3db9e.min.js"></script>
      
        <script src="../../../javascripts/mathjac.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>