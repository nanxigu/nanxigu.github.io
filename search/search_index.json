{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Gu Nanxi","title":"\u9996\u9875"},{"location":"#gu-nanxi","text":"","title":"Gu Nanxi"},{"location":"Books/","text":"\u4e66\u7c4d\u5217\u8868 2021.08 \u300a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357\u300b","title":"\u4e66\u7c4d"},{"location":"Books/#_1","text":"2021.08 \u300a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357\u300b","title":"\u4e66\u7c4d\u5217\u8868"},{"location":"Courses/","text":"","title":"\u8bfe\u7a0b"},{"location":"Models/","text":"\u6a21\u578b \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840 PINN \u7cfb\u5217","title":"\u6a21\u578b"},{"location":"Models/#_1","text":"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840 PINN \u7cfb\u5217","title":"\u6a21\u578b"},{"location":"Projects/","text":"\u9879\u76ee\u5217\u8868 NanoDet \u8be6\u89e3","title":"\u9879\u76ee"},{"location":"Projects/#_1","text":"NanoDet \u8be6\u89e3","title":"\u9879\u76ee\u5217\u8868"},{"location":"Scholars/","text":"\u5b66\u8005\u8bba\u6587\u5408\u96c6 \u9102\u7ef4\u5357 \u8bb8\u8dc3\u751f 2022.07 Sparse DNN for Nonlinear PDEs","title":"\u5b66\u8005"},{"location":"Scholars/#_1","text":"","title":"\u5b66\u8005\u8bba\u6587\u5408\u96c6"},{"location":"Scholars/#_2","text":"","title":"\u9102\u7ef4\u5357"},{"location":"Scholars/#_3","text":"2022.07 Sparse DNN for Nonlinear PDEs","title":"\u8bb8\u8dc3\u751f"},{"location":"Songs/","text":"\u6b4c\u8bcd\u8bb0\u5f55 \u5e7e\u7530\u308a\u3089 - \u30ed\u30de\u30f3\u30b9\u306e\u7d04\u675f [ChiliChill - \u534a\u9192]","title":"\u6b4c\u8bcd\u8bb0\u5f55"},{"location":"Songs/#_1","text":"\u5e7e\u7530\u308a\u3089 - \u30ed\u30de\u30f3\u30b9\u306e\u7d04\u675f [ChiliChill - \u534a\u9192]","title":"\u6b4c\u8bcd\u8bb0\u5f55"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/","text":"\u63cf\u8ff0\u6d41\u4f53\u8fd0\u52a8\u7684\u65b9\u6cd5 \u4ee5\u8fde\u7eed\u4ecb\u8d28\u5047\u8bbe\u4e3a\u57fa\u7840, \u7814\u7a76\u6d41\u4f53\u8d28\u70b9\u6240\u5177\u6709\u7684\u5b8f\u89c2\u7269\u7406\u91cf\u6ee1\u8db3\u7684\u7269\u7406\u6027\u8d28\u548c\u7269\u7406\u5b9a\u5f8b\u7684\u65b9\u6cd5\u6709\u4e24\u79cd: \u6b27\u62c9\u65b9\u6cd5\u548c\u62c9\u683c\u6717\u65e5\u65b9\u6cd5 Lagrange \u65b9\u6cd5 Lagrange \u65b9\u6cd5\u7740\u773c\u4e8e\u6d41\u4f53\u8d28\u70b9, \u8bbe\u6cd5\u63cf\u8ff0\u6bcf\u4e2a\u6d41\u4f53\u8d28\u70b9\u81ea\u59cb\u81f3\u7ec8\u7684\u8fd0\u52a8\u8fc7\u7a0b, \u5373\u4f4d\u7f6e\u968f\u65f6\u95f4\u7684\u53d8\u5316\u89c4\u5f8b. \u7531\u4e8e\u6d41\u4f53\u8d28\u70b9\u65f6\u8fde\u7eed\u5206\u5e03\u7684, \u56e0\u6b64\u9996\u5148\u8981\u6709\u4e00\u4e2a\u6807\u8bc6\u8d28\u70b9\u7684\u65b9\u6cd5. \u7531\u4e8e\u5728\u6bcf\u4e00\u65f6\u523b, \u6bcf\u4e00\u8d28\u70b9\u90fd\u5360\u6709\u552f\u4e00\u786e\u5b9a\u7684\u7a7a\u95f4\u4f4d\u7f6e, \u56e0\u6b64\u53d6 \\(t=t_0\\) \u65f6\u523b, \u4ee5\u6d41\u4f53\u8d28\u70b9\u6240\u5360\u7684\u7a7a\u95f4\u4f4d\u7f6e\u5750\u6807 \\((a,b,c)\\) \u6765\u6807\u8bc6\u4e00\u4e2a\u6d41\u4f53\u8d28\u70b9, \u76f4\u89d2\u5750\u6807\u7cfb\u4e2d\u4e3a \\[ \\begin{cases} a = x|_{t=y_0}\\\\ b = y|_{t=y_0}\\\\ c = z|_{t=y_0} \\end{cases} \\] \u5bf9\u4e8e\u67d0\u4e00\u4e2a\u7279\u5b9a\u7684\u6d41\u4f53\u8d28\u70b9, \u5176\u6807\u8bc6\u65f6\u56fa\u5b9a\u4e0d\u53d8\u7684, \u56e0\u6b64\u5b83\u5728\u7a7a\u95f4\u4e2d\u7684\u4f4d\u7f6e\u5c06\u53ea\u662f\u65f6\u95f4\u7684\u51fd\u6570: \\[ \\vec{r} = \\vec{r}(t) \\] \u5f53\u7814\u7a76\u6240\u6709\u6d41\u4f53\u8d28\u70b9\u5728\u7a7a\u95f4\u8fd0\u52a8\u65f6, \u4f4d\u7f6e\u77e2\u91cf\u5c06\u662f\u4f4d\u7f6e\u548c\u65f6\u95f4\u7684\u51fd\u6570: \\[ \\vec{r} = \\vec{r}(a,b,c,t) \\] \u67d0\u4e00\u786e\u5b9a\u7684\u6d41\u4f53\u8d28\u70b9\u5728 \\(\\Delta t\\) \u65f6\u95f4\u95f4\u9694\u5185\u4ece\u70b9 \\(A\\) \u8fd0\u52a8\u5230\u70b9 \\(B\\) , \u5219\u5176\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u5206\u522b\u5b9a\u4e49\u4e3a: \\[ \\begin{aligned} \\vec{V}(t)&=\\lim_{\\Delta t\\to0}\\frac{\\vec{r}(t+\\Delta t)-\\vec{r}(t)}{\\Delta t}=\\frac{\\text{d}\\vec{r}(t)}{\\text{d}t}\\\\ \\vec{a}(t)&=\\frac{\\text{d}\\vec{V}(t)}{\\text{d}t}=\\frac{\\text{d}^2\\vec{r}(t)}{\\text{d}t^2} \\end{aligned} \\] \u5f53\u7814\u7a76\u6240\u6709\u6d41\u4f53\u8d28\u70b9\u5728\u7a7a\u95f4\u8fd0\u52a8\u65f6, \u5176\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u8868\u8fbe\u5f0f\u5206\u522b\u4e3a \\[ \\begin{aligned} \\vec{V}(a,b,c,t)&=\\frac{\\partial\\vec{r}(a,b,c,t)}{\\partial t}\\\\ \\vec{a}(a,b,c,t)&=\\frac{\\partial\\vec{V}(t)}{\\partial t}=\\frac{\\partial^2\\vec{r}(t)}{\\partial t^2} \\end{aligned} \\] Lagrange \u65b9\u6cd5\u7684 \\((a,b,c)\\) \u662f\u4e3a\u4e86\u8bc6\u522b\u6d41\u4f53\u8d28\u70b9\u8fdb\u884c\u7684\u4e00\u79cd\u7f16\u53f7, \u56e0\u6b64 \\(\\vec{V}\\) \u548c \\(\\vec{a}\\) \u90fd\u4e0d\u662f\u968f\u7a7a\u95f4\u53d8\u5316\u7684\u573a\u53d8\u91cf, \u6ca1\u6709\u68af\u5ea6, \u6563\u5ea6\u548c\u65cb\u5ea6\u7684\u6982\u5ff5. Euler \u65b9\u6cd5 Euler \u65b9\u6cd5\u7740\u773c\u4e8e\u7a7a\u95f4\u70b9, \u8bbe\u6cd5\u5c06\u5404\u4e2a\u65f6\u523b\u6d41\u8fc7\u7a7a\u95f4\u4e2d\u7684\u4efb\u4e00\u56fa\u5b9a\u70b9\u7684\u6d41\u4f53\u8d28\u70b9\u7684\u67d0\u4e9b\u7269\u7406\u91cf\u8868\u793a\u4e3a\u8be5\u70b9\u4f4d\u7f6e\u548c\u65f6\u95f4\u7684\u51fd\u6570. \u901f\u5ea6\u8868\u793a\u4e3a \\[ \\vec{V}=\\vec{V}(x,y,z,t) \\] \u573a\u8bba\u77e5\u8bc6? \u52a0\u901f\u5ea6\u8868\u793a\u4e3a \\[ \\vec{a}=\\frac{\\text{D}\\vec{V}}{\\text{D}t} \\] \u8868\u793a\u901f\u5ea6\u77e2\u91cf\u7684\u7269\u8d28\u5bfc\u6570 (\u5168\u5bfc\u6570, \u8d28\u70b9\u5bfc\u6570) \u4e09\u5927\u57fa\u672c\u65b9\u7a0b \u8d28\u91cf\u5b88\u6052 \u52a8\u91cf\u5b88\u6052 \u80fd\u91cf\u5b88\u6052","title":"\u63cf\u8ff0\u6d41\u4f53\u8fd0\u52a8\u7684\u65b9\u6cd5"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#_1","text":"\u4ee5\u8fde\u7eed\u4ecb\u8d28\u5047\u8bbe\u4e3a\u57fa\u7840, \u7814\u7a76\u6d41\u4f53\u8d28\u70b9\u6240\u5177\u6709\u7684\u5b8f\u89c2\u7269\u7406\u91cf\u6ee1\u8db3\u7684\u7269\u7406\u6027\u8d28\u548c\u7269\u7406\u5b9a\u5f8b\u7684\u65b9\u6cd5\u6709\u4e24\u79cd: \u6b27\u62c9\u65b9\u6cd5\u548c\u62c9\u683c\u6717\u65e5\u65b9\u6cd5","title":"\u63cf\u8ff0\u6d41\u4f53\u8fd0\u52a8\u7684\u65b9\u6cd5"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#lagrange","text":"Lagrange \u65b9\u6cd5\u7740\u773c\u4e8e\u6d41\u4f53\u8d28\u70b9, \u8bbe\u6cd5\u63cf\u8ff0\u6bcf\u4e2a\u6d41\u4f53\u8d28\u70b9\u81ea\u59cb\u81f3\u7ec8\u7684\u8fd0\u52a8\u8fc7\u7a0b, \u5373\u4f4d\u7f6e\u968f\u65f6\u95f4\u7684\u53d8\u5316\u89c4\u5f8b. \u7531\u4e8e\u6d41\u4f53\u8d28\u70b9\u65f6\u8fde\u7eed\u5206\u5e03\u7684, \u56e0\u6b64\u9996\u5148\u8981\u6709\u4e00\u4e2a\u6807\u8bc6\u8d28\u70b9\u7684\u65b9\u6cd5. \u7531\u4e8e\u5728\u6bcf\u4e00\u65f6\u523b, \u6bcf\u4e00\u8d28\u70b9\u90fd\u5360\u6709\u552f\u4e00\u786e\u5b9a\u7684\u7a7a\u95f4\u4f4d\u7f6e, \u56e0\u6b64\u53d6 \\(t=t_0\\) \u65f6\u523b, \u4ee5\u6d41\u4f53\u8d28\u70b9\u6240\u5360\u7684\u7a7a\u95f4\u4f4d\u7f6e\u5750\u6807 \\((a,b,c)\\) \u6765\u6807\u8bc6\u4e00\u4e2a\u6d41\u4f53\u8d28\u70b9, \u76f4\u89d2\u5750\u6807\u7cfb\u4e2d\u4e3a \\[ \\begin{cases} a = x|_{t=y_0}\\\\ b = y|_{t=y_0}\\\\ c = z|_{t=y_0} \\end{cases} \\] \u5bf9\u4e8e\u67d0\u4e00\u4e2a\u7279\u5b9a\u7684\u6d41\u4f53\u8d28\u70b9, \u5176\u6807\u8bc6\u65f6\u56fa\u5b9a\u4e0d\u53d8\u7684, \u56e0\u6b64\u5b83\u5728\u7a7a\u95f4\u4e2d\u7684\u4f4d\u7f6e\u5c06\u53ea\u662f\u65f6\u95f4\u7684\u51fd\u6570: \\[ \\vec{r} = \\vec{r}(t) \\] \u5f53\u7814\u7a76\u6240\u6709\u6d41\u4f53\u8d28\u70b9\u5728\u7a7a\u95f4\u8fd0\u52a8\u65f6, \u4f4d\u7f6e\u77e2\u91cf\u5c06\u662f\u4f4d\u7f6e\u548c\u65f6\u95f4\u7684\u51fd\u6570: \\[ \\vec{r} = \\vec{r}(a,b,c,t) \\] \u67d0\u4e00\u786e\u5b9a\u7684\u6d41\u4f53\u8d28\u70b9\u5728 \\(\\Delta t\\) \u65f6\u95f4\u95f4\u9694\u5185\u4ece\u70b9 \\(A\\) \u8fd0\u52a8\u5230\u70b9 \\(B\\) , \u5219\u5176\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u5206\u522b\u5b9a\u4e49\u4e3a: \\[ \\begin{aligned} \\vec{V}(t)&=\\lim_{\\Delta t\\to0}\\frac{\\vec{r}(t+\\Delta t)-\\vec{r}(t)}{\\Delta t}=\\frac{\\text{d}\\vec{r}(t)}{\\text{d}t}\\\\ \\vec{a}(t)&=\\frac{\\text{d}\\vec{V}(t)}{\\text{d}t}=\\frac{\\text{d}^2\\vec{r}(t)}{\\text{d}t^2} \\end{aligned} \\] \u5f53\u7814\u7a76\u6240\u6709\u6d41\u4f53\u8d28\u70b9\u5728\u7a7a\u95f4\u8fd0\u52a8\u65f6, \u5176\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u8868\u8fbe\u5f0f\u5206\u522b\u4e3a \\[ \\begin{aligned} \\vec{V}(a,b,c,t)&=\\frac{\\partial\\vec{r}(a,b,c,t)}{\\partial t}\\\\ \\vec{a}(a,b,c,t)&=\\frac{\\partial\\vec{V}(t)}{\\partial t}=\\frac{\\partial^2\\vec{r}(t)}{\\partial t^2} \\end{aligned} \\] Lagrange \u65b9\u6cd5\u7684 \\((a,b,c)\\) \u662f\u4e3a\u4e86\u8bc6\u522b\u6d41\u4f53\u8d28\u70b9\u8fdb\u884c\u7684\u4e00\u79cd\u7f16\u53f7, \u56e0\u6b64 \\(\\vec{V}\\) \u548c \\(\\vec{a}\\) \u90fd\u4e0d\u662f\u968f\u7a7a\u95f4\u53d8\u5316\u7684\u573a\u53d8\u91cf, \u6ca1\u6709\u68af\u5ea6, \u6563\u5ea6\u548c\u65cb\u5ea6\u7684\u6982\u5ff5.","title":"Lagrange \u65b9\u6cd5"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#euler","text":"Euler \u65b9\u6cd5\u7740\u773c\u4e8e\u7a7a\u95f4\u70b9, \u8bbe\u6cd5\u5c06\u5404\u4e2a\u65f6\u523b\u6d41\u8fc7\u7a7a\u95f4\u4e2d\u7684\u4efb\u4e00\u56fa\u5b9a\u70b9\u7684\u6d41\u4f53\u8d28\u70b9\u7684\u67d0\u4e9b\u7269\u7406\u91cf\u8868\u793a\u4e3a\u8be5\u70b9\u4f4d\u7f6e\u548c\u65f6\u95f4\u7684\u51fd\u6570. \u901f\u5ea6\u8868\u793a\u4e3a \\[ \\vec{V}=\\vec{V}(x,y,z,t) \\] \u573a\u8bba\u77e5\u8bc6? \u52a0\u901f\u5ea6\u8868\u793a\u4e3a \\[ \\vec{a}=\\frac{\\text{D}\\vec{V}}{\\text{D}t} \\] \u8868\u793a\u901f\u5ea6\u77e2\u91cf\u7684\u7269\u8d28\u5bfc\u6570 (\u5168\u5bfc\u6570, \u8d28\u70b9\u5bfc\u6570)","title":"Euler \u65b9\u6cd5"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#_2","text":"","title":"\u4e09\u5927\u57fa\u672c\u65b9\u7a0b"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#_3","text":"","title":"\u8d28\u91cf\u5b88\u6052"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#_4","text":"","title":"\u52a8\u91cf\u5b88\u6052"},{"location":"Books/The%20Finite%20Volume%20Method%20in%20CFD/01/#_5","text":"","title":"\u80fd\u91cf\u5b88\u6052"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/","tags":["\u5f3a\u5316\u5b66\u4e60","\u6df1\u5ea6\u5b66\u4e60"],"text":"\u7b2c\u4e00\u7ae0 \u9700\u6c42\u5206\u6790 \u9700\u6c42\u5206\u6790 \u672c\u7ae0\u8be6\u7ec6\u8ba8\u8bba\u54ea\u4e9b\u95ee\u9898\u9002\u5408\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\uff0c\u5bf9\u4e8e\u8bc4\u4f30\u7528\u6237\u9700\u6c42\u548c\u9879\u76ee\u53ef\u884c\u6027\u81f3\u5173\u91cd\u8981\u3002 \u4e00\u4e2a\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u6838\u5fc3\u80fd\u529b\u53ef\u4ee5\u603b\u7ed3\u4e3a\u4e09\u70b9\uff1a 1. \u5bf9\u5404\u79cd\u7b97\u6cd5\u672c\u8d28\u53ca\u5176\u80fd\u529b\u8fb9\u754c\u7684\u6df1\u523b\u7406\u89e3\u3002 2. \u5bf9\u76ee\u6807\u95ee\u9898\u5185\u5728\u903b\u8f91\u7684\u6df1\u5165\u5206\u6790\u3002 3. \u5bf9\u4e24\u8005\u7ed3\u5408\u70b9\u7684\u654f\u9510\u76f4\u89c9\u3002 \u4e00\u95ee\u201c\u662f\u4e0d\u662f\u201d \u667a\u80fd\u4f53\u548c\u73af\u5883\u5b9a\u4e49 \u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u548c\u5f3a\u5316\u5b66\u4e60 \u4e8c\u95ee\u201c\u503c\u4e0d\u503c\u201d \u8bd5\u8bd5\u89c4\u5219\u548c\u542f\u53d1\u5f0f\u641c\u7d22 \u8bd5\u8bd5\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60 \u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u7531 \u4e09\u95ee\u201c\u80fd\u4e0d\u80fd\u201d \u573a\u666f\u56fa\u5b9a \u6570\u636e\u5ec9\u4ef7 \u56db\u95ee\u201c\u8fb9\u754c\u5728\u54ea\u91cc\u201d \u603b\u7ed3 \u53c2\u8003\u6587\u732e","title":"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357 01"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_1","text":"","title":"\u7b2c\u4e00\u7ae0 \u9700\u6c42\u5206\u6790"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_2","text":"\u672c\u7ae0\u8be6\u7ec6\u8ba8\u8bba\u54ea\u4e9b\u95ee\u9898\u9002\u5408\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\uff0c\u5bf9\u4e8e\u8bc4\u4f30\u7528\u6237\u9700\u6c42\u548c\u9879\u76ee\u53ef\u884c\u6027\u81f3\u5173\u91cd\u8981\u3002 \u4e00\u4e2a\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u6838\u5fc3\u80fd\u529b\u53ef\u4ee5\u603b\u7ed3\u4e3a\u4e09\u70b9\uff1a 1. \u5bf9\u5404\u79cd\u7b97\u6cd5\u672c\u8d28\u53ca\u5176\u80fd\u529b\u8fb9\u754c\u7684\u6df1\u523b\u7406\u89e3\u3002 2. \u5bf9\u76ee\u6807\u95ee\u9898\u5185\u5728\u903b\u8f91\u7684\u6df1\u5165\u5206\u6790\u3002 3. \u5bf9\u4e24\u8005\u7ed3\u5408\u70b9\u7684\u654f\u9510\u76f4\u89c9\u3002","title":"\u9700\u6c42\u5206\u6790"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_3","text":"","title":"\u4e00\u95ee\u201c\u662f\u4e0d\u662f\u201d"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_4","text":"","title":"\u667a\u80fd\u4f53\u548c\u73af\u5883\u5b9a\u4e49"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_5","text":"","title":"\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u548c\u5f3a\u5316\u5b66\u4e60"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_6","text":"","title":"\u4e8c\u95ee\u201c\u503c\u4e0d\u503c\u201d"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_7","text":"","title":"\u8bd5\u8bd5\u89c4\u5219\u548c\u542f\u53d1\u5f0f\u641c\u7d22"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_8","text":"","title":"\u8bd5\u8bd5\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_9","text":"","title":"\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u7531"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_10","text":"","title":"\u4e09\u95ee\u201c\u80fd\u4e0d\u80fd\u201d"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_11","text":"","title":"\u573a\u666f\u56fa\u5b9a"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_12","text":"","title":"\u6570\u636e\u5ec9\u4ef7"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_13","text":"","title":"\u56db\u95ee\u201c\u8fb9\u754c\u5728\u54ea\u91cc\u201d"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_14","text":"","title":"\u603b\u7ed3"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-01/#_15","text":"","title":"\u53c2\u8003\u6587\u732e"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/","text":"\u7b2c\u4e94\u7ae0 \u7b97\u6cd5\u9009\u62e9 5.1 \u62ff\u6765\u4e3b\u4e49 & \u6539\u826f\u4e3b\u4e49 \u5c3d\u7ba1\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5df2\u7ecf\u53d6\u5f97\u957f\u8db3\u8fdb\u6b65, \u4f46\u5c1a\u672a\u5728\u7406\u8bba\u5c42\u9762\u53d6\u5f97\u8d28\u7684\u7a81\u7834, \u800c\u53ea\u662f\u5728\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\u57fa\u7840\u4e0a\u5f15\u5165\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc, \u5e76\u505a\u4e86\u4e00\u7cfb\u5217\u9002\u914d\u548c\u589e\u91cf\u5f0f\u6539\u8fdb\u5de5\u4f5c. \u603b\u4f53\u4e0a, DRL \u7b97\u6cd5\u6cbf\u7740 Model-Based \u548c Model-Free \u4e24\u5927\u5206\u652f\u53d1\u5c55. Model-Based Model-Based \u7b97\u6cd5\u5229\u7528\u5df2\u77e5\u73af\u5883\u6a21\u578b/\u5bf9\u672a\u77e5\u73af\u5883\u6a21\u578b\u8fdb\u884c\u663e\u5f0f\u5efa\u6a21, \u5e76\u4e0e \u524d\u5411\u641c\u7d22 (Look Ahead Search) \u548c \u8f68\u8ff9\u4f18\u5316 (Trajectory Optimization) \u7b49\u89c4\u5212\u7b97\u6cd5\u7ed3\u5408\u8fbe\u5230\u63d0\u5347\u6570\u636e\u6548\u7387\u7684\u76ee\u7684. \u4f46\u672a\u5728\u5b9e\u8df5\u4e2d\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528, \u56e0\u4e3a\u73b0\u5b9e\u4efb\u52a1\u7684\u73af\u5883\u6a21\u578b\u901a\u5e38\u5341\u5206\u590d\u6742, \u5bfc\u81f4\u6a21\u578b\u5b66\u4e60\u7684\u96be\u5ea6\u5f88\u9ad8 [1] [2], \u5e76\u4e14\u5efa\u6a21\u8bef\u5dee\u4e5f\u4f1a\u5bf9\u7b56\u7565\u9020\u6210\u8d1f\u9762\u5f71\u54cd. Model-Free Model-Free \u7b97\u6cd5\u53ef\u4ee5\u89e3\u6784\u4e3a: \u57fa\u672c\u539f\u7406-\u63a2\u7d22\u65b9\u5f0f-\u6837\u672c\u7ba1\u7406-\u68af\u5ea6\u8ba1\u7b97 \u7684\u56db\u5143\u6838\u5fc3\u7ec4\u4ef6\u3002 \u6309\u7167 \u57fa\u672c\u539f\u7406 \u6709\u4e24\u79cd\u5212\u5206\u4f53\u7cfb Value-Based & Policy-Based \u4ee5\u53ca On-Policy & Off-Policy\u3002 Value-Based: \u7b97\u6cd5\u76f4\u63a5\u5b66\u4e60\u72b6\u6001-\u52a8\u4f5c\u7ec4\u5408\u7684\u503c\u4f30\u8ba1; Policy-Based: \u7b97\u6cd5\u5177\u6709\u72ec\u7acb\u7b56\u7565; Actor-Critic: \u540c\u65f6\u5177\u5907\u72ec\u7acb\u7b56\u7565\u548c\u503c\u4f30\u8ba1\u51fd\u6570\u7684\u7b97\u6cd5; On-Policy: \u91c7\u6837\u7b56\u7565\u548c\u5f85\u4f18\u5316\u7b56\u7565\u76f8\u540c\u6216\u5dee\u5f02\u5f88\u5c0f; Off-Policy: \u91c7\u6837\u7b56\u7565\u548c\u5f85\u4f18\u5316\u7b56\u7565\u4e0d\u540c. DQN[3], DDPG[4], A3C[5] \u4f5c\u4e3a\u8fd9\u4e24\u79cd\u5f7c\u6b64\u4ea4\u7ec7\u7684\u5212\u5206\u4f53\u7cfb\u4e0b\u7684\u7ecf\u5178\u7b97\u6cd5\u6846\u67b6, \u6784\u6210\u4e86 DRL \u7814\u7a76\u4e2d\u7684\u91cd\u8981\u8282\u70b9, \u540e\u7eed\u63d0\u51fa\u7684\u5927\u90e8\u5206\u7b97\u6cd5\u57fa\u672c\u90fd\u7acb\u8db3\u4e8e\u8fd9\u4e09\u79cd\u6846\u67b6, \u9488\u5bf9\u5176\u6838\u5fc3\u7ec4\u4ef6\u6240\u8fdb\u884c\u7684\u8fed\u4ee3\u4f18\u5316\u6216\u8005\u62c6\u5206\u91cd\u7ec4. \u56db\u5143\u6838\u5fc3\u7ec4\u4ef6: \u57fa\u672c\u539f\u7406: \u8fdb\u5c55\u7f13\u6162, \u4f46\u5374\u662f DRL \u7b97\u6cd5\u5c06\u6765\u5927\u89c4\u6a21\u63a8\u5e7f\u7684\u5173\u952e\u6240\u5728. \u63a2\u7d22\u65b9\u5f0f: \u76f8\u5e94\u6539\u8fdb\u4f7f\u7b97\u6cd5\u66f4\u5145\u5206\u63a2\u7d22\u73af\u5883, \u66f4\u597d\u5730\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528, \u4ece\u800c\u6709\u673a\u4f1a\u5b66\u4e60\u5230\u66f4\u597d\u7684\u7b56\u7565. \u6837\u672c\u7ba1\u7406: \u76f8\u5e94\u6539\u8fdb\u6709\u52a9\u4e8e\u63d0\u5347\u7b97\u6cd5\u7684\u6837\u672c\u6548\u7387, \u52a0\u5feb\u6536\u655b\u901f\u5ea6, \u63d0\u9ad8\u7b97\u6cd5\u5b9e\u7528\u6027. \u68af\u5ea6\u8ba1\u7b97: \u81f4\u529b\u4e8e\u4f7f\u6bcf\u4e00\u6b21\u68af\u5ea6\u66f4\u65b0\u90fd\u66f4\u7a33\u5b9a, \u65e0\u504f\u548c\u9ad8\u6548. \u603b\u4f53\u800c\u8a00, \u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6b63\u671d\u7740\u901a\u7528\u5316\u548c\u9ad8\u6548\u5316\u7684\u65b9\u5411\u53d1\u5c55. \u4e00\u7b5b\u3001\u4e8c\u6bd4\u3001\u4e09\u6539\u826f \u7c97\u7565\u6765\u770b, \u6839\u636e\u95ee\u9898\u5b9a\u4e49, \u52a8\u4f5c\u7a7a\u95f4\u7c7b\u578b, \u91c7\u6837\u6210\u672c, \u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\u7b49\u56e0\u7d20\u7684\u4e0d\u540c, \u786e\u5b9e\u5b58\u5728\u4e00\u4e9b\u5173\u4e8e\u4e0d\u540c\u7c7b\u578b DRL \u7b97\u6cd5\u9002\u7528\u6027\u65b9\u9762\u7684\u7ed3\u8bba. DQN \u53ca\u5176\u53d8\u4f53\u4e00\u822c\u53ea\u9002\u7528\u4e8e\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4; DDPG \u53ca\u5176\u53d8\u4f53\u53ea\u9002\u5408\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4; A3C \u53ca SAC \u7b49\u5219\u652f\u6301\u79bb\u6563\u548c\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4. \u968f\u673a\u6027\u7b56\u7565\u901a\u5e38\u6bd4\u786e\u5b9a\u6027\u7b56\u7565\u6709\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027. \u5bf9\u4e8e\u673a\u5668\u4eba\u7b49\u6d89\u53ca\u786c\u4ef6\u7684\u5e94\u7528\u6216\u91c7\u6837\u6210\u672c\u8f83\u9ad8\u7684\u4efb\u52a1, \u80fd\u591f\u91cd\u590d\u5229\u7528\u5386\u53f2\u6570\u636e\u7684 Off-Policy \u7b97\u6cd5\u6bd4 On-Policy \u7b97\u6cd5\u66f4\u6709\u4f18\u52bf[7]\u3002 \u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1, \u591a\u4e2a\u4ea4\u4e92\u7684\u667a\u80fd\u4f53\u4e92\u76f8\u6784\u6210\u5bf9\u65b9\u73af\u5883\u7684\u4e00\u90e8\u5206, \u5e76\u968f\u7740\u5404\u81ea\u7b56\u7565\u7684\u8fed\u4ee3\u5bfc\u81f4\u8fd9\u4e9b\u73af\u5883\u6a21\u578b\u53d1\u751f\u53d8\u5316, \u4ece\u800c\u5bfc\u81f4\u57fa\u4e8e\u8fd9\u4e9b\u6a21\u578b\u6784\u5efa\u7684\u77e5\u8bc6/\u6280\u80fd\u5931\u6548, \u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a \u73af\u5883\u4e0d\u7a33\u5b9a\u6027 (Environment Nonstationarity) . \u56e0\u6b64\u9664\u975e \u7ecf\u9a8c\u56de\u653e\u7f13\u5b58 (Replay Buffer) \u4e2d\u7684\u6570\u636e\u66f4\u65b0\u5f97\u8db3\u591f\u5feb, \u5426\u5219 Off-Policy \u7b97\u6cd5\u53cd\u800c\u53ef\u80fd\u5f15\u5165\u504f\u5dee[8]. \u7531\u4e8e\u5229\u7528\u8d1d\u5c14\u66fc\u516c\u5f0f Bootstrap \u7279\u6027\u7684\u503c\u8fed\u4ee3\u65b9\u6cd5\u662f\u6709\u504f\u7684, On-Policy \u7b97\u6cd5\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u8981\u597d\u4e8e Off-Policy \u7b97\u6cd5. \u7136\u800c\u4e3a\u4e86\u5c3d\u53ef\u80fd\u83b7\u53d6\u5173\u4e8e\u503c\u51fd\u6570\u7684\u65e0\u504f\u4f30\u8ba1, On-Policy \u7b97\u6cd5\u5f80\u5f80\u9700\u8981\u5229\u7528\u591a\u4e2a\u73af\u5883\u5e76\u884c\u91c7\u96c6\u8db3\u591f\u591a\u7684\u6837\u672c, \u8fd9\u5bf9\u786c\u4ef6\u6709\u6240\u8981\u6c42, \u800c Off-Policy \u5219\u4e0d\u5fc5, \u867d\u7136\u4e5f\u80fd\u591f\u4ece\u5e76\u884c\u91c7\u6837\u4e2d\u53d7\u76ca[5]\u3002 \u4e0b\u9762\u603b\u7ed3\u4e86 Model-Free DRL \u7b97\u6cd5\u9002\u7528\u6027\u7684\u4e00\u822c\u7ed3\u8bba: \u52a8\u4f5c\u7a7a\u95f4\u517c\u5bb9\u6027: Value-Based: \u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4; Policy-Based + \u786e\u5b9a\u6027\u7b56\u7565: \u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4; Policy-Based + \u968f\u673a\u6027\u7b56\u7565: \u79bb\u6563&\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4. \u91c7\u6837\u6210\u672c\u5bb9\u5fcd\u5ea6: Off-Policy > On-Policy. \u8fd0\u7b97\u8d44\u6e90\u9700\u6c42: On-Policy \u9700\u8981\u66f4\u591a\u7684 CPU \u6838\u5fc3. \u8bad\u7ec3\u7a33\u5b9a\u6027: On-Policy > Off-Policy; \u968f\u673a\u6027\u7b56\u7565 > \u786e\u5b9a\u6027\u7b56\u7565. \u5176\u4ed6: Off-Policy \u5bb9\u6613\u53d7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u73af\u5883\u4e0d\u7a33\u5b9a\u6027\u7684\u5f71\u54cd. \u5b8c\u6210\u7c97\u7565\u7684\u7b5b\u9009\u540e, \u5bf9\u4e8e\u7b26\u5408\u6761\u4ef6\u7684\u4e0d\u540c DRL \u7b97\u6cd5\u4e4b\u95f4\u7684\u53d6\u820d\u5c31\u76f8\u5bf9\u5fae\u5999. \u4e00\u822c\u800c\u8a00\u5b66\u672f\u754c\u63d0\u51fa\u7684 SOTA \u7b97\u6cd5, \u6027\u80fd\u901a\u5e38\u4f18\u4e8e\u65e7\u7b97\u6cd5, \u4f46\u5728\u5177\u4f53\u4efb\u52a1\u4e0a\u5e76\u4e0d\u7edd\u5bf9, \u56e0\u6b64\u9700\u8981\u6839\u636e\u5b9e\u9645\u8868\u73b0\u4ece\u82e5\u5e72\u5907\u9009\u7b97\u6cd5\u4e2d\u627e\u51fa\u6027\u80fd\u6700\u597d\u7684\u90a3\u4e2a. \u6b64\u5916, \u53ea\u6709\u90e8\u5206\u7ecf\u8fc7\u7cbe\u7ec6\u5b9a\u4e49\u7684\u5b9e\u9645\u4efb\u52a1\u53ef\u4ee5\u901a\u8fc7\u76f4\u63a5\u5e94\u7528\u6807\u51c6\u7b97\u6cd5\u5f97\u5230\u8f83\u597d\u89e3\u51b3, \u800c\u8bb8\u591a\u4efb\u52a1\u7531\u4e8e\u81ea\u8eab\u7684\u590d\u6742\u6027\u548c\u7279\u6b8a\u6027, \u9700\u8981\u9488\u5bf9\u6807\u51c6\u7b97\u6cd5\u7684\u6838\u5fc3\u7ec4\u4ef6\u8fdb\u884c\u4e0d\u540c\u7a0b\u5ea6\u7684\u4f18\u5316\u540e\u624d\u80fd\u5f97\u5230\u8f83\u4e3a\u7406\u60f3\u7684\u7ed3\u679c. [9] [10] [11] \u6b64\u5904\u7684\u4f18\u5316\u66f4\u591a\u65f6\u5019\u662f\u57fa\u4e8e\u5bf9\u5f53\u524d\u6027\u80fd\u74f6\u9888\u6210\u56e0\u7684\u6df1\u5165\u5206\u6790, \u5728\u5b66\u672f\u754c\u73b0\u6709\u7684\u7ec4\u4ef6\u6539\u826f\u63aa\u65bd\u548c\u601d\u60f3\u4e2d\u5bf9\u75c7\u9009\u62e9. DQN \u63a2\u7d22\u6539\u5584: \u52a0\u5165\u566a\u58f0\u7f51\u7edc Noisy Net \u4ee3\u66ff\u9ed8\u8ba4 \\(\\varepsilon\\) -greedy; DQN \u6837\u672c\u6548\u7387\u6539\u5584: \u5c06\u5e38\u89c4\u7ecf\u9a8c\u56de\u8bbf\u6539\u4e3a\u4f18\u5148\u7ea7\u7ecf\u9a8c\u56de\u653e PER [13]; DQN \u8bad\u7ec3\u7a33\u5b9a\u6027\u6539\u5584: \u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u7531\u5355\u6b65 Boostrap \u6539\u4e3a\u591a\u6b65; \u5b66\u672f\u7814\u7a76\u4e3a\u4e86\u7a81\u51fa\u7b97\u6cd5\u7684\u4f18\u52bf, \u5176\u4ed6\u8981\u7d20\u53ea\u8981\u4fdd\u6301\u4e00\u81f4\u751a\u81f3\u88ab\u523b\u610f\u5f31\u5316; \u843d\u5730\u5e94\u7528\u4e3a\u4e86\u5145\u5206\u53d1\u6325\u7b97\u6cd5\u7684\u6027\u80fd, \u5176\u4ed6\u8981\u7d20\u5e94\u8be5\u4e3b\u52a8\u8fce\u5408\u7b97\u6cd5\u9700\u6c42\u4ee5\u964d\u4f4e\u5176\u5b66\u4e60\u96be\u5ea6. \u5b66\u672f\u7814\u7a76\u7684\u76ee\u6807\u662f\u5728\u666e\u904d\u610f\u4e49\u4e0a\u89e3\u51b3\u6216\u6539\u5584 DRL \u7b97\u6cd5\u5b58\u5728\u7684\u56fa\u6709\u7f3a\u9677: \u5982\u4f4e\u6837\u672c\u6548\u7387, \u5bf9\u8d85\u53c2\u6570\u654f\u611f\u7b49\u95ee\u9898, \u7b97\u6cd5\u81ea\u8eab\u7279\u8d28\u7684\u4f18\u52a3\u662f\u6838\u5fc3. \u8bb8\u591a\u5f00\u653e\u5e73\u53f0\u4e3a\u5404\u79cd\u4efb\u52a1\u9884\u8bbe\u4e86\u56fa\u5b9a\u7684\u72b6\u6001\u7a7a\u95f4, \u52a8\u4f5c\u7a7a\u95f4\u548c\u56de\u62a5\u51fd\u6570. \u7814\u7a76\u8005\u5f88\u5c11\u9700\u8981\u4e3b\u52a8\u4fee\u6539\u8fd9\u4e9b\u8981\u7d20. \u843d\u5730\u5e94\u7528\u7684\u76ee\u6807\u662f\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u83b7\u5f97\u6700\u4f73\u7b56\u7565\u6027\u80fd, \u800c\u7b97\u6cd5\u4ec5\u4ec5\u662f\u5b9e\u73b0\u8be5\u76ee\u6807\u7684\u4f17\u591a\u73af\u8282\u4e4b\u4e00. \u843d\u5730\u5e94\u7528\u4e2d\u7684\u7b56\u7565\u6027\u80fd\u4f18\u5316\u662f\u4e00\u9879\u7cfb\u7edf\u5de5\u7a0b, \u9700\u8981\u5145\u5206\u8c03\u52a8\u5404\u79cd\u6709\u5229\u56e0\u7d20. 5.2 \u7ecf\u5178\u7b97\u6cd5 DQN \u57fa\u672c\u539f\u7406 : \u6df1\u5ea6 Q \u7f51\u7edc (Deep Q-Networks, DQNs) \u7ee7\u627f\u4e86 Q-Learning \u7684\u601d\u60f3, \u5229\u7528\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684 Boostrap \u7279\u6027, \u8ba1\u7b97\u76ee\u6807\u503c\u5e76\u4e0d\u65ad\u8fed\u4ee3\u4f18\u5316\u4e00\u4e2a\u72b6\u6001-\u52a8\u4f5c\u4f30\u503c\u51fd\u6570 \\(Q_\\theta(s,a):\\mathcal{S}\\to\\mathbb{R}^{|\\mathcal{A}|}\\) \u76f4\u81f3\u6536\u655b, \\(Q_\\theta(s,a)\\) \u7528\u53c2\u6570\u4e3a \\(\\theta\\) \u7684\u795e\u7ecf\u7f51\u7edc\u8868\u793a, \u7ecf\u8fc7\u4e00\u6b21\u524d\u5411\u8ba1\u7b97\u8f93\u51fa\u6240\u6709\u53ef\u80fd\u52a8\u4f5c (\u603b\u6570\u4e3a\u52a8\u4f5c\u7a7a\u95f4\u7ef4\u5ea6 \\(|\\mathcal{A}|\\) ) \u7684 \\(Q\\) \u503c\u4f30\u8ba1, \u4ece\u800c\u53ef\u4ee5\u6839\u636e\u5b83\u4eec\u7684\u76f8\u5bf9\u5927\u5c0f\u5728\u5404\u79cd\u72b6\u6001\u4e0b\u9009\u62e9\u6700\u4f18\u52a8\u4f5c. $$ J_Q(\\theta) = \\mathbb{E} {s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma\\max {a'\\in\\mathcal{A}}Q_\\theta(s',a')-Q_\\theta(s,a)\\big)^2\\bigg] $$ \u63a2\u7d22\u65b9\u5f0f : DQN \u5728\u8bad\u7ec3\u65f6\u9ed8\u8ba4\u4f7f\u7528 \\(\\varepsilon\\) -greedy \u7684\u63a2\u7d22\u7b56\u7565, \u6839\u636e\u5f53\u524d\u8f93\u5165\u72b6\u6001 \\(s\\) \u548c\u4f30\u503c\u51fd\u6570 \\(Q_\\theta(s,a)\\) , \u4ee5\u6982\u7387 \\(1-\\varepsilon\\) \u9009\u62e9 \\(\\arg\\max_{a\\in\\mathcal{A}}Q(s,a)\\) , \u4ee5\u6982\u7387 \\(\\varepsilon\\) \u968f\u673a\u9009\u62e9\u52a8\u4f5c, \u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c, \\(\\varepsilon\\) \u5728\u533a\u95f4 \\((0,1]\\) \u5185\u7531\u5927\u5230\u5c0f\u7ebf\u6027\u53d8\u5316, DQN \u4ece\u5f3a\u63a2\u7d22\u8f6c\u4e3a\u5f3a\u5229\u7528. \u6837\u672c\u7ba1\u7406 : DQN \u5c5e\u4e8e Off-Policy \u7b97\u6cd5, \u4f7f\u7528 Replay Buffer \u7684\u5148\u5165\u5148\u51fa\u5806\u6808\u5b58\u50a8\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91c7\u96c6\u7684\u5355\u6b65\u8f6c\u79fb\u6837\u672c \\((s,a,s',r)\\) , \u5e76\u6bcf\u6b21\u4ece\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u6279\u6b21\u7528\u4e8e\u68af\u5ea6\u8ba1\u7b97\u548c\u53c2\u6570\u66f4\u65b0. Replay Buffer \u5141\u8bb8\u91cd\u590d\u5229\u7528\u5386\u53f2\u6570\u636e, \u4ee5\u6279\u6b21\u4e3a\u5355\u4f4d\u7684\u8bad\u7ec3\u65b9\u5f0f\u8986\u76d6\u4e86\u66f4\u5927\u7684\u72b6\u6001\u7a7a\u95f4, \u4e2d\u548c\u4e86\u5355\u4e2a\u6837\u672c\u8ba1\u7b97\u68af\u5ea6\u65f6\u7684\u65b9\u5dee, \u56e0\u6b64\u662f\u7a33\u5b9a DQN \u8bad\u7ec3\u548c\u63d0\u9ad8\u5176\u6837\u672c\u6548\u7387\u7684\u91cd\u8981\u63aa\u65bd. \u68af\u5ea6\u8ba1\u7b97 : \u4e3a\u4e86\u514b\u670d Boostrap \u7ed9\u8bad\u7ec3\u5e26\u6765\u7684\u4e0d\u7a33\u5b9a\u6027, DQN \u8bbe\u7f6e\u4e86\u4e00\u4e2a\u4e0e Q \u7f51\u7edc\u7ed3\u6784\u5b8c\u5168\u76f8\u540c\u7684\u76ee\u6807 Q \u7f51\u7edc\u4e13\u95e8\u7528\u4e8e\u8ba1\u7b97\u76ee\u6807\u503c, \u5176\u53c2\u6570\u7528 \\(\\theta^-\\) \u8868\u793a. \u76ee\u6807 Q \u7f51\u7edc\u662f\u6bcf N \u6b21\u8fed\u4ee3\u540e\u5c06\u4e3b Q \u7f51\u7edc\u53c2\u6570\u6574\u4f53\u590d\u5236, \u6709\u6548\u63d0\u5347 DQN \u8bad\u7ec3\u7a33\u5b9a\u6027. \u7279\u70b9\u5206\u6790 : DQN \u4f5c\u4e3a Value-Based \u7b97\u6cd5\u53ea\u9002\u7528\u4e8e\u53ef\u7a77\u4e3e\u7684\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4, \u53ea\u6709\u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u5728\u7279\u5b9a\u72b6\u6001\u4e0b\u4e0d\u540c\u52a8\u4f5c\u95f4\u901a\u8fc7 \\(Q\\) \u503c\u6bd4\u8f83\u62e9\u4f18\u7684\u8fd0\u7b97\u91cf\u53ef\u63a7, \u5bf9\u4e8e\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u663e\u7136\u65e0\u6cd5\u505a\u5230, \u4f46\u53ef\u4ee5\u5c1d\u8bd5\u4fdd\u6301\u8db3\u591f\u63a7\u5236\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b, \u5c06\u8fde\u7eed\u52a8\u4f5c\u533a\u95f4\u79bb\u6563\u5316. DQN \u5728\u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u4f7f\u7528\u540c\u4e00\u4e2a\u76ee\u6807 Q \u7f51\u7edc\u8fdb\u884c\u52a8\u4f5c\u7684\u9009\u62e9\u548c\u8bc4\u4f30, \u5728\u566a\u58f0\u548c\u8bef\u5dee\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u5bb9\u6613\u4ea7\u751f\u504f\u9ad8\u7684\u503c\u4f30\u8ba1, \u79f0\u4e3a\u8fc7\u4f30\u8ba1\u95ee\u9898 (Overestimation), \u4f1a\u5bf9 DQN \u6027\u80fd\u9020\u6210\u5f71\u54cd. \u6539\u8fdb\u63aa\u65bd : [15] \u57fa\u672c\u539f\u7406: Dueling DQN[16], Distributional DQN[17], Multi-Step Boostrap[14]; \u63a2\u7d22\u65b9\u5f0f: \u53c2\u6570\u566a\u58f0[12,18]; \u6837\u672c\u7ba1\u7406: \u4f18\u5148\u7ea7\u7ecf\u9a8c\u56de\u653e PER[13,19], \u6b63\u8d1f Episode \u5206\u5f00\u5b58\u50a8 Double Bin Replay Buffer[20,21], \u4e8b\u540e\u7ecf\u9a8c\u56de\u653e HER[22], \u591a\u6838\u5e76\u884c\u91c7\u6837\u6539\u5584\u63a2\u7d22\u548c\u91c7\u6837\u6548\u7387[5, 23, 24]; \u68af\u5ea6\u8ba1\u7b97: Double DQN; Twin Q [26] DDPG \u57fa\u672c\u539f\u7406 : \u4e3a\u4e86\u652f\u6301\u8fde\u7eed\u63a7\u5236\u4efb\u52a1, \u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6 (Deep Deterministic Policy Gradient) \u5728 DQN \u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u4e2a\u53c2\u6570\u4e3a \\(\\phi\\) \u7684\u7b56\u7565\u7f51\u7edc \\(\\pi_\\phi(a|s)\\) , \u6839\u636e\u8f93\u5165\u72b6\u6001 \\(s\\) \u8f93\u51fa\u552f\u4e00\u786e\u5b9a\u6027\u52a8\u4f5c \\(a\\in\\mathcal{A}\\) , \\(\\mathcal{A}\\) \u662f \\(n\\) \u7ef4\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4. \u503c\u7f51\u7edc \\(Q_\\theta(s,a):\\mathcal{S}\\times\\mathcal{A}\\to\\mathbb{R}\\) \u8f93\u5165\u72b6\u6001\u548c\u52a8\u4f5c\u5e76\u8f93\u51fa\u5355\u4e2a\u503c\u4f30\u8ba1, \u5176\u66f4\u65b0\u540c\u6837\u57fa\u4e8e\u5229\u7528\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684 Boostrap \u5c5e\u6027\u7684\u65f6\u5e8f\u5dee\u5206\u65b9\u6cd5, \u4f46\u7531\u4e8e\u52a8\u4f5c\u662f\u8fde\u7eed\u53d6\u503c\u7684, \u5728\u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u653e\u5f03\u57fa\u4e8e \\(Q\\) \u503c\u7684\u52a8\u4f5c\u5bfb\u4f18\u800c\u76f4\u63a5\u4f7f\u7528\u7b56\u7565\u7f51\u7edc\u8f93\u51fa. \u7b56\u7565\u7f51\u7edc\u626e\u6f14\u4e86 Q \u7f51\u7edc\u4f18\u5316\u5668\u7684\u89d2\u8272, \u66f4\u65b0\u68af\u5ea6\u5b8c\u5168\u6765\u81ea Q \u7f51\u7edc, \u76ee\u6807\u662f\u6700\u5927\u5316\u5f53\u524d Q \u7f51\u7edc\u8f93\u51fa, \u63a8\u7406\u65f6\u53ea\u9700\u7b56\u7565\u7f51\u7edc\u505a\u4e00\u6b21\u524d\u5411\u8ba1\u7b97. $$ \\begin{aligned} J_Q(\\theta)&=\\mathbb{E} {s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma \\textcolor{red}{Q {\\theta^-}(s',\\pi_\\phi(a'|s'))}-Q_\\theta(s,a)\\big)^2\\bigg]\\ J_\\pi(\\phi)&=-\\mathbb{E} {s,a\\sim\\mathcal{D}}[Q \\theta(s,\\pi_\\phi(a|s))] \\end{aligned} $$ \u63a2\u7d22\u65b9\u5f0f : DDPG \u91c7\u7528\u52a0\u6027\u566a\u58f0\u63a2\u7d22\u65b9\u5f0f, \u5373\u7b56\u7565\u7f51\u7edc\u7684\u8f93\u51fa\u4e0e\u76f8\u540c\u7ef4\u5ea6\u7684\u9ad8\u65af\u566a\u58f0\u76f8\u52a0, \u566a\u58f0\u7684\u65b9\u5dee\u51b3\u5b9a\u4e86\u63a2\u7d22\u529b\u5ea6. \u4ee5\u5f53\u524d\u8f93\u51fa\u52a8\u4f5c\u4e3a\u4e2d\u5fc3\u5f62\u6210\u4e86\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03, \u800c\u6bcf\u6b21\u66f4\u65b0\u7b56\u7565\u7f51\u7edc\u90fd\u4f7f\u5f97\u8f93\u51fa\u52a8\u4f5c\u5411\u8be5\u5206\u5e03\u4e2d \\(Q\\) \u503c\u66f4\u9ad8\u7684\u65b9\u5411\u79fb\u52a8, \u76f4\u5230\u5206\u5e03\u5185\u5176\u4ed6\u65b9\u5411\u90fd\u662f\u66f4\u5dee\u7684\u65b9\u5411, \u7b56\u7565\u8f93\u51fa\u4e5f\u5c31\u7a33\u5b9a\u5728\u6700\u4f18\u52a8\u4f5c\u9644\u8fd1, \u4ece\u800c\u5b9e\u73b0\u63a2\u7d22\u548c\u5229\u7528\u7684\u5e73\u8861. \u9664\u4e86\u9ad8\u65af\u566a\u58f0, DDPG \u539f\u8bba\u6587\u63a8\u8350\u4f7f\u7528 OU \u566a\u58f0, \u5373\u65b9\u5dee\u7ebf\u6027\u8870\u51cf\u7684\u9ad8\u65af\u566a\u58f0, \u5b9e\u73b0\u5f3a\u63a2\u7d22\u5230\u5f3a\u5229\u7528\u7684\u8fc7\u6e21. \u6837\u672c\u7ba1\u7406 : DDPG \u662f Off-Policy \u7b97\u6cd5, \u4f7f\u7528\u4e86\u7ecf\u9a8c\u56de\u653e\u548c Replay Buffer. \u68af\u5ea6\u8ba1\u7b97 : \u4e3a\u4e86\u7a33\u5b9a\u8bad\u7ec3, DDPG \u4e3a\u4ef7\u503c\u7f51\u7edc\u548c\u7b56\u7565\u7f51\u7edc\u5206\u522b\u8bbe\u7f6e\u4e86\u5bf9\u5e94\u7684\u76ee\u6807\u7f51\u7edc, \u5e76\u5728 Q \u7f51\u7edc\u66f4\u65b0\u4e2d\u4f7f\u7528\u5b83\u4eec\u6765\u8ba1\u7b97\u76ee\u6807\u503c, \u9632\u6b62 Boostrap \u7684\u81ea\u6fc0\u6548\u5e94\u653e\u5927\u8bef\u5dee. DDPG \u7684\u76ee\u6807\u7f51\u7edc\u6bcf\u6b21\u8fed\u4ee3\u90fd\u8ddf\u968f\u4e3b\u7f51\u7edc\u8fdb\u884c\u66f4\u65b0, \u4f7f\u7528\u8ba1\u7b97\u5f53\u524d\u76ee\u6807\u7f51\u7edc\u548c\u4e3b\u7f51\u7edc\u7684\u52a0\u6743\u79fb\u52a8\u5e73\u5747, Temperature, \u7528\u4e8e\u8c03\u8282\u76ee\u6807\u7f51\u7edc\u6bcf\u6b65\u66f4\u65b0\u5e45\u5ea6. \u7279\u70b9\u5206\u6790 : DDPG \u7a81\u7834\u4e86\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u7684\u9650\u5236, \u4f7f\u5f97\u7b97\u6cd5\u7684\u4f7f\u7528\u4ef7\u503c\u5f97\u5230\u8fdb\u4e00\u6b65\u63d0\u5347. \u8fde\u7eed\u52a8\u4f5c\u4f7f\u5f97\u4efb\u52a1\u63a2\u7d22\u7a7a\u95f4\u6025\u5267\u6269\u5927, \u4ece\u800c\u5bfc\u81f4\u5b66\u4e60\u96be\u5ea6\u4e0a\u5347. \u6b64\u5916 Q \u7f51\u7edc\u540c\u6837\u9762\u4e34\u8fc7\u4f30\u8ba1\u95ee\u9898, \u5e76\u5c06\u5176\u62df\u5408\u8bef\u5dee\u76f4\u63a5\u901a\u8fc7\u68af\u5ea6\u4f20\u5bfc\u4e3a\u7b56\u7565\u7f51\u7edc, \u591a\u91cd\u56e0\u7d20\u4f1a\u4f7f\u5f97 DDPG \u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u76f8\u5bf9\u8f83\u5dee, \u5c24\u5176\u5728\u52a8\u4f5c\u7ef4\u5ea6\u8f83\u9ad8\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73. \u6539\u8fdb\u63aa\u65bd : \u57fa\u672c\u539f\u7406: \u5f15\u5165\u6700\u5927\u71b5\u5b66\u4e60\u76ee\u6807\u548c\u968f\u673a\u7b56\u7565\u7684 SAC[27,28]; \u5f15\u5165\u503c\u5206\u5e03\u601d\u60f3\u7684 D4PG[29]; \u63a2\u7d22\u65b9\u5f0f: \u53c2\u6570\u566a\u58f0[18]\u548c\u5e76\u884c\u91c7\u6837 [5] \u6837\u672c\u7ba1\u7406: \u7528\u4e8e DQN \u7684\u90fd\u53ef\u7528\u4e8e DDPG \u68af\u5ea6\u8ba1\u7b97: \u5b6a\u751f Q \u7f51\u7edc, \u5ef6\u8fdf\u7b56\u7565\u66f4\u65b0, \u76ee\u6807\u7b56\u7565\u5e73\u6ed1\u7b49\u4e00\u7cfb\u5217\u6539\u5584\u76ee\u6807\u503c\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u8fc7\u4f30\u8ba1\u95ee\u9898\u548c\u65b9\u5dee\u6291\u5236\u63aa\u65bd\u7684 TD3[26]. A3C \u57fa\u672c\u539f\u7406 : Asynchronous Advantage Actor-Critic, A3C \u7b97\u6cd5\u91c7\u7528\u968f\u673a\u7b56\u7565\u5e76\u8f93\u51fa\u52a8\u4f5c\u7684\u6982\u7387\u5206\u5e03, \u56e0\u6b64\u4e0d\u80fd\u76f4\u63a5\u4ece\u503c\u7f51\u7edc\u83b7\u5f97\u66f4\u65b0\u68af\u5ea6, \u800c\u53ea\u80fd\u901a\u8fc7\u968f\u673a\u91c7\u6837\u4f30\u8ba1\u5176\u68af\u5ea6. A3C \u7ee7\u627f\u4e86\u7ecf\u5178\u7684 REINFORCE \u7b56\u7565\u68af\u5ea6[31] $$ \\nabla_\\phi \\log\\pi_{\\phi}(a_t|s_t)(R-b(s_t))\\ R=\\sum_{i=0}^{k-1}\\gamma^i r_{t+1} + \\gamma^k V_\\theta(s_{t+k}) $$ \\(R\\) \u662f\u4e00\u6bb5\u4ece\u72b6\u6001 \\(s_t\\) \u8d77\u59cb\u7684 Episode \u7684\u6298\u6263\u7d2f\u8ba1\u56de\u62a5. \\(b(s_t)\\) \u7528\u4e8e\u964d\u4f4e\u5956\u52b1\u65b9\u5dee[32] \u7684\u5173\u4e8e\u72b6\u6001 \\(s_t\\) \u7684\u57fa\u51c6\u51fd\u6570. A3C \u4ee5\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u7684\u503c\u51fd\u6570 \\(V_\\theta(s_t)\\) \u4e3a\u57fa\u51c6, \u5e76\u5c06 \\(A(s_t,a_t)=R-V_\\theta(s_t)\\) \u8be0\u91ca\u4e3a\u5728\u72b6\u6001 \\(s_t\\) \u4e0b\u9009\u62e9\u52a8\u4f5c \\(a_t\\) \u7684\u4f18\u52bf\u4f30\u8ba1, \\(J_\\pi\\) \u9f13\u52b1\u7b56\u7565\u7f51\u7edc\u589e\u52a0\u72b6\u6001 \\(s_t\\) \u7684\u4f18\u52bf\u4f30\u8ba1\u8f83\u9ad8\u7684\u52a8\u4f5c\u7684\u8f93\u51fa\u6982\u7387. \u7b56\u7565\u7f51\u7edc\u548c\u503c\u7f51\u7edc\u5171\u4eab\u4e86\u4e00\u90e8\u5206\u5e95\u5c42\u7ed3\u6784, \u6709\u52a9\u4e8e\u7b97\u6cd5\u66f4\u9ad8\u6548\u5730\u5b66\u4e60\u7279\u5f81\u63d0\u53d6. $$ \\begin{aligned} J_Q(\\theta)&=\\mathbb{E} {s,a\\sim\\rho^\\pi}\\bigg[\\frac{1}{2}\\big(R-V \\theta(s)\\big)^2\\bigg]\\ J_\\pi(\\phi)&=-\\mathbb{E} {s,a\\sim\\rho^\\pi}[\\log\\pi \\phi(a|s)A(s,a) +\\omega\\mathcal{H}(\\pi_\\phi(a|s))] \\end{aligned} $$ \u63a2\u7d22\u65b9\u5f0f : \u7531\u4e8e\u968f\u673a\u7b56\u7565\u81ea\u5e26\u63a2\u7d22\u5c5e\u6027, \u4e0d\u5fc5\u4f9d\u9760\u989d\u5916\u7684\u63a2\u7d22\u624b\u6bb5, \u53ea\u9700\u6bcf\u6b21\u6309\u7167\u8f93\u51fa\u52a8\u4f5c\u6982\u7387\u5206\u5e03\u8fdb\u884c\u968f\u673a\u91c7\u6837\u5373\u53ef. \u968f\u7740\u8bad\u7ec3\u7684\u4e0d\u65ad\u63a8\u8fdb, \u7b56\u7565\u5bf9\u52a8\u4f5c\u9009\u62e9\u8d8a\u6765\u8d8a\u81ea\u4fe1, \u5176\u8f93\u51fa\u7684\u968f\u673a\u6027\u76f8\u5e94\u5730\u4e0b\u964d, \u4ece\u800c\u5b9e\u73b0\u63a2\u7d22\u548c\u5229\u7528\u7684\u5e73\u8861. \u4e3a\u4e86\u907f\u514d\u7b56\u7565\u8fc7\u65e9\u9677\u5165\u5c40\u90e8\u6700\u4f18\u800c\u800c\u9000\u5316\u4e3a\u786e\u5b9a\u6027\u7b56\u7565, A3C \u5f15\u5165\u4e86\u7b56\u7565\u71b5\u635f\u5931\u9f13\u52b1\u7b56\u7565\u7f51\u7edc\u4fdd\u6301\u968f\u673a\u6027, \u53c2\u6570 \\(\\omega\\) \u7528\u4e8e\u8c03\u8282\u7b56\u7565\u71b5\u635f\u5931\u548c\u7b56\u7565\u635f\u5931\u4e4b\u95f4\u7684\u76f8\u5bf9\u6743\u91cd. A3C \u91c7\u7528\u4e86\u591a\u73af\u5883\u5e76\u884c\u91c7\u6837\u65b9\u6848, \u6bcf\u4e2a\u73af\u5883\u90fd\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u968f\u673a\u79cd\u5b50\u751a\u81f3\u662f\u4e0d\u540c\u7684\u63a2\u7d22\u65b9\u6848, \u4e0d\u540c\u7684 Actor \u5404\u81ea\u72ec\u7acb\u63a2\u7d22\u5e76\u5171\u4eab\u7ecf\u9a8c, \u6781\u5927\u63d0\u5347\u63a2\u7d22\u6548\u7387, \u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570\u566a\u58f0\u8fdb\u4e00\u6b65\u52a0\u5f3a. \u6837\u672c\u7ba1\u7406 : On-Policy \u7b97\u6cd5\u6bcf\u6b21\u66f4\u65b0\u6a21\u578b\u65f6\u90fd\u662f\u7528\u5f53\u524d\u6700\u65b0\u7684\u7b56\u7565\u91c7\u96c6\u4e00\u6279\u6837\u672c\u5e76\u5728\u66f4\u65b0\u5b8c\u6210\u540e\u5f7b\u5e95\u629b\u5f03\u8fd9\u4e9b\u6837\u672c, \u800c\u4e0d\u662f\u91cd\u590d\u5229\u7528 (On-Policy \u7b97\u6cd5\u76f4\u63a5\u4f7f\u7528 Replay Buffer \u4e2d\u65e7\u7b56\u7565\u91c7\u96c6\u7684\u5386\u53f2\u6837\u672c\u8ba1\u7b97\u68af\u5ea6\u4f1a\u5f15\u5165\u504f\u5dee). \u4e0a\u8ff0\u5e76\u884c\u91c7\u6837\u901a\u8fc7\u8db3\u591f\u9ad8\u7684\u91c7\u6837\u6548\u7387\u5728\u4e8b\u5b9e\u4e0a\u4fdd\u8bc1\u4e86\u503c\u7f51\u7edc \\(V_\\theta(s_t)\\) \u66f4\u65b0\u68af\u5ea6\u7684\u65e0\u504f\u6027, \u4ece\u800c\u8fbe\u5230\u7a33\u5b9a\u8bad\u7ec3\u7684\u76ee\u7684. \u68af\u5ea6\u8ba1\u7b97 : A3C \u4f7f\u7528\u6bcf\u6bb5 Episode \u7684\u6298\u6263\u7d2f\u8ba1\u56de\u62a5\u51cf\u53bb\u503c\u7f51\u7edc\u8f93\u51fa\u4f5c\u4e3a\u4f18\u52bf\u4f30\u8ba1\u5e76\u53c2\u4e0e\u5230 REINFORCE \u7b56\u7565\u68af\u5ea6\u8ba1\u7b97\u4e2d. \u57fa\u4e8e\u4f18\u52bf\u7684\u7b56\u7565\u68af\u5ea6\u53ef\u4ee5\u5728\u4e0d\u5f15\u5165\u504f\u5dee\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u68af\u5ea6\u65b9\u5dee\u7684\u7edd\u5bf9\u503c, \u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027. A3C \u5728\u6bcf\u4e2a\u91c7\u6837\u8fdb\u7a0b\u4e2d\u72ec\u7acb\u8ba1\u7b97\u68af\u5ea6, \u5e76\u5728\u4e3b\u7ebf\u7a0b\u805a\u5408\u540e\u7528\u6765\u66f4\u65b0\u503c\u7f51\u7edc\u548c\u7b56\u7565\u7f51\u7edc\u53c2\u6570. A3C \u9ed8\u8ba4\u91c7\u7528\u5f02\u6b65\u805a\u5408\u7684\u65b9\u5f0f, \u4f18\u70b9\u662f\u8fd0\u884c\u6548\u7387\u8f83\u9ad8[34], \u4f46\u91c7\u6837\u7b56\u7565\u4e0e\u5b9e\u9645\u88ab\u66f4\u65b0\u7b56\u7565\u95f4\u7684\u5dee\u5f02\u53ef\u80fd\u635f\u5bb3\u7b97\u6cd5\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u6027\u80fd, \u56e0\u6b64\u540e\u7eed\u7814\u7a76\u66f4\u591a\u6cbf\u7528\u4e86 A3C \u7684\u540c\u6b65\u68af\u5ea6\u805a\u5408\u7248\u672c A2C. \u7279\u70b9\u5206\u6790 : \u5e76\u884c\u91c7\u6837\u548c\u8499\u7279\u5361\u6d1b\u76ee\u6807\u503c\u4f30\u8ba1\u4e3a On-Polcy \u7b97\u6cd5\u5e26\u6765\u4e86\u4f4e\u6837\u672c\u6548\u7387\u548c\u9ad8\u68af\u5ea6\u56de\u4f20\u6548\u7387. A3C \u9664\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u66f4\u9ad8, \u5176\u91c7\u7528\u7684\u968f\u673a\u7b56\u7565\u5bf9\u5916\u754c\u6270\u52a8\u4e5f\u66f4\u9c81\u68d2, \u56e0\u6b64\u5177\u6709\u6bd4\u786e\u5b9a\u6027\u7b56\u7565\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u5bf9\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u800c\u8a00, \u5176\u7406\u8bba\u7eb3\u4ec0\u5747\u8861\u70b9\u6240\u5bf9\u5e94\u7684\u6700\u4f18\u7b56\u7565\u662f\u968f\u673a\u7684. A3C \u652f\u6301\u591a\u79cd\u6982\u7387\u5206\u5e03: \u7c7b\u522b\u5206\u5e03, \u4f2f\u52aa\u5229\u5206\u5e03, \u591a\u53d8\u91cf\u9ad8\u65af\u5206\u5e03, \u901a\u7528\u6027\u5f3a. \u6539\u8fdb\u63aa\u65bd : \u4f4e\u4e0b\u7684\u6837\u672c\u6548\u7387\u4f7f\u5176\u5728\u91c7\u6837\u6210\u672c\u9ad8\u7684\u4efb\u52a1\u4e2d\u51e0\u4e4e\u4e0d\u5177\u5907\u5b9e\u7528\u4ef7\u503c. \u7406\u8bba\u4e0a\u53ef\u4ee5\u591a\u6b21\u5229\u7528\u540c\u4e00\u6279\u5728\u7ebf\u91c7\u96c6\u7684\u6837\u672c, \u4f46\u8fd9\u6837\u4f1a\u5bfc\u81f4\u5355\u4e00\u68af\u5ea6\u65b9\u5411\u8fc7\u5927\u7684\u53c2\u6570\u66f4\u65b0\u800c\u7834\u574f\u8bad\u7ec3\u7a33\u5b9a\u6027. TRPO \u91cd\u6784\u4e86\u57fa\u4e8e\u4f18\u52bf\u7684\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u76ee\u6807 [35], \u5e76\u4ee5\u66f4\u65b0\u524d\u540e\u7b56\u7565\u8f93\u51fa\u5206\u5e03\u7684 KL \u6563\u5ea6\u6765\u7ea6\u675f\u7b56\u7565\u53c2\u6570\u7684\u53d8\u5316\u5e45\u5ea6, ACKTR[36] \u4f7f\u7528\u4e8c\u9636\u65b9\u6cd5\u8ba1\u7b97\u7684\u81ea\u7136\u68af\u5ea6\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387, \u5e76\u540c\u6837\u91c7\u7528 KL \u6563\u5ea6\u7ea6\u675f\u66f4\u65b0\u5e45\u5ea6. PPO[37]\u7ee7\u627f\u4e86 TRPO \u7684\u601d\u60f3, \u5c06 KL \u6563\u5ea6\u7ea6\u675f\u8fdb\u4e00\u6b65\u7b80\u5316\u4e3a\u5bf9\u7b56\u7565\u5206\u5e03\u6bd4\u4f8b\u504f\u79fb 1 \u7684\u7a0b\u5ea6\u7684\u7ea6\u675f. IMPALA [38] \u5728\u4fdd\u7559 A3C \u9ad8\u6548\u7387\u7684\u540c\u65f6\u5229\u7528\u91cd\u8981\u6027\u91c7\u6837\u514b\u670d\u4e86\u5f02\u6b65\u91c7\u6837\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd. \\[ \\begin{aligned} \\max_{\\phi'}\\mathbb{E}_{s,a\\sim\\rho^\\pi}\\bigg[\\frac{\\pi_{\\phi'}(a|s)}{\\pi_\\phi(a|s)}A^\\pi(s,a)\\bigg]\\\\ s.t. \\mathbb{E}_{s,a\\sim\\rho^\\pi} D_{KL}(\\pi_\\phi(\\cdot|s)\\|\\pi_{\\phi'}(\\cdot|s)) \\end{aligned} \\] 5.3 SOTA \u7b97\u6cd5 TD3 Twin Delayed Deep Deterministic Policy Gradient, TD3 \u662f\u5728 DDPG \u7b97\u6cd5\u57fa\u7840\u4e0a\u8fed\u4ee3\u4ea7\u751f\u7684\u6539\u826f\u7248\u672c, \u5176\u57fa\u672c\u539f\u7406, \u63a2\u7d22\u65b9\u5f0f, \u6837\u672c\u7ba1\u7406\u90fd\u6cbf\u7528 DPPG, TD3 \u7684\u4e3b\u8981\u6539\u8fdb\u5728\u4e8e\u964d\u4f4e\u8ba1\u7b97\u76ee\u6807\u503c\u5b58\u5728\u7684\u504f\u5dee\u548c\u65b9\u5dee\u8fdb\u884c\u7684, \u5747\u5c5e\u4e8e\u5bf9\u68af\u5ea6\u8ba1\u7b97\u7684\u4f18\u5316. \u57fa\u672c\u539f\u7406 :- \u63a2\u7d22\u65b9\u5f0f :- \u6837\u672c\u7ba1\u7406 :- \u68af\u5ea6\u8ba1\u7b97 : \u76ee\u6807\u503c\u8ba1\u7b97\u7684\u504f\u5dee\u4e3b\u8981\u6765\u81ea\u4e8e Boostrap \u65b9\u6cd5\u666e\u904d\u5b58\u5728\u7684 Overestimation \u95ee\u9898, Double DQN \u901a\u8fc7\u5c06\u72b6\u6001 \\(s'\\) \u4e0b\u6700\u4f18\u52a8\u4f5c\u7684Q\u503c\u8bc4\u4f30\u548c\u9009\u62e9\u76f8\u5206\u79bb, \u4ece\u800c\u5b9e\u73b0\u5bf9\u8fc7\u4f30\u8ba1\u95ee\u9898\u7684\u4e00\u81f4, \u4f46 Double DQN \u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u5230\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4, \u4e3a\u6b64 TD3 \u7ed9\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u662f\u8bbe\u7f6e\u4e24\u4e2a\u5b8c\u5168\u76f8\u540c\u7684 Q \u7f51\u7edc (\u5b6a\u751f Q \u7f51\u7edc Twin Q) \u4ee5\u53ca\u914d\u5957\u7684\u4e24\u4e2a\u76ee\u6807 Q \u7f51\u7edc, \u5e76\u5bf9\u5b83\u4eec\u5206\u522b\u505a\u72ec\u7acb\u66f4\u65b0, \u6bcf\u6b21\u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u603b\u662f\u9009\u62e9\u8f83\u5c0f\u7684\u90a3\u4e2a $$ J_Q(\\theta_t)=\\mathbb{E} {s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma\\min {i=1,2}Q_{\\theta_i^-}(s',\\pi_{\\phi^-}(a'|s')+\\varepsilon)-Q_{\\theta_i}(s,a)\\big)^2\\bigg] $$ \u4e3a\u4e86\u964d\u4f4e\u76ee\u6807\u503c\u8ba1\u7b97\u7684\u65b9\u5dee, \u5e76\u7f13\u89e3\u786e\u5b9a\u6027\u6d4b\u4e86\u5bf9\u503c\u51fd\u6570\u5c40\u90e8\u7a84\u5cf0\u7684\u8fc7\u62df\u5408\u503e\u5411, TD3 \u501f\u9274 SARSA[31] \u7684\u601d\u60f3, \u79c9\u6301\u8fd1\u4f3c\u52a8\u4f5c\u5e94\u6709\u8fd1\u4f3c\u503c\u4f30\u8ba1\u7684\u542f\u53d1\u5f0f\u539f\u5219, \u5728\u72b6\u6001 \\(s'\\) \u4e0b\u76ee\u6807\u7b56\u7565\u8f93\u51fa\u7684\u57fa\u7840\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u968f\u5373\u9ad8\u65af\u566a\u58f0 \\(\\varepsilon\\sim\\text{clip}(\\mathcal{N}(0,\\sigma^2),-c,c)\\) , \u622a\u65ad\u662f\u4e3a\u4e86\u4fdd\u6301\u566a\u58f0\u5316\u540e\u7684\u65b0\u52a8\u4f5c\u5728\u539f\u8f93\u51fa\u52a8\u4f5c\u9644\u8fd1. \u8fd9\u4e3a\u76ee\u6807\u7b56\u7565\u5e73\u6ed1, \u6ce8\u610f\u548c\u63a2\u7d22\u566a\u58f0\u7684\u533a\u5206. \u4e3a\u4e86\u964d\u4f4e\u76ee\u6807\u503c\u8ba1\u7b97\u7684\u65b9\u5dee\u5bf9\u7b56\u7565\u5b66\u4e60\u7684\u8d1f\u9762\u5f71\u54cd, TD3 \u964d\u4f4e\u4e86\u7b56\u7565\u7f51\u7edc\u53c2\u6570\u4e0e\u76ee\u6807\u7f51\u7edc\u53c2\u6570\u7684\u66f4\u65b0\u9891\u7387, \u4ee5\u4fdd\u8bc1 Q \u7f51\u7edc\u7ecf\u8fc7\u5145\u5206\u5b66\u4e60\u964d\u4f4e\u65b9\u5dee\u4e4b\u540e\u518d\u5f71\u54cd\u7b56\u7565\u7f51\u7edc\u548c\u76ee\u6807\u7f51\u7edc, \u7c7b\u4f3c DQN \u548c DDPG \u7684\u6df7\u5408\u65b9\u6848, \u6bcf\u66f4\u65b0 \\(d\\) \u6b21\u5b6a\u751f Q \u7f51\u7edc\u66f4\u65b0\u4e00\u6b21\u7b56\u7565\u7f51\u7edc, \u68af\u5ea6\u9ed8\u8ba4\u6765\u6e90\u4e8e\u5b6a\u751f Q \u7f51\u7edc\u4e2d\u7684 \\(Q_{\\theta_1}\\) \u5e76\u91c7\u7528\u79fb\u52a8\u5e73\u5747\u66f4\u65b0\u76ee\u6807\u7f51\u7edc. \u7279\u70b9\u5206\u6790 : TD3 \u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u83b7\u5f97\u4e86\u663e\u8457\u6539\u5584, \u65e0\u8bba\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u8fd8\u662f\u6700\u7ec8\u6027\u80fd\u4e0a\u90fd\u5f88\u6709\u7ade\u4e89\u529b. Off-Policy \u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684\u6837\u672c\u6548\u7387. \u6b64\u5916\u63a2\u7d22\u65b9\u5f0f\u548c\u6837\u672c\u7ba1\u7406\u7684\u6539\u8fdb\u540c\u6837\u9002\u7528\u4e8e TD3. \u5728\u7f3a\u70b9\u65b9\u9762, \u4ec5\u4ec5\u9002\u7528\u4e8e\u8fde\u7eed\u63a7\u5236\u4efb\u52a1, \u4e0d\u652f\u6301\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4. \u6539\u8fdb\u63aa\u65bd : - SAC SAC \u540c\u6837\u4e3b\u8981\u9488\u5bf9 DDPG \u5728\u9ad8\u7ef4\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u7684, \u4f46\u4e0e TD3 \u96c6\u4e2d\u5173\u6ce8\u68af\u5ea6\u8ba1\u7b97\u7ec4\u4ef6\u7684\u6539\u8fdb\u4e0d\u540c, SAC \u5728\u5e38\u89c4\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u76ee\u6807\u7684\u57fa\u7840\u4e0a\u5f15\u5165\u4e86\u6700\u5927\u71b5\u76ee\u6807, \u5e76\u4e3a\u4e4b\u505a\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u9002\u914d\u5de5\u4f5c. \u57fa\u672c\u539f\u7406 : \u4e3a\u4e86\u5b9e\u73b0\u6700\u5927\u71b5\u76ee\u6807, \\(\\pi_\\phi(a|s)\\) \u7531\u786e\u5b9a\u8f6c\u968f\u673a, \u8f93\u51fa\u52a8\u4f5c\u7684\u6982\u7387\u5206\u5e03. \u76f8\u5e94\u5730\u5728 Q \u7f51\u7edc\u76ee\u6807\u503c\u8ba1\u7b97\u4e2d\u589e\u52a0\u4e86\u7b56\u7565\u71b5\u6210\u5206. \u9488\u5bf9\u968f\u673a\u7b56\u7565\u4e3a\u4e86\u76f4\u63a5\u4ece Q \u7f51\u7edc\u83b7\u5f97\u66f4\u65b0\u68af\u5ea6, \u540c\u65f6\u907f\u514d\u7c7b\u4f3c\u4e8e REINFORCE \u4e2d\u7684\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u964d\u4f4e\u6837\u672c\u6548\u7387, SAC \u4f7f\u7528\u4e86 VAE \u7684\u91cd\u53c2\u6570\u5316\u6280\u5de7, \u5e76\u5c06\u7b56\u7565\u8f93\u51fa\u91cd\u65b0\u8868\u793a\u4e3a \\(f_\\phi(s;\\varepsilon)\\) , \u800c\u7b56\u7565\u5b66\u4e60\u76ee\u6807\u4e5f\u4ece\u6700\u5927\u5316 Q \u7f51\u7edc\u8f93\u51fa\u6539\u4e3a\u6700\u5c0f\u5316\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684 KL \u6563\u5ea6. SAC \u5728\u7ecf\u8fc7\u5c11\u91cf\u9002\u914d\u540e\u5373\u53ef\u652f\u6301\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4, \u5f52\u529f\u4e8e\u7b97\u6cd5\u6240\u91c7\u7528\u7684\u968f\u673a\u7b56\u7565\u53ca\u5176\u5206\u5e03\u62df\u5408\u5b66\u4e60\u76ee\u6807 \\[ \\begin{aligned} J_Q(\\theta_i) &= \\mathbb{E}_{s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma(\\min_{i=1,2}Q_{\\theta_i^-}(s',a')-\\alpha\\log\\pi_\\phi(a'|s'))-Q_{\\theta_i}(s,a)\\big)^2\\bigg]\\\\ J_\\pi(\\phi) &= \\mathbb{E}_{s\\sim\\mathcal{D},\\varepsilon\\sim\\mathcal{N}(0,I)}[\\alpha\\log\\pi_\\phi(f_\\phi(s;\\varepsilon)|s)-\\min_{i=1,2}Q_{\\theta_i}(s,f_\\phi(s;\\varepsilon))] \\end{aligned} \\] \u63a2\u7d22\u65b9\u5f0f : SAC \u4e3a\u63a7\u5236\u6700\u5927\u71b5\u76ee\u6807\u5206\u91cf\u4e0e Reward \u76f8\u5bf9\u5c3a\u5ea6\u7684\u8d85\u53c2\u6570 \\(\\alpha\\) \u8bbe\u8ba1\u4e86\u81ea\u52a8\u8c03\u8282\u673a\u5236, \u65b9\u6cd5\u662f\u5c06\u539f\u76ee\u6807\u91cd\u6784\u4e3a\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u6c42\u89e3\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u76ee\u6807, \u5e76\u5229\u7528\u5bf9\u5076\u95ee\u9898\u63a8\u5bfc\u51fa \\(\\alpha\\) \u7684\u66f4\u65b0\u516c\u5f0f, \u6ce8\u610f\u4e0a\u8ff0\u7ea6\u675f\u6761\u4ef6\u9488\u5bf9\u7684\u662f\u7b56\u7565\u71b5\u7684\u6570\u5b66\u671f\u671b, \u800c\u4e0d\u662f\u673a\u68b0\u5730\u8981\u6c42\u7b56\u7565\u5728\u4efb\u610f\u65f6\u523b\u90fd\u4fdd\u6301\u9ad8\u968f\u673a\u6027\u548c\u9ad8\u63a2\u7d22\u5f3a\u5ea6. \u591a\u6570\u72b6\u6001\u4e0b\u7684\u4f18\u52a3\u52a8\u4f5c\u968f\u7740\u8bad\u7ec3\u7684\u63a8\u8fdb\u53d8\u5f97\u6e05\u6670\u65e0\u9700\u7ee7\u7eed\u63a2\u7d22, \u4e3a\u4e86\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6, \u63a2\u7d22\u529b\u5ea6\u4f1a\u9010\u6e10\u96c6\u4e2d\u5230\u89e3\u7a7a\u95f4\u4e2d\u4e0d\u786e\u5b9a\u6027\u4ecd\u8f83\u5927\u7684\u90e8\u5206, \u4f7f\u7b56\u7565\u5448\u73b0\u591a\u6a21\u6001\u7279\u5f81. \u6837\u672c\u7ba1\u7406 : Off-Policy \u7b97\u6cd5 \u68af\u5ea6\u8ba1\u7b97 : SAC \u501f\u9274\u4e86 TD3 \u7684\u5b6a\u751f Q \u7f51\u7edc, \u4f46\u6ca1\u6709\u8bbe\u7f6e\u72ec\u7acb\u5730\u76ee\u6807\u7b56\u7565\u7f51\u7edc\u800c\u662f\u76f4\u63a5\u4f7f\u7528\u5f53\u524d\u6700\u65b0\u7b56\u7565 \\(\\pi_\\phi\\) \u8fdb\u884c\u52a8\u4f5c\u91c7\u6837. \u6b64\u5916 SAC \u5728\u91cd\u53c2\u6570\u5316\u540e\u5229\u7528 Tanh \u6fc0\u6d3b\u51fd\u6570\u5c06\u6bcf\u4e2a\u52a8\u4f5c\u538b\u7f29\u5230 [-1,1], \u4f7f\u5f97\u7b56\u7565\u8f93\u51fa\u7531\u9ad8\u65af\u5206\u5e03\u53d8\u4e3a\u6324\u538b\u9ad8\u65af\u5206\u5e03, \u540e\u7eed\u68af\u5ea6\u8ba1\u7b97\u505a\u4e86\u76f8\u5e94\u5730\u9002\u914d.[27] \u7279\u70b9\u5206\u6790 : \u4f7f\u7528\u968f\u673a\u7b56\u7565\u66ff\u6362\u786e\u5b9a\u6027\u7b56\u7565, \u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027, \u5e76\u901a\u8fc7\u5f15\u5165\u6700\u5927\u71b5\u5b66\u4e60\u76ee\u6807\u6781\u5927\u5730\u6539\u5584\u4e86\u63a2\u7d22\u6548\u7387, \u8fd9\u6bd4 A3C \u4e2d\u5355\u7eaf\u5730\u5c06\u7b56\u7565\u71b5\u635f\u5931\u4f5c\u4e3a\u7ef4\u6301\u7b56\u7565\u968f\u673a\u6027\u5730\u6b63\u5219\u5316\u624b\u6bb5\u66f4\u6709\u6548. \u5b9e\u8df5\u4e2d SAC \u7edd\u5bf9\u6536\u655b\u901f\u5ea6\u901a\u5e38\u5feb\u4e8e\u5176\u4ed6 DRL \u7b97\u6cd5, \u652f\u6301\u79bb\u6563\u548c\u8fde\u7eed\u63a7\u5236\u4efb\u52a1, \u6838\u5fc3\u8d85\u53c2\u6570 \\(\\alpha\\) \u7684\u81ea\u52a8\u8c03\u8282\u673a\u5236\u4f7f\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8c03\u53c2\u5de5\u4f5c\u53d8\u5f97\u7b80\u5355, \u4f7f\u5f97 SAC \u5b9e\u7528\u4ef7\u503c\u8f83\u9ad8. \u6539\u8fdb\u63aa\u65bd : DDPG \u63a2\u7d22\u65b9\u5f0f\u548c\u6837\u672c\u7ba1\u7406\u6539\u8fdb\u5747\u9002\u7528 (\u79bb\u6563SAC\u53ef\u4ee5\u5c1d\u8bd5 Dueling Network \u548c Multi-Step Boostrap) PPO PPO \u5728 A2C \u57fa\u7840\u4e0a\u5bf9\u6837\u672c\u7ba1\u7406\u548c\u68af\u5ea6\u8ba1\u7b97\u505a\u51fa\u4e86\u6539\u8fdb. \u63d0\u9ad8\u5728\u7ebf\u91c7\u96c6\u6837\u672c\u7684\u4f7f\u7528\u6548\u7387, PPO \u5c06\u540c\u4e00\u6279\u6837\u672c\u5206\u6210 MINI-BATCH \u5e76\u91cd\u590d\u5229\u7528\u591a\u6b21, \u540c\u65f6\u5728\u8ba1\u7b97\u7b56\u7565\u68af\u5ea6\u65f6, \u9650\u5236\u53c2\u6570\u66f4\u65b0\u5e45\u5ea6, \u4ece\u800c\u907f\u514d\u4ea7\u751f\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027. \u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9, PPO \u7ee7\u627f\u4e86 TRPO \u7f6e\u4fe1\u533a\u57df\u7684\u601d\u60f3, \u540c\u65f6\u907f\u514d\u4e86\u5171\u8f6d\u68af\u5ea6\u8ba1\u7b97\u7684\u590d\u6742\u6027. PPO \u5c06 KL \u6563\u5ea6\u7ea6\u675f\u66ff\u6362\u4e3a\u5bf9 \\(\\pi_{\\phi'}(a|s)/\\pi_\\phi(a|s)\\) \u504f\u79bb 1 \u7684\u7a0b\u5ea6\u7ea6\u675f. \u5229\u7528 \\(\\varepsilon\\in(0,1)\\) \u5b9a\u4e49\u4e86\u4ee5 1 \u4e3a\u4e2d\u5fc3\u7684\u7a84\u533a\u95f4, \u5728\u4e00\u4e2amini-batch \u5185\u4f7f\u65b0\u65e7\u7b56\u7565\u8f93\u51fa\u4e4b\u6bd4\u8d85\u51fa\u8be5\u533a\u95f4\u8303\u56f4\u7684\u90e8\u5206\u6570\u636e, \u7531\u4e8e\u622a\u65ad\u64cd\u4f5c\u800c\u5b9e\u9645\u4e0d\u4ea7\u751f\u68af\u5ea6, \u53ea\u6709\u5904\u4e8e\u7f6e\u4fe1\u8303\u56f4\u5185\u7684\u6570\u636e\u624d\u80fd\u5c06\u68af\u5ea6\u56de\u4f20\u81f3\u7b56\u7565\u7f51\u7edc, \u53ef\u89c1 PPO \u4ee5\u5728\u5fae\u89c2\u5c42\u9762(\u4e00\u4e2amini-batch) \u964d\u4f4e\u6837\u672c\u5229\u7528\u7387\u4e3a\u4ee3\u4ef7, \u5b9e\u73b0\u4e86\u6574\u4f53 (batch) \u6837\u672c\u5229\u7528\u7387\u7684\u63d0\u5347. \\[ J_\\pi(\\phi) = \\mathbb{E}_{s,a\\sim\\rho^\\pi}[\\min(\\frac{\\pi_{\\phi'}(a|s)}{\\pi_{\\phi}(a|s)}A^\\pi(s,a),\\text{clip}(\\frac{\\pi_{\\phi'}(a|s)}{\\pi_{\\phi}(a|s)},1-\\varepsilon,1+\\varepsilon)A^\\pi(s,a))] \\] PPO \u5728\u8ba1\u7b97\u4e00\u6bb5\u56fa\u5b9a\u957f\u5ea6 Episode \u5185\u7684\u52a8\u4f5c\u4f18\u52bf\u65f6, \u91c7\u7528\u4e86\u7c7b\u4f3c\u4e8e \\(TD(\\lambda)\\) \u7684\u901a\u7528\u4f18\u52bf\u4f30\u8ba1 (Generalized Advantage Estimation, GAE) \u6765\u964d\u4f4e\u68af\u5ea6\u7684\u65b9\u5dee. \u57fa\u672c\u539f\u7406 : \u63a2\u7d22\u65b9\u5f0f : \u6837\u672c\u7ba1\u7406 : \u68af\u5ea6\u8ba1\u7b97 : \u7279\u70b9\u5206\u6790 : On-Policy \u7b97\u6cd5\u548c\u968f\u673a\u7b56\u7565\u7a33\u5b9a\u6027\u9ad8\u7684\u4f18\u70b9, \u540c\u65f6\u4ee5\u8f83\u5c0f\u7684\u8fd0\u7b97\u4ee3\u4ef7\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6539\u5584\u4e86 On-Policy \u7b97\u6cd5\u5730\u4e0b\u7684\u6837\u672c\u5229\u7528\u7387, \u7c7b\u4f3c A2C \u591a\u73af\u5883\u5e76\u884c\u91c7\u6837\u4f7f\u5f97 PPO \u5177\u6709\u8f83\u9ad8\u7684\u63a2\u7d22\u6548\u7387, \u5c24\u5176\u9002\u5408\u5728\u5177\u6709\u4f18\u8d28\u73af\u5883\u6a21\u62df\u5668\u7684\u4efb\u52a1\u4e2d\u4f7f\u7528. \u6539\u8fdb\u63aa\u65bd : \u63a2\u7d22\u65b9\u5f0f 12 18 \u548c\u68af\u5ea6\u8ba1\u7b97 40 44 \u65b9\u9762\u7684\u6539\u8fdb\u53ef\u4ee5\u7528\u4e8e\u63d0\u5347 PPO \u7684\u6027\u80fd.","title":"\u7b2c\u4e94\u7ae0 \u7b97\u6cd5\u9009\u62e9"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#_1","text":"","title":"\u7b2c\u4e94\u7ae0 \u7b97\u6cd5\u9009\u62e9"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#51","text":"\u5c3d\u7ba1\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5df2\u7ecf\u53d6\u5f97\u957f\u8db3\u8fdb\u6b65, \u4f46\u5c1a\u672a\u5728\u7406\u8bba\u5c42\u9762\u53d6\u5f97\u8d28\u7684\u7a81\u7834, \u800c\u53ea\u662f\u5728\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\u57fa\u7840\u4e0a\u5f15\u5165\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc, \u5e76\u505a\u4e86\u4e00\u7cfb\u5217\u9002\u914d\u548c\u589e\u91cf\u5f0f\u6539\u8fdb\u5de5\u4f5c. \u603b\u4f53\u4e0a, DRL \u7b97\u6cd5\u6cbf\u7740 Model-Based \u548c Model-Free \u4e24\u5927\u5206\u652f\u53d1\u5c55.","title":"5.1 \u62ff\u6765\u4e3b\u4e49 &amp; \u6539\u826f\u4e3b\u4e49"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#model-based","text":"Model-Based \u7b97\u6cd5\u5229\u7528\u5df2\u77e5\u73af\u5883\u6a21\u578b/\u5bf9\u672a\u77e5\u73af\u5883\u6a21\u578b\u8fdb\u884c\u663e\u5f0f\u5efa\u6a21, \u5e76\u4e0e \u524d\u5411\u641c\u7d22 (Look Ahead Search) \u548c \u8f68\u8ff9\u4f18\u5316 (Trajectory Optimization) \u7b49\u89c4\u5212\u7b97\u6cd5\u7ed3\u5408\u8fbe\u5230\u63d0\u5347\u6570\u636e\u6548\u7387\u7684\u76ee\u7684. \u4f46\u672a\u5728\u5b9e\u8df5\u4e2d\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528, \u56e0\u4e3a\u73b0\u5b9e\u4efb\u52a1\u7684\u73af\u5883\u6a21\u578b\u901a\u5e38\u5341\u5206\u590d\u6742, \u5bfc\u81f4\u6a21\u578b\u5b66\u4e60\u7684\u96be\u5ea6\u5f88\u9ad8 [1] [2], \u5e76\u4e14\u5efa\u6a21\u8bef\u5dee\u4e5f\u4f1a\u5bf9\u7b56\u7565\u9020\u6210\u8d1f\u9762\u5f71\u54cd.","title":"Model-Based"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#model-free","text":"Model-Free \u7b97\u6cd5\u53ef\u4ee5\u89e3\u6784\u4e3a: \u57fa\u672c\u539f\u7406-\u63a2\u7d22\u65b9\u5f0f-\u6837\u672c\u7ba1\u7406-\u68af\u5ea6\u8ba1\u7b97 \u7684\u56db\u5143\u6838\u5fc3\u7ec4\u4ef6\u3002 \u6309\u7167 \u57fa\u672c\u539f\u7406 \u6709\u4e24\u79cd\u5212\u5206\u4f53\u7cfb Value-Based & Policy-Based \u4ee5\u53ca On-Policy & Off-Policy\u3002 Value-Based: \u7b97\u6cd5\u76f4\u63a5\u5b66\u4e60\u72b6\u6001-\u52a8\u4f5c\u7ec4\u5408\u7684\u503c\u4f30\u8ba1; Policy-Based: \u7b97\u6cd5\u5177\u6709\u72ec\u7acb\u7b56\u7565; Actor-Critic: \u540c\u65f6\u5177\u5907\u72ec\u7acb\u7b56\u7565\u548c\u503c\u4f30\u8ba1\u51fd\u6570\u7684\u7b97\u6cd5; On-Policy: \u91c7\u6837\u7b56\u7565\u548c\u5f85\u4f18\u5316\u7b56\u7565\u76f8\u540c\u6216\u5dee\u5f02\u5f88\u5c0f; Off-Policy: \u91c7\u6837\u7b56\u7565\u548c\u5f85\u4f18\u5316\u7b56\u7565\u4e0d\u540c. DQN[3], DDPG[4], A3C[5] \u4f5c\u4e3a\u8fd9\u4e24\u79cd\u5f7c\u6b64\u4ea4\u7ec7\u7684\u5212\u5206\u4f53\u7cfb\u4e0b\u7684\u7ecf\u5178\u7b97\u6cd5\u6846\u67b6, \u6784\u6210\u4e86 DRL \u7814\u7a76\u4e2d\u7684\u91cd\u8981\u8282\u70b9, \u540e\u7eed\u63d0\u51fa\u7684\u5927\u90e8\u5206\u7b97\u6cd5\u57fa\u672c\u90fd\u7acb\u8db3\u4e8e\u8fd9\u4e09\u79cd\u6846\u67b6, \u9488\u5bf9\u5176\u6838\u5fc3\u7ec4\u4ef6\u6240\u8fdb\u884c\u7684\u8fed\u4ee3\u4f18\u5316\u6216\u8005\u62c6\u5206\u91cd\u7ec4. \u56db\u5143\u6838\u5fc3\u7ec4\u4ef6: \u57fa\u672c\u539f\u7406: \u8fdb\u5c55\u7f13\u6162, \u4f46\u5374\u662f DRL \u7b97\u6cd5\u5c06\u6765\u5927\u89c4\u6a21\u63a8\u5e7f\u7684\u5173\u952e\u6240\u5728. \u63a2\u7d22\u65b9\u5f0f: \u76f8\u5e94\u6539\u8fdb\u4f7f\u7b97\u6cd5\u66f4\u5145\u5206\u63a2\u7d22\u73af\u5883, \u66f4\u597d\u5730\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528, \u4ece\u800c\u6709\u673a\u4f1a\u5b66\u4e60\u5230\u66f4\u597d\u7684\u7b56\u7565. \u6837\u672c\u7ba1\u7406: \u76f8\u5e94\u6539\u8fdb\u6709\u52a9\u4e8e\u63d0\u5347\u7b97\u6cd5\u7684\u6837\u672c\u6548\u7387, \u52a0\u5feb\u6536\u655b\u901f\u5ea6, \u63d0\u9ad8\u7b97\u6cd5\u5b9e\u7528\u6027. \u68af\u5ea6\u8ba1\u7b97: \u81f4\u529b\u4e8e\u4f7f\u6bcf\u4e00\u6b21\u68af\u5ea6\u66f4\u65b0\u90fd\u66f4\u7a33\u5b9a, \u65e0\u504f\u548c\u9ad8\u6548. \u603b\u4f53\u800c\u8a00, \u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6b63\u671d\u7740\u901a\u7528\u5316\u548c\u9ad8\u6548\u5316\u7684\u65b9\u5411\u53d1\u5c55.","title":"Model-Free"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#_2","text":"\u7c97\u7565\u6765\u770b, \u6839\u636e\u95ee\u9898\u5b9a\u4e49, \u52a8\u4f5c\u7a7a\u95f4\u7c7b\u578b, \u91c7\u6837\u6210\u672c, \u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\u7b49\u56e0\u7d20\u7684\u4e0d\u540c, \u786e\u5b9e\u5b58\u5728\u4e00\u4e9b\u5173\u4e8e\u4e0d\u540c\u7c7b\u578b DRL \u7b97\u6cd5\u9002\u7528\u6027\u65b9\u9762\u7684\u7ed3\u8bba. DQN \u53ca\u5176\u53d8\u4f53\u4e00\u822c\u53ea\u9002\u7528\u4e8e\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4; DDPG \u53ca\u5176\u53d8\u4f53\u53ea\u9002\u5408\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4; A3C \u53ca SAC \u7b49\u5219\u652f\u6301\u79bb\u6563\u548c\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4. \u968f\u673a\u6027\u7b56\u7565\u901a\u5e38\u6bd4\u786e\u5b9a\u6027\u7b56\u7565\u6709\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027. \u5bf9\u4e8e\u673a\u5668\u4eba\u7b49\u6d89\u53ca\u786c\u4ef6\u7684\u5e94\u7528\u6216\u91c7\u6837\u6210\u672c\u8f83\u9ad8\u7684\u4efb\u52a1, \u80fd\u591f\u91cd\u590d\u5229\u7528\u5386\u53f2\u6570\u636e\u7684 Off-Policy \u7b97\u6cd5\u6bd4 On-Policy \u7b97\u6cd5\u66f4\u6709\u4f18\u52bf[7]\u3002 \u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1, \u591a\u4e2a\u4ea4\u4e92\u7684\u667a\u80fd\u4f53\u4e92\u76f8\u6784\u6210\u5bf9\u65b9\u73af\u5883\u7684\u4e00\u90e8\u5206, \u5e76\u968f\u7740\u5404\u81ea\u7b56\u7565\u7684\u8fed\u4ee3\u5bfc\u81f4\u8fd9\u4e9b\u73af\u5883\u6a21\u578b\u53d1\u751f\u53d8\u5316, \u4ece\u800c\u5bfc\u81f4\u57fa\u4e8e\u8fd9\u4e9b\u6a21\u578b\u6784\u5efa\u7684\u77e5\u8bc6/\u6280\u80fd\u5931\u6548, \u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a \u73af\u5883\u4e0d\u7a33\u5b9a\u6027 (Environment Nonstationarity) . \u56e0\u6b64\u9664\u975e \u7ecf\u9a8c\u56de\u653e\u7f13\u5b58 (Replay Buffer) \u4e2d\u7684\u6570\u636e\u66f4\u65b0\u5f97\u8db3\u591f\u5feb, \u5426\u5219 Off-Policy \u7b97\u6cd5\u53cd\u800c\u53ef\u80fd\u5f15\u5165\u504f\u5dee[8]. \u7531\u4e8e\u5229\u7528\u8d1d\u5c14\u66fc\u516c\u5f0f Bootstrap \u7279\u6027\u7684\u503c\u8fed\u4ee3\u65b9\u6cd5\u662f\u6709\u504f\u7684, On-Policy \u7b97\u6cd5\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u8981\u597d\u4e8e Off-Policy \u7b97\u6cd5. \u7136\u800c\u4e3a\u4e86\u5c3d\u53ef\u80fd\u83b7\u53d6\u5173\u4e8e\u503c\u51fd\u6570\u7684\u65e0\u504f\u4f30\u8ba1, On-Policy \u7b97\u6cd5\u5f80\u5f80\u9700\u8981\u5229\u7528\u591a\u4e2a\u73af\u5883\u5e76\u884c\u91c7\u96c6\u8db3\u591f\u591a\u7684\u6837\u672c, \u8fd9\u5bf9\u786c\u4ef6\u6709\u6240\u8981\u6c42, \u800c Off-Policy \u5219\u4e0d\u5fc5, \u867d\u7136\u4e5f\u80fd\u591f\u4ece\u5e76\u884c\u91c7\u6837\u4e2d\u53d7\u76ca[5]\u3002 \u4e0b\u9762\u603b\u7ed3\u4e86 Model-Free DRL \u7b97\u6cd5\u9002\u7528\u6027\u7684\u4e00\u822c\u7ed3\u8bba: \u52a8\u4f5c\u7a7a\u95f4\u517c\u5bb9\u6027: Value-Based: \u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4; Policy-Based + \u786e\u5b9a\u6027\u7b56\u7565: \u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4; Policy-Based + \u968f\u673a\u6027\u7b56\u7565: \u79bb\u6563&\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4. \u91c7\u6837\u6210\u672c\u5bb9\u5fcd\u5ea6: Off-Policy > On-Policy. \u8fd0\u7b97\u8d44\u6e90\u9700\u6c42: On-Policy \u9700\u8981\u66f4\u591a\u7684 CPU \u6838\u5fc3. \u8bad\u7ec3\u7a33\u5b9a\u6027: On-Policy > Off-Policy; \u968f\u673a\u6027\u7b56\u7565 > \u786e\u5b9a\u6027\u7b56\u7565. \u5176\u4ed6: Off-Policy \u5bb9\u6613\u53d7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u73af\u5883\u4e0d\u7a33\u5b9a\u6027\u7684\u5f71\u54cd. \u5b8c\u6210\u7c97\u7565\u7684\u7b5b\u9009\u540e, \u5bf9\u4e8e\u7b26\u5408\u6761\u4ef6\u7684\u4e0d\u540c DRL \u7b97\u6cd5\u4e4b\u95f4\u7684\u53d6\u820d\u5c31\u76f8\u5bf9\u5fae\u5999. \u4e00\u822c\u800c\u8a00\u5b66\u672f\u754c\u63d0\u51fa\u7684 SOTA \u7b97\u6cd5, \u6027\u80fd\u901a\u5e38\u4f18\u4e8e\u65e7\u7b97\u6cd5, \u4f46\u5728\u5177\u4f53\u4efb\u52a1\u4e0a\u5e76\u4e0d\u7edd\u5bf9, \u56e0\u6b64\u9700\u8981\u6839\u636e\u5b9e\u9645\u8868\u73b0\u4ece\u82e5\u5e72\u5907\u9009\u7b97\u6cd5\u4e2d\u627e\u51fa\u6027\u80fd\u6700\u597d\u7684\u90a3\u4e2a. \u6b64\u5916, \u53ea\u6709\u90e8\u5206\u7ecf\u8fc7\u7cbe\u7ec6\u5b9a\u4e49\u7684\u5b9e\u9645\u4efb\u52a1\u53ef\u4ee5\u901a\u8fc7\u76f4\u63a5\u5e94\u7528\u6807\u51c6\u7b97\u6cd5\u5f97\u5230\u8f83\u597d\u89e3\u51b3, \u800c\u8bb8\u591a\u4efb\u52a1\u7531\u4e8e\u81ea\u8eab\u7684\u590d\u6742\u6027\u548c\u7279\u6b8a\u6027, \u9700\u8981\u9488\u5bf9\u6807\u51c6\u7b97\u6cd5\u7684\u6838\u5fc3\u7ec4\u4ef6\u8fdb\u884c\u4e0d\u540c\u7a0b\u5ea6\u7684\u4f18\u5316\u540e\u624d\u80fd\u5f97\u5230\u8f83\u4e3a\u7406\u60f3\u7684\u7ed3\u679c. [9] [10] [11] \u6b64\u5904\u7684\u4f18\u5316\u66f4\u591a\u65f6\u5019\u662f\u57fa\u4e8e\u5bf9\u5f53\u524d\u6027\u80fd\u74f6\u9888\u6210\u56e0\u7684\u6df1\u5165\u5206\u6790, \u5728\u5b66\u672f\u754c\u73b0\u6709\u7684\u7ec4\u4ef6\u6539\u826f\u63aa\u65bd\u548c\u601d\u60f3\u4e2d\u5bf9\u75c7\u9009\u62e9. DQN \u63a2\u7d22\u6539\u5584: \u52a0\u5165\u566a\u58f0\u7f51\u7edc Noisy Net \u4ee3\u66ff\u9ed8\u8ba4 \\(\\varepsilon\\) -greedy; DQN \u6837\u672c\u6548\u7387\u6539\u5584: \u5c06\u5e38\u89c4\u7ecf\u9a8c\u56de\u8bbf\u6539\u4e3a\u4f18\u5148\u7ea7\u7ecf\u9a8c\u56de\u653e PER [13]; DQN \u8bad\u7ec3\u7a33\u5b9a\u6027\u6539\u5584: \u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u7531\u5355\u6b65 Boostrap \u6539\u4e3a\u591a\u6b65; \u5b66\u672f\u7814\u7a76\u4e3a\u4e86\u7a81\u51fa\u7b97\u6cd5\u7684\u4f18\u52bf, \u5176\u4ed6\u8981\u7d20\u53ea\u8981\u4fdd\u6301\u4e00\u81f4\u751a\u81f3\u88ab\u523b\u610f\u5f31\u5316; \u843d\u5730\u5e94\u7528\u4e3a\u4e86\u5145\u5206\u53d1\u6325\u7b97\u6cd5\u7684\u6027\u80fd, \u5176\u4ed6\u8981\u7d20\u5e94\u8be5\u4e3b\u52a8\u8fce\u5408\u7b97\u6cd5\u9700\u6c42\u4ee5\u964d\u4f4e\u5176\u5b66\u4e60\u96be\u5ea6. \u5b66\u672f\u7814\u7a76\u7684\u76ee\u6807\u662f\u5728\u666e\u904d\u610f\u4e49\u4e0a\u89e3\u51b3\u6216\u6539\u5584 DRL \u7b97\u6cd5\u5b58\u5728\u7684\u56fa\u6709\u7f3a\u9677: \u5982\u4f4e\u6837\u672c\u6548\u7387, \u5bf9\u8d85\u53c2\u6570\u654f\u611f\u7b49\u95ee\u9898, \u7b97\u6cd5\u81ea\u8eab\u7279\u8d28\u7684\u4f18\u52a3\u662f\u6838\u5fc3. \u8bb8\u591a\u5f00\u653e\u5e73\u53f0\u4e3a\u5404\u79cd\u4efb\u52a1\u9884\u8bbe\u4e86\u56fa\u5b9a\u7684\u72b6\u6001\u7a7a\u95f4, \u52a8\u4f5c\u7a7a\u95f4\u548c\u56de\u62a5\u51fd\u6570. \u7814\u7a76\u8005\u5f88\u5c11\u9700\u8981\u4e3b\u52a8\u4fee\u6539\u8fd9\u4e9b\u8981\u7d20. \u843d\u5730\u5e94\u7528\u7684\u76ee\u6807\u662f\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u83b7\u5f97\u6700\u4f73\u7b56\u7565\u6027\u80fd, \u800c\u7b97\u6cd5\u4ec5\u4ec5\u662f\u5b9e\u73b0\u8be5\u76ee\u6807\u7684\u4f17\u591a\u73af\u8282\u4e4b\u4e00. \u843d\u5730\u5e94\u7528\u4e2d\u7684\u7b56\u7565\u6027\u80fd\u4f18\u5316\u662f\u4e00\u9879\u7cfb\u7edf\u5de5\u7a0b, \u9700\u8981\u5145\u5206\u8c03\u52a8\u5404\u79cd\u6709\u5229\u56e0\u7d20.","title":"\u4e00\u7b5b\u3001\u4e8c\u6bd4\u3001\u4e09\u6539\u826f"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#52","text":"","title":"5.2 \u7ecf\u5178\u7b97\u6cd5"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#dqn","text":"\u57fa\u672c\u539f\u7406 : \u6df1\u5ea6 Q \u7f51\u7edc (Deep Q-Networks, DQNs) \u7ee7\u627f\u4e86 Q-Learning \u7684\u601d\u60f3, \u5229\u7528\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684 Boostrap \u7279\u6027, \u8ba1\u7b97\u76ee\u6807\u503c\u5e76\u4e0d\u65ad\u8fed\u4ee3\u4f18\u5316\u4e00\u4e2a\u72b6\u6001-\u52a8\u4f5c\u4f30\u503c\u51fd\u6570 \\(Q_\\theta(s,a):\\mathcal{S}\\to\\mathbb{R}^{|\\mathcal{A}|}\\) \u76f4\u81f3\u6536\u655b, \\(Q_\\theta(s,a)\\) \u7528\u53c2\u6570\u4e3a \\(\\theta\\) \u7684\u795e\u7ecf\u7f51\u7edc\u8868\u793a, \u7ecf\u8fc7\u4e00\u6b21\u524d\u5411\u8ba1\u7b97\u8f93\u51fa\u6240\u6709\u53ef\u80fd\u52a8\u4f5c (\u603b\u6570\u4e3a\u52a8\u4f5c\u7a7a\u95f4\u7ef4\u5ea6 \\(|\\mathcal{A}|\\) ) \u7684 \\(Q\\) \u503c\u4f30\u8ba1, \u4ece\u800c\u53ef\u4ee5\u6839\u636e\u5b83\u4eec\u7684\u76f8\u5bf9\u5927\u5c0f\u5728\u5404\u79cd\u72b6\u6001\u4e0b\u9009\u62e9\u6700\u4f18\u52a8\u4f5c. $$ J_Q(\\theta) = \\mathbb{E} {s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma\\max {a'\\in\\mathcal{A}}Q_\\theta(s',a')-Q_\\theta(s,a)\\big)^2\\bigg] $$ \u63a2\u7d22\u65b9\u5f0f : DQN \u5728\u8bad\u7ec3\u65f6\u9ed8\u8ba4\u4f7f\u7528 \\(\\varepsilon\\) -greedy \u7684\u63a2\u7d22\u7b56\u7565, \u6839\u636e\u5f53\u524d\u8f93\u5165\u72b6\u6001 \\(s\\) \u548c\u4f30\u503c\u51fd\u6570 \\(Q_\\theta(s,a)\\) , \u4ee5\u6982\u7387 \\(1-\\varepsilon\\) \u9009\u62e9 \\(\\arg\\max_{a\\in\\mathcal{A}}Q(s,a)\\) , \u4ee5\u6982\u7387 \\(\\varepsilon\\) \u968f\u673a\u9009\u62e9\u52a8\u4f5c, \u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c, \\(\\varepsilon\\) \u5728\u533a\u95f4 \\((0,1]\\) \u5185\u7531\u5927\u5230\u5c0f\u7ebf\u6027\u53d8\u5316, DQN \u4ece\u5f3a\u63a2\u7d22\u8f6c\u4e3a\u5f3a\u5229\u7528. \u6837\u672c\u7ba1\u7406 : DQN \u5c5e\u4e8e Off-Policy \u7b97\u6cd5, \u4f7f\u7528 Replay Buffer \u7684\u5148\u5165\u5148\u51fa\u5806\u6808\u5b58\u50a8\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91c7\u96c6\u7684\u5355\u6b65\u8f6c\u79fb\u6837\u672c \\((s,a,s',r)\\) , \u5e76\u6bcf\u6b21\u4ece\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u6279\u6b21\u7528\u4e8e\u68af\u5ea6\u8ba1\u7b97\u548c\u53c2\u6570\u66f4\u65b0. Replay Buffer \u5141\u8bb8\u91cd\u590d\u5229\u7528\u5386\u53f2\u6570\u636e, \u4ee5\u6279\u6b21\u4e3a\u5355\u4f4d\u7684\u8bad\u7ec3\u65b9\u5f0f\u8986\u76d6\u4e86\u66f4\u5927\u7684\u72b6\u6001\u7a7a\u95f4, \u4e2d\u548c\u4e86\u5355\u4e2a\u6837\u672c\u8ba1\u7b97\u68af\u5ea6\u65f6\u7684\u65b9\u5dee, \u56e0\u6b64\u662f\u7a33\u5b9a DQN \u8bad\u7ec3\u548c\u63d0\u9ad8\u5176\u6837\u672c\u6548\u7387\u7684\u91cd\u8981\u63aa\u65bd. \u68af\u5ea6\u8ba1\u7b97 : \u4e3a\u4e86\u514b\u670d Boostrap \u7ed9\u8bad\u7ec3\u5e26\u6765\u7684\u4e0d\u7a33\u5b9a\u6027, DQN \u8bbe\u7f6e\u4e86\u4e00\u4e2a\u4e0e Q \u7f51\u7edc\u7ed3\u6784\u5b8c\u5168\u76f8\u540c\u7684\u76ee\u6807 Q \u7f51\u7edc\u4e13\u95e8\u7528\u4e8e\u8ba1\u7b97\u76ee\u6807\u503c, \u5176\u53c2\u6570\u7528 \\(\\theta^-\\) \u8868\u793a. \u76ee\u6807 Q \u7f51\u7edc\u662f\u6bcf N \u6b21\u8fed\u4ee3\u540e\u5c06\u4e3b Q \u7f51\u7edc\u53c2\u6570\u6574\u4f53\u590d\u5236, \u6709\u6548\u63d0\u5347 DQN \u8bad\u7ec3\u7a33\u5b9a\u6027. \u7279\u70b9\u5206\u6790 : DQN \u4f5c\u4e3a Value-Based \u7b97\u6cd5\u53ea\u9002\u7528\u4e8e\u53ef\u7a77\u4e3e\u7684\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4, \u53ea\u6709\u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u5728\u7279\u5b9a\u72b6\u6001\u4e0b\u4e0d\u540c\u52a8\u4f5c\u95f4\u901a\u8fc7 \\(Q\\) \u503c\u6bd4\u8f83\u62e9\u4f18\u7684\u8fd0\u7b97\u91cf\u53ef\u63a7, \u5bf9\u4e8e\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u663e\u7136\u65e0\u6cd5\u505a\u5230, \u4f46\u53ef\u4ee5\u5c1d\u8bd5\u4fdd\u6301\u8db3\u591f\u63a7\u5236\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b, \u5c06\u8fde\u7eed\u52a8\u4f5c\u533a\u95f4\u79bb\u6563\u5316. DQN \u5728\u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u4f7f\u7528\u540c\u4e00\u4e2a\u76ee\u6807 Q \u7f51\u7edc\u8fdb\u884c\u52a8\u4f5c\u7684\u9009\u62e9\u548c\u8bc4\u4f30, \u5728\u566a\u58f0\u548c\u8bef\u5dee\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u5bb9\u6613\u4ea7\u751f\u504f\u9ad8\u7684\u503c\u4f30\u8ba1, \u79f0\u4e3a\u8fc7\u4f30\u8ba1\u95ee\u9898 (Overestimation), \u4f1a\u5bf9 DQN \u6027\u80fd\u9020\u6210\u5f71\u54cd. \u6539\u8fdb\u63aa\u65bd : [15] \u57fa\u672c\u539f\u7406: Dueling DQN[16], Distributional DQN[17], Multi-Step Boostrap[14]; \u63a2\u7d22\u65b9\u5f0f: \u53c2\u6570\u566a\u58f0[12,18]; \u6837\u672c\u7ba1\u7406: \u4f18\u5148\u7ea7\u7ecf\u9a8c\u56de\u653e PER[13,19], \u6b63\u8d1f Episode \u5206\u5f00\u5b58\u50a8 Double Bin Replay Buffer[20,21], \u4e8b\u540e\u7ecf\u9a8c\u56de\u653e HER[22], \u591a\u6838\u5e76\u884c\u91c7\u6837\u6539\u5584\u63a2\u7d22\u548c\u91c7\u6837\u6548\u7387[5, 23, 24]; \u68af\u5ea6\u8ba1\u7b97: Double DQN; Twin Q [26]","title":"DQN"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#ddpg","text":"\u57fa\u672c\u539f\u7406 : \u4e3a\u4e86\u652f\u6301\u8fde\u7eed\u63a7\u5236\u4efb\u52a1, \u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6 (Deep Deterministic Policy Gradient) \u5728 DQN \u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u4e2a\u53c2\u6570\u4e3a \\(\\phi\\) \u7684\u7b56\u7565\u7f51\u7edc \\(\\pi_\\phi(a|s)\\) , \u6839\u636e\u8f93\u5165\u72b6\u6001 \\(s\\) \u8f93\u51fa\u552f\u4e00\u786e\u5b9a\u6027\u52a8\u4f5c \\(a\\in\\mathcal{A}\\) , \\(\\mathcal{A}\\) \u662f \\(n\\) \u7ef4\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4. \u503c\u7f51\u7edc \\(Q_\\theta(s,a):\\mathcal{S}\\times\\mathcal{A}\\to\\mathbb{R}\\) \u8f93\u5165\u72b6\u6001\u548c\u52a8\u4f5c\u5e76\u8f93\u51fa\u5355\u4e2a\u503c\u4f30\u8ba1, \u5176\u66f4\u65b0\u540c\u6837\u57fa\u4e8e\u5229\u7528\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684 Boostrap \u5c5e\u6027\u7684\u65f6\u5e8f\u5dee\u5206\u65b9\u6cd5, \u4f46\u7531\u4e8e\u52a8\u4f5c\u662f\u8fde\u7eed\u53d6\u503c\u7684, \u5728\u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u653e\u5f03\u57fa\u4e8e \\(Q\\) \u503c\u7684\u52a8\u4f5c\u5bfb\u4f18\u800c\u76f4\u63a5\u4f7f\u7528\u7b56\u7565\u7f51\u7edc\u8f93\u51fa. \u7b56\u7565\u7f51\u7edc\u626e\u6f14\u4e86 Q \u7f51\u7edc\u4f18\u5316\u5668\u7684\u89d2\u8272, \u66f4\u65b0\u68af\u5ea6\u5b8c\u5168\u6765\u81ea Q \u7f51\u7edc, \u76ee\u6807\u662f\u6700\u5927\u5316\u5f53\u524d Q \u7f51\u7edc\u8f93\u51fa, \u63a8\u7406\u65f6\u53ea\u9700\u7b56\u7565\u7f51\u7edc\u505a\u4e00\u6b21\u524d\u5411\u8ba1\u7b97. $$ \\begin{aligned} J_Q(\\theta)&=\\mathbb{E} {s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma \\textcolor{red}{Q {\\theta^-}(s',\\pi_\\phi(a'|s'))}-Q_\\theta(s,a)\\big)^2\\bigg]\\ J_\\pi(\\phi)&=-\\mathbb{E} {s,a\\sim\\mathcal{D}}[Q \\theta(s,\\pi_\\phi(a|s))] \\end{aligned} $$ \u63a2\u7d22\u65b9\u5f0f : DDPG \u91c7\u7528\u52a0\u6027\u566a\u58f0\u63a2\u7d22\u65b9\u5f0f, \u5373\u7b56\u7565\u7f51\u7edc\u7684\u8f93\u51fa\u4e0e\u76f8\u540c\u7ef4\u5ea6\u7684\u9ad8\u65af\u566a\u58f0\u76f8\u52a0, \u566a\u58f0\u7684\u65b9\u5dee\u51b3\u5b9a\u4e86\u63a2\u7d22\u529b\u5ea6. \u4ee5\u5f53\u524d\u8f93\u51fa\u52a8\u4f5c\u4e3a\u4e2d\u5fc3\u5f62\u6210\u4e86\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03, \u800c\u6bcf\u6b21\u66f4\u65b0\u7b56\u7565\u7f51\u7edc\u90fd\u4f7f\u5f97\u8f93\u51fa\u52a8\u4f5c\u5411\u8be5\u5206\u5e03\u4e2d \\(Q\\) \u503c\u66f4\u9ad8\u7684\u65b9\u5411\u79fb\u52a8, \u76f4\u5230\u5206\u5e03\u5185\u5176\u4ed6\u65b9\u5411\u90fd\u662f\u66f4\u5dee\u7684\u65b9\u5411, \u7b56\u7565\u8f93\u51fa\u4e5f\u5c31\u7a33\u5b9a\u5728\u6700\u4f18\u52a8\u4f5c\u9644\u8fd1, \u4ece\u800c\u5b9e\u73b0\u63a2\u7d22\u548c\u5229\u7528\u7684\u5e73\u8861. \u9664\u4e86\u9ad8\u65af\u566a\u58f0, DDPG \u539f\u8bba\u6587\u63a8\u8350\u4f7f\u7528 OU \u566a\u58f0, \u5373\u65b9\u5dee\u7ebf\u6027\u8870\u51cf\u7684\u9ad8\u65af\u566a\u58f0, \u5b9e\u73b0\u5f3a\u63a2\u7d22\u5230\u5f3a\u5229\u7528\u7684\u8fc7\u6e21. \u6837\u672c\u7ba1\u7406 : DDPG \u662f Off-Policy \u7b97\u6cd5, \u4f7f\u7528\u4e86\u7ecf\u9a8c\u56de\u653e\u548c Replay Buffer. \u68af\u5ea6\u8ba1\u7b97 : \u4e3a\u4e86\u7a33\u5b9a\u8bad\u7ec3, DDPG \u4e3a\u4ef7\u503c\u7f51\u7edc\u548c\u7b56\u7565\u7f51\u7edc\u5206\u522b\u8bbe\u7f6e\u4e86\u5bf9\u5e94\u7684\u76ee\u6807\u7f51\u7edc, \u5e76\u5728 Q \u7f51\u7edc\u66f4\u65b0\u4e2d\u4f7f\u7528\u5b83\u4eec\u6765\u8ba1\u7b97\u76ee\u6807\u503c, \u9632\u6b62 Boostrap \u7684\u81ea\u6fc0\u6548\u5e94\u653e\u5927\u8bef\u5dee. DDPG \u7684\u76ee\u6807\u7f51\u7edc\u6bcf\u6b21\u8fed\u4ee3\u90fd\u8ddf\u968f\u4e3b\u7f51\u7edc\u8fdb\u884c\u66f4\u65b0, \u4f7f\u7528\u8ba1\u7b97\u5f53\u524d\u76ee\u6807\u7f51\u7edc\u548c\u4e3b\u7f51\u7edc\u7684\u52a0\u6743\u79fb\u52a8\u5e73\u5747, Temperature, \u7528\u4e8e\u8c03\u8282\u76ee\u6807\u7f51\u7edc\u6bcf\u6b65\u66f4\u65b0\u5e45\u5ea6. \u7279\u70b9\u5206\u6790 : DDPG \u7a81\u7834\u4e86\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u7684\u9650\u5236, \u4f7f\u5f97\u7b97\u6cd5\u7684\u4f7f\u7528\u4ef7\u503c\u5f97\u5230\u8fdb\u4e00\u6b65\u63d0\u5347. \u8fde\u7eed\u52a8\u4f5c\u4f7f\u5f97\u4efb\u52a1\u63a2\u7d22\u7a7a\u95f4\u6025\u5267\u6269\u5927, \u4ece\u800c\u5bfc\u81f4\u5b66\u4e60\u96be\u5ea6\u4e0a\u5347. \u6b64\u5916 Q \u7f51\u7edc\u540c\u6837\u9762\u4e34\u8fc7\u4f30\u8ba1\u95ee\u9898, \u5e76\u5c06\u5176\u62df\u5408\u8bef\u5dee\u76f4\u63a5\u901a\u8fc7\u68af\u5ea6\u4f20\u5bfc\u4e3a\u7b56\u7565\u7f51\u7edc, \u591a\u91cd\u56e0\u7d20\u4f1a\u4f7f\u5f97 DDPG \u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u76f8\u5bf9\u8f83\u5dee, \u5c24\u5176\u5728\u52a8\u4f5c\u7ef4\u5ea6\u8f83\u9ad8\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73. \u6539\u8fdb\u63aa\u65bd : \u57fa\u672c\u539f\u7406: \u5f15\u5165\u6700\u5927\u71b5\u5b66\u4e60\u76ee\u6807\u548c\u968f\u673a\u7b56\u7565\u7684 SAC[27,28]; \u5f15\u5165\u503c\u5206\u5e03\u601d\u60f3\u7684 D4PG[29]; \u63a2\u7d22\u65b9\u5f0f: \u53c2\u6570\u566a\u58f0[18]\u548c\u5e76\u884c\u91c7\u6837 [5] \u6837\u672c\u7ba1\u7406: \u7528\u4e8e DQN \u7684\u90fd\u53ef\u7528\u4e8e DDPG \u68af\u5ea6\u8ba1\u7b97: \u5b6a\u751f Q \u7f51\u7edc, \u5ef6\u8fdf\u7b56\u7565\u66f4\u65b0, \u76ee\u6807\u7b56\u7565\u5e73\u6ed1\u7b49\u4e00\u7cfb\u5217\u6539\u5584\u76ee\u6807\u503c\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u8fc7\u4f30\u8ba1\u95ee\u9898\u548c\u65b9\u5dee\u6291\u5236\u63aa\u65bd\u7684 TD3[26].","title":"DDPG"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#a3c","text":"\u57fa\u672c\u539f\u7406 : Asynchronous Advantage Actor-Critic, A3C \u7b97\u6cd5\u91c7\u7528\u968f\u673a\u7b56\u7565\u5e76\u8f93\u51fa\u52a8\u4f5c\u7684\u6982\u7387\u5206\u5e03, \u56e0\u6b64\u4e0d\u80fd\u76f4\u63a5\u4ece\u503c\u7f51\u7edc\u83b7\u5f97\u66f4\u65b0\u68af\u5ea6, \u800c\u53ea\u80fd\u901a\u8fc7\u968f\u673a\u91c7\u6837\u4f30\u8ba1\u5176\u68af\u5ea6. A3C \u7ee7\u627f\u4e86\u7ecf\u5178\u7684 REINFORCE \u7b56\u7565\u68af\u5ea6[31] $$ \\nabla_\\phi \\log\\pi_{\\phi}(a_t|s_t)(R-b(s_t))\\ R=\\sum_{i=0}^{k-1}\\gamma^i r_{t+1} + \\gamma^k V_\\theta(s_{t+k}) $$ \\(R\\) \u662f\u4e00\u6bb5\u4ece\u72b6\u6001 \\(s_t\\) \u8d77\u59cb\u7684 Episode \u7684\u6298\u6263\u7d2f\u8ba1\u56de\u62a5. \\(b(s_t)\\) \u7528\u4e8e\u964d\u4f4e\u5956\u52b1\u65b9\u5dee[32] \u7684\u5173\u4e8e\u72b6\u6001 \\(s_t\\) \u7684\u57fa\u51c6\u51fd\u6570. A3C \u4ee5\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u7684\u503c\u51fd\u6570 \\(V_\\theta(s_t)\\) \u4e3a\u57fa\u51c6, \u5e76\u5c06 \\(A(s_t,a_t)=R-V_\\theta(s_t)\\) \u8be0\u91ca\u4e3a\u5728\u72b6\u6001 \\(s_t\\) \u4e0b\u9009\u62e9\u52a8\u4f5c \\(a_t\\) \u7684\u4f18\u52bf\u4f30\u8ba1, \\(J_\\pi\\) \u9f13\u52b1\u7b56\u7565\u7f51\u7edc\u589e\u52a0\u72b6\u6001 \\(s_t\\) \u7684\u4f18\u52bf\u4f30\u8ba1\u8f83\u9ad8\u7684\u52a8\u4f5c\u7684\u8f93\u51fa\u6982\u7387. \u7b56\u7565\u7f51\u7edc\u548c\u503c\u7f51\u7edc\u5171\u4eab\u4e86\u4e00\u90e8\u5206\u5e95\u5c42\u7ed3\u6784, \u6709\u52a9\u4e8e\u7b97\u6cd5\u66f4\u9ad8\u6548\u5730\u5b66\u4e60\u7279\u5f81\u63d0\u53d6. $$ \\begin{aligned} J_Q(\\theta)&=\\mathbb{E} {s,a\\sim\\rho^\\pi}\\bigg[\\frac{1}{2}\\big(R-V \\theta(s)\\big)^2\\bigg]\\ J_\\pi(\\phi)&=-\\mathbb{E} {s,a\\sim\\rho^\\pi}[\\log\\pi \\phi(a|s)A(s,a) +\\omega\\mathcal{H}(\\pi_\\phi(a|s))] \\end{aligned} $$ \u63a2\u7d22\u65b9\u5f0f : \u7531\u4e8e\u968f\u673a\u7b56\u7565\u81ea\u5e26\u63a2\u7d22\u5c5e\u6027, \u4e0d\u5fc5\u4f9d\u9760\u989d\u5916\u7684\u63a2\u7d22\u624b\u6bb5, \u53ea\u9700\u6bcf\u6b21\u6309\u7167\u8f93\u51fa\u52a8\u4f5c\u6982\u7387\u5206\u5e03\u8fdb\u884c\u968f\u673a\u91c7\u6837\u5373\u53ef. \u968f\u7740\u8bad\u7ec3\u7684\u4e0d\u65ad\u63a8\u8fdb, \u7b56\u7565\u5bf9\u52a8\u4f5c\u9009\u62e9\u8d8a\u6765\u8d8a\u81ea\u4fe1, \u5176\u8f93\u51fa\u7684\u968f\u673a\u6027\u76f8\u5e94\u5730\u4e0b\u964d, \u4ece\u800c\u5b9e\u73b0\u63a2\u7d22\u548c\u5229\u7528\u7684\u5e73\u8861. \u4e3a\u4e86\u907f\u514d\u7b56\u7565\u8fc7\u65e9\u9677\u5165\u5c40\u90e8\u6700\u4f18\u800c\u800c\u9000\u5316\u4e3a\u786e\u5b9a\u6027\u7b56\u7565, A3C \u5f15\u5165\u4e86\u7b56\u7565\u71b5\u635f\u5931\u9f13\u52b1\u7b56\u7565\u7f51\u7edc\u4fdd\u6301\u968f\u673a\u6027, \u53c2\u6570 \\(\\omega\\) \u7528\u4e8e\u8c03\u8282\u7b56\u7565\u71b5\u635f\u5931\u548c\u7b56\u7565\u635f\u5931\u4e4b\u95f4\u7684\u76f8\u5bf9\u6743\u91cd. A3C \u91c7\u7528\u4e86\u591a\u73af\u5883\u5e76\u884c\u91c7\u6837\u65b9\u6848, \u6bcf\u4e2a\u73af\u5883\u90fd\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u968f\u673a\u79cd\u5b50\u751a\u81f3\u662f\u4e0d\u540c\u7684\u63a2\u7d22\u65b9\u6848, \u4e0d\u540c\u7684 Actor \u5404\u81ea\u72ec\u7acb\u63a2\u7d22\u5e76\u5171\u4eab\u7ecf\u9a8c, \u6781\u5927\u63d0\u5347\u63a2\u7d22\u6548\u7387, \u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570\u566a\u58f0\u8fdb\u4e00\u6b65\u52a0\u5f3a. \u6837\u672c\u7ba1\u7406 : On-Policy \u7b97\u6cd5\u6bcf\u6b21\u66f4\u65b0\u6a21\u578b\u65f6\u90fd\u662f\u7528\u5f53\u524d\u6700\u65b0\u7684\u7b56\u7565\u91c7\u96c6\u4e00\u6279\u6837\u672c\u5e76\u5728\u66f4\u65b0\u5b8c\u6210\u540e\u5f7b\u5e95\u629b\u5f03\u8fd9\u4e9b\u6837\u672c, \u800c\u4e0d\u662f\u91cd\u590d\u5229\u7528 (On-Policy \u7b97\u6cd5\u76f4\u63a5\u4f7f\u7528 Replay Buffer \u4e2d\u65e7\u7b56\u7565\u91c7\u96c6\u7684\u5386\u53f2\u6837\u672c\u8ba1\u7b97\u68af\u5ea6\u4f1a\u5f15\u5165\u504f\u5dee). \u4e0a\u8ff0\u5e76\u884c\u91c7\u6837\u901a\u8fc7\u8db3\u591f\u9ad8\u7684\u91c7\u6837\u6548\u7387\u5728\u4e8b\u5b9e\u4e0a\u4fdd\u8bc1\u4e86\u503c\u7f51\u7edc \\(V_\\theta(s_t)\\) \u66f4\u65b0\u68af\u5ea6\u7684\u65e0\u504f\u6027, \u4ece\u800c\u8fbe\u5230\u7a33\u5b9a\u8bad\u7ec3\u7684\u76ee\u7684. \u68af\u5ea6\u8ba1\u7b97 : A3C \u4f7f\u7528\u6bcf\u6bb5 Episode \u7684\u6298\u6263\u7d2f\u8ba1\u56de\u62a5\u51cf\u53bb\u503c\u7f51\u7edc\u8f93\u51fa\u4f5c\u4e3a\u4f18\u52bf\u4f30\u8ba1\u5e76\u53c2\u4e0e\u5230 REINFORCE \u7b56\u7565\u68af\u5ea6\u8ba1\u7b97\u4e2d. \u57fa\u4e8e\u4f18\u52bf\u7684\u7b56\u7565\u68af\u5ea6\u53ef\u4ee5\u5728\u4e0d\u5f15\u5165\u504f\u5dee\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u68af\u5ea6\u65b9\u5dee\u7684\u7edd\u5bf9\u503c, \u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027. A3C \u5728\u6bcf\u4e2a\u91c7\u6837\u8fdb\u7a0b\u4e2d\u72ec\u7acb\u8ba1\u7b97\u68af\u5ea6, \u5e76\u5728\u4e3b\u7ebf\u7a0b\u805a\u5408\u540e\u7528\u6765\u66f4\u65b0\u503c\u7f51\u7edc\u548c\u7b56\u7565\u7f51\u7edc\u53c2\u6570. A3C \u9ed8\u8ba4\u91c7\u7528\u5f02\u6b65\u805a\u5408\u7684\u65b9\u5f0f, \u4f18\u70b9\u662f\u8fd0\u884c\u6548\u7387\u8f83\u9ad8[34], \u4f46\u91c7\u6837\u7b56\u7565\u4e0e\u5b9e\u9645\u88ab\u66f4\u65b0\u7b56\u7565\u95f4\u7684\u5dee\u5f02\u53ef\u80fd\u635f\u5bb3\u7b97\u6cd5\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u6027\u80fd, \u56e0\u6b64\u540e\u7eed\u7814\u7a76\u66f4\u591a\u6cbf\u7528\u4e86 A3C \u7684\u540c\u6b65\u68af\u5ea6\u805a\u5408\u7248\u672c A2C. \u7279\u70b9\u5206\u6790 : \u5e76\u884c\u91c7\u6837\u548c\u8499\u7279\u5361\u6d1b\u76ee\u6807\u503c\u4f30\u8ba1\u4e3a On-Polcy \u7b97\u6cd5\u5e26\u6765\u4e86\u4f4e\u6837\u672c\u6548\u7387\u548c\u9ad8\u68af\u5ea6\u56de\u4f20\u6548\u7387. A3C \u9664\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u66f4\u9ad8, \u5176\u91c7\u7528\u7684\u968f\u673a\u7b56\u7565\u5bf9\u5916\u754c\u6270\u52a8\u4e5f\u66f4\u9c81\u68d2, \u56e0\u6b64\u5177\u6709\u6bd4\u786e\u5b9a\u6027\u7b56\u7565\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u5bf9\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u800c\u8a00, \u5176\u7406\u8bba\u7eb3\u4ec0\u5747\u8861\u70b9\u6240\u5bf9\u5e94\u7684\u6700\u4f18\u7b56\u7565\u662f\u968f\u673a\u7684. A3C \u652f\u6301\u591a\u79cd\u6982\u7387\u5206\u5e03: \u7c7b\u522b\u5206\u5e03, \u4f2f\u52aa\u5229\u5206\u5e03, \u591a\u53d8\u91cf\u9ad8\u65af\u5206\u5e03, \u901a\u7528\u6027\u5f3a. \u6539\u8fdb\u63aa\u65bd : \u4f4e\u4e0b\u7684\u6837\u672c\u6548\u7387\u4f7f\u5176\u5728\u91c7\u6837\u6210\u672c\u9ad8\u7684\u4efb\u52a1\u4e2d\u51e0\u4e4e\u4e0d\u5177\u5907\u5b9e\u7528\u4ef7\u503c. \u7406\u8bba\u4e0a\u53ef\u4ee5\u591a\u6b21\u5229\u7528\u540c\u4e00\u6279\u5728\u7ebf\u91c7\u96c6\u7684\u6837\u672c, \u4f46\u8fd9\u6837\u4f1a\u5bfc\u81f4\u5355\u4e00\u68af\u5ea6\u65b9\u5411\u8fc7\u5927\u7684\u53c2\u6570\u66f4\u65b0\u800c\u7834\u574f\u8bad\u7ec3\u7a33\u5b9a\u6027. TRPO \u91cd\u6784\u4e86\u57fa\u4e8e\u4f18\u52bf\u7684\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u76ee\u6807 [35], \u5e76\u4ee5\u66f4\u65b0\u524d\u540e\u7b56\u7565\u8f93\u51fa\u5206\u5e03\u7684 KL \u6563\u5ea6\u6765\u7ea6\u675f\u7b56\u7565\u53c2\u6570\u7684\u53d8\u5316\u5e45\u5ea6, ACKTR[36] \u4f7f\u7528\u4e8c\u9636\u65b9\u6cd5\u8ba1\u7b97\u7684\u81ea\u7136\u68af\u5ea6\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387, \u5e76\u540c\u6837\u91c7\u7528 KL \u6563\u5ea6\u7ea6\u675f\u66f4\u65b0\u5e45\u5ea6. PPO[37]\u7ee7\u627f\u4e86 TRPO \u7684\u601d\u60f3, \u5c06 KL \u6563\u5ea6\u7ea6\u675f\u8fdb\u4e00\u6b65\u7b80\u5316\u4e3a\u5bf9\u7b56\u7565\u5206\u5e03\u6bd4\u4f8b\u504f\u79fb 1 \u7684\u7a0b\u5ea6\u7684\u7ea6\u675f. IMPALA [38] \u5728\u4fdd\u7559 A3C \u9ad8\u6548\u7387\u7684\u540c\u65f6\u5229\u7528\u91cd\u8981\u6027\u91c7\u6837\u514b\u670d\u4e86\u5f02\u6b65\u91c7\u6837\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd. \\[ \\begin{aligned} \\max_{\\phi'}\\mathbb{E}_{s,a\\sim\\rho^\\pi}\\bigg[\\frac{\\pi_{\\phi'}(a|s)}{\\pi_\\phi(a|s)}A^\\pi(s,a)\\bigg]\\\\ s.t. \\mathbb{E}_{s,a\\sim\\rho^\\pi} D_{KL}(\\pi_\\phi(\\cdot|s)\\|\\pi_{\\phi'}(\\cdot|s)) \\end{aligned} \\]","title":"A3C"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#53-sota","text":"","title":"5.3 SOTA \u7b97\u6cd5"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#td3","text":"Twin Delayed Deep Deterministic Policy Gradient, TD3 \u662f\u5728 DDPG \u7b97\u6cd5\u57fa\u7840\u4e0a\u8fed\u4ee3\u4ea7\u751f\u7684\u6539\u826f\u7248\u672c, \u5176\u57fa\u672c\u539f\u7406, \u63a2\u7d22\u65b9\u5f0f, \u6837\u672c\u7ba1\u7406\u90fd\u6cbf\u7528 DPPG, TD3 \u7684\u4e3b\u8981\u6539\u8fdb\u5728\u4e8e\u964d\u4f4e\u8ba1\u7b97\u76ee\u6807\u503c\u5b58\u5728\u7684\u504f\u5dee\u548c\u65b9\u5dee\u8fdb\u884c\u7684, \u5747\u5c5e\u4e8e\u5bf9\u68af\u5ea6\u8ba1\u7b97\u7684\u4f18\u5316. \u57fa\u672c\u539f\u7406 :- \u63a2\u7d22\u65b9\u5f0f :- \u6837\u672c\u7ba1\u7406 :- \u68af\u5ea6\u8ba1\u7b97 : \u76ee\u6807\u503c\u8ba1\u7b97\u7684\u504f\u5dee\u4e3b\u8981\u6765\u81ea\u4e8e Boostrap \u65b9\u6cd5\u666e\u904d\u5b58\u5728\u7684 Overestimation \u95ee\u9898, Double DQN \u901a\u8fc7\u5c06\u72b6\u6001 \\(s'\\) \u4e0b\u6700\u4f18\u52a8\u4f5c\u7684Q\u503c\u8bc4\u4f30\u548c\u9009\u62e9\u76f8\u5206\u79bb, \u4ece\u800c\u5b9e\u73b0\u5bf9\u8fc7\u4f30\u8ba1\u95ee\u9898\u7684\u4e00\u81f4, \u4f46 Double DQN \u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u5230\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4, \u4e3a\u6b64 TD3 \u7ed9\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u662f\u8bbe\u7f6e\u4e24\u4e2a\u5b8c\u5168\u76f8\u540c\u7684 Q \u7f51\u7edc (\u5b6a\u751f Q \u7f51\u7edc Twin Q) \u4ee5\u53ca\u914d\u5957\u7684\u4e24\u4e2a\u76ee\u6807 Q \u7f51\u7edc, \u5e76\u5bf9\u5b83\u4eec\u5206\u522b\u505a\u72ec\u7acb\u66f4\u65b0, \u6bcf\u6b21\u8ba1\u7b97\u76ee\u6807\u503c\u65f6\u603b\u662f\u9009\u62e9\u8f83\u5c0f\u7684\u90a3\u4e2a $$ J_Q(\\theta_t)=\\mathbb{E} {s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma\\min {i=1,2}Q_{\\theta_i^-}(s',\\pi_{\\phi^-}(a'|s')+\\varepsilon)-Q_{\\theta_i}(s,a)\\big)^2\\bigg] $$ \u4e3a\u4e86\u964d\u4f4e\u76ee\u6807\u503c\u8ba1\u7b97\u7684\u65b9\u5dee, \u5e76\u7f13\u89e3\u786e\u5b9a\u6027\u6d4b\u4e86\u5bf9\u503c\u51fd\u6570\u5c40\u90e8\u7a84\u5cf0\u7684\u8fc7\u62df\u5408\u503e\u5411, TD3 \u501f\u9274 SARSA[31] \u7684\u601d\u60f3, \u79c9\u6301\u8fd1\u4f3c\u52a8\u4f5c\u5e94\u6709\u8fd1\u4f3c\u503c\u4f30\u8ba1\u7684\u542f\u53d1\u5f0f\u539f\u5219, \u5728\u72b6\u6001 \\(s'\\) \u4e0b\u76ee\u6807\u7b56\u7565\u8f93\u51fa\u7684\u57fa\u7840\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u968f\u5373\u9ad8\u65af\u566a\u58f0 \\(\\varepsilon\\sim\\text{clip}(\\mathcal{N}(0,\\sigma^2),-c,c)\\) , \u622a\u65ad\u662f\u4e3a\u4e86\u4fdd\u6301\u566a\u58f0\u5316\u540e\u7684\u65b0\u52a8\u4f5c\u5728\u539f\u8f93\u51fa\u52a8\u4f5c\u9644\u8fd1. \u8fd9\u4e3a\u76ee\u6807\u7b56\u7565\u5e73\u6ed1, \u6ce8\u610f\u548c\u63a2\u7d22\u566a\u58f0\u7684\u533a\u5206. \u4e3a\u4e86\u964d\u4f4e\u76ee\u6807\u503c\u8ba1\u7b97\u7684\u65b9\u5dee\u5bf9\u7b56\u7565\u5b66\u4e60\u7684\u8d1f\u9762\u5f71\u54cd, TD3 \u964d\u4f4e\u4e86\u7b56\u7565\u7f51\u7edc\u53c2\u6570\u4e0e\u76ee\u6807\u7f51\u7edc\u53c2\u6570\u7684\u66f4\u65b0\u9891\u7387, \u4ee5\u4fdd\u8bc1 Q \u7f51\u7edc\u7ecf\u8fc7\u5145\u5206\u5b66\u4e60\u964d\u4f4e\u65b9\u5dee\u4e4b\u540e\u518d\u5f71\u54cd\u7b56\u7565\u7f51\u7edc\u548c\u76ee\u6807\u7f51\u7edc, \u7c7b\u4f3c DQN \u548c DDPG \u7684\u6df7\u5408\u65b9\u6848, \u6bcf\u66f4\u65b0 \\(d\\) \u6b21\u5b6a\u751f Q \u7f51\u7edc\u66f4\u65b0\u4e00\u6b21\u7b56\u7565\u7f51\u7edc, \u68af\u5ea6\u9ed8\u8ba4\u6765\u6e90\u4e8e\u5b6a\u751f Q \u7f51\u7edc\u4e2d\u7684 \\(Q_{\\theta_1}\\) \u5e76\u91c7\u7528\u79fb\u52a8\u5e73\u5747\u66f4\u65b0\u76ee\u6807\u7f51\u7edc. \u7279\u70b9\u5206\u6790 : TD3 \u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u83b7\u5f97\u4e86\u663e\u8457\u6539\u5584, \u65e0\u8bba\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u8fd8\u662f\u6700\u7ec8\u6027\u80fd\u4e0a\u90fd\u5f88\u6709\u7ade\u4e89\u529b. Off-Policy \u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684\u6837\u672c\u6548\u7387. \u6b64\u5916\u63a2\u7d22\u65b9\u5f0f\u548c\u6837\u672c\u7ba1\u7406\u7684\u6539\u8fdb\u540c\u6837\u9002\u7528\u4e8e TD3. \u5728\u7f3a\u70b9\u65b9\u9762, \u4ec5\u4ec5\u9002\u7528\u4e8e\u8fde\u7eed\u63a7\u5236\u4efb\u52a1, \u4e0d\u652f\u6301\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4. \u6539\u8fdb\u63aa\u65bd : -","title":"TD3"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#sac","text":"SAC \u540c\u6837\u4e3b\u8981\u9488\u5bf9 DDPG \u5728\u9ad8\u7ef4\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u7684, \u4f46\u4e0e TD3 \u96c6\u4e2d\u5173\u6ce8\u68af\u5ea6\u8ba1\u7b97\u7ec4\u4ef6\u7684\u6539\u8fdb\u4e0d\u540c, SAC \u5728\u5e38\u89c4\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u76ee\u6807\u7684\u57fa\u7840\u4e0a\u5f15\u5165\u4e86\u6700\u5927\u71b5\u76ee\u6807, \u5e76\u4e3a\u4e4b\u505a\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u9002\u914d\u5de5\u4f5c. \u57fa\u672c\u539f\u7406 : \u4e3a\u4e86\u5b9e\u73b0\u6700\u5927\u71b5\u76ee\u6807, \\(\\pi_\\phi(a|s)\\) \u7531\u786e\u5b9a\u8f6c\u968f\u673a, \u8f93\u51fa\u52a8\u4f5c\u7684\u6982\u7387\u5206\u5e03. \u76f8\u5e94\u5730\u5728 Q \u7f51\u7edc\u76ee\u6807\u503c\u8ba1\u7b97\u4e2d\u589e\u52a0\u4e86\u7b56\u7565\u71b5\u6210\u5206. \u9488\u5bf9\u968f\u673a\u7b56\u7565\u4e3a\u4e86\u76f4\u63a5\u4ece Q \u7f51\u7edc\u83b7\u5f97\u66f4\u65b0\u68af\u5ea6, \u540c\u65f6\u907f\u514d\u7c7b\u4f3c\u4e8e REINFORCE \u4e2d\u7684\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u964d\u4f4e\u6837\u672c\u6548\u7387, SAC \u4f7f\u7528\u4e86 VAE \u7684\u91cd\u53c2\u6570\u5316\u6280\u5de7, \u5e76\u5c06\u7b56\u7565\u8f93\u51fa\u91cd\u65b0\u8868\u793a\u4e3a \\(f_\\phi(s;\\varepsilon)\\) , \u800c\u7b56\u7565\u5b66\u4e60\u76ee\u6807\u4e5f\u4ece\u6700\u5927\u5316 Q \u7f51\u7edc\u8f93\u51fa\u6539\u4e3a\u6700\u5c0f\u5316\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684 KL \u6563\u5ea6. SAC \u5728\u7ecf\u8fc7\u5c11\u91cf\u9002\u914d\u540e\u5373\u53ef\u652f\u6301\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4, \u5f52\u529f\u4e8e\u7b97\u6cd5\u6240\u91c7\u7528\u7684\u968f\u673a\u7b56\u7565\u53ca\u5176\u5206\u5e03\u62df\u5408\u5b66\u4e60\u76ee\u6807 \\[ \\begin{aligned} J_Q(\\theta_i) &= \\mathbb{E}_{s,a\\sim\\mathcal{D}}\\bigg[\\frac{1}{2}\\big(r(s,a)+\\gamma(\\min_{i=1,2}Q_{\\theta_i^-}(s',a')-\\alpha\\log\\pi_\\phi(a'|s'))-Q_{\\theta_i}(s,a)\\big)^2\\bigg]\\\\ J_\\pi(\\phi) &= \\mathbb{E}_{s\\sim\\mathcal{D},\\varepsilon\\sim\\mathcal{N}(0,I)}[\\alpha\\log\\pi_\\phi(f_\\phi(s;\\varepsilon)|s)-\\min_{i=1,2}Q_{\\theta_i}(s,f_\\phi(s;\\varepsilon))] \\end{aligned} \\] \u63a2\u7d22\u65b9\u5f0f : SAC \u4e3a\u63a7\u5236\u6700\u5927\u71b5\u76ee\u6807\u5206\u91cf\u4e0e Reward \u76f8\u5bf9\u5c3a\u5ea6\u7684\u8d85\u53c2\u6570 \\(\\alpha\\) \u8bbe\u8ba1\u4e86\u81ea\u52a8\u8c03\u8282\u673a\u5236, \u65b9\u6cd5\u662f\u5c06\u539f\u76ee\u6807\u91cd\u6784\u4e3a\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u6c42\u89e3\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u76ee\u6807, \u5e76\u5229\u7528\u5bf9\u5076\u95ee\u9898\u63a8\u5bfc\u51fa \\(\\alpha\\) \u7684\u66f4\u65b0\u516c\u5f0f, \u6ce8\u610f\u4e0a\u8ff0\u7ea6\u675f\u6761\u4ef6\u9488\u5bf9\u7684\u662f\u7b56\u7565\u71b5\u7684\u6570\u5b66\u671f\u671b, \u800c\u4e0d\u662f\u673a\u68b0\u5730\u8981\u6c42\u7b56\u7565\u5728\u4efb\u610f\u65f6\u523b\u90fd\u4fdd\u6301\u9ad8\u968f\u673a\u6027\u548c\u9ad8\u63a2\u7d22\u5f3a\u5ea6. \u591a\u6570\u72b6\u6001\u4e0b\u7684\u4f18\u52a3\u52a8\u4f5c\u968f\u7740\u8bad\u7ec3\u7684\u63a8\u8fdb\u53d8\u5f97\u6e05\u6670\u65e0\u9700\u7ee7\u7eed\u63a2\u7d22, \u4e3a\u4e86\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6, \u63a2\u7d22\u529b\u5ea6\u4f1a\u9010\u6e10\u96c6\u4e2d\u5230\u89e3\u7a7a\u95f4\u4e2d\u4e0d\u786e\u5b9a\u6027\u4ecd\u8f83\u5927\u7684\u90e8\u5206, \u4f7f\u7b56\u7565\u5448\u73b0\u591a\u6a21\u6001\u7279\u5f81. \u6837\u672c\u7ba1\u7406 : Off-Policy \u7b97\u6cd5 \u68af\u5ea6\u8ba1\u7b97 : SAC \u501f\u9274\u4e86 TD3 \u7684\u5b6a\u751f Q \u7f51\u7edc, \u4f46\u6ca1\u6709\u8bbe\u7f6e\u72ec\u7acb\u5730\u76ee\u6807\u7b56\u7565\u7f51\u7edc\u800c\u662f\u76f4\u63a5\u4f7f\u7528\u5f53\u524d\u6700\u65b0\u7b56\u7565 \\(\\pi_\\phi\\) \u8fdb\u884c\u52a8\u4f5c\u91c7\u6837. \u6b64\u5916 SAC \u5728\u91cd\u53c2\u6570\u5316\u540e\u5229\u7528 Tanh \u6fc0\u6d3b\u51fd\u6570\u5c06\u6bcf\u4e2a\u52a8\u4f5c\u538b\u7f29\u5230 [-1,1], \u4f7f\u5f97\u7b56\u7565\u8f93\u51fa\u7531\u9ad8\u65af\u5206\u5e03\u53d8\u4e3a\u6324\u538b\u9ad8\u65af\u5206\u5e03, \u540e\u7eed\u68af\u5ea6\u8ba1\u7b97\u505a\u4e86\u76f8\u5e94\u5730\u9002\u914d.[27] \u7279\u70b9\u5206\u6790 : \u4f7f\u7528\u968f\u673a\u7b56\u7565\u66ff\u6362\u786e\u5b9a\u6027\u7b56\u7565, \u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027, \u5e76\u901a\u8fc7\u5f15\u5165\u6700\u5927\u71b5\u5b66\u4e60\u76ee\u6807\u6781\u5927\u5730\u6539\u5584\u4e86\u63a2\u7d22\u6548\u7387, \u8fd9\u6bd4 A3C \u4e2d\u5355\u7eaf\u5730\u5c06\u7b56\u7565\u71b5\u635f\u5931\u4f5c\u4e3a\u7ef4\u6301\u7b56\u7565\u968f\u673a\u6027\u5730\u6b63\u5219\u5316\u624b\u6bb5\u66f4\u6709\u6548. \u5b9e\u8df5\u4e2d SAC \u7edd\u5bf9\u6536\u655b\u901f\u5ea6\u901a\u5e38\u5feb\u4e8e\u5176\u4ed6 DRL \u7b97\u6cd5, \u652f\u6301\u79bb\u6563\u548c\u8fde\u7eed\u63a7\u5236\u4efb\u52a1, \u6838\u5fc3\u8d85\u53c2\u6570 \\(\\alpha\\) \u7684\u81ea\u52a8\u8c03\u8282\u673a\u5236\u4f7f\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8c03\u53c2\u5de5\u4f5c\u53d8\u5f97\u7b80\u5355, \u4f7f\u5f97 SAC \u5b9e\u7528\u4ef7\u503c\u8f83\u9ad8. \u6539\u8fdb\u63aa\u65bd : DDPG \u63a2\u7d22\u65b9\u5f0f\u548c\u6837\u672c\u7ba1\u7406\u6539\u8fdb\u5747\u9002\u7528 (\u79bb\u6563SAC\u53ef\u4ee5\u5c1d\u8bd5 Dueling Network \u548c Multi-Step Boostrap)","title":"SAC"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-05/#ppo","text":"PPO \u5728 A2C \u57fa\u7840\u4e0a\u5bf9\u6837\u672c\u7ba1\u7406\u548c\u68af\u5ea6\u8ba1\u7b97\u505a\u51fa\u4e86\u6539\u8fdb. \u63d0\u9ad8\u5728\u7ebf\u91c7\u96c6\u6837\u672c\u7684\u4f7f\u7528\u6548\u7387, PPO \u5c06\u540c\u4e00\u6279\u6837\u672c\u5206\u6210 MINI-BATCH \u5e76\u91cd\u590d\u5229\u7528\u591a\u6b21, \u540c\u65f6\u5728\u8ba1\u7b97\u7b56\u7565\u68af\u5ea6\u65f6, \u9650\u5236\u53c2\u6570\u66f4\u65b0\u5e45\u5ea6, \u4ece\u800c\u907f\u514d\u4ea7\u751f\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027. \u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9, PPO \u7ee7\u627f\u4e86 TRPO \u7f6e\u4fe1\u533a\u57df\u7684\u601d\u60f3, \u540c\u65f6\u907f\u514d\u4e86\u5171\u8f6d\u68af\u5ea6\u8ba1\u7b97\u7684\u590d\u6742\u6027. PPO \u5c06 KL \u6563\u5ea6\u7ea6\u675f\u66ff\u6362\u4e3a\u5bf9 \\(\\pi_{\\phi'}(a|s)/\\pi_\\phi(a|s)\\) \u504f\u79bb 1 \u7684\u7a0b\u5ea6\u7ea6\u675f. \u5229\u7528 \\(\\varepsilon\\in(0,1)\\) \u5b9a\u4e49\u4e86\u4ee5 1 \u4e3a\u4e2d\u5fc3\u7684\u7a84\u533a\u95f4, \u5728\u4e00\u4e2amini-batch \u5185\u4f7f\u65b0\u65e7\u7b56\u7565\u8f93\u51fa\u4e4b\u6bd4\u8d85\u51fa\u8be5\u533a\u95f4\u8303\u56f4\u7684\u90e8\u5206\u6570\u636e, \u7531\u4e8e\u622a\u65ad\u64cd\u4f5c\u800c\u5b9e\u9645\u4e0d\u4ea7\u751f\u68af\u5ea6, \u53ea\u6709\u5904\u4e8e\u7f6e\u4fe1\u8303\u56f4\u5185\u7684\u6570\u636e\u624d\u80fd\u5c06\u68af\u5ea6\u56de\u4f20\u81f3\u7b56\u7565\u7f51\u7edc, \u53ef\u89c1 PPO \u4ee5\u5728\u5fae\u89c2\u5c42\u9762(\u4e00\u4e2amini-batch) \u964d\u4f4e\u6837\u672c\u5229\u7528\u7387\u4e3a\u4ee3\u4ef7, \u5b9e\u73b0\u4e86\u6574\u4f53 (batch) \u6837\u672c\u5229\u7528\u7387\u7684\u63d0\u5347. \\[ J_\\pi(\\phi) = \\mathbb{E}_{s,a\\sim\\rho^\\pi}[\\min(\\frac{\\pi_{\\phi'}(a|s)}{\\pi_{\\phi}(a|s)}A^\\pi(s,a),\\text{clip}(\\frac{\\pi_{\\phi'}(a|s)}{\\pi_{\\phi}(a|s)},1-\\varepsilon,1+\\varepsilon)A^\\pi(s,a))] \\] PPO \u5728\u8ba1\u7b97\u4e00\u6bb5\u56fa\u5b9a\u957f\u5ea6 Episode \u5185\u7684\u52a8\u4f5c\u4f18\u52bf\u65f6, \u91c7\u7528\u4e86\u7c7b\u4f3c\u4e8e \\(TD(\\lambda)\\) \u7684\u901a\u7528\u4f18\u52bf\u4f30\u8ba1 (Generalized Advantage Estimation, GAE) \u6765\u964d\u4f4e\u68af\u5ea6\u7684\u65b9\u5dee. \u57fa\u672c\u539f\u7406 : \u63a2\u7d22\u65b9\u5f0f : \u6837\u672c\u7ba1\u7406 : \u68af\u5ea6\u8ba1\u7b97 : \u7279\u70b9\u5206\u6790 : On-Policy \u7b97\u6cd5\u548c\u968f\u673a\u7b56\u7565\u7a33\u5b9a\u6027\u9ad8\u7684\u4f18\u70b9, \u540c\u65f6\u4ee5\u8f83\u5c0f\u7684\u8fd0\u7b97\u4ee3\u4ef7\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6539\u5584\u4e86 On-Policy \u7b97\u6cd5\u5730\u4e0b\u7684\u6837\u672c\u5229\u7528\u7387, \u7c7b\u4f3c A2C \u591a\u73af\u5883\u5e76\u884c\u91c7\u6837\u4f7f\u5f97 PPO \u5177\u6709\u8f83\u9ad8\u7684\u63a2\u7d22\u6548\u7387, \u5c24\u5176\u9002\u5408\u5728\u5177\u6709\u4f18\u8d28\u73af\u5883\u6a21\u62df\u5668\u7684\u4efb\u52a1\u4e2d\u4f7f\u7528. \u6539\u8fdb\u63aa\u65bd : \u63a2\u7d22\u65b9\u5f0f 12 18 \u548c\u68af\u5ea6\u8ba1\u7b97 40 44 \u65b9\u9762\u7684\u6539\u8fdb\u53ef\u4ee5\u7528\u4e8e\u63d0\u5347 PPO \u7684\u6027\u80fd.","title":"PPO"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-06/","text":"","title":"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357 06"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-%E7%9B%AE%E5%BD%95/","text":"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357 \u7b2c\u4e00\u7ae0 \u9700\u6c42\u5206\u6790 \u7b2c\u4e8c\u7ae0 \u52a8\u4f5c\u7a7a\u95f4\u8bbe\u8ba1 \u7b2c\u4e09\u7ae0 \u72b6\u6001\u7a7a\u95f4\u8bbe\u8ba1 \u7b2c\u56db\u7ae0 \u56de\u62a5\u51fd\u6570\u8bbe\u8ba1 \u7b2c\u4e94\u7ae0 \u7b97\u6cd5\u9009\u62e9 \u7b2c\u516d\u7ae0 \u8bad\u7ec3\u8c03\u8bd5 \u7b2c\u4e03\u7ae0 \u6027\u80fd\u51b2\u523a","title":"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357"},{"location":"Books/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%90%BD%E5%9C%B0%E6%8C%87%E5%8D%97-%E7%9B%AE%E5%BD%95/#_1","text":"\u7b2c\u4e00\u7ae0 \u9700\u6c42\u5206\u6790 \u7b2c\u4e8c\u7ae0 \u52a8\u4f5c\u7a7a\u95f4\u8bbe\u8ba1 \u7b2c\u4e09\u7ae0 \u72b6\u6001\u7a7a\u95f4\u8bbe\u8ba1 \u7b2c\u56db\u7ae0 \u56de\u62a5\u51fd\u6570\u8bbe\u8ba1 \u7b2c\u4e94\u7ae0 \u7b97\u6cd5\u9009\u62e9 \u7b2c\u516d\u7ae0 \u8bad\u7ec3\u8c03\u8bd5 \u7b2c\u4e03\u7ae0 \u6027\u80fd\u51b2\u523a","title":"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357"},{"location":"Concepts/JL%20Lemma/","text":"Johnson-Lindenstrauss Lemma","title":"Johnson-Lindenstrauss Lemma"},{"location":"Concepts/JL%20Lemma/#johnson-lindenstrauss-lemma","text":"","title":"Johnson-Lindenstrauss Lemma"},{"location":"Concepts/Space/","text":"\u7a7a\u95f4 \u5411\u91cf\u7a7a\u95f4 \u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4","title":"\u7a7a\u95f4"},{"location":"Concepts/Space/#_1","text":"","title":"\u7a7a\u95f4"},{"location":"Concepts/Space/#_2","text":"","title":"\u5411\u91cf\u7a7a\u95f4"},{"location":"Concepts/Space/#_3","text":"","title":"\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4"},{"location":"Models/MultiModal/PN-2206.05826-Appx/","text":"Appendix The appendix is organized as follows: In Section A, we provide more visualizations of our model\u2019s predictions on various local- ization and VL understanding tasks. In Section B, we describe all our evaluated tasks and their dataset in detail. In Section C, we discuss the difference between our additional inter-image region-word contrastive loss and some other well-known losses that were also applied over a full batch in multiple works. In Section D, we introduce the training details and hyperparameters used in Section 4 in the main paper. Section E, we analyze the effect of using different language encoder and their pre-trained weights in our models. In Section F, we provide more results for all the checkpoints of adding pre-training data (refer to Section 4 in the main paper). In Section G, we provide a detailed analysis of the experiments of grounded captioning (mentioned in Section 4 in the main paper). In Section H, we give out a comparison for the model\u2019s inference speed. In Section I, we clearly provide the original sources of the images that are used in our paper. In Section J, we present per-dataset results for all experiments in ODinW. Bike. Umbrella. Dog... Agreenumbrella. Apinkstriped umbrella.Aplain whiteumbrella. Whatistheleft girlholding? [MASK] Apictureof [MASK] VL Grounding VisualQuestion Answering ImageCaption Image Encoder TextEncoder DeepFusionBlock Object Detection Localization tasks Answer:umbrella Car. Umbrella. Bike... Instance Segmentation Decode:girlsholding umbrellas. textinput GLIPv2 UnifiedOutputs imageinput Understanding tasks Figure 4: GLIPv2 , a pre-trained grounded VL understanding model, unifies various localization and VL understanding tasks. These two kinds of tasks mutually benefit each other and enable new capabilities such as language-guided detection/segmentation and grounded VQA/captioning. A Visualization We provide a clearer illustration of GLIPv2 in Figure 4, which elegantly unifies various localization (object detection, instance segmentation) and VL understanding (phrase grounding, VQA and captioning) tasks. More visualizations of the predictions under various tasks from GLIPv2 are also provided to indicate the model\u2019s strength and capability. Please refer to Figure 5 for OD / Grounding, Figure 6 for Instance / Referring Image Segmentation, and Figure 7 for Grounded VL Understanding. Prompt: person. dog... backpack. umbrella. horse. toothbrush. Prompt: person. hairdryer...baseball bat.baseballglove. bottle. toothbrush. Prompt: person. cup.sink... microwave.refrigerator.bear. Prompt: Mounted officersin bright green jacketssit on their horses wearing helmets. Prompt: 2 couples are eating dinner on the floorbehind a large plant. Prompt: A woman figure skaterin a blue costumeholds her legby the blade of her skate Prompt: fish. jellyfish. penguin. puffin. shark. starfish. stingray Prompt: dog. person. Prompt: smoke. Figure 5: Visualization for OD / Grounding. Row 1: Object Detection on COCO. Row 2: Phrase Grounding on Flickr30K. Row 3: Object Detection on ODinW. B Tasks and dataset descriptions B.1 (Language-guided) object detection and phrase grounding COCO.[ 8 ] The Microsoft Common Objects in Context dataset is a medium-scale object detection dataset. It has about 900k bounding box annotations for 80 object categories, with about 7.3 annotations per image. It is one of the most used object detection datasets, and its images are often used within other datasets (including VG and LVIS). Flickr30k-entities.[ 50 ] Given one or more phrases, which may be interrelated, the phrase grounding task is to provide a set of bounding boxes for each given phrase. We use the Flickr30k-entities dataset for this task, with the train/val/test splits as provided by [ 41 ] and evaluate our performance in terms of Recall. Flickr30K is included in the gold grounding data so we directly evaluate the models after pre-training as in MDETR [30]. We predict use any-box protocol specified in MDETR. ODinW.We use 13 datasets from Roboflow^2. Roboflow hosts over 30 datasets, and we exclude datasets that are too challenging (e.g., detecting different kinds of chess pieces) or impossible to solve without specific domain knowledge (e.g., understanding sign language). We provide the details of the 13 datasets we use in Table 7. We include the PASCAL VOC 2012 dataset as a reference dataset, as public baselines have been established on this dataset. For PascalVOC, we follow the convention (^2) https://public.roboflow.com/object-detection Prompt: person. hairdryer... baseballbat.baseballglove. bottle. toothbrush. Prompt: person.chair. dining table ... potted plant. vase. Prompt: person. cup.sink... microwave.refrigerator.bear. Prompt: green bush Prompt: windowhasaframe Prompt: brownlampshade Prompt: tissue.jacket....fork. pineapple.dinningtable. Prompt: donut. wineglass ... banana. pineapple. Prompt: person. teddybear... lollipop. flower. Figure 6: Visualization for Instance / Referring Image Segmentation. Row 1: Instance Segmentation on COCO Mask. Row 2: Instance Segmentation on LVIS. Row 3: Referring Image Segmentation on PhraseCut. Dataset Objects of Interest Train/Val/Test URL PascalVOC Common objects (PascalVOC 2012) 13690/3422/ https://public.roboflow.com/object-detection/pascal-voc-2012 AerialDrone Boats, cars, etc. from drone images 52/15/7 https://public.roboflow.com/object-detection/aerial-maritime Aquarium Penguins, starfish, etc. in an aquarium 448/127/63 https://public.roboflow.com/object-detection/aquarium Rabbits Cottontail rabbits 1980/19/10 https://public.roboflow.com/object-detection/cottontail-rabbits-video-dataset EgoHands Hands in ego-centric images 3840/480/480 https://public.roboflow.com/object-detection/hands Mushrooms Two kinds of mushrooms 41/5/5 https://public.roboflow.com/object-detection/na-mushrooms Packages Delivery packages 19/4/3 https://public.roboflow.com/object-detection/packages-dataset Raccoon Raccoon 150/29/17 https://public.roboflow.com/object-detection/raccoon Shellfish Shrimp, lobster, and crab 406/116/58 https://public.roboflow.com/object-detection/shellfish-openimages Vehicles Car, bus, motorcycle, truck, and ambulance 878/250/126 https://public.roboflow.com/object-detection/vehicles-openimages Pistols Pistol 2377/297/297 https://public.roboflow.com/object-detection/pistols/1 Pothole Potholes on the road 465/133/67 https://public.roboflow.com/object-detection/pothole Thermal Dogs and people in thermal images 142/41/20 https://public.roboflow.com/object-detection/thermal-dogs-and-people Table 7: 13 ODinW dataset statistics. We summarize the objects of interest for each dataset and report the image number of each split. and report on the validation set. For Pistols, there are no official validation or test sets so we split the dataset ourselves. B.2 (Language-guided) instance segmentation and referring image segmentation LVIS.[ 23 ] The Large Vocabulary Instance Segmentation dataset has over a thousand object categories, following a long-tail distribution with some categories having only a few examples. Similar to VG, LVIS uses the same images as in COCO, re-annotated with more object categories. In contrast to COCO, LVIS is a federated dataset, which means that only a subset of categories is annotated in each image. Annotations, therefore, include positive and negative object labels for objects that are present Figure 7: Visualization for Grounded VL Understanding. Row 1: Grounded VQA predictions (The model is given the input question and a placeholder token \u201c[MASK]\u201d for the answer. The model can ground not only entities in the question but also the implied answer entity). Row 2: Grounded captioning on COCO (The model can generate high-quality captions and, in the meantime, provide localization results. and categories that are not present, respectively. In addition, LVIS categories are not pairwise disjoint, such that the same object can belong to several categories. PhraseCut.[ 63 ] Besides object detection, we show that our GLIPv2 can be extended to perform segmentation by evaluating the referring expression segmentation task of the recent PhraseCut[ 63 ] which consists of images from VG, annotated with segmentation masks for each referring expression. These expressions comprise a wide vocabulary of objects, attributes and relations, making it a challenging benchmark. Contrary to other referring expression segmentation datasets, in PhraseCut the expression may refer to several objects and the model is expected to find all the corresponding instances. B.3 VQA and image captioning VQA.[ 20 ] requires the model to predict an answer given an image and a question. We conduct experiments on the VQA2.0 dataset, which is constructed using images from COCO. It contains 83k images for training, 41k for validation, and 81k for testing. We treat VQA as a classification problem with an answer set of 3,129 candidates following the common practice of this task. For our best models, we report test-dev and test-std scores by submitting to the official evaluation server.^3 COCO image captioning.[ 11 ] The goal of image captioning is to generate a natural language description given an input image. We evaluate GLIPv2 on COCO Captioning dataset and report BLEU-4, CIDEr, and SPICE scores on the Karparthy test split. C Difference between inter-image region-word contrastive loss with other \"region-word\" losses As far as we know, up to the deadline (05/19/2022) for NeurIPS submission, there are only three published papers (VILD [ 21 ], RegionCLIP [ 72 ], and X-VLM [ 69 ]) that have the flavor of \"region (^3) https://eval.ai/challenge/830/overview Model Image Text Detection Pre-Train Data Grounding Caption GLIPv2 -T Swin-T BERT-Base O365 GoldG (no COCO) Cap4M GLIPv2 -B Swin-B CLIP O365, COCO, OpenImages, VG, ImageNetBoxes GoldG CC15M+ SBU GLIPv2 -H CoSwin-H [67] CLIP O365, COCO, OpenImages, VG, ImageNetBoxes GoldG CC15M+SBU Mask Head \u2013 \u2013 LVIS, COCO PhraseCut \u2013 Table 8: A detailed list of GLIPv2 model variants word\" loss applied over full batch. We discuss the difference between our work and the three aforementioned works in the following: All these three works use \u201cregion-sentence\" loss, i.e., the similarity between a region feature and the [CLS] token of a sentence, instead of true \"region-word\" loss used in GLIPv2 . As a result, none of these three works made use of the phrase grounding data, which may contain multiple entities in one sentence during their training. It is the most important point in GLIPv2 to use phrase grounding data and pseudo grounding data to train a unified grounded VL understanding model. GLIPv2 has carefully designed the positive label propagation in our inter-image region-word contrastive loss to mitigate the wrong assumption that \"every unpaired region-word pair is negative\". As far as we know, no previous work has mentioned this mechanism of positive label propagation before. There are some other differences. For example, in VILD, its \u201cregion-sentence loss\" is actually not a contrastive loss over full-batch but a classification loss over a fixed vocabulary per sample (see the definition ofLV iLD\u2212text). Upon all three points above, we believe that our inter-image region-word contrastive loss is novel and has a significant difference from previous works. D Training details and hyperparamters D.1 Pre-training Pre-training data. There are three different types of data in pre-training 1) detection data 2) grounding data 3) caption data, as shown in Table 8. The detection data includes Object365 [ 54 ], COCO [ 8 ], OpenImages [ 33 ], Visual Genome [ 34 ], and ImageNetBoxes [ 16 ]. The grounding data includes GoldG, 0.8M human-annotated gold grounding data curated by MDETR [ 30 ] combining Flick30K, VG Caption, and GQA [ 29 ]. The Cap4M is a 4M image-text pairs collected from the web with boxes generated by GLIP-T(C) in [41], and CC (Conceptual Captions) + SBU (with 1M data). Implementation details. In Section 4 in the main paper, we introduced GLIPv2 -T, GLIPv2 -B, GLIPv2 -H, and we introduce the implementation details in the following. We pre-train GLIPv2 -T based on Swin-Tiny models with 32 GPUs and a batch size of 64. We use a base learning rate of 1 \u00d7 10 \u2212^5 for the language backbone (BERT-Base) and 1 \u00d7 10 \u2212^4 for all other parameters. The learning rate is stepped down by a factor of 0.1 at the 67% and 89% of the total 330,000 training steps. We decay the learning rate when the zero-shot performance on COCO saturates. The max input length is 256 tokens for all models. To optimize the results for object detection, we continue pre-training without the MLM loss for another 300,000 steps. We pre-train GLIPv2 -B based on Swin-Base models with 64 GPUs and a batch size of 64. We use a base learning rate of 1 \u00d7 10 \u2212^4 for all parameters, including the language backbone (CLIP-type pre-layernorm transformer). The learning rate is stepped down by a factor of 0.1 at the 67% and 89% of the total 1 million training steps. We decay the learning rate when the zero-shot performance on COCO saturates. The max input length is 256 tokens for all models. To optimize the results for object detection, we continue pre-training without the MLM loss for another 500,000 steps. We pre-train GLIPv2 -H based on the CoSwin-Huge model from Florence [ 67 ] with 64 GPUs and a batch size of 64. We use a base learning rate of 1 \u00d7 10 \u2212^4 for all parameters, including the language backbone (CLIP-type pre-layernorm transformer). The learning rate is stepped down by a factor of ...DyHead Module Fusion BERTLayer Image Encoder Text Encoder DyHead Module Fusion LayerBERT ... MaskHead prompt image GroundingHead MLM (0)Pre-training ...DyHead Module Fusion LayerBERT Image Encoder EncoderText DyHead Module Fusion prompt BERTLayer ... image GroundingHead (i)OD/Grounding ...DyHead Module Fusion BERTLayer EncoderImage EncoderText DyHead Module Fusion BERTLayer ... MaskHead prompt image GroundingHead (ii)Instance/Referring ImageSegmentation ...DyHead Module Fusion LayerBERT EncoderImage EncoderText DyHead Module Fusion prompt BERTLayer ... image GroundingHead DecodeAnswerr (iii)GroundedVisual QuestionAnswering ...DyHead Module Fusion BERTLayer EncoderImage Text Encoder DyHead Module Fusion LayerBERT ... image GroundingHead (iv)GroundedImageCaptioning (textencoderisuni-directional) \u2018a pictureof\u2019 CaptionHead Figure 8: The model architecture for pre-training (0), and downstream tasks (i) OD / Grounding (ii) Instance / Referring Image Segmentation (iii) Grounded Visual Question Answering (iv) Grounded Image Captioning. 0.1 at the 67% and 89% of the total 1 million training steps. We decay the learning rate when the zero-shot performance on COCO saturates. The max input length is 256 tokens for all models. We found that there isnoneed to continue pre-training without MLM loss for the huge model. Mask heads of GLIPv2 -T, GLIPv2 -B and GLIPv2 -H are pre-trained COCO, LVIS and PhraseCut, while freezing all the other model parameters. This mask head pre-training uses batch size 64, and goes through COCO for 24 epochs, LVIS for 24 epochs, and PhraseCut for 8 epochs, respectively. GLIPv2 uses Hourglass network [ 49 ] as instance segmentation head feature extractor, and utilizes the \"classification-to-matching\" trick to change the instance segmentation head linear prediction layer (outputsK-dimensional logits on each pixel) to a dot product layer between pixel visual features and the word features after VL fusion. GLIPv2 -T and GLIPv2 -B use a very basic Hourglass network for segmentation head feature extractor: only 1 scale and 1 layer, with hidden dimension 256. GLIPv2 -H uses a larger Hourglass network for segmentation head feature extractor: 2 scales and 4 layers, with hidden dimension 384. D.2 Downstream tasks OD / Grounding.When fine-tuning on COCO, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 24 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 5 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. For direct evaluation on LVIS, since LVIS has over 1,200 categories and they cannot be fit into one text prompt, so we segment them into multiple chunks, fitting 40 categories into one prompt and query the model multiple times with the different prompts. We find that models tend to overfit on LVIS during the course of pre-training so we closely monitor the performance on minival for all models and report the results with the best checkpoints in Table 2 in the main paper. For direct evaluation on Flickr30K, models may also overfit during the course of pre-training so we monitor the performance on the validation set for all models and report the results with the best checkpoints in Table 2 in the main paper. Instance segmentation / Referring Image Segmentation.Given the pre-trained model with pretrained mask head, we simply fine-tune theentirenetwork to get the task-specific fine-tuned models. For fine-tuning on COCO instance segmentation, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 24 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 5 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. For fine-tuning on LVIS instance segmentation, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 24 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 5 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. For fine-tuning on PhraseCut Referring Image segmentation, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 12 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 3 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. (Grounded) VQA.To fine-tune GLIPv2 for VQA, we feed the image and question into the model and then take the output feature sequencePfrom the language side (after the VL fusion) and apply a \u2018attention pooling\u2019 layer to obtain a feature vectorPvqa. More specifically, the attention pooling layer applies a linear layer followed by softmax to obtain normalized scaler weights, and then these weights are used to compute a weighted sum to produce the feature vectorpvqa. This feature vector is then fed to a 2-layer MLP with GeLU activation [ 27 ] and a final linear layer to obtain the logits for the 3129-way classification.^4 Following standard practice [ 58 ], we use binary cross entropy loss to take account of different answers from multiple human annotators. Following VinVL [ 71 ], we train on the combination of train2014 + val2014 splits of the VQAv2 dataset, except for the reserved 2k dev split.^5. For the ablation studies we report the accuracy on this 2k dev split. Other than the conventional VQA setting, we also experimented a new \u2018grounded VQA\u2019 setup, which the model is required to not only predict the answer, but also ground the objects (predict bounding boxes in the image) mentioned in the question and answer text, see Figure 8(iii). Note that the language input is the question appended by a[MASK]token, and this[MASK]token should ground to the object if the answer is indeed an object in the image. The total training loss is summing the grounding loss (intra-image region-word contrastive loss) and the VQA loss described previously. (Grounded) Image Captioning.We fine-tune the pre-trained model on COCO Caption \u201cKarpathy\u201d training split. The training objective is uni-directional Language Modeling (LM), which maximizes the likelihood of the next word at each position given the image and the text sequence before it. To enable autoregressive generation, we use uni-directional attention mask for the text part, and prevent the image part from attending to the text part in the fusion layers. Although the training objective (LM) is different from that in pre-training (i.e., bi-directional MLM), we directly fine-tune the model for image captioning to evaluate its capability of generalizing to VL generation tasks. Our model is trained with cross entropy loss only, without using CIDEr optimization. For grounded image captioning (Figure 8), we add the grounding loss (intra-image region-word contrastive loss) in training, which is calculated in the same way as in pre-training. We use Flickr30K training split for this task. During inference, for each predicted text token, we get its dot product logits with all the region representations and choose the maximum as the associated bounding box. E Analysis on the effect of different language encoders and pre-trained weights For GLIPv2 -T, we use the ImageNet pre-trained Swin-Transformer to initialize the image encoder and BERT-base-uncased to initialize the language encoder. For GLIPv2 -B, we use the pre-trained paired image-language encoder from UniCL (CLIP-like pre-training, https://github.com/microsoft/ UniCL) for initialization. We did an ablation study on the different language encoders (UniCL vs. BERT) and found that their results are nearly the same, as shown in Figure 9. Therefore, UniCL initialization does not skew the good localization performance. The main reason for us to keep the UniCL(CLIP-like) language encoder is due to its Pre-LayerNorm [ 64 ] operation. We find the UniCL(CLIP-like) language encoder with Pre-LayerNorm is more stable during the training compared with BERT, which uses Post-LayerNorm. F More analysis on pre-training data Table 5 in the main paper reports the last checkpoint results on GLIPv2 when we do the scaling up of pre-training data. As more weak image-text pair data (Cap) is involved in our training, it benefits both standard/in-domain (i.e., COCO, Flickr30K) and large-domain gap (i.e., ODinW, LVIS) tasks. Further adding the inter-image region-word contrastive helps when we are fixing the data at the same scale. For large-domain gap tasks, adding the inter-image region-word contrastive loss will further (^4) We experimented simpler pooling methods such as average pooling and[CLS]pooling [ 17 ] in the early experiments and found the attention pooling described above works better. (^5) 2000 images sampled from the val2014 split (and their corresponding question-answer pairs). Figure 9: GLIP-B with image encoder initialized from UniCL pre-trained image encoder, but with different language encoder initialization. Blue: language encoder initialized by Bert-Base, thus un-paired image-language pre-trained encoders. Yellow: language encoder initialized from UniCL pre-trained language encoder, thus paired UniCL pre-trained image-language encoders. From the results, we can see that the COCO zero-shot transfer results from two initializations are nearly the same. Similar results have been observed for other metrics, i.e., LVIS zero-shot AP, ODinW benchmark, and Flickr30k grounding performance. boost the model to learn better representation. To learn more scaling-up effects on various tasks under all the checkpoints for GLIP and GLIPv2 , see Figure 10. Given the considerable amount of improvement of GLIPv2 when the number of caption data increases from 0M to 12M, we hypothesize that it has potential to further grow by training on even larger-scale web image-text pairs. G Experiments on grounded image captioning The grounded captioning task requires the model to generate an image caption and also ground predicted phrases to object regions. The final predictions consist of (1) the text captions (2) predicted object regions, and (3) the grounding correspondence between the phrases and regions. Following the established benchmarks [ 48 , 74 ], we evaluate the caption metrics on COCO Captions and report the grounding metrics on Flick30K, as shown in Table 9. Model B@4COCO CaptionCIDEr SPICE R@1Flickr30K GroundingR@5 R@10 No Pretrain 35.4 115.3 21.2 77.0 92.9 95.7 +Lmlm 33.4 107.6 19.9 70.9 90.0 93.2 +Lloc+Lintra+Linter 36.6 120.3 21.6 80.8 94.9 96.7 GLIPv2 -T 36.5 119.8 21.6 80.8 94.4 96.5 GLIPv2 -B 37.4 123.0 21.9 81.0 94.5 96.5 Table 9: Grounded image captioning results on the COCO Caption, and Flickr30K Entities. We report BLEU@4, CIDer, and SPICE metrics for caption evaluation, and we use R@1, R@5, R@10 for grounding evaluation. H Inference speed We test the inference speed for GLIPv2 on V100 with batch size 1 and show its comparison to MDETR, as shown in Table 10. +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M Figure 10: Pre-train data scale up on Base-scale model. Left: GLIP, Right: GLIPv2 ; Row 1: COCO minival, Row 2: ODinW test split, Row 3: LVIS minival, Row 4: Flick30K test. I Figure Reference We provided the original sources of the images that are used in our paper in the following. All datasets above were collected by the creators (cited) and consent for any personally identifiable information (PII) was ascertained by the authors where necessary. Figure 1 in the main paper The top left and the bottom middle figures are the 281759.jpg in COCO val set; The left right images are (from top to down: (1) 2588.jpg in ODinW Aquarium test set. (2) 13923.jpg in LVIS val set. (3) 132690.jpg in VQA2.0 val set (question id is 132690002). (4) 462565.jpg in COCO Caption val set. Model Object Detection (COCO) Phrase Grounding (Flick30K) Referring Expression Segmentation (PhraseCut) MDETR R101 [30] \u2013 9.31 3.80 MDETR EffB3 [30] \u2013 11.20 3.98 MDETR EffB5 [30] \u2013 9.15 \u2013 GLIPv2 -T 4.12 3.74 2.26 GLIPv2 -B 3.01 3.23 2.39 GLIPv2 -H 1.21 1.13 0.89 Table 10: Model inference speed on various tasks. We report FPS, which is the number of images processed per second per GPU (higher is better). Figure 2 in the main paper The top left figure is the 209297.jpg in COCO train set; The bottom left figure is the 9378.jpg in COCO val set. Figure 4 in the Appendix Same as Figure 1. The top left and the bottom middle figures are the 281759.jpg in COCO val set. Figure 5 in the Appendix Row 1 (from left to right): (1) 439715.jpg in COCO val set. (2) 6471.jpg in COCO val set. (3) 13923.jpg in COCO val set; Row 2: (1) 5521996.jpg in Flickr30K val set. (2) 764507.jpg in Flickr30K val set. (3) 7520721.jpg in Flick30K val set; Row 3: (1) 2588.jpg in ODinW Aquarium test set. (2) 143.jpg in Thermal val set. (3) ck0l9j6n6oqjo0848ps5blk3b.jpg in WildFire val set. Figure 6 in the Appendix Row 1 (from left to right): (1) 13923.jpg in COCO val set. (2) 6471.jpg in COCO val set. (3) 7574.jpg in COCO val set; Row 2: (1) 117320.jpg in LVIS val set. (2) 2587.jpg in LVIS val set. (3) 211120.jpg in LVIS val set; Row 3: (1) 4744.jpg in PhraseCut test set. (2) 4744.jpg in PhraseCut val set. (3) 567.jpg in PhraseCut train set. Figure 7 in the Appendix Row 1 (from left to right): (1) 486.jpg in VQA2.0 val set (question id is 486002). (2) 262746.jpg in VQA2.0 val set (question id is 262746002). (3) 132690.jpg in VQA2.0 val set (question id is 132690002); Row 2: (1) 391895.jpg in COCO Caption val set. (2) 462565.jpg in COCO Caption val set. (3) 579056.jpg in COCO Caption val set. J All results for ODinW We report the per-dataset performance under 0,1,3,5,10-shot and full data as well as prompt tuning, and full-model tuning in Table 11 and Table 12 (on the next page). Model PascalVOC AerialDrone Aquarium Rabbits EgoHands Mushrooms Packages Raccoon Shellfish Vehicles Pistols Pothole Thermal Avg GLIP-T 56.2 12.5 18.4 70.2 50.0 73.8 72.3 57.8 26.3 56.0 49.6 17.7 44.1 46.5 GLIP-L 61.7 7.1 26.9 75.0 45.5 49.0 62.8 63.3 68.9 57.3 68.6 25.7 66.0 52.1 GLIPv2 -T 57.6 10.5 18.4 71.4 52.7 77.7 67.7 58.8 27.8 55.6 60.1 20.0 52.4 48.5 GLIPv2 -B 62.8 8.6 18.9 73.7 50.3 83.0 68.6 61.6 56.0 53.8 67.8 32.6 53.8 54.2 GLIPv2 -H 66.3 10.9 30.4 74.6 55.1 52.1 71.3 63.8 66.2 57.2 66.4 33.8 73.3 55.5 Table 11: Zero-shot performance on 13 ODinW datasets. Model Shot Tune PascalVOC AerialDrone Aquarium Rabbits EgoHands Mushrooms PackagesRaccoon Shellfish Vehicles Pistols Pothole Thermal Avg DyHeadO365 1 Full 25.8\u00b13.0 16.5\u00b11.8 15.9\u00b12.7 55.7\u00b16.044.0\u00b13.6 66.9\u00b13.9 54.2\u00b15.7 50.7\u00b17.714.1\u00b13.633.0\u00b111.0 11.0\u00b16.58.2\u00b14.1 43.2\u00b110.033.8\u00b13.5 DyHeadO365 3 Full 40.4\u00b11.0 20.5\u00b14.0 26.5\u00b11.3 57.9\u00b12.053.9\u00b12.5 76.5\u00b12.3 62.6\u00b113.352.5\u00b15.022.4\u00b11.747.4\u00b12.0 30.1\u00b16.919.7\u00b11.557.0\u00b12.3 43.6\u00b11.0 DyHeadO365 5 Full 43.5\u00b11.0 25.3\u00b11.8 35.8\u00b10.5 63.0\u00b11.056.2\u00b13.9 76.8\u00b15.9 62.5\u00b18.7 46.6\u00b13.128.8\u00b12.251.2\u00b12.2 38.7\u00b14.121.0\u00b11.453.4\u00b15.2 46.4\u00b11.1 DyHeadDyHeadO365O365 All 10 FullFull 46.653.3\u00b10.3 29.028.4\u00b12.8 41.749.5\u00b11.0 65.273.5\u00b12.562.577.9\u00b10.8 85.484.0\u00b12.2 67.969.2\u00b14.5 47.956.2\u00b12.228.643.6\u00b15.053.859.2\u00b11.0 39.268.9\u00b14.927.953.7\u00b12.364.173.7\u00b12.6 50.860.8\u00b11.3 GLIP-T 1 Prompt 54.4\u00b10.9 15.2\u00b11.4 32.5\u00b11.0 68.0\u00b13.260.0\u00b10.7 75.8\u00b11.2 72.3\u00b10.0 54.5\u00b13.924.1\u00b13.059.2\u00b10.9 57.4\u00b10.618.9\u00b11.856.9\u00b12.7 49.9\u00b10.6 GLIP-TGLIP-T 35 PromptPrompt 56.858.5\u00b1\u00b10.80.5 18.918.2\u00b1\u00b13.60.1 37.641.0\u00b1\u00b11.61.2 72.471.8\u00b1\u00b10.52.462.865.7\u00b1\u00b11.30.7 85.487.5\u00b1\u00b12.82.2 64.572.3\u00b1\u00b14.60.0 69.160.6\u00b1\u00b11.82.222.031.4\u00b1\u00b10.94.262.761.0\u00b1\u00b11.11.8 56.154.4\u00b1\u00b10.60.625.932.6\u00b1\u00b10.71.463.866.3\u00b1\u00b14.82.8 53.755.5\u00b1\u00b11.30.5 GLIP-T 10 Prompt 59.7\u00b10.7 19.8\u00b11.6 44.8\u00b10.9 72.1\u00b12.065.9\u00b10.6 87.4\u00b11.1 72.3\u00b10.0 57.5\u00b11.230.0\u00b11.462.1\u00b11.4 57.8\u00b10.933.5\u00b10.173.1\u00b11.4 56.6\u00b10.2 GLIP-T All Prompt 66.4 27.6 50.9 70.6 73.3 88.1 67.7 64.0 40.3 65.4 68.3 50.7 78.5 62.4 GLIP-T 1 Full 54.8\u00b12.0 18.4\u00b11.0 33.8\u00b11.1 70.1\u00b12.964.2\u00b11.8 83.7\u00b13.0 70.8\u00b12.1 56.2\u00b11.822.9\u00b10.256.6\u00b10.5 59.9\u00b10.418.9\u00b11.354.5\u00b12.7 51.1\u00b10.1 GLIP-T 3 Full 58.1\u00b10.5 22.9\u00b11.3 40.8\u00b10.9 65.7\u00b11.666.0\u00b10.2 84.7\u00b10.5 65.7\u00b12.8 62.6\u00b11.427.2\u00b12.761.9\u00b11.8 60.7\u00b10.227.1\u00b11.270.4\u00b12.5 54.9\u00b10.2 GLIP-T 5 Full 59.5\u00b10.4 23.8\u00b10.9 43.6\u00b11.4 68.7\u00b11.366.1\u00b10.6 85.4\u00b10.4 72.3\u00b10.0 62.1\u00b12.027.3\u00b11.261.0\u00b11.8 62.7\u00b11.634.5\u00b10.566.6\u00b12.3 56.4\u00b10.4 GLIP-TGLIP-T All 10 FullFull 59.162.3\u00b11.3 26.331.2\u00b11.1 46.352.5\u00b11.6 67.370.8\u00b11.567.178.7\u00b10.7 87.888.1\u00b10.5 72.375.6\u00b10.0 57.761.4\u00b11.734.651.4\u00b11.765.465.3\u00b11.4 61.671.2\u00b11.039.358.7\u00b11.074.776.7\u00b12.3 58.464.9\u00b10.2 GLIP-L 1 Prompt 62.8\u00b10.4 18.0\u00b11.8 37.4\u00b10.3 71.9\u00b12.468.9\u00b10.1 81.8\u00b13.4 65.0\u00b12.8 63.9\u00b10.470.2\u00b11.267.0\u00b10.4 69.3\u00b10.127.6\u00b10.469.8\u00b10.6 59.5\u00b10.4 GLIP-L 3 Prompt 65.0\u00b10.5 21.4\u00b11.0 43.6\u00b11.1 72.9\u00b10.770.4\u00b10.1 91.4\u00b10.7 57.7\u00b13.7 70.7\u00b11.169.7\u00b10.962.6\u00b10.8 67.7\u00b10.436.2\u00b11.168.8\u00b11.5 61.4\u00b10.3 GLIP-LGLIP-L 105 PromptPrompt 65.665.9\u00b1\u00b10.30.2 19.923.4\u00b1\u00b11.62.6 47.750.3\u00b1\u00b10.70.7 73.773.6\u00b1\u00b10.70.770.671.8\u00b1\u00b10.30.3 86.886.5\u00b1\u00b10.50.3 64.670.5\u00b1\u00b10.71.1 69.469.0\u00b1\u00b13.30.568.069.4\u00b1\u00b11.32.467.870.8\u00b1\u00b11.51.2 68.368.8\u00b1\u00b10.30.636.639.3\u00b1\u00b11.60.971.974.9\u00b1\u00b10.62.1 62.464.2\u00b1\u00b10.50.4 GLIP-L All Prompt 72.9 23.0 51.8 72.0 75.8 88.1 75.2 69.5 73.6 72.1 73.7 53.5 81.4 67.9\u00b10.0 GLIP-L 1 Full 64.8\u00b10.6 18.7\u00b10.6 39.5\u00b11.2 70.0\u00b11.570.5\u00b10.2 69.8\u00b118.0 70.6\u00b14.0 68.4\u00b11.271.0\u00b11.365.4\u00b11.1 68.1\u00b10.228.9\u00b12.972.9\u00b14.7 59.9\u00b11.4 GLIP-L 3 Full 65.6\u00b10.6 22.3\u00b11.1 45.2\u00b10.4 72.3\u00b11.470.4\u00b10.4 81.6\u00b113.3 71.8\u00b10.3 65.3\u00b11.667.6\u00b11.066.7\u00b10.9 68.1\u00b10.337.0\u00b11.973.1\u00b13.3 62.1\u00b10.7 GLIP-L 5 Full 66.6\u00b10.4 26.4\u00b12.5 49.5\u00b11.1 70.7\u00b10.271.9\u00b10.2 88.1\u00b10.0 71.1\u00b10.6 68.8\u00b11.268.5\u00b11.770.0\u00b10.9 68.3\u00b10.539.9\u00b11.475.2\u00b12.7 64.2\u00b10.3 GLIP-LGLIP-L All 10 FullFull 66.469.6\u00b10.7 32.032.6\u00b11.4 52.356.6\u00b11.1 70.676.4\u00b10.772.479.4\u00b10.3 88.188.1\u00b10.0 67.167.1\u00b13.6 64.769.4\u00b13.169.465.8\u00b11.471.571.6\u00b10.8 68.475.7\u00b10.744.360.3\u00b10.676.383.1\u00b11.1 64.968.9\u00b10.7 GLIPv2 -T 1 Prompt 51.2\u00b10.3 17.7\u00b11.2 34.2\u00b10.1 68.7\u00b11.267.3\u00b10.9 83.7\u00b12.1 68.1\u00b11.7 53.4\u00b10.230.0\u00b10.959.0\u00b10.1 60.0\u00b10.321.9\u00b10.266.5\u00b10.7 52.4\u00b10.5 GLIPv2 -T 3 Prompt 66.6\u00b10.2 11.5\u00b10.7 37.2\u00b11.0 71.7\u00b10.370.1\u00b10.4 45.7\u00b10.1 57.7\u00b11.2 69.7\u00b11.542.7\u00b10.467.5\u00b10.9 65.6\u00b11.036.7\u00b11.269.2\u00b11.2 55.6\u00b10.4 GLIPv2 -T GLIPv2 -T 105 PromptPrompt 58.959.9\u00b1\u00b11.20.4 17.421.6\u00b1\u00b10.62.0 42.843.7\u00b1\u00b10.40.3 72.674.3\u00b1\u00b10.50.466.168.2\u00b1\u00b10.20.7 84.988.1\u00b1\u00b10.80.1 69.772.0\u00b1\u00b10.60.9 65.560.0\u00b1\u00b12.10.435.635.6\u00b1\u00b10.81.262.866.1\u00b1\u00b10.90.6 59.861.0\u00b1\u00b10.20.335.542.8\u00b1\u00b10.90.474.470.9\u00b1\u00b10.23.2 57.458.8\u00b1\u00b10.40.5 GLIPv2 -T All Prompt 67.4 22.3 50.5 74.3 73.4 85.5 74.7 65.8 53.7 67.4 68.9 52.3 83.7 64.8\u00b10.0 GLIPv2 -T 1 Full 64.8\u00b10.6 18.7\u00b10.6 39.5\u00b11.2 70.0\u00b11.570.5\u00b10.2 69.8\u00b118.0 70.6\u00b14.0 68.4\u00b11.271.0\u00b11.365.4\u00b11.1 68.1\u00b10.228.9\u00b12.972.9\u00b14.7 52.8\u00b11.4 GLIPv2 -T 3 Full 53.9\u00b10.1 17.8\u00b10.7 42.7\u00b11.1 73.1\u00b11.065.9\u00b10.2 84.7\u00b13.4 69.7\u00b10.8 60.7\u00b11.328.8\u00b10.861.7\u00b11.3 60.6\u00b10.235.5\u00b10.468.3\u00b11.7 55.6\u00b10.7 GLIPv2 -T 5 Full 58.9\u00b10.2 17.4\u00b11.1 42.8\u00b11.3 72.6\u00b10.766.1\u00b10.6 84.9\u00b10.9 69.7\u00b10.3 65.5\u00b11.035.6\u00b10.962.8\u00b10.3 59.8\u00b10.235.5\u00b11.274.4\u00b12.1 57.4\u00b10.4 GLIPv2 -T GLIPv2 -T All 10 FullFull 57.666.4\u00b11.0 27.630.2\u00b11.2 49.152.5\u00b11.0 70.474.8\u00b10.569.280.0\u00b10.2 88.188.1\u00b10.0 73.174.3\u00b12.3 58.063.7\u00b12.842.954.4\u00b11.264.863.0\u00b10.2 62.173.0\u00b10.939.960.1\u00b10.471.683.5\u00b10.8 59.766.5\u00b10.3 GLIPv2 -B 1 Prompt 68.7\u00b10.1 19.9\u00b10.3 38.4\u00b10.8 68.5\u00b11.068.6\u00b10.8 87.7\u00b13.0 69.3\u00b11.7 68.5\u00b10.455.2\u00b10.365.7\u00b10.7 67.2\u00b10.134.8\u00b10.869.6\u00b10.4 60.4\u00b10.3 GLIPv2 -B 3 Prompt 67.2\u00b10.6 22.2\u00b10.3 46.5\u00b10.9 71.2\u00b10.870.9\u00b10.1 86.9\u00b10.2 67.7\u00b11.8 63.7\u00b12.346.9\u00b10.868.1\u00b10.4 67.4\u00b10.947.9\u00b11.078.9\u00b11.7 62.0\u00b10.5 GLIPv2 -B GLIPv2 -B 105 PromptPrompt 68.969.4\u00b1\u00b11.00.7 25.721.8\u00b1\u00b10.41.3 50.548.7\u00b1\u00b10.90.2 73.871.3\u00b1\u00b11.50.269.771.0\u00b1\u00b10.60.7 84.988.1\u00b1\u00b10.30.4 69.368.6\u00b1\u00b10.70.7 65.873.5\u00b1\u00b11.60.365.761.5\u00b1\u00b11.01.969.269.3\u00b1\u00b10.30.2 67.568.6\u00b1\u00b10.70.734.041.3\u00b1\u00b10.20.273.175.2\u00b1\u00b10.61.3 62.963.8\u00b1\u00b10.40.3 GLIPv2 -B All Prompt 71.9 26.1 50.6 74.5 73.5 86.9 74.9 71.0 71.6 71.0 72.4 50.2 80.5 67.3\u00b10.0 GLIPv2 -B 1 Full 67.8\u00b10.4 18.7\u00b10.3 44.2\u00b10.9 71.4\u00b10.370.4\u00b11.2 87.9\u00b17.3 66.1\u00b12.4 68.9\u00b11.160.6\u00b11.668.1\u00b10.6 69.0\u00b10.735.1\u00b10.968.9\u00b12.1 61.2\u00b10.6 GLIPv2 -B 3 Full 68.1\u00b10.2 25.7\u00b10.4 46.4\u00b11.6 69.8\u00b11.371.3\u00b11.2 88.0\u00b13.4 68.6\u00b10.9 69.8\u00b11.760.1\u00b10.368.4\u00b11.9 68.5\u00b10.639.8\u00b10.871.4\u00b12.1 62.8\u00b10.8 GLIPv2 -B 5 Full 68.6\u00b11.0 21.6\u00b10.6 46.7\u00b10.7 70.9\u00b10.971.0\u00b11.2 88.1\u00b13.7 69.1\u00b10.2 71.8\u00b11.061.5\u00b10.768.7\u00b10.2 69.3\u00b10.840.2\u00b11.074.8\u00b12.8 63.3\u00b10.6 GLIPv2 -B GLIPv2 -B All 10 FullFull 67.471.1\u00b11.3 22.332.6\u00b11.1 50.557.5\u00b10.7 74.373.6\u00b10.473.480.0\u00b10.4 85.588.1\u00b10.1 74.774.9\u00b10.9 65.868.2\u00b12.453.770.6\u00b11.167.471.2\u00b10.9 68.976.5\u00b10.752.358.7\u00b10.683.779.6\u00b13.2 64.669.4\u00b10.3 GLIPv2 -H 1 Prompt 68.3\u00b10.6 16.4\u00b10.6 45.8\u00b10.3 72.0\u00b10.567.9\u00b10.9 89.3\u00b13.2 69.3\u00b11.7 67.9\u00b10.866.3\u00b11.968.0\u00b10.7 66.8\u00b10.333.9\u00b10.470.7\u00b11.5 61.4\u00b10.5 GLIPv2 -H 3 Prompt 69.5\u00b10.7 25.9\u00b10.2 50.0\u00b11.2 75.4\u00b11.470.1\u00b10.9 85.9\u00b12.5 69.3\u00b10.7 70.8\u00b11.266.4\u00b10.868.0\u00b11.2 68.8\u00b10.934.0\u00b10.372.7\u00b11.6 63.6\u00b10.6 GLIPv2 -H GLIPv2 -H 105 PromptPrompt 69.466.0\u00b1\u00b10.70.7 22.027.5\u00b1\u00b10.61.3 49.153.8\u00b1\u00b10.10.2 70.774.6\u00b1\u00b11.00.273.080.1\u00b1\u00b10.50.7 88.187.4\u00b1\u00b10.80.4 70.369.3\u00b1\u00b10.40.7 71.266.0\u00b1\u00b11.80.362.951.2\u00b1\u00b11.41.970.167.2\u00b1\u00b10.30.2 68.372.8\u00b1\u00b10.60.742.758.3\u00b1\u00b10.60.274.376.5\u00b1\u00b10.51.3 63.965.5\u00b1\u00b10.70.6 GLIPv2 -H All Prompt 71.2 31.1 57.1 75.0 79.8 88.1 68.6 68.3 59.6 70.9 73.6 61.4 78.6 69.1\u00b10.0 GLIPv2 -H 1 Full 67.8\u00b10.6 17.3\u00b10.6 50.7\u00b10.3 63.8\u00b10.567.3\u00b10.9 89.4\u00b13.2 69.3\u00b11.7 68.2\u00b10.866.6\u00b11.966.8\u00b10.7 67.0\u00b10.334.0\u00b10.475.0\u00b11.5 61.7\u00b10.5 GLIPv2 -H 3 Full 62.3\u00b10.2 29.1\u00b10.4 53.8\u00b11.6 72.7\u00b11.378.4\u00b11.2 85.8\u00b13.4 68.6\u00b10.9 60.7\u00b11.743.6\u00b10.365.9\u00b11.9 72.2\u00b10.655.9\u00b10.881.1\u00b12.1 64.1\u00b10.8 GLIPv2 -H 5 Full 66.4\u00b11.0 23.4\u00b10.6 50.7\u00b10.7 73.9\u00b10.971.8\u00b11.2 84.2\u00b13.7 71.2\u00b10.2 68.1\u00b11.067.4\u00b10.770.8\u00b10.2 65.8\u00b10.854.6\u00b11.075.6\u00b12.8 64.4\u00b10.6 GLIPv2 -H GLIPv2 -H All 10 FullFull 67.374.4\u00b11.3 31.636.3\u00b11.1 52.458.7\u00b10.7 71.377.1\u00b10.480.079.3\u00b10.4 88.188.1\u00b10.1 72.974.3\u00b10.9 56.973.1\u00b12.452.270.0\u00b11.165.472.2\u00b10.9 73.972.5\u00b10.761.058.3\u00b10.684.081.4\u00b13.2 65.970.4\u00b10.3 Table 12: Per-dataset performance of DyHead, GLIP-T, GLIP-L, and GLIPv2 -T, GLIPv2 -B and GLIPv2 -H. For PascalVOC, we report the mAP (IoU=0.50:0.95) using the COCO evaluation script, to be consistent with other 12 datasets. \u201cPrompt\u201d denotes prompt tuning. \u201cFull\u201d denotes full-model tuning.","title":"PN 2206.05826 Appx"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#appendix","text":"The appendix is organized as follows: In Section A, we provide more visualizations of our model\u2019s predictions on various local- ization and VL understanding tasks. In Section B, we describe all our evaluated tasks and their dataset in detail. In Section C, we discuss the difference between our additional inter-image region-word contrastive loss and some other well-known losses that were also applied over a full batch in multiple works. In Section D, we introduce the training details and hyperparameters used in Section 4 in the main paper. Section E, we analyze the effect of using different language encoder and their pre-trained weights in our models. In Section F, we provide more results for all the checkpoints of adding pre-training data (refer to Section 4 in the main paper). In Section G, we provide a detailed analysis of the experiments of grounded captioning (mentioned in Section 4 in the main paper). In Section H, we give out a comparison for the model\u2019s inference speed. In Section I, we clearly provide the original sources of the images that are used in our paper. In Section J, we present per-dataset results for all experiments in ODinW. Bike. Umbrella. Dog... Agreenumbrella. Apinkstriped umbrella.Aplain whiteumbrella. Whatistheleft girlholding? [MASK] Apictureof [MASK] VL Grounding VisualQuestion Answering ImageCaption Image Encoder TextEncoder DeepFusionBlock Object Detection Localization tasks Answer:umbrella Car. Umbrella. Bike... Instance Segmentation Decode:girlsholding umbrellas. textinput GLIPv2 UnifiedOutputs imageinput Understanding tasks Figure 4: GLIPv2 , a pre-trained grounded VL understanding model, unifies various localization and VL understanding tasks. These two kinds of tasks mutually benefit each other and enable new capabilities such as language-guided detection/segmentation and grounded VQA/captioning.","title":"Appendix"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#a-visualization","text":"We provide a clearer illustration of GLIPv2 in Figure 4, which elegantly unifies various localization (object detection, instance segmentation) and VL understanding (phrase grounding, VQA and captioning) tasks. More visualizations of the predictions under various tasks from GLIPv2 are also provided to indicate the model\u2019s strength and capability. Please refer to Figure 5 for OD / Grounding, Figure 6 for Instance / Referring Image Segmentation, and Figure 7 for Grounded VL Understanding. Prompt: person. dog... backpack. umbrella. horse. toothbrush. Prompt: person. hairdryer...baseball bat.baseballglove. bottle. toothbrush. Prompt: person. cup.sink... microwave.refrigerator.bear. Prompt: Mounted officersin bright green jacketssit on their horses wearing helmets. Prompt: 2 couples are eating dinner on the floorbehind a large plant. Prompt: A woman figure skaterin a blue costumeholds her legby the blade of her skate Prompt: fish. jellyfish. penguin. puffin. shark. starfish. stingray Prompt: dog. person. Prompt: smoke. Figure 5: Visualization for OD / Grounding. Row 1: Object Detection on COCO. Row 2: Phrase Grounding on Flickr30K. Row 3: Object Detection on ODinW.","title":"A Visualization"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#b-tasks-and-dataset-descriptions","text":"B.1 (Language-guided) object detection and phrase grounding COCO.[ 8 ] The Microsoft Common Objects in Context dataset is a medium-scale object detection dataset. It has about 900k bounding box annotations for 80 object categories, with about 7.3 annotations per image. It is one of the most used object detection datasets, and its images are often used within other datasets (including VG and LVIS). Flickr30k-entities.[ 50 ] Given one or more phrases, which may be interrelated, the phrase grounding task is to provide a set of bounding boxes for each given phrase. We use the Flickr30k-entities dataset for this task, with the train/val/test splits as provided by [ 41 ] and evaluate our performance in terms of Recall. Flickr30K is included in the gold grounding data so we directly evaluate the models after pre-training as in MDETR [30]. We predict use any-box protocol specified in MDETR. ODinW.We use 13 datasets from Roboflow^2. Roboflow hosts over 30 datasets, and we exclude datasets that are too challenging (e.g., detecting different kinds of chess pieces) or impossible to solve without specific domain knowledge (e.g., understanding sign language). We provide the details of the 13 datasets we use in Table 7. We include the PASCAL VOC 2012 dataset as a reference dataset, as public baselines have been established on this dataset. For PascalVOC, we follow the convention (^2) https://public.roboflow.com/object-detection Prompt: person. hairdryer... baseballbat.baseballglove. bottle. toothbrush. Prompt: person.chair. dining table ... potted plant. vase. Prompt: person. cup.sink... microwave.refrigerator.bear. Prompt: green bush Prompt: windowhasaframe Prompt: brownlampshade Prompt: tissue.jacket....fork. pineapple.dinningtable. Prompt: donut. wineglass ... banana. pineapple. Prompt: person. teddybear... lollipop. flower. Figure 6: Visualization for Instance / Referring Image Segmentation. Row 1: Instance Segmentation on COCO Mask. Row 2: Instance Segmentation on LVIS. Row 3: Referring Image Segmentation on PhraseCut. Dataset Objects of Interest Train/Val/Test URL PascalVOC Common objects (PascalVOC 2012) 13690/3422/ https://public.roboflow.com/object-detection/pascal-voc-2012 AerialDrone Boats, cars, etc. from drone images 52/15/7 https://public.roboflow.com/object-detection/aerial-maritime Aquarium Penguins, starfish, etc. in an aquarium 448/127/63 https://public.roboflow.com/object-detection/aquarium Rabbits Cottontail rabbits 1980/19/10 https://public.roboflow.com/object-detection/cottontail-rabbits-video-dataset EgoHands Hands in ego-centric images 3840/480/480 https://public.roboflow.com/object-detection/hands Mushrooms Two kinds of mushrooms 41/5/5 https://public.roboflow.com/object-detection/na-mushrooms Packages Delivery packages 19/4/3 https://public.roboflow.com/object-detection/packages-dataset Raccoon Raccoon 150/29/17 https://public.roboflow.com/object-detection/raccoon Shellfish Shrimp, lobster, and crab 406/116/58 https://public.roboflow.com/object-detection/shellfish-openimages Vehicles Car, bus, motorcycle, truck, and ambulance 878/250/126 https://public.roboflow.com/object-detection/vehicles-openimages Pistols Pistol 2377/297/297 https://public.roboflow.com/object-detection/pistols/1 Pothole Potholes on the road 465/133/67 https://public.roboflow.com/object-detection/pothole Thermal Dogs and people in thermal images 142/41/20 https://public.roboflow.com/object-detection/thermal-dogs-and-people Table 7: 13 ODinW dataset statistics. We summarize the objects of interest for each dataset and report the image number of each split. and report on the validation set. For Pistols, there are no official validation or test sets so we split the dataset ourselves. B.2 (Language-guided) instance segmentation and referring image segmentation LVIS.[ 23 ] The Large Vocabulary Instance Segmentation dataset has over a thousand object categories, following a long-tail distribution with some categories having only a few examples. Similar to VG, LVIS uses the same images as in COCO, re-annotated with more object categories. In contrast to COCO, LVIS is a federated dataset, which means that only a subset of categories is annotated in each image. Annotations, therefore, include positive and negative object labels for objects that are present Figure 7: Visualization for Grounded VL Understanding. Row 1: Grounded VQA predictions (The model is given the input question and a placeholder token \u201c[MASK]\u201d for the answer. The model can ground not only entities in the question but also the implied answer entity). Row 2: Grounded captioning on COCO (The model can generate high-quality captions and, in the meantime, provide localization results. and categories that are not present, respectively. In addition, LVIS categories are not pairwise disjoint, such that the same object can belong to several categories. PhraseCut.[ 63 ] Besides object detection, we show that our GLIPv2 can be extended to perform segmentation by evaluating the referring expression segmentation task of the recent PhraseCut[ 63 ] which consists of images from VG, annotated with segmentation masks for each referring expression. These expressions comprise a wide vocabulary of objects, attributes and relations, making it a challenging benchmark. Contrary to other referring expression segmentation datasets, in PhraseCut the expression may refer to several objects and the model is expected to find all the corresponding instances. B.3 VQA and image captioning VQA.[ 20 ] requires the model to predict an answer given an image and a question. We conduct experiments on the VQA2.0 dataset, which is constructed using images from COCO. It contains 83k images for training, 41k for validation, and 81k for testing. We treat VQA as a classification problem with an answer set of 3,129 candidates following the common practice of this task. For our best models, we report test-dev and test-std scores by submitting to the official evaluation server.^3 COCO image captioning.[ 11 ] The goal of image captioning is to generate a natural language description given an input image. We evaluate GLIPv2 on COCO Captioning dataset and report BLEU-4, CIDEr, and SPICE scores on the Karparthy test split.","title":"B Tasks and dataset descriptions"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#c-difference-between-inter-image-region-word-contrastive-loss-with-other","text":"","title":"C Difference between inter-image region-word contrastive loss with other"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#region-word-losses","text":"As far as we know, up to the deadline (05/19/2022) for NeurIPS submission, there are only three published papers (VILD [ 21 ], RegionCLIP [ 72 ], and X-VLM [ 69 ]) that have the flavor of \"region (^3) https://eval.ai/challenge/830/overview Model Image Text Detection Pre-Train Data Grounding Caption GLIPv2 -T Swin-T BERT-Base O365 GoldG (no COCO) Cap4M GLIPv2 -B Swin-B CLIP O365, COCO, OpenImages, VG, ImageNetBoxes GoldG CC15M+ SBU GLIPv2 -H CoSwin-H [67] CLIP O365, COCO, OpenImages, VG, ImageNetBoxes GoldG CC15M+SBU Mask Head \u2013 \u2013 LVIS, COCO PhraseCut \u2013 Table 8: A detailed list of GLIPv2 model variants word\" loss applied over full batch. We discuss the difference between our work and the three aforementioned works in the following: All these three works use \u201cregion-sentence\" loss, i.e., the similarity between a region feature and the [CLS] token of a sentence, instead of true \"region-word\" loss used in GLIPv2 . As a result, none of these three works made use of the phrase grounding data, which may contain multiple entities in one sentence during their training. It is the most important point in GLIPv2 to use phrase grounding data and pseudo grounding data to train a unified grounded VL understanding model. GLIPv2 has carefully designed the positive label propagation in our inter-image region-word contrastive loss to mitigate the wrong assumption that \"every unpaired region-word pair is negative\". As far as we know, no previous work has mentioned this mechanism of positive label propagation before. There are some other differences. For example, in VILD, its \u201cregion-sentence loss\" is actually not a contrastive loss over full-batch but a classification loss over a fixed vocabulary per sample (see the definition ofLV iLD\u2212text). Upon all three points above, we believe that our inter-image region-word contrastive loss is novel and has a significant difference from previous works.","title":"\"region-word\" losses"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#d-training-details-and-hyperparamters","text":"D.1 Pre-training Pre-training data. There are three different types of data in pre-training 1) detection data 2) grounding data 3) caption data, as shown in Table 8. The detection data includes Object365 [ 54 ], COCO [ 8 ], OpenImages [ 33 ], Visual Genome [ 34 ], and ImageNetBoxes [ 16 ]. The grounding data includes GoldG, 0.8M human-annotated gold grounding data curated by MDETR [ 30 ] combining Flick30K, VG Caption, and GQA [ 29 ]. The Cap4M is a 4M image-text pairs collected from the web with boxes generated by GLIP-T(C) in [41], and CC (Conceptual Captions) + SBU (with 1M data). Implementation details. In Section 4 in the main paper, we introduced GLIPv2 -T, GLIPv2 -B, GLIPv2 -H, and we introduce the implementation details in the following. We pre-train GLIPv2 -T based on Swin-Tiny models with 32 GPUs and a batch size of 64. We use a base learning rate of 1 \u00d7 10 \u2212^5 for the language backbone (BERT-Base) and 1 \u00d7 10 \u2212^4 for all other parameters. The learning rate is stepped down by a factor of 0.1 at the 67% and 89% of the total 330,000 training steps. We decay the learning rate when the zero-shot performance on COCO saturates. The max input length is 256 tokens for all models. To optimize the results for object detection, we continue pre-training without the MLM loss for another 300,000 steps. We pre-train GLIPv2 -B based on Swin-Base models with 64 GPUs and a batch size of 64. We use a base learning rate of 1 \u00d7 10 \u2212^4 for all parameters, including the language backbone (CLIP-type pre-layernorm transformer). The learning rate is stepped down by a factor of 0.1 at the 67% and 89% of the total 1 million training steps. We decay the learning rate when the zero-shot performance on COCO saturates. The max input length is 256 tokens for all models. To optimize the results for object detection, we continue pre-training without the MLM loss for another 500,000 steps. We pre-train GLIPv2 -H based on the CoSwin-Huge model from Florence [ 67 ] with 64 GPUs and a batch size of 64. We use a base learning rate of 1 \u00d7 10 \u2212^4 for all parameters, including the language backbone (CLIP-type pre-layernorm transformer). The learning rate is stepped down by a factor of ...DyHead Module Fusion BERTLayer Image Encoder Text Encoder DyHead Module Fusion LayerBERT ... MaskHead prompt image GroundingHead MLM (0)Pre-training ...DyHead Module Fusion LayerBERT Image Encoder EncoderText DyHead Module Fusion prompt BERTLayer ... image GroundingHead (i)OD/Grounding ...DyHead Module Fusion BERTLayer EncoderImage EncoderText DyHead Module Fusion BERTLayer ... MaskHead prompt image GroundingHead (ii)Instance/Referring ImageSegmentation ...DyHead Module Fusion LayerBERT EncoderImage EncoderText DyHead Module Fusion prompt BERTLayer ... image GroundingHead DecodeAnswerr (iii)GroundedVisual QuestionAnswering ...DyHead Module Fusion BERTLayer EncoderImage Text Encoder DyHead Module Fusion LayerBERT ... image GroundingHead (iv)GroundedImageCaptioning (textencoderisuni-directional) \u2018a pictureof\u2019 CaptionHead Figure 8: The model architecture for pre-training (0), and downstream tasks (i) OD / Grounding (ii) Instance / Referring Image Segmentation (iii) Grounded Visual Question Answering (iv) Grounded Image Captioning. 0.1 at the 67% and 89% of the total 1 million training steps. We decay the learning rate when the zero-shot performance on COCO saturates. The max input length is 256 tokens for all models. We found that there isnoneed to continue pre-training without MLM loss for the huge model. Mask heads of GLIPv2 -T, GLIPv2 -B and GLIPv2 -H are pre-trained COCO, LVIS and PhraseCut, while freezing all the other model parameters. This mask head pre-training uses batch size 64, and goes through COCO for 24 epochs, LVIS for 24 epochs, and PhraseCut for 8 epochs, respectively. GLIPv2 uses Hourglass network [ 49 ] as instance segmentation head feature extractor, and utilizes the \"classification-to-matching\" trick to change the instance segmentation head linear prediction layer (outputsK-dimensional logits on each pixel) to a dot product layer between pixel visual features and the word features after VL fusion. GLIPv2 -T and GLIPv2 -B use a very basic Hourglass network for segmentation head feature extractor: only 1 scale and 1 layer, with hidden dimension 256. GLIPv2 -H uses a larger Hourglass network for segmentation head feature extractor: 2 scales and 4 layers, with hidden dimension 384. D.2 Downstream tasks OD / Grounding.When fine-tuning on COCO, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 24 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 5 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. For direct evaluation on LVIS, since LVIS has over 1,200 categories and they cannot be fit into one text prompt, so we segment them into multiple chunks, fitting 40 categories into one prompt and query the model multiple times with the different prompts. We find that models tend to overfit on LVIS during the course of pre-training so we closely monitor the performance on minival for all models and report the results with the best checkpoints in Table 2 in the main paper. For direct evaluation on Flickr30K, models may also overfit during the course of pre-training so we monitor the performance on the validation set for all models and report the results with the best checkpoints in Table 2 in the main paper. Instance segmentation / Referring Image Segmentation.Given the pre-trained model with pretrained mask head, we simply fine-tune theentirenetwork to get the task-specific fine-tuned models. For fine-tuning on COCO instance segmentation, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 24 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 5 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. For fine-tuning on LVIS instance segmentation, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 24 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 5 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. For fine-tuning on PhraseCut Referring Image segmentation, we use a base learning rate of 1 \u00d7 10 \u2212^5 and 12 training epochs for the pre-trained GLIPv2 -T model, and a base learning rate of 5 \u00d7 10 \u2212^6 and 3 training epochs for the pre-trained GLIPv2 -B and GLIPv2 -H models. (Grounded) VQA.To fine-tune GLIPv2 for VQA, we feed the image and question into the model and then take the output feature sequencePfrom the language side (after the VL fusion) and apply a \u2018attention pooling\u2019 layer to obtain a feature vectorPvqa. More specifically, the attention pooling layer applies a linear layer followed by softmax to obtain normalized scaler weights, and then these weights are used to compute a weighted sum to produce the feature vectorpvqa. This feature vector is then fed to a 2-layer MLP with GeLU activation [ 27 ] and a final linear layer to obtain the logits for the 3129-way classification.^4 Following standard practice [ 58 ], we use binary cross entropy loss to take account of different answers from multiple human annotators. Following VinVL [ 71 ], we train on the combination of train2014 + val2014 splits of the VQAv2 dataset, except for the reserved 2k dev split.^5. For the ablation studies we report the accuracy on this 2k dev split. Other than the conventional VQA setting, we also experimented a new \u2018grounded VQA\u2019 setup, which the model is required to not only predict the answer, but also ground the objects (predict bounding boxes in the image) mentioned in the question and answer text, see Figure 8(iii). Note that the language input is the question appended by a[MASK]token, and this[MASK]token should ground to the object if the answer is indeed an object in the image. The total training loss is summing the grounding loss (intra-image region-word contrastive loss) and the VQA loss described previously. (Grounded) Image Captioning.We fine-tune the pre-trained model on COCO Caption \u201cKarpathy\u201d training split. The training objective is uni-directional Language Modeling (LM), which maximizes the likelihood of the next word at each position given the image and the text sequence before it. To enable autoregressive generation, we use uni-directional attention mask for the text part, and prevent the image part from attending to the text part in the fusion layers. Although the training objective (LM) is different from that in pre-training (i.e., bi-directional MLM), we directly fine-tune the model for image captioning to evaluate its capability of generalizing to VL generation tasks. Our model is trained with cross entropy loss only, without using CIDEr optimization. For grounded image captioning (Figure 8), we add the grounding loss (intra-image region-word contrastive loss) in training, which is calculated in the same way as in pre-training. We use Flickr30K training split for this task. During inference, for each predicted text token, we get its dot product logits with all the region representations and choose the maximum as the associated bounding box.","title":"D Training details and hyperparamters"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#e-analysis-on-the-effect-of-different-language-encoders-and-pre-trained","text":"","title":"E Analysis on the effect of different language encoders and pre-trained"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#weights","text":"For GLIPv2 -T, we use the ImageNet pre-trained Swin-Transformer to initialize the image encoder and BERT-base-uncased to initialize the language encoder. For GLIPv2 -B, we use the pre-trained paired image-language encoder from UniCL (CLIP-like pre-training, https://github.com/microsoft/ UniCL) for initialization. We did an ablation study on the different language encoders (UniCL vs. BERT) and found that their results are nearly the same, as shown in Figure 9. Therefore, UniCL initialization does not skew the good localization performance. The main reason for us to keep the UniCL(CLIP-like) language encoder is due to its Pre-LayerNorm [ 64 ] operation. We find the UniCL(CLIP-like) language encoder with Pre-LayerNorm is more stable during the training compared with BERT, which uses Post-LayerNorm.","title":"weights"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#f-more-analysis-on-pre-training-data","text":"Table 5 in the main paper reports the last checkpoint results on GLIPv2 when we do the scaling up of pre-training data. As more weak image-text pair data (Cap) is involved in our training, it benefits both standard/in-domain (i.e., COCO, Flickr30K) and large-domain gap (i.e., ODinW, LVIS) tasks. Further adding the inter-image region-word contrastive helps when we are fixing the data at the same scale. For large-domain gap tasks, adding the inter-image region-word contrastive loss will further (^4) We experimented simpler pooling methods such as average pooling and[CLS]pooling [ 17 ] in the early experiments and found the attention pooling described above works better. (^5) 2000 images sampled from the val2014 split (and their corresponding question-answer pairs). Figure 9: GLIP-B with image encoder initialized from UniCL pre-trained image encoder, but with different language encoder initialization. Blue: language encoder initialized by Bert-Base, thus un-paired image-language pre-trained encoders. Yellow: language encoder initialized from UniCL pre-trained language encoder, thus paired UniCL pre-trained image-language encoders. From the results, we can see that the COCO zero-shot transfer results from two initializations are nearly the same. Similar results have been observed for other metrics, i.e., LVIS zero-shot AP, ODinW benchmark, and Flickr30k grounding performance. boost the model to learn better representation. To learn more scaling-up effects on various tasks under all the checkpoints for GLIP and GLIPv2 , see Figure 10. Given the considerable amount of improvement of GLIPv2 when the number of caption data increases from 0M to 12M, we hypothesize that it has potential to further grow by training on even larger-scale web image-text pairs.","title":"F More analysis on pre-training data"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#g-experiments-on-grounded-image-captioning","text":"The grounded captioning task requires the model to generate an image caption and also ground predicted phrases to object regions. The final predictions consist of (1) the text captions (2) predicted object regions, and (3) the grounding correspondence between the phrases and regions. Following the established benchmarks [ 48 , 74 ], we evaluate the caption metrics on COCO Captions and report the grounding metrics on Flick30K, as shown in Table 9. Model B@4COCO CaptionCIDEr SPICE R@1Flickr30K GroundingR@5 R@10 No Pretrain 35.4 115.3 21.2 77.0 92.9 95.7 +Lmlm 33.4 107.6 19.9 70.9 90.0 93.2 +Lloc+Lintra+Linter 36.6 120.3 21.6 80.8 94.9 96.7 GLIPv2 -T 36.5 119.8 21.6 80.8 94.4 96.5 GLIPv2 -B 37.4 123.0 21.9 81.0 94.5 96.5 Table 9: Grounded image captioning results on the COCO Caption, and Flickr30K Entities. We report BLEU@4, CIDer, and SPICE metrics for caption evaluation, and we use R@1, R@5, R@10 for grounding evaluation.","title":"G Experiments on grounded image captioning"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#h-inference-speed","text":"We test the inference speed for GLIPv2 on V100 with batch size 1 and show its comparison to MDETR, as shown in Table 10. +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M +0M +Cap4M +Cap1 2 M +Cap48M +0M +Cap 4 M +Cap12M Figure 10: Pre-train data scale up on Base-scale model. Left: GLIP, Right: GLIPv2 ; Row 1: COCO minival, Row 2: ODinW test split, Row 3: LVIS minival, Row 4: Flick30K test.","title":"H Inference speed"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#i-figure-reference","text":"We provided the original sources of the images that are used in our paper in the following. All datasets above were collected by the creators (cited) and consent for any personally identifiable information (PII) was ascertained by the authors where necessary. Figure 1 in the main paper The top left and the bottom middle figures are the 281759.jpg in COCO val set; The left right images are (from top to down: (1) 2588.jpg in ODinW Aquarium test set. (2) 13923.jpg in LVIS val set. (3) 132690.jpg in VQA2.0 val set (question id is 132690002). (4) 462565.jpg in COCO Caption val set. Model Object Detection (COCO) Phrase Grounding (Flick30K) Referring Expression Segmentation (PhraseCut) MDETR R101 [30] \u2013 9.31 3.80 MDETR EffB3 [30] \u2013 11.20 3.98 MDETR EffB5 [30] \u2013 9.15 \u2013 GLIPv2 -T 4.12 3.74 2.26 GLIPv2 -B 3.01 3.23 2.39 GLIPv2 -H 1.21 1.13 0.89 Table 10: Model inference speed on various tasks. We report FPS, which is the number of images processed per second per GPU (higher is better). Figure 2 in the main paper The top left figure is the 209297.jpg in COCO train set; The bottom left figure is the 9378.jpg in COCO val set. Figure 4 in the Appendix Same as Figure 1. The top left and the bottom middle figures are the 281759.jpg in COCO val set. Figure 5 in the Appendix Row 1 (from left to right): (1) 439715.jpg in COCO val set. (2) 6471.jpg in COCO val set. (3) 13923.jpg in COCO val set; Row 2: (1) 5521996.jpg in Flickr30K val set. (2) 764507.jpg in Flickr30K val set. (3) 7520721.jpg in Flick30K val set; Row 3: (1) 2588.jpg in ODinW Aquarium test set. (2) 143.jpg in Thermal val set. (3) ck0l9j6n6oqjo0848ps5blk3b.jpg in WildFire val set. Figure 6 in the Appendix Row 1 (from left to right): (1) 13923.jpg in COCO val set. (2) 6471.jpg in COCO val set. (3) 7574.jpg in COCO val set; Row 2: (1) 117320.jpg in LVIS val set. (2) 2587.jpg in LVIS val set. (3) 211120.jpg in LVIS val set; Row 3: (1) 4744.jpg in PhraseCut test set. (2) 4744.jpg in PhraseCut val set. (3) 567.jpg in PhraseCut train set. Figure 7 in the Appendix Row 1 (from left to right): (1) 486.jpg in VQA2.0 val set (question id is 486002). (2) 262746.jpg in VQA2.0 val set (question id is 262746002). (3) 132690.jpg in VQA2.0 val set (question id is 132690002); Row 2: (1) 391895.jpg in COCO Caption val set. (2) 462565.jpg in COCO Caption val set. (3) 579056.jpg in COCO Caption val set.","title":"I Figure Reference"},{"location":"Models/MultiModal/PN-2206.05826-Appx/#j-all-results-for-odinw","text":"We report the per-dataset performance under 0,1,3,5,10-shot and full data as well as prompt tuning, and full-model tuning in Table 11 and Table 12 (on the next page). Model PascalVOC AerialDrone Aquarium Rabbits EgoHands Mushrooms Packages Raccoon Shellfish Vehicles Pistols Pothole Thermal Avg GLIP-T 56.2 12.5 18.4 70.2 50.0 73.8 72.3 57.8 26.3 56.0 49.6 17.7 44.1 46.5 GLIP-L 61.7 7.1 26.9 75.0 45.5 49.0 62.8 63.3 68.9 57.3 68.6 25.7 66.0 52.1 GLIPv2 -T 57.6 10.5 18.4 71.4 52.7 77.7 67.7 58.8 27.8 55.6 60.1 20.0 52.4 48.5 GLIPv2 -B 62.8 8.6 18.9 73.7 50.3 83.0 68.6 61.6 56.0 53.8 67.8 32.6 53.8 54.2 GLIPv2 -H 66.3 10.9 30.4 74.6 55.1 52.1 71.3 63.8 66.2 57.2 66.4 33.8 73.3 55.5 Table 11: Zero-shot performance on 13 ODinW datasets. Model Shot Tune PascalVOC AerialDrone Aquarium Rabbits EgoHands Mushrooms PackagesRaccoon Shellfish Vehicles Pistols Pothole Thermal Avg DyHeadO365 1 Full 25.8\u00b13.0 16.5\u00b11.8 15.9\u00b12.7 55.7\u00b16.044.0\u00b13.6 66.9\u00b13.9 54.2\u00b15.7 50.7\u00b17.714.1\u00b13.633.0\u00b111.0 11.0\u00b16.58.2\u00b14.1 43.2\u00b110.033.8\u00b13.5 DyHeadO365 3 Full 40.4\u00b11.0 20.5\u00b14.0 26.5\u00b11.3 57.9\u00b12.053.9\u00b12.5 76.5\u00b12.3 62.6\u00b113.352.5\u00b15.022.4\u00b11.747.4\u00b12.0 30.1\u00b16.919.7\u00b11.557.0\u00b12.3 43.6\u00b11.0 DyHeadO365 5 Full 43.5\u00b11.0 25.3\u00b11.8 35.8\u00b10.5 63.0\u00b11.056.2\u00b13.9 76.8\u00b15.9 62.5\u00b18.7 46.6\u00b13.128.8\u00b12.251.2\u00b12.2 38.7\u00b14.121.0\u00b11.453.4\u00b15.2 46.4\u00b11.1 DyHeadDyHeadO365O365 All 10 FullFull 46.653.3\u00b10.3 29.028.4\u00b12.8 41.749.5\u00b11.0 65.273.5\u00b12.562.577.9\u00b10.8 85.484.0\u00b12.2 67.969.2\u00b14.5 47.956.2\u00b12.228.643.6\u00b15.053.859.2\u00b11.0 39.268.9\u00b14.927.953.7\u00b12.364.173.7\u00b12.6 50.860.8\u00b11.3 GLIP-T 1 Prompt 54.4\u00b10.9 15.2\u00b11.4 32.5\u00b11.0 68.0\u00b13.260.0\u00b10.7 75.8\u00b11.2 72.3\u00b10.0 54.5\u00b13.924.1\u00b13.059.2\u00b10.9 57.4\u00b10.618.9\u00b11.856.9\u00b12.7 49.9\u00b10.6 GLIP-TGLIP-T 35 PromptPrompt 56.858.5\u00b1\u00b10.80.5 18.918.2\u00b1\u00b13.60.1 37.641.0\u00b1\u00b11.61.2 72.471.8\u00b1\u00b10.52.462.865.7\u00b1\u00b11.30.7 85.487.5\u00b1\u00b12.82.2 64.572.3\u00b1\u00b14.60.0 69.160.6\u00b1\u00b11.82.222.031.4\u00b1\u00b10.94.262.761.0\u00b1\u00b11.11.8 56.154.4\u00b1\u00b10.60.625.932.6\u00b1\u00b10.71.463.866.3\u00b1\u00b14.82.8 53.755.5\u00b1\u00b11.30.5 GLIP-T 10 Prompt 59.7\u00b10.7 19.8\u00b11.6 44.8\u00b10.9 72.1\u00b12.065.9\u00b10.6 87.4\u00b11.1 72.3\u00b10.0 57.5\u00b11.230.0\u00b11.462.1\u00b11.4 57.8\u00b10.933.5\u00b10.173.1\u00b11.4 56.6\u00b10.2 GLIP-T All Prompt 66.4 27.6 50.9 70.6 73.3 88.1 67.7 64.0 40.3 65.4 68.3 50.7 78.5 62.4 GLIP-T 1 Full 54.8\u00b12.0 18.4\u00b11.0 33.8\u00b11.1 70.1\u00b12.964.2\u00b11.8 83.7\u00b13.0 70.8\u00b12.1 56.2\u00b11.822.9\u00b10.256.6\u00b10.5 59.9\u00b10.418.9\u00b11.354.5\u00b12.7 51.1\u00b10.1 GLIP-T 3 Full 58.1\u00b10.5 22.9\u00b11.3 40.8\u00b10.9 65.7\u00b11.666.0\u00b10.2 84.7\u00b10.5 65.7\u00b12.8 62.6\u00b11.427.2\u00b12.761.9\u00b11.8 60.7\u00b10.227.1\u00b11.270.4\u00b12.5 54.9\u00b10.2 GLIP-T 5 Full 59.5\u00b10.4 23.8\u00b10.9 43.6\u00b11.4 68.7\u00b11.366.1\u00b10.6 85.4\u00b10.4 72.3\u00b10.0 62.1\u00b12.027.3\u00b11.261.0\u00b11.8 62.7\u00b11.634.5\u00b10.566.6\u00b12.3 56.4\u00b10.4 GLIP-TGLIP-T All 10 FullFull 59.162.3\u00b11.3 26.331.2\u00b11.1 46.352.5\u00b11.6 67.370.8\u00b11.567.178.7\u00b10.7 87.888.1\u00b10.5 72.375.6\u00b10.0 57.761.4\u00b11.734.651.4\u00b11.765.465.3\u00b11.4 61.671.2\u00b11.039.358.7\u00b11.074.776.7\u00b12.3 58.464.9\u00b10.2 GLIP-L 1 Prompt 62.8\u00b10.4 18.0\u00b11.8 37.4\u00b10.3 71.9\u00b12.468.9\u00b10.1 81.8\u00b13.4 65.0\u00b12.8 63.9\u00b10.470.2\u00b11.267.0\u00b10.4 69.3\u00b10.127.6\u00b10.469.8\u00b10.6 59.5\u00b10.4 GLIP-L 3 Prompt 65.0\u00b10.5 21.4\u00b11.0 43.6\u00b11.1 72.9\u00b10.770.4\u00b10.1 91.4\u00b10.7 57.7\u00b13.7 70.7\u00b11.169.7\u00b10.962.6\u00b10.8 67.7\u00b10.436.2\u00b11.168.8\u00b11.5 61.4\u00b10.3 GLIP-LGLIP-L 105 PromptPrompt 65.665.9\u00b1\u00b10.30.2 19.923.4\u00b1\u00b11.62.6 47.750.3\u00b1\u00b10.70.7 73.773.6\u00b1\u00b10.70.770.671.8\u00b1\u00b10.30.3 86.886.5\u00b1\u00b10.50.3 64.670.5\u00b1\u00b10.71.1 69.469.0\u00b1\u00b13.30.568.069.4\u00b1\u00b11.32.467.870.8\u00b1\u00b11.51.2 68.368.8\u00b1\u00b10.30.636.639.3\u00b1\u00b11.60.971.974.9\u00b1\u00b10.62.1 62.464.2\u00b1\u00b10.50.4 GLIP-L All Prompt 72.9 23.0 51.8 72.0 75.8 88.1 75.2 69.5 73.6 72.1 73.7 53.5 81.4 67.9\u00b10.0 GLIP-L 1 Full 64.8\u00b10.6 18.7\u00b10.6 39.5\u00b11.2 70.0\u00b11.570.5\u00b10.2 69.8\u00b118.0 70.6\u00b14.0 68.4\u00b11.271.0\u00b11.365.4\u00b11.1 68.1\u00b10.228.9\u00b12.972.9\u00b14.7 59.9\u00b11.4 GLIP-L 3 Full 65.6\u00b10.6 22.3\u00b11.1 45.2\u00b10.4 72.3\u00b11.470.4\u00b10.4 81.6\u00b113.3 71.8\u00b10.3 65.3\u00b11.667.6\u00b11.066.7\u00b10.9 68.1\u00b10.337.0\u00b11.973.1\u00b13.3 62.1\u00b10.7 GLIP-L 5 Full 66.6\u00b10.4 26.4\u00b12.5 49.5\u00b11.1 70.7\u00b10.271.9\u00b10.2 88.1\u00b10.0 71.1\u00b10.6 68.8\u00b11.268.5\u00b11.770.0\u00b10.9 68.3\u00b10.539.9\u00b11.475.2\u00b12.7 64.2\u00b10.3 GLIP-LGLIP-L All 10 FullFull 66.469.6\u00b10.7 32.032.6\u00b11.4 52.356.6\u00b11.1 70.676.4\u00b10.772.479.4\u00b10.3 88.188.1\u00b10.0 67.167.1\u00b13.6 64.769.4\u00b13.169.465.8\u00b11.471.571.6\u00b10.8 68.475.7\u00b10.744.360.3\u00b10.676.383.1\u00b11.1 64.968.9\u00b10.7 GLIPv2 -T 1 Prompt 51.2\u00b10.3 17.7\u00b11.2 34.2\u00b10.1 68.7\u00b11.267.3\u00b10.9 83.7\u00b12.1 68.1\u00b11.7 53.4\u00b10.230.0\u00b10.959.0\u00b10.1 60.0\u00b10.321.9\u00b10.266.5\u00b10.7 52.4\u00b10.5 GLIPv2 -T 3 Prompt 66.6\u00b10.2 11.5\u00b10.7 37.2\u00b11.0 71.7\u00b10.370.1\u00b10.4 45.7\u00b10.1 57.7\u00b11.2 69.7\u00b11.542.7\u00b10.467.5\u00b10.9 65.6\u00b11.036.7\u00b11.269.2\u00b11.2 55.6\u00b10.4 GLIPv2 -T GLIPv2 -T 105 PromptPrompt 58.959.9\u00b1\u00b11.20.4 17.421.6\u00b1\u00b10.62.0 42.843.7\u00b1\u00b10.40.3 72.674.3\u00b1\u00b10.50.466.168.2\u00b1\u00b10.20.7 84.988.1\u00b1\u00b10.80.1 69.772.0\u00b1\u00b10.60.9 65.560.0\u00b1\u00b12.10.435.635.6\u00b1\u00b10.81.262.866.1\u00b1\u00b10.90.6 59.861.0\u00b1\u00b10.20.335.542.8\u00b1\u00b10.90.474.470.9\u00b1\u00b10.23.2 57.458.8\u00b1\u00b10.40.5 GLIPv2 -T All Prompt 67.4 22.3 50.5 74.3 73.4 85.5 74.7 65.8 53.7 67.4 68.9 52.3 83.7 64.8\u00b10.0 GLIPv2 -T 1 Full 64.8\u00b10.6 18.7\u00b10.6 39.5\u00b11.2 70.0\u00b11.570.5\u00b10.2 69.8\u00b118.0 70.6\u00b14.0 68.4\u00b11.271.0\u00b11.365.4\u00b11.1 68.1\u00b10.228.9\u00b12.972.9\u00b14.7 52.8\u00b11.4 GLIPv2 -T 3 Full 53.9\u00b10.1 17.8\u00b10.7 42.7\u00b11.1 73.1\u00b11.065.9\u00b10.2 84.7\u00b13.4 69.7\u00b10.8 60.7\u00b11.328.8\u00b10.861.7\u00b11.3 60.6\u00b10.235.5\u00b10.468.3\u00b11.7 55.6\u00b10.7 GLIPv2 -T 5 Full 58.9\u00b10.2 17.4\u00b11.1 42.8\u00b11.3 72.6\u00b10.766.1\u00b10.6 84.9\u00b10.9 69.7\u00b10.3 65.5\u00b11.035.6\u00b10.962.8\u00b10.3 59.8\u00b10.235.5\u00b11.274.4\u00b12.1 57.4\u00b10.4 GLIPv2 -T GLIPv2 -T All 10 FullFull 57.666.4\u00b11.0 27.630.2\u00b11.2 49.152.5\u00b11.0 70.474.8\u00b10.569.280.0\u00b10.2 88.188.1\u00b10.0 73.174.3\u00b12.3 58.063.7\u00b12.842.954.4\u00b11.264.863.0\u00b10.2 62.173.0\u00b10.939.960.1\u00b10.471.683.5\u00b10.8 59.766.5\u00b10.3 GLIPv2 -B 1 Prompt 68.7\u00b10.1 19.9\u00b10.3 38.4\u00b10.8 68.5\u00b11.068.6\u00b10.8 87.7\u00b13.0 69.3\u00b11.7 68.5\u00b10.455.2\u00b10.365.7\u00b10.7 67.2\u00b10.134.8\u00b10.869.6\u00b10.4 60.4\u00b10.3 GLIPv2 -B 3 Prompt 67.2\u00b10.6 22.2\u00b10.3 46.5\u00b10.9 71.2\u00b10.870.9\u00b10.1 86.9\u00b10.2 67.7\u00b11.8 63.7\u00b12.346.9\u00b10.868.1\u00b10.4 67.4\u00b10.947.9\u00b11.078.9\u00b11.7 62.0\u00b10.5 GLIPv2 -B GLIPv2 -B 105 PromptPrompt 68.969.4\u00b1\u00b11.00.7 25.721.8\u00b1\u00b10.41.3 50.548.7\u00b1\u00b10.90.2 73.871.3\u00b1\u00b11.50.269.771.0\u00b1\u00b10.60.7 84.988.1\u00b1\u00b10.30.4 69.368.6\u00b1\u00b10.70.7 65.873.5\u00b1\u00b11.60.365.761.5\u00b1\u00b11.01.969.269.3\u00b1\u00b10.30.2 67.568.6\u00b1\u00b10.70.734.041.3\u00b1\u00b10.20.273.175.2\u00b1\u00b10.61.3 62.963.8\u00b1\u00b10.40.3 GLIPv2 -B All Prompt 71.9 26.1 50.6 74.5 73.5 86.9 74.9 71.0 71.6 71.0 72.4 50.2 80.5 67.3\u00b10.0 GLIPv2 -B 1 Full 67.8\u00b10.4 18.7\u00b10.3 44.2\u00b10.9 71.4\u00b10.370.4\u00b11.2 87.9\u00b17.3 66.1\u00b12.4 68.9\u00b11.160.6\u00b11.668.1\u00b10.6 69.0\u00b10.735.1\u00b10.968.9\u00b12.1 61.2\u00b10.6 GLIPv2 -B 3 Full 68.1\u00b10.2 25.7\u00b10.4 46.4\u00b11.6 69.8\u00b11.371.3\u00b11.2 88.0\u00b13.4 68.6\u00b10.9 69.8\u00b11.760.1\u00b10.368.4\u00b11.9 68.5\u00b10.639.8\u00b10.871.4\u00b12.1 62.8\u00b10.8 GLIPv2 -B 5 Full 68.6\u00b11.0 21.6\u00b10.6 46.7\u00b10.7 70.9\u00b10.971.0\u00b11.2 88.1\u00b13.7 69.1\u00b10.2 71.8\u00b11.061.5\u00b10.768.7\u00b10.2 69.3\u00b10.840.2\u00b11.074.8\u00b12.8 63.3\u00b10.6 GLIPv2 -B GLIPv2 -B All 10 FullFull 67.471.1\u00b11.3 22.332.6\u00b11.1 50.557.5\u00b10.7 74.373.6\u00b10.473.480.0\u00b10.4 85.588.1\u00b10.1 74.774.9\u00b10.9 65.868.2\u00b12.453.770.6\u00b11.167.471.2\u00b10.9 68.976.5\u00b10.752.358.7\u00b10.683.779.6\u00b13.2 64.669.4\u00b10.3 GLIPv2 -H 1 Prompt 68.3\u00b10.6 16.4\u00b10.6 45.8\u00b10.3 72.0\u00b10.567.9\u00b10.9 89.3\u00b13.2 69.3\u00b11.7 67.9\u00b10.866.3\u00b11.968.0\u00b10.7 66.8\u00b10.333.9\u00b10.470.7\u00b11.5 61.4\u00b10.5 GLIPv2 -H 3 Prompt 69.5\u00b10.7 25.9\u00b10.2 50.0\u00b11.2 75.4\u00b11.470.1\u00b10.9 85.9\u00b12.5 69.3\u00b10.7 70.8\u00b11.266.4\u00b10.868.0\u00b11.2 68.8\u00b10.934.0\u00b10.372.7\u00b11.6 63.6\u00b10.6 GLIPv2 -H GLIPv2 -H 105 PromptPrompt 69.466.0\u00b1\u00b10.70.7 22.027.5\u00b1\u00b10.61.3 49.153.8\u00b1\u00b10.10.2 70.774.6\u00b1\u00b11.00.273.080.1\u00b1\u00b10.50.7 88.187.4\u00b1\u00b10.80.4 70.369.3\u00b1\u00b10.40.7 71.266.0\u00b1\u00b11.80.362.951.2\u00b1\u00b11.41.970.167.2\u00b1\u00b10.30.2 68.372.8\u00b1\u00b10.60.742.758.3\u00b1\u00b10.60.274.376.5\u00b1\u00b10.51.3 63.965.5\u00b1\u00b10.70.6 GLIPv2 -H All Prompt 71.2 31.1 57.1 75.0 79.8 88.1 68.6 68.3 59.6 70.9 73.6 61.4 78.6 69.1\u00b10.0 GLIPv2 -H 1 Full 67.8\u00b10.6 17.3\u00b10.6 50.7\u00b10.3 63.8\u00b10.567.3\u00b10.9 89.4\u00b13.2 69.3\u00b11.7 68.2\u00b10.866.6\u00b11.966.8\u00b10.7 67.0\u00b10.334.0\u00b10.475.0\u00b11.5 61.7\u00b10.5 GLIPv2 -H 3 Full 62.3\u00b10.2 29.1\u00b10.4 53.8\u00b11.6 72.7\u00b11.378.4\u00b11.2 85.8\u00b13.4 68.6\u00b10.9 60.7\u00b11.743.6\u00b10.365.9\u00b11.9 72.2\u00b10.655.9\u00b10.881.1\u00b12.1 64.1\u00b10.8 GLIPv2 -H 5 Full 66.4\u00b11.0 23.4\u00b10.6 50.7\u00b10.7 73.9\u00b10.971.8\u00b11.2 84.2\u00b13.7 71.2\u00b10.2 68.1\u00b11.067.4\u00b10.770.8\u00b10.2 65.8\u00b10.854.6\u00b11.075.6\u00b12.8 64.4\u00b10.6 GLIPv2 -H GLIPv2 -H All 10 FullFull 67.374.4\u00b11.3 31.636.3\u00b11.1 52.458.7\u00b10.7 71.377.1\u00b10.480.079.3\u00b10.4 88.188.1\u00b10.1 72.974.3\u00b10.9 56.973.1\u00b12.452.270.0\u00b11.165.472.2\u00b10.9 73.972.5\u00b10.761.058.3\u00b10.684.081.4\u00b13.2 65.970.4\u00b10.3 Table 12: Per-dataset performance of DyHead, GLIP-T, GLIP-L, and GLIPv2 -T, GLIPv2 -B and GLIPv2 -H. For PascalVOC, we report the mAP (IoU=0.50:0.95) using the COCO evaluation script, to be consistent with other 12 datasets. \u201cPrompt\u201d denotes prompt tuning. \u201cFull\u201d denotes full-model tuning.","title":"J All results for ODinW"},{"location":"Models/MultiModal/PN-2206.05836/","text":"GLIPv2: Unifying Localization and VL Understanding \u4f5c\u8005: Haotian Zhang | Pengchuan Zhang | Xiaowei Hu | Yen-Chun Chen | Liunian Harold Li | Xiyang Dai | Lijuan Wang | Lu Yuan | Jenq-Neng Hwang | Jianfeng Gao \u673a\u6784: \u534e\u76db\u987f\u5927\u5b66 | Meta AI | \u5fae\u8f6f | UCLA \u65f6\u95f4: 2022-06-12 -> 2022-10-11 \u53d1\u8868: NeurIPS 2022 \u9884\u5370: arXiv:2206.05836v2 \u9886\u57df: #\u8ba1\u7b97\u673a\u89c6\u89c9 \u6807\u7b7e: #\u5f00\u6e90 \u5f15\u7528: 77 \u7bc7 \u4ee3\u7801: Github cur{ color:red; } term{ color:blue; } abbv{ color:orange; } Abstract \u6458\u8981 We present GLIPv2 , a grounded VL understanding model, that serves both localization tasks (e.g., object detection, instance segmentation) and Vision-Language (VL) understanding tasks (e.g., VQA, image captioning). GLIPv2 elegantly unifies localization pre-training and Vision-Language Pre-training (VLP) with three pre-training tasks: phrase grounding as a VL reformulation of the detection task, region-word contrastive learning as a novel region-word level contrastive learning task, and the masked language modeling. This unification not only simplifies the previous multi-stage VLP procedure but also achieves mutual benefits between localization and understanding tasks. Experimental results show that a single GLIPv2 model (all model weights are shared) achieves near SoTA performance on various localization and understanding tasks. The model also shows (1) strong zero-shot and few-shot adaption performance on open-vocabulary object detection tasks and (2) superior grounding capability on VL understanding tasks. Code is released at Github. 1. Introduction \u4ecb\u7ecd Recently, a general interest arises in building general-purpose vision systems [ 24 , 28 , 66 , 47 ], also called vision foundation models [ 6 , 67 ], that solve various vision tasks simultaneously, such as image classification [ 35 ], object detection [ 44 ], and Visual-Language (VL) understanding [ 3 , 11 , 32 ]. Of particular interest, is the unification betweenlocalizationtasks (e.g., object detection [ 44 ] and segmentation [ 8 , 23 ]) and VLunderstandingtasks (e.g., VQA [ 3 ] and image captioning [ 11 ]). Localization pre-training benefits VL tasks [ 1 , 70 ], and the \u201clocalization->VLP\u201d two-stage pretraining procedure [ 46 , 57 , 13 , 56 , 39 , 37 , 75 , 42 , 40 ] is the common practice in VL community. A long-standing challenge is the unification of localization and understanding, which aims atmutual benefit between these two kinds of tasks, simplified pre-training procedure, and reduced pre-training cost. However, these two kinds of tasks appear to be dramatically different: localization tasks are visiononly and require fine-grained output (e.g., bounding boxes or pixel masks), while VL understanding tasks emphasize fusion between two modalities and require high-level semantic outputs (e.g., answers or captions). [ 24 , 28 , 66 ] have made early attempts at unifying these tasks in a straightforward multi-task manner, where a low-level visual encoder is shared across tasks, and two separate high-level branches are designed for localization and VL understanding, respectively. The localization tasks are still vision-only and do not benefit from the rich semantics in vision-language data. As a result, such unified models see the marginal mutual benefit or even performance degradation [ 28 ] compared with task-specific models. In this paper, we identify \u201cVL grounding\u201d as a \u201cmeta\u201d-capability for localization and understanding capabilities. VL grounding involves not onlyunderstandingan input sentence but alsolocalizingthe mentioned entities in the image (see an example in Figure 1). We build agrounded VL understandingmodel ( GLIPv2 ) as a unified model for localization and VL understanding tasks. Localization + VL understanding = grounded VL understanding Localization tasks involve both localization and semantic classification, where classification can be cast as a VL understanding problem using theclassification-to-matchingtrick (Section 3.1). Therefore, we reformulate localization tasks as VL grounding tasks, in which the language input is a synthesized sentence as the concatenation of category names [ 41 ]. Localization data are turned into VL grounding data, accordingly. The massive VL understanding data (image-text pairs) can be easily turned into VL grounding data in a self-training manner [ 41 ]. Therefore, GLIPv2 has a unified pre-training process: all task data are turned into grounding data and GLIPv2 is pre-trained to perform grounded VL understanding. A stronger VL grounding task inter-image region-word contrastive learning GLIP [ 41 ] proposes the phrase grounding task as its pre-training task, which we argue is an easy task and does not fully utilize data information. For example, in the VL grounding task in Figure 1, the phrase grounding task only requires the model to match a given image region to one of the three phrases in the text input, i.e., \u201cgreen, pink striped, or plain white umbrella?\u201d. This 1-in-3 choice is very easy, only requires color understanding, but loses lots of information in this grounding data: the umbrellas are not any other colors, like black, yellow, etc; objects in those regions are umbrellas but not any other categories, like car, bike, etc. From a contrastive learning view, this phrase grounding task only has two negatives. More negatives can be created from this annotation and thus enable stronger contrastive learning. In GLIPv2 , we introduce the novel inter-image region-word contrastive learning task, which leverages phrases from other sentences in the same batch as potential negatives, as another much stronger VL grounding task. This new region-word contrastive loss enables GLIPv2 to learn more discriminative region-word features and demonstrates improvements over all downstream tasks. GLIPv2 achieves mutual benefit between localization and VL understanding 1) Experimental results (Table 2) show that a single GLIPv2 model (all model weights are shared) achieves near SoTA performance on various localization and understanding tasks. 2) Thanks to semantic-rich annotations from the image-text data, GLIPv2 shows superior zero-shot and few-shot transfer learning ability to open-world object detection and instance segmentation tasks, evaluated on the LVIS dataset and the \"Object Detection in the Wild (ODinW)\" benchmark. 3) GLIPv2 enables language-guided detection and segmentation ability, and achieves new SoTA performance on the Flick30K-entities phrase grounding and PhraseCut referring image segmentation tasks. 4) Inherently a grounding model, GLIPv2 leads to VL understanding models with strong grounding ability, which are self-explainable and easy to debug. For example, GLIPv2 , when GLIPv2 is finetuned on VQA, it can answer questions while localizing mentioned entities (see Figure 1 and Section 4.4). 2. Related Work \u76f8\u5173\u5de5\u4f5c Localization Models \u5b9a\u4f4d\u6a21\u578b Traditionally, localization tasks such as object detection and segmentation are single-modality and output bounding boxes or pixel masks [ 52 , 43 , 26 , 14 , 53 , 10 , 9 ]. One challenge of these single-modality models lies in generalization to rare and novel concepts: it is hard to collect localization data that cover many rare categories [ 23 ]. A long line of research focuses on this generalization problem, under the name of zero-shot [ 4 , 76 , 7 , 77 ], weakly-supervised [ 19 , 5 , 61 ], or open-vocabulary [ 68 , 22 ] localization. \u4f20\u7edf\u7684\u5b9a\u4f4d\u4efb\u52a1\u5982\u76ee\u6807\u68c0\u6d4b\u548c\u5206\u5272\u662f\u5355\u6a21\u6001\u5e76\u8f93\u51fa\u8fb9\u754c\u6846\u6216\u50cf\u7d20\u63a9\u819c. \u8fd9\u4e9b\u5355\u6a21\u6001\u6a21\u578b\u7684\u4e00\u4e2a\u6311\u6218\u5728\u4e8e\u5bf9\u7a00\u6709\u7684\u548c\u65b0\u9896\u6982\u5ff5\u7684\u63a8\u5e7f: \u5f88\u96be\u6536\u96c6\u6db5\u76d6\u8bb8\u591a\u7a00\u6709\u7c7b\u522b\u7684\u5b9a\u4f4d\u6570\u636e. \u4e00\u957f\u4e32\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u8fd9\u4e2a\u6cdb\u5316\u95ee\u9898\u4e0a, \u4ee5\u96f6\u6837\u672c, \u5f31\u76d1\u7763\u6216\u5f00\u653e\u8bcd\u6c47\u8868\u5b9a\u4f4d\u4e3a\u540d. Built upon MDETR[^30] and GLIP[^41], GLIPv2 converts localization tasks into a grounded vision-language task using the classification-to-matching trick (Section 3). Thus GLIPv2 can learn from the semantic-rich vision-language data and shows strong performance on open-vocabulary localization tasks. \u57fa\u4e8e MDETR \u548c GLIP, GLIPv2 \u4f7f\u7528\u5206\u7c7b\u5339\u914d\u6280\u5de7 (\u7b2c3\u8282) \u5c06\u5b9a\u4f4d\u4efb\u52a1\u8f6c\u6362\u4e3a Grounded \u89c6\u89c9\u8bed\u8a00\u4efb\u52a1. \u56e0\u6b64, GLIPv2 \u53ef\u4ee5\u4ece\u8bed\u4e49\u4e30\u5bcc\u7684\u89c6\u89c9\u8bed\u8a00\u6570\u636e\u4e2d\u5b66\u4e60, \u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u8868\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd. Vision-Language Understanding Models \u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6a21\u578b Vision-language (VL) understanding tasks such as VQA[^3], image captioning [ 11 ], and image-text retrieval [ 31 ] involve understanding visual semantics and how they are expressed in natural language. Many VL models (e.g., BUTD) [ 2 , 70 ] rely on a pre-trained localization model as their visual encoder; the downside is the pro-longed \u201clocalization->VLP\u201d pre-training pipeline [ 46 , 57 , 13 , 56 , 39 , 37 , 75 , 42 , 40 ]. In contrast, GLIPv2 simplifies the pre-training pipeline and enables grounded VL understanding for better interpretability (Section 4.4). \u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6a21\u578b\u4f8b\u5982 VQA, image captioning \u548c image-text retrieval \u6d89\u53ca\u5230\u7406\u89e3\u89c6\u89c9\u8bed\u4e49\u548c\u5982\u4f55\u4ee5\u81ea\u7136\u8bed\u8a00\u8868\u793a\u5b83\u4eec. \u8bb8\u591a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5982 BUTD \u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u5b9a\u4f4d\u6a21\u578b\u4f5c\u4e3a\u5176\u89c6\u89c9\u7f16\u7801\u5668, \u5e95\u4fa7\u662f\u957f\u671f\u7684 \"\u5b9a\u4f4d\u2192VLP\" \u9884\u8bad\u7ec3\u8fc7\u7a0b. \u76f8\u6bd4\u4e4b\u4e0b, GLIPv2 \u7b80\u5316\u4e86\u9884\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u4f7f\u5f97 grounded \u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6709\u4e86\u66f4\u5f3a\u7684\u89e3\u91ca\u6027. Unifying localization and understanding [24, 28, 66] made pioneering efforts in unifying localization and understanding. However, localization tasks are still treated as single-modality tasks, while VL tasks involve two modalities. The unification is achieved via straightforward multi-tasking: a low-level visual encoder is shared across tasks and two separate branches are designed for localization and VL understanding. Such unified models do not bring evident mutual benefit and often underperform task-specific models. In contrast, GLIPv2 identifies grounded VL understanding as a meta-task for localization and understanding. The task unification brings architecture unification: the unified grounded VL understanding model empowers a localization branch with VL capacity, arriving at a unified branch that excels at both tasks. GLIPv2 vs GLIP GLIP shows that grounded pre-training improves localization. GLIPv2 further shows grounded pre-training improves VL understanding and thus leads to a unified model for localization and VL understanding. GLIPv2 introduces the inter-image region-word contrastive loss, which is another and stronger grounding task than the pre-training task in GLIP. The proposed loss can be viewed as a region-word level generalization of the prevalent image-level contrastive learning [38, 51, 65]. GLIPv2 outperforms GLIP on all benchmarks with the same pre-training data. 3. GLIPv2 : Unifying Localization and VL Understanding Based on the reformulation of object detection as a generalized phrase grounding task in GLIP [ 41 ], we unify both localization and VL understanding tasks as grounded vision-language tasks. A grounded vision-language task takes both image and text as inputs, and outputs region-level understanding results (e.g., detection, segmentation) and/or image-level understanding results with associated grounding/localization information (e.g., VQA, image captioning). We will present the unified grounded VL formulation and architecture in Section 3.1, the pre-training losses in Section 3.2, and transfer to downstream tasks in Section 3.3. 3.1. A Unified VL Formulation and Architecture At the center of GLIPv2 \u2019s unified formulation is theclassification-to-matchingtrick, which reformulates anytask-specific fixed-vocab classification problem as an task-agnostic open-vocabulary vision-language matchingproblem. The best example is the reformulation of image classification as image-text matching in CLIP [ 51 ], which enables the model to learn from raw image-text data directly, and achieves strong zero-shot results on open-vocabulary classification tasks. In GLIPv2 , we replace every semantic classification linear layer in traditional single-modality vision models with a vision-language matching dot-product layer. As illustrated in Figure 1, GLIPv2 \u2019s unified VL architecture is based on the generic architecture we term Architecture\u03a0. It consists of a dual encoder, denoted asEncVandEncL, and a fusion encoder, denoted asEncV L. The model takes an image-text pair(Img,Text)as input, and extract visual and text features as below: O \u030a=EncV(Img), P \u030a=EncL(Text), O, P=EncV L(O, \u030aP \u030a), (1) where(O \u030a,P \u030a)and(O, P)denote the image/text featuresbeforeandafterVL fusion, respectively. Vision-Language understanding tasks Arch\u03a0is the most popular model architecture for VL understanding tasks. Given the cross-modality fused representationsOandP, it is straightforward to add lightweight task-specific heads for various VL tasks. For example, GLIPv2 adds a two-layer MLP on top of text featuresPas the masked language modeling (MLM) head, to perform the MLM pre-training. We provide model details of VQA and image captioning in Section 3.3. (Language-guided) object detection and phrase grounding Following GLIP [ 41 ], GLIPv2 uses the classification-to-matching trick to unify detection and grounding. More specifically, for detection, we simply replace the class logitsScls=OWT, whereWis the weight matrix of the box classifier, with a task-agnostic region-word similarity logitsSground=OPT, where text featuresPare label embeddings from a task-agnostic language encoder. As shown in Figure 1, object detection and phrase grounding share the same input/output format and model architecture. See GLIP [ 41 ] for more details. Their only difference is the input text format: (1) for object detection, the text input is a string of concatenated candidate object labels; (2) for phrase grounding, the text input is a natural language sentence. We refer to GLIP [41] for more details. (Language-guided) instance segmentation and referring image segmentation Given the object detection results, an instance segmentation head is added to classify each pixel within the box into a semantic class. Again, GLIPv2 uses the classification-to-matching trick to produce a unified instance segmentation head for the standard instance segmentation tasks and the referring image segmentation tasks and leverage both types of data for its pre-training. This classification-to-matching trick can also apply to many other semantic classification heads in single modality CV models (e.g., semantic segmentation) and thus transfers them to language-guided CV models. 3.2. GLIPv2 Pre-training The GLIPv2 is pre-trained with three pre-training losses: phrase grounding lossLgroundfrom a vision-language reformulation of the object detection task, region-word contrastive lossLinterfrom a novel region-word level contrastive learning task, and the standard masked language modeling loss Lmlmproposed in BERT [17]. L GLIPv2 =Lloc+Lintra \ufe38 \ufe37\ufe37 \ufe38 Lground +Linter+Lmlm (2) Similar to losses in detection tasks, the grounding lossLgroundhas two parts: the localization lossLloc trains localization heads with bounding-box supervision, e.g., RPN loss, box regression loss and/or centerness loss [ 59 ]; the intra-image region-word alignment lossLintrais essentially the semantic classification/retrieval loss for each region. Intra-image region-word alignment loss Given one image-text pair(Img,Text), we obtain the image and text featuresaftercross-modality fusionOandP. The Intra-image region-word alignment loss is computed by Lintra=loss(OPT;T), (3) whereOPTis the similarity score between image regions and word tokens, andTis the target affinity matrix determined by the ground-truth annotations. The loss functionlossis typically a cross-entropy loss for two-stage detectors [53] and a focal loss [43] for one-stage detectors. However, as discussed in Section 1, this intra-image region-word contrastive learning is rather weak in the sense of contrastive learning, due to the limited number of phrases that can one caption can contain. GLIP [ 41 ] alleviates this problem by appending a few negative sentences to form a longer text input with more (negative) phrases. However, constrained by the maximal length of text tokens (256 in GLIP and GLIPv2 ), only a few negative sentences can be added and the number of negative phrases remains in the order of 10\u2019s. This small-negative-example problem also exists in detection data [41] when the input text cannot include all class names in a detection dataset, e.g., Objects365. Inter-image region-word contrastive loss.In GLIPv2 , we propose using phrases from other imagetext pairs in the same batch as negative examples, which effectively increases the number of negative examples to the order of 1000\u2019s, with nearly negligible additional computational cost. As in(1), given a batch of image-text pairs(Imgi,Texti)Bi=1and their ground-truth annotations (Ti)Bi=1, the model produces the image and text featuresbeforeandafterVL fusion, denoted as (O \u030ai,P \u030ai)Bi=1and(Oi, Pi)Bi=1, respectively. Then as illustrated in Figure 2 (Left), a batch-wise similarity matrixSbatchgroundand a batch-wise target affinity matrixTbatchare constructed by considering all the image regions and text phrases across this batch. Their(i, j)\u2019th blocks are obtained as below: Sbatchground[i, j] =O \u030ai(P \u030aj)T, Tbatch[i, j] = Ti, ifi=j obtained by label propagation, otherwise. The inter-image region-word contrastive loss is then defined as the standard bi-directional contrastive loss applied on all image regions and phrases in this batch: Linter=cross_entropy_loss(Sbatchground, Tbatch,axis= 0)+cross_entropy_loss(Sbatchground, Tbatch,axis= 1). (5) Compared with that in the inter-image contrastive loss(3), the number of negatives is multiplied by batch sizeBin this inter-image contrastive loss(5). We elaborate two important details in(4). (1) GLIPv2 uses the image text features(O \u030ai,P \u030ai)Bi=1before VL fusion,not(Oi, Pi)Bi=1after VL fusion, to compute the batch-wise similarity matrix in the inter-image contrastive loss(4). Otherwise, the image and text features after VL fusion would have seen the paired information(1), and thus the model can easily rule out the negatives from misaligned images/texts. (2) We cannot simply assign all regions and texts from unpaired image-text as negative pairs, as done in the standard contrastive loss in CLIP [ 51 ]. Instead, we determine the off-diagonal blocks in the target affinity matrixTbatchby label propagation. For example, as illustrated in Figure 2 (Left), if a region is annotated as \u201cperson\u201d, it should be a positive pair with all \u201cperson\u201d phrases in detection-type texts. We do not propagate positives to grounding-type texts (natural sentences) because phrases in sentences carry contexts that are unique to that image-sentence pair. Pre-training with both detection and paired-image-text data GLIPv2 pre-training data is in the image-text-target triplet format(Img,Text, T), where the target affinity matrixTcontains the box-label localization annotations. We also use massive image-text pair data(Img,Text)to pre-train GLIPv2 , by generating grounding boxesT\u02c6for phrases in the text with the GLIP pre-trained model from [ 41 ]. The human-annotated OD/grounding data provides high-fidelity localization supervision, while the massive image-text data greatly improves the concept diversity for GLIPv2 . Second-stage pre-training of the segmentation head GLIPv2 performs a second-stage pre-training of the language-guided segmentation head on both instance segmentation and image referring segmentation data, while fixing all other parts of the model. 3.3. Transfer GLIPv2 to Localization and VL Tasks We introduce two ways to easily transfer GLIPv2 to various downstream tasks. In addition, GLIPv2 can perform conventional VL tasks (e.g., VQA) along with localization, effectively making every task we consider a \u201cgrounded VL understanding\u201d task. One model architecture for all GLIPv2 can be transferred to downstream tasks by fine-tuning the model with an (optional) task-specific head. 1) Fordetection and segmentationtasks, no task-specific head is needed as the pre-training architecture can inherently perform detection and segmentation. 2) ForVLtasks: for VQA, a classification head is added on top of the hidden representation of the start-of-sequence token; for caption generation, we train with a unidirectional language modeling loss, which maximizes the likelihood of the next word given context. We use a unidirectional attention mask and prevent the image part from attending to the text in the fusion layers. One set of weights for all There is a growing interest in developing models that can be transferred to various tasks while only changing the least amount of parameters to save training time and storage cost [ 55 , 36 ]. Following GLIP, GLIPv2 can be transferred to localization tasks in azero-shotor aprompt-tuningsetting (Section 4.2). One single GLIPv2 model can serve various tasks, where each task only keeps few or no parameters. Of particular interest is the prompt tuning setting. For a certain localization task, the text prompt is the same for all input images; thus, we could directly tuneP \u030a, a small prompt embedding matrix, to adapt GLIPv2 to new tasks. Prompt tuning in a deep-fused model such as GLIPv2 is different from the conventional linear probing/prompt tuning setting [ 62 , 51 , 73 ] in shallow-interacting vision models such as CLIP. The latter can also be viewed as only tuning a small prompt/softmax embeddingP; however, tuningPonly affects the very last layer of the model while the visual representation is still frozen. In contrast, GLIP/ GLIPv2 \u2019s visual representation is conditioned on the prompt embeddingP \u030a; tuningP \u030achanges the text, visual, as well as fused embeddings. As a result, prompt tuning in GLIPv2 is highly effective, often matching the performance of fine-tuning (see Table 2). This is in contrast to the common observation in CV that linear probing lags behind fine-tuning by a large gap [25]. Grounded VL understanding GLIPv2 also enables grounded VL understanding, where we retain the ability to perform grounding when fine-tuning the model to a downstream VL task. This increases the interpretability of the model. Specifically, we first turn the VL data of the downstream task into grounded VL data using a pre-trained GLIP model. Then we train the model with both the downstream task head and grounding head. For VQA, the model is trained to predict the answer and ground entities in the question as well as the implied entity in the answer; for captioning, the model is trained to predict the next word given the context and ground the current decoded word. By tuning localization tasks into a grounded VL task and augmenting VL tasks with grounding ability, we effectively turn every task into a grounded VL understanding task (see examples in Figure 1). 4. Experiments \u5b9e\u9a8c In this section, we show that GLIPv2 serves as a performant and easy-to-deploy general-purpose vision system. 1)One Model Architecture for All(Section 4.1). GLIPv2 can be directly fine-tuned to both localization and VL understanding tasks with minimal architecture change. It achieves performance on par with SOTA models with specialized architectures. 2)One Model Weight for All(Section 4.2). GLIPv2 can be transferred to localization tasks in a zero-shot manner with zero Model Model Type COCO-Det ODinW(test-dev) (test) (minival)LVIS COCO-Mask(test-dev) Flickr30K PhraseCut(test) (test) (test-dev / test-std) (Karpathy-test)VQA Captioning Mask R-CNN [26] Localization 39.8 33.3 / / 37.1 DETR [9] 42.0 17.8 / DyHead-T [15] 49.7 60.8 DyHead-L [15] 60.3* VisualBERT [39] Understanding - - - - 71.33 - 70.8 / 71.0 - UNITER [12] - - - - - - 73.8 / 74.0 - VinVL [70] - - - - - - 76.5 / 76.6 130.8 GPV [24] Localization & Understanding - - - - - - 62.5 / - 102.3 UniT [28] 42.3 - - - - - 67.6 / - - MDETR [30] - - 24.2 / - - 84.3 53.7 70.6 / 70.6 - Unicorn [66] - - - - 80.4 - 69.2 / 69.4 119.1 GLIP-T [41] Localization & Understanding 55.2 64.9 85.7 GLIP-L [41] 61.5* 68.9 87.1 GLIPv2 -T (Ours) Localization & Understanding 55.5 66.5 50.6 / 41.4 53.5 / 42.0 86.5 59.4 71.6 / 71.8 122.1 GLIPv2 -B (Ours) 58.8 69.4 57.3 / 46.2 59.0 / 45.8 87.5 61.3 73.1 / 73.3 128.5 GLIPv2 -H (Ours) 60.6 (62.4*) 70.4 59.8 / 48.8 59.8 / 48.9 87.7 61.3 74.6 / 74.8 131.0 Table 1: One model architecture results. For COCO-Det test-dev, * indicates multi-scale evaluation. For LVIS, we report the numbers for bothbboxandsegmon minival to avoid data contamination due to the pre-training. For Flickr30K test, we report the metric underR@1. For COCO-Mask, we also report bothbboxandsegmon test-dev. parameter update; with prompt tuning, a single GLIPv2 model can achieve comparable performance with fully fine-tuned settings on both localization and understanding tasks. Following GLIP [41], we adopt Swin Transformer [45] as the image encoder EncV, text transformers [ 60 , 51 ] as the text encoderEncL, Dynamic Head [ 15 ] with language-aware deep fusion [ 41 ] as the fusion encoderEncV L, and Hourglass network [ 49 ] as instance segmentation head feature extractor. We train GLIPv2 at three scales: GLIPv2 -T, GLIPv2 -B, and GLIPv2 -H. GLIPv2 -Thas the same model config and initialization as GLIP-T: Swin-Tiny and BERT-Base as the dual encoder. The model is pre-trained on the following data: 1) O365, 2) GoldG as in GLIP-T (C), and 3) Cap4M, 4M image-text pairs collected from the web with boxes generated by GLIP-T [ 41 ]. GLIPv2 -B/ GLIPv2 -Hare based on Swin-Base/Swin-Huge and the pre-layernorm text transformer [ 18 ] as dual encoder, and are initialized from the UniCL [ 65 ] checkpoints. We observe much stabler training with GPT-type pre-layernorm transformer [ 18 ] than BERT-type post-layernorm transformer. The training data contain: 1) FiveODs (2.78M data)^1 ; 2) GoldG as in MDETR [ 30 ]; and 3) CC15M+SBU, 16M public image-text data with generated boxes by GLIP-L [ 41 ].Segmentation headsof GLIPv2 models are pre-trained on COCO, LVIS [ 23 ] and PhraseCut [ 63 ], with all other model parameters are frozen. NoteAll datasets above were collected by the creators (cited) and consent for any personally identifiable information (PII) was ascertained by the authors where necessary. Due to limited space, we refer to supplementary for details of training recipes and hyper-parameters. 4.1. One Model Architecture for All We compare GLIPv2 to existing object detection and vision-language pre-training methods on a wide range of tasks. We fine-tune the model on 8 different downstream tasks and report the performance in Table 1. We make the following observations. GLIPv2 v.s. specialized Localization methods. GLIPv2 outperforms previous localization models on generalization to both common and rare classes and domainswith a single model architecture and pre-training stage.1) OD on common categories (COCO-Det), GLIPv2 -T achieves 5.8 improvement compared to the standard DyHead-T trained on O365 (55.5 v.s. 49.7). GLIPv2 -H reaches 62.4 AP on test-dev, and surpass the performance of the previous SoTA model GLIP-L.2) OD on rare / unseen categories (LVIS), GLIPv2 -T outperforms a supervised MDETR on thebboxby a great margin (59.8 v.s. 24.2).3) Generalization to diverse real-word tasks (ODinw), GLIPv2 -T (55.5) performs better than original GLIP-T (64.9) on the average of 13 public datasets; GLIPv2 -B outperforms GLIP-L by 0.5 AP.4) Instance segmentation (COCO-Mask & PhraseCut), for traditional instance segmentation (^1) Besides O365, it combines with 4 additional OD datasets including COCO [44], OpenImages [33], Visual Genome [34], and ImageNetBoxes [35] Model Direct Evaluation Prompt Tuning COCO-Mask ODinW LVIS-Det Flickr30K COCO-Det ODinW LVIS COCO-Mask PhraseCut (minival) (test) (minival) (minival) (test-dev) (test) (minival) (test-dev) (test) GLIP-T 46.6/\u2013 46.5 26.0 85.7 \u2013 46.5 GLIP-L 49.8/\u2013 52.1 37.3 87.1 58.8 67.9 GLIPv2 -T 47.3/35.7 48.5 29.0 86.0 53.4(-2.1) 64.8(-1.7) 49.3 / 34.8(-1.3 / -6.6) 53.2 / 41.2(-0.3 / -0.8) 49.4 GLIPv2 -B 61.9\u2020/43.4 54.2 48.5 87.2 59.0(+0.2) 67.3(-2.1) 56.8 / 41.7(-0.5 / -4.5) 58.8 / 44.9(-0.2 / -0.9) 55.9 GLIPv2 -H 64.1\u2020/47.4 55.5 50.1 87.7 60.2 / 61.9*(-0.4 / -0.5) 69.1(-1.3) 59.2 / 43.2(-0.6 / -5.7) 59.8 / 47.2(-0.0 / -1.7) 56.1 Table 2: One set of weights results v.s. Original GLIP. * indicates multi-scale evaluation. Numbers in red clearly points out the difference between the prompt tuning and full fine-tuning results (see Table 1). Numbers in gray mean that they are not inzero-shotmanner.\u2020: these two numbers are artificially high due to some overlap between COCO-minival and VisualGenome-train. FullTuning-Model Prompt Tuning GLIPv2 -H GLIP GLIPv2 v2--BT GLIP-T DyHead-T Figure 3: Data efficiency of GLIPv2 on ODinW. The X-axis is the amount of task-specific data, from zero-shot to all data. Y-axis is the average AP across 13 datasets. Model Zero-Shot 0 1 Prompt Tuning / Fine Tuning 3 5 10 All DyHead-TO365[41] 33.843.646.450.860.8Lloc+Lintra(GLIP-T) 46.5 49.951.3 53.754.9 55.556.4 56.658.4 62.464.9 Lloc+Lintra+Linter 48.4 52.151.4 55.655.3 56.756.6 58.359.5 62.966.3 Lloc+Lintra+Linter+Lmlm 48.5 52.452.8 55.655.6 57.457.4 58.859.7 64.866.5 Table 3: Zero-shot, prompt tuning, and full finetuning performance on ODinW. GLIPv2 models exhibit superior data efficiency. (i.e., COCO-Mask), GLIPv2 -H outperforms the well-known Mask R-CNN by a great margin onsegm. For language-guided segmentation (i.e., PhraseCut), compared to MDETR, GLIPv2 -T achieves an improvement of 5.7 mask AP. GLIPv2 v.s. specialized VL Understanding methods. GLIPv2 rivals with SoTA specialized models for VL tasks.1) For VQA, GLIPv2 outperforms VisualBERT and UNITER and approaches the previous SoTA model VinVL.2) For Captioning, the best GLIPv2 even surpasses VinVL (VinVL and GLIPv2 are not trained with CIDEr optimization). GLIPv2 v.s. localization and VL models.Prior works such GPV, UniT and Unicorn have also explored unifying localization and VL models (see a discussion in Section 2). GLIPv2 outperforms all previous systems on both localization and VL tasks. For the best GLIPv2 -H, it outperforms the UniT by a great margin (18.3 AP) on COCO object detection tasks. Meanwhile, it also surpasses UniT\u2019s performance on VQA by 6.9 points and GPV\u2019s peformance on Image Captioning as well. Takeaway.Most notably, GLIPv2 outperforms previous \u201cunified\u201d models (GPV, UniT, MDETR, Unicorn) by a large margin. This is the first time that a single model architecture could achieve near SoTA performance on both localization and understanding. In contrast, in prior work, there exists certain trade-off between localization and understanding: models that aim to achieve high understanding performance tend to have lower localization performance (e.g., UNiT\u2019s detection performance is limited to the DETR [ 9 ] architecture), as it is not trivial to merge a SoTA localization branch and a SoTA VL branch into a single model. 4.2. One Set of Model Parameters for All GLIPv2 is pre-trained to perform grounding; thus it can be transferred to various localization tasks with changing zero or few parameters. We evaluate GLIPv2 under two such settings: 1) direct evaluation, where we transfer the model \u201cas is\u201d without any parameter change, and 2) prompt tuning, where only the prompt embedding is tuned for specific tasks (Section 3.3). Direct evaluation. The pre-trained GLIPv2 can be directly evaluated on any object detection task (by concatenating the object categories into a text prompt) and visual grounding task without any further tuning. We evaluate the models on four localization tasks: COCO, ODinW, LVIS, and Flickr30, and their results are presented in Table 2. Note that for GLIPv2 -B and GLIPv2 -H, the training sets of Flick30K and LVIS are present in the pre-training data. Thus, reported numbers on these metrics are notzero-shotevaluation (we have marked them gray). For all other evaluation results, the models are evaluated inzero-shotsettings without any further tuning. GLIPv2 can be effortlessly transferred to different localization tasks without further tuning.1) For COCO, GLIPv2 -T achieves a zero-shot performance of 47.3 without seeing any COCO training images. This surpasses well-established supervised systems (e.g., Mask R-CNN) and also outperforms GLIP-T by 0.7 AP. 2) ForODinW, GLIPv2 also shows strong zero-shot performance. GLIPv2 -T (48.5) surpasses the GLIP-T (46.5). Meanwhile, the zero-shot performance of GLIPv2 -B and GLIPv2 H even surpasses the 10-shot tuning performance of DyHead-T (to be introduced in Figure 3). 3) ForLVIS, GLIPv2 -T achieves a 3 AP improvement performance compared to the GLIP-T. 4) For Flickr30K, GLIPv2 -B achieves even higher number (87.2) compared to original GLIP-L (87.1). Prompt Tuning. Following GLIP, GLIPv2 supports efficient prompt tuning: the visual representation is heavily conditioned on the text representation due to the deep fusion block (Section 3.3); thus we could fine-tune only the prompt embedding for each task but still maintain high performance. Prompt tuning GLIPv2 achieves similar performance as full fine-tuning. When comparing the performance of each task in Table 1 and 2 at the same time, for GLIPv2 , prompt tuning performance almost matches the one model architecture results on localization tasks, without changing any of the grounding model parameters. 4.3. GLIPv2 as a Strong Few-Shot Learner We demonstrate GLIPv2 \u2019s performance on ODinW datasets with respect to different amounts of training data in Figure 3. The performance improvement between GLIPv2 -T and GLIP-T exhibits more superior data efficiency for prompt tuning. We compare with the SoTA detector DyHead-T, pre-trained on Objects365 in Table 3. It can be seen that a zero-shot GLIPv2 -T (48.5) outperforms a outperforms 5-shot DyHead-T (46.4) while the performance of one-shot GLIPv2 -H (61.3) surpasses a all-shot fully supervised DyHead-T (60.8). 4.4. Analysis Pre-training lossesTable 4 shows the performance of the downstream tasks with different variants of our method. Compared to the GLIP pre-training tasks with only intra-image region-word contrastive loss (Row 3), adding inter-image word-region loss (Row 5) substantially improves the pre-trained model performance across all the object detection tasks (COCO, ODinW, and LVIS) on both zero-shot and fine-tuned manner. Consistent with common observations from most VL understanding methods, adding MLM loss (Row4) benefits for learning the representation for understanding tasks (Flick30k, VQA, and Captioning). Furthermore, using all three losses together at the 1st stage pre-training and doing the 2nd stage pre-training without MLM on OD and GoldG data, GLIPv2 (Row6) can perform well on both the localization and VL understanding tasks. An additional stage of pre-training is applied for small models ( GLIPv2 -T and GLIPv2 -B) due to limited model capacity. In order to achieve higher performance on both localization and understanding tasks, we find that including all data (even with some noise) and MLM loss in the first stage of pre-training will benefit the model for learning a better representation of both localization and understanding capability. Since the OD tasks require the model with more accurate localization ability, in our 2nd stage of pre-training, we decide to eliminate the MLM loss. The large model ( GLIPv2 -H) does not need this additional stage because it has enough capacity to learn both wordregion alignment and MLM together in a single stage. Pre-training dataTable 5 reports the last checkpoint results on GLIPv2 when we do the scaling up of pre-training data. As more weak image-text pair data (Cap) is involved in our training, it benefits both standard/in-domain (i.e., COCO, Flickr30K) and large-domain gap (i.e., ODinW, LVIS) tasks. We also show that by adding the inter-image region-word contrastive helps when we are fixing the data at the same scale. For large-domain gap tasks, adding the inter-image region-word contrastive Row Model COCO ODinW LVISFlickr30K VQA Captioning 1 No pre-train \u2013/50.6 \u2013/60.8 \u2013 \u2013 64.6 111.5 2 +Lmlm \u2013/48.5 \u2013/37.4 \u2013 \u2013 64.6 110.9 3 +Lloc+Lintra 46.6/55.2 46.5/64.9 26.0 85.7 69.4 119.7 4 +Lloc+Lintra+Lmlm 47.0/55.2 47.6/66.2 28.5 86.5 69.8 120.7 5 +Lloc+Lintra+Linter 47.1/55.4 48.4/66.3 28.6 85.8 68.7 120.4 6 +Lloc+Lintra+Linter+Lmlm47.3/55.5 48.5/66.5 29.0 86.3 70.7 122.1 Table 4: Pre-training losses on Tiny-scale model. Involving intra-image region-word alignment lossLintra, inter-image region-word contrastive lossLinterand MLM lossLmlmwill benefit both localization and understanding tasks. Linter Pre-train Data COCO ODinW LVIS Flick30K 7 O365, GoldG 48.06 43.14 25.6 84.36 3 O365, GoldG 48.59 42.64 26.9 83.90 7 O365, GoldG, Cap4M 48.21 51.35 34.2 85.56 3 O365, GoldG, Cap4M 48.79 52.70 35.0 85.50 7 O365, GoldG, Cap12M 48.50 49.32 35.5 85.79 3 O365, GoldG, Cap12M 49.26 53.15 36.6 85.84 Table 5: Pre-train data scale up on Base-scale model. Results are reported at the last checkpoint. See supplementary for results at all checkpoints. Model B4 CIDEr SPICECOCO Caption Flickr30K GroundingR@1 R@5 R@10 GLIPv2 -T 36.5 119.8 21.6 80.8 94.4 96.5 GLIPv2 -B37.4 123.0 21.9 81.0 94.5 96.5 Table 6: GLIPv2 can perform captioning and grounding at the same time (a.k.a., grounded VL understanding). loss will further boost the model to learn better representation. For more detailed scaling-up effects on various tasks under all the checkpoints for GLIP and GLIPv2 , refer to Appendix. Note that the(Img,Text, T)data used in GLIPv2 pre-training can be just human-annotated data (Row1&2 in Table 5), with which GLIPv2 pre-training does not involve any pseudo data from a pre-trained grounding/localization model. In order to achieve the best performance, GLIPv2 uses image-text pair data with pseudo boxes (Cap) from a pre-trained GLIP model (Row3-6 in Table 4), which is trained with the same \"grounded VL understanding\" task but just with smaller data. Grounded Vision-Language Understanding GLIPv2 can be trained to perform a VL task and grounding at the same time (Section 3.3). We denote such an ability as grounded VL understanding. In Figure 1, we showcase grounded predictions of GLIPv2 on VQA and COCO captions. We also conduct quantitative evaluations (Table 6). The model achieves strong performance for both VL understanding (on COCO Caption) and localization (on Flickr30K Grounding). Such an ability to produce high-level semantic outputs (i.e., answers and captions) and supporting localization results is another appealing trait of GLIPv2 , as potential users can have a better understanding of the model behaviour. See more detailed analysis and qualitative examples in the Appendix. 5. Conclusion and Social Impacts This paper proposes GLIPv2 , a unified framework for VL representation learning that serves both localization tasks and VL understanding tasks. We experimentally verify the effectiveness of the unified model and the novel region-word contrastive learning. Compared to existing methods, GLIPv2 achieves competitive near SoTA performance on various localization and understanding tasks. However, additional analysis of the data and the model is necessary before deploying it in practice since large-scale web data may contain unintended private information, unsuitable images/text, or some bias leakage. Further investigation may be needed for web data due to the above issues. References \u53c2\u8003\u6587\u732e [1] Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.: Bottom-up and top-down attention for image captioning and visual question answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 6077\u20136086. IEEE (2018) [2] Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.: Bottom-up and top-down attention for image captioning and visual question answering. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 6077\u20136086 (2018) [3] Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.: VQA: Visual Question Answering. In: International Conference on Computer Vision (ICCV) (2015) \\ [4] Bansal, A., Sikka, K., Sharma, G., Chellappa, R., Divakaran, A.: Zero-shot object detection. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 384\u2013400 (2018) [5] Bilen, H., Vedaldi, A.: Weakly supervised deep detection networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2846\u20132854 (2016) [6] Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E., et al.: On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021) [7] Bucher, M., Vu, T.H., Cord, M., P\u00e9rez, P.: Zero-shot semantic segmentation. Advances in Neural Information Processing Systems 32 (2019) [8] Caesar, H., Uijlings, J., Ferrari, V.: Coco-stuff: Thing and stuff classes in context. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 1209\u20131218 (2018) [9] Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-to-end object detection with transformers. In: European Conference on Computer Vision. pp. 213\u2013229. Springer (2020) [10] Chen, K., Pang, J., Wang, J., Xiong, Y., Li, X., Sun, S., Feng, W., Liu, Z., Shi, J., Ouyang, W., et al.: Hybrid task cascade for instance segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4974\u20134983 (2019) [11] Chen, X., Fang, H., Lin, T.Y., Vedantam, R., Gupta, S., Doll\u00e1r, P., Zitnick, C.L.: Microsoft COCO captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325 (2015) [12] Chen, Y.C., Li, L., Yu, L., El Kholy, A., Ahmed, F., Gan, Z., Cheng, Y., Liu, J.: UNITER: Universal image-text representation learning. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 104\u2013120. Springer (2020) [13] Chen, Y.C., Li, L., Yu, L., Kholy, A.E., Ahmed, F., Gan, Z., Cheng, Y., Liu, J.: Uniter: Learning universal image-text representations. arXiv preprint arXiv:1909.11740 (2019) [14]Dai, J., Li, Y., He, K., Sun, J.: R-fcn: Object detection via region-based fully convolutional networks. In: Advances in neural information processing systems. pp. 379\u2013387 (2016) [15]Dai, X., Chen, Y., Xiao, B., Chen, D., Liu, M., Yuan, L., Zhang, L.: Dynamic head: Unifying object detection heads with attentions. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 7373\u20137382 (2021) [16]Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: ImageNet: A Large-Scale Hierarchical Image Database. In: Proceedings of the IEEE conference on computer vision and pattern recognition (2009) [17]Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018) [18]Gao, P., Geng, S., Zhang, R., Ma, T., Fang, R., Zhang, Y., Li, H., Qiao, Y.: Clip-adapter: Better vision-language models with feature adapters. arXiv preprint arXiv:2110.04544 (2021) [19]Gokberk Cinbis, R., Verbeek, J., Schmid, C.: Multi-fold mil training for weakly supervised object localization. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2409\u20132416 (2014) [20]Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 6904\u20136913 (2017) [21]Gu, X., Lin, T.Y., Kuo, W., Cui, Y.: Open-vocabulary object detection via vision and language knowledge distillation. arXiv preprint arXiv:2104.13921 (2021) [22]Gu, X., Lin, T.Y., Kuo, W., Cui, Y.: Zero-shot detection via vision and language knowledge distillation. arXiv preprint arXiv:2104.13921 (2021) [23]Gupta, A., Dollar, P., Girshick, R.: Lvis: A dataset for large vocabulary instance segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 5356\u20135364 (2019) [24]Gupta, T., Kamath, A., Kembhavi, A., Hoiem, D.: Towards general purpose vision systems. arXiv preprint arXiv:2104.00743 (2021) [25]He, K., Chen, X., Xie, S., Li, Y., Doll\u00e1r, P., Girshick, R.: Masked autoencoders are scalable vision learners. arXiv preprint arXiv:2111.06377 (2021) [26]He, K., Gkioxari, G., Doll\u00e1r, P., Girshick, R.: Mask r-cnn. In: Proceedings of the IEEE international conference on computer vision. pp. 2961\u20132969 (2017) [27]Hendrycks, D., Gimpel, K.: Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415 (2016) [28]Hu, R., Singh, A.: Unit: Multimodal multitask learning with a unified transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 1439\u20131449 (2021) [29]Hudson, D.A., Manning, C.D.: Gqa: A new dataset for real-world visual reasoning and compositional question answering. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 6700\u20136709 (2019) [30]Kamath, A., Singh, M., LeCun, Y., Synnaeve, G., Misra, I., Carion, N.: Mdetr-modulated detection for end-to-end multi-modal understanding. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 1780\u20131790 (2021) [31]Karpathy, A., Joulin, A., Fei-Fei, L.F.: Deep fragment embeddings for bidirectional image sentence mapping. Advances in neural information processing systems 27 (2014) [32]Kiros, R., Salakhutdinov, R., Zemel, R.S.: Unifying visual-semantic embeddings with multimodal neural language models. arXiv preprint arXiv:1411.2539 (2014) [33]Krasin, I., Duerig, T., Alldrin, N., Ferrari, V., Abu-El-Haija, S., Kuznetsova, A., Rom, H., Uijlings, J., Popov, S., Veit, A., et al.: Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github . com/openimages 2 (3), 18 (2017) [34]Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L.J., Shamma, D.A., et al.: Visual Genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of Computer Vision (IJCV) 123 (1), 32\u201373 (2017) [35]Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems 25 , 1097\u20131105 (2012) [36]Lester, B., Al-Rfou, R., Constant, N.: The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021) [37]Li, G., Duan, N., Fang, Y., Jiang, D., Zhou, M.: Unicoder-VL: A universal encoder for vision and language by cross-modal pre-training. arXiv preprint arXiv:1908.06066 (2019) [38]Li, J., Selvaraju, R., Gotmare, A., Joty, S., Xiong, C., Hoi, S.C.H.: Align before fuse: Vision and language representation learning with momentum distillation. Advances in Neural Information Processing Systems 34 (2021) [39]Li, L.H., Yatskar, M., Yin, D., Hsieh, C.J., Chang, K.W.: Visualbert: A simple and performant baseline for vision and language. arXiv preprint arXiv:1908.03557 (2019) [40]Li, L.H., You, H., Wang, Z., Zareian, A., Chang, S.F., Chang, K.W.: Unsupervised vision-andlanguage pre-training without parallel images and captions. arXiv preprint arXiv:2010.12831 (2020) [41]Li, L.H., Zhang, P., Zhang, H., Yang, J., Li, C., Zhong, Y., Wang, L., Yuan, L., Zhang, L., Hwang, J.N., et al.: Grounded language-image pre-training. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10965\u201310975 (2022) [42]Li, X., Yin, X., Li, C., Zhang, P., Hu, X., Zhang, L., Wang, L., Hu, H., Dong, L., Wei, F., et al.: Oscar: Object-semantics aligned pre-training for vision-language tasks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 121\u2013137. Springer (2020) [43]Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll\u00e1r, P.: Focal loss for dense object detection. In: Proceedings of the IEEE international conference on computer vision. pp. 2980\u20132988 (2017) [44]Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: European conference on computer vision. pp. 740\u2013755. Springer (2014) [45]Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B.: Swin transformer: Hierarchical vision transformer using shifted windows. arXiv preprint arXiv:2103.14030 (2021) [46]Lu, J., Batra, D., Parikh, D., Lee, S.: ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. In: Advances in Neural Information Processing Systems (NeurIPS). pp. 13\u201323 (2019) [47]Lu, J., Clark, C., Zellers, R., Mottaghi, R., Kembhavi, A.: Unified-io: A unified model for vision, language, and multi-modal tasks. arXiv preprint arXiv:2206.08916 (2022) [48]Ma, C.Y., Kalantidis, Y., AlRegib, G., Vajda, P., Rohrbach, M., Kira, Z.: Learning to generate grounded visual captions without localization supervision. In: European Conference on Computer Vision. pp. 353\u2013370. Springer (2020) [49]Newell, A., Yang, K., Deng, J.: Stacked hourglass networks for human pose estimation. In: European conference on computer vision. pp. 483\u2013499. Springer (2016) [50]Plummer, B.A., Wang, L., Cervantes, C.M., Caicedo, J.C., Hockenmaier, J., Lazebnik, S.: Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models. In: Proceedings of the IEEE international conference on computer vision. pp. 2641\u2013 2649 (2015) [51]Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al.: Learning transferable visual models from natural language supervision. In: International Conference on Machine Learning (ICML) (2021) [52]Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: Unified, real-time object detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 779\u2013788 (2016) [53]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems 28 , 91\u201399 (2015) [54]Shao, S., Li, Z., Zhang, T., Peng, C., Yu, G., Zhang, X., Li, J., Sun, J.: Objects365: A large-scale, high-quality dataset for object detection. In: Proceedings of the IEEE international conference on computer vision. pp. 8430\u20138439 (2019) [55]Shin, T., Razeghi, Y., Logan IV, R.L., Wallace, E., Singh, S.: Autoprompt: Eliciting knowledge from language models with automatically generated prompts. arXiv preprint arXiv:2010.15980 (2020) [56]Su, W., Zhu, X., Cao, Y., Li, B., Lu, L., Wei, F., Dai, J.: VL-BERT: Pre-training of generic visual-linguistic representations. arXiv preprint arXiv:1908.08530 (2019) [57]Tan, H., Bansal, M.: Lxmert: Learning cross-modality encoder representations from transformers. arXiv preprint arXiv:1908.07490 (2019) [58]Teney, D., Anderson, P., He, X., Van Den Hengel, A.: Tips and tricks for visual question answering: Learnings from the 2017 challenge. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 4223\u20134232 (2018) [59]Tian, Z., Shen, C., Chen, H., He, T.: Fcos: Fully convolutional one-stage object detection. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 9627\u20139636 (2019) [60]Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, \u0141., Polosukhin, I.: Attention is all you need. In: Advances in neural information processing systems. pp. 5998\u20136008 (2017) [61]Wang, P., Cai, Z., Yang, H., Swaminathan, G., Vasconcelos, N., Schiele, B., Soatto, S.: Omnidetr: Omni-supervised object detection with transformers. arXiv preprint arXiv:2203.16089 (2022) [62]Wang, X., Huang, T.E., Darrell, T., Gonzalez, J.E., Yu, F.: Frustratingly simple few-shot object detection. arXiv preprint arXiv:2003.06957 (2020) [63]Wu, C., Lin, Z., Cohen, S., Bui, T., Maji, S.: Phrasecut: Language-based image segmentation in the wild. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10216\u201310225 (2020) [64]Xiong, R., Yang, Y., He, D., Zheng, K., Zheng, S., Xing, C., Zhang, H., Lan, Y., Wang, L., Liu, T.: On layer normalization in the transformer architecture. In: International Conference on Machine Learning. pp. 10524\u201310533. PMLR (2020) [65]Yang, J., Li, C., Zhang, P., Xiao, B., Liu, C., Yuan, L., Gao, J.: Unified contrastive learning in image-text-label space. arXiv preprint arXiv:2204.03610 (2022) [66]Yang, Z., Gan, Z., Wang, J., Hu, X., Ahmed, F., Liu, Z., Lu, Y., Wang, L.: Crossing the format boundary of text and boxes: Towards unified vision-language modeling. arXiv preprint arXiv:2111.12085 (2021) [67]Yuan, L., Chen, D., Chen, Y.L., Codella, N., Dai, X., Gao, J., Hu, H., Huang, X., Li, B., Li, C., et al.: Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432 (2021) [68]Zareian, A., Rosa, K.D., Hu, D.H., Chang, S.F.: Open-vocabulary object detection using captions. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 14393\u201314402 (2021) [69]Zeng, Y., Zhang, X., Li, H.: Multi-grained vision language pre-training: Aligning texts with visual concepts. arXiv preprint arXiv:2111.08276 (2021) [70]Zhang, P., Li, X., Hu, X., Yang, J., Zhang, L., Wang, L., Choi, Y., Gao, J.: Vinvl: Revisiting visual representations in vision-language models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 5579\u20135588 (2021) [71]Zhang, P., Li, X., Hu, X., Yang, J., Zhang, L., Wang, L., Choi, Y., Gao, J.: Vinvl: Revisiting visual representations in vision-language models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 5579\u20135588 (June 2021) [72]Zhong, Y., Yang, J., Zhang, P., Li, C., Codella, N., Li, L.H., Zhou, L., Dai, X., Yuan, L., Li, Y., et al.: Regionclip: Region-based language-image pretraining. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 16793\u201316803 (2022) [73]Zhou, K., Yang, J., Loy, C.C., Liu, Z.: Learning to prompt for vision-language models. arXiv preprint arXiv:2109.01134 (2021) [74]Zhou, L., Palangi, H., Zhang, L., Hu, H., Corso, J., Gao, J.: Unified vision-language pre-training for image captioning and vqa. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 34, pp. 13041\u201313049 (2020) [75]Zhou, L., Palangi, H., Zhang, L., Hu, H., Corso, J.J., Gao, J.: Unified vision-language pretraining for image captioning and VQA. AAAI (2020) [76]Zhu, P., Wang, H., Saligrama, V.: Zero shot detection. IEEE Transactions on Circuits and Systems for Video Technology 30 (4), 998\u20131010 (2019) [77]Zhu, P., Wang, H., Saligrama, V.: Don\u2019t even look once: Synthesizing features for zero-shot detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 11693\u201311702 (2020)","title":"GLIPv2: Unifying Localization and VL Understanding"},{"location":"Models/MultiModal/PN-2206.05836/#glipv2-unifying-localization-and-vl-understanding","text":"\u4f5c\u8005: Haotian Zhang | Pengchuan Zhang | Xiaowei Hu | Yen-Chun Chen | Liunian Harold Li | Xiyang Dai | Lijuan Wang | Lu Yuan | Jenq-Neng Hwang | Jianfeng Gao \u673a\u6784: \u534e\u76db\u987f\u5927\u5b66 | Meta AI | \u5fae\u8f6f | UCLA \u65f6\u95f4: 2022-06-12 -> 2022-10-11 \u53d1\u8868: NeurIPS 2022 \u9884\u5370: arXiv:2206.05836v2 \u9886\u57df: #\u8ba1\u7b97\u673a\u89c6\u89c9 \u6807\u7b7e: #\u5f00\u6e90 \u5f15\u7528: 77 \u7bc7 \u4ee3\u7801: Github cur{ color:red; } term{ color:blue; } abbv{ color:orange; }","title":"GLIPv2: Unifying Localization and VL Understanding"},{"location":"Models/MultiModal/PN-2206.05836/#abstract","text":"We present GLIPv2 , a grounded VL understanding model, that serves both localization tasks (e.g., object detection, instance segmentation) and Vision-Language (VL) understanding tasks (e.g., VQA, image captioning). GLIPv2 elegantly unifies localization pre-training and Vision-Language Pre-training (VLP) with three pre-training tasks: phrase grounding as a VL reformulation of the detection task, region-word contrastive learning as a novel region-word level contrastive learning task, and the masked language modeling. This unification not only simplifies the previous multi-stage VLP procedure but also achieves mutual benefits between localization and understanding tasks. Experimental results show that a single GLIPv2 model (all model weights are shared) achieves near SoTA performance on various localization and understanding tasks. The model also shows (1) strong zero-shot and few-shot adaption performance on open-vocabulary object detection tasks and (2) superior grounding capability on VL understanding tasks. Code is released at Github.","title":"Abstract \u6458\u8981"},{"location":"Models/MultiModal/PN-2206.05836/#1-introduction","text":"Recently, a general interest arises in building general-purpose vision systems [ 24 , 28 , 66 , 47 ], also called vision foundation models [ 6 , 67 ], that solve various vision tasks simultaneously, such as image classification [ 35 ], object detection [ 44 ], and Visual-Language (VL) understanding [ 3 , 11 , 32 ]. Of particular interest, is the unification betweenlocalizationtasks (e.g., object detection [ 44 ] and segmentation [ 8 , 23 ]) and VLunderstandingtasks (e.g., VQA [ 3 ] and image captioning [ 11 ]). Localization pre-training benefits VL tasks [ 1 , 70 ], and the \u201clocalization->VLP\u201d two-stage pretraining procedure [ 46 , 57 , 13 , 56 , 39 , 37 , 75 , 42 , 40 ] is the common practice in VL community. A long-standing challenge is the unification of localization and understanding, which aims atmutual benefit between these two kinds of tasks, simplified pre-training procedure, and reduced pre-training cost. However, these two kinds of tasks appear to be dramatically different: localization tasks are visiononly and require fine-grained output (e.g., bounding boxes or pixel masks), while VL understanding tasks emphasize fusion between two modalities and require high-level semantic outputs (e.g., answers or captions). [ 24 , 28 , 66 ] have made early attempts at unifying these tasks in a straightforward multi-task manner, where a low-level visual encoder is shared across tasks, and two separate high-level branches are designed for localization and VL understanding, respectively. The localization tasks are still vision-only and do not benefit from the rich semantics in vision-language data. As a result, such unified models see the marginal mutual benefit or even performance degradation [ 28 ] compared with task-specific models. In this paper, we identify \u201cVL grounding\u201d as a \u201cmeta\u201d-capability for localization and understanding capabilities. VL grounding involves not onlyunderstandingan input sentence but alsolocalizingthe mentioned entities in the image (see an example in Figure 1). We build agrounded VL understandingmodel ( GLIPv2 ) as a unified model for localization and VL understanding tasks.","title":"1. Introduction \u4ecb\u7ecd"},{"location":"Models/MultiModal/PN-2206.05836/#localization-vl-understanding-grounded-vl-understanding","text":"Localization tasks involve both localization and semantic classification, where classification can be cast as a VL understanding problem using theclassification-to-matchingtrick (Section 3.1). Therefore, we reformulate localization tasks as VL grounding tasks, in which the language input is a synthesized sentence as the concatenation of category names [ 41 ]. Localization data are turned into VL grounding data, accordingly. The massive VL understanding data (image-text pairs) can be easily turned into VL grounding data in a self-training manner [ 41 ]. Therefore, GLIPv2 has a unified pre-training process: all task data are turned into grounding data and GLIPv2 is pre-trained to perform grounded VL understanding.","title":"Localization + VL understanding = grounded VL understanding"},{"location":"Models/MultiModal/PN-2206.05836/#a-stronger-vl-grounding-task-inter-image-region-word-contrastive-learning","text":"GLIP [ 41 ] proposes the phrase grounding task as its pre-training task, which we argue is an easy task and does not fully utilize data information. For example, in the VL grounding task in Figure 1, the phrase grounding task only requires the model to match a given image region to one of the three phrases in the text input, i.e., \u201cgreen, pink striped, or plain white umbrella?\u201d. This 1-in-3 choice is very easy, only requires color understanding, but loses lots of information in this grounding data: the umbrellas are not any other colors, like black, yellow, etc; objects in those regions are umbrellas but not any other categories, like car, bike, etc. From a contrastive learning view, this phrase grounding task only has two negatives. More negatives can be created from this annotation and thus enable stronger contrastive learning. In GLIPv2 , we introduce the novel inter-image region-word contrastive learning task, which leverages phrases from other sentences in the same batch as potential negatives, as another much stronger VL grounding task. This new region-word contrastive loss enables GLIPv2 to learn more discriminative region-word features and demonstrates improvements over all downstream tasks.","title":"A stronger VL grounding task inter-image region-word contrastive learning"},{"location":"Models/MultiModal/PN-2206.05836/#glipv2-achieves-mutual-benefit-between-localization-and-vl-understanding","text":"1) Experimental results (Table 2) show that a single GLIPv2 model (all model weights are shared) achieves near SoTA performance on various localization and understanding tasks. 2) Thanks to semantic-rich annotations from the image-text data, GLIPv2 shows superior zero-shot and few-shot transfer learning ability to open-world object detection and instance segmentation tasks, evaluated on the LVIS dataset and the \"Object Detection in the Wild (ODinW)\" benchmark. 3) GLIPv2 enables language-guided detection and segmentation ability, and achieves new SoTA performance on the Flick30K-entities phrase grounding and PhraseCut referring image segmentation tasks. 4) Inherently a grounding model, GLIPv2 leads to VL understanding models with strong grounding ability, which are self-explainable and easy to debug. For example, GLIPv2 , when GLIPv2 is finetuned on VQA, it can answer questions while localizing mentioned entities (see Figure 1 and Section 4.4).","title":"GLIPv2 achieves mutual benefit between localization and VL understanding"},{"location":"Models/MultiModal/PN-2206.05836/#2-related-work","text":"","title":"2. Related Work \u76f8\u5173\u5de5\u4f5c"},{"location":"Models/MultiModal/PN-2206.05836/#localization-models","text":"Traditionally, localization tasks such as object detection and segmentation are single-modality and output bounding boxes or pixel masks [ 52 , 43 , 26 , 14 , 53 , 10 , 9 ]. One challenge of these single-modality models lies in generalization to rare and novel concepts: it is hard to collect localization data that cover many rare categories [ 23 ]. A long line of research focuses on this generalization problem, under the name of zero-shot [ 4 , 76 , 7 , 77 ], weakly-supervised [ 19 , 5 , 61 ], or open-vocabulary [ 68 , 22 ] localization. \u4f20\u7edf\u7684\u5b9a\u4f4d\u4efb\u52a1\u5982\u76ee\u6807\u68c0\u6d4b\u548c\u5206\u5272\u662f\u5355\u6a21\u6001\u5e76\u8f93\u51fa\u8fb9\u754c\u6846\u6216\u50cf\u7d20\u63a9\u819c. \u8fd9\u4e9b\u5355\u6a21\u6001\u6a21\u578b\u7684\u4e00\u4e2a\u6311\u6218\u5728\u4e8e\u5bf9\u7a00\u6709\u7684\u548c\u65b0\u9896\u6982\u5ff5\u7684\u63a8\u5e7f: \u5f88\u96be\u6536\u96c6\u6db5\u76d6\u8bb8\u591a\u7a00\u6709\u7c7b\u522b\u7684\u5b9a\u4f4d\u6570\u636e. \u4e00\u957f\u4e32\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u8fd9\u4e2a\u6cdb\u5316\u95ee\u9898\u4e0a, \u4ee5\u96f6\u6837\u672c, \u5f31\u76d1\u7763\u6216\u5f00\u653e\u8bcd\u6c47\u8868\u5b9a\u4f4d\u4e3a\u540d. Built upon MDETR[^30] and GLIP[^41], GLIPv2 converts localization tasks into a grounded vision-language task using the classification-to-matching trick (Section 3). Thus GLIPv2 can learn from the semantic-rich vision-language data and shows strong performance on open-vocabulary localization tasks. \u57fa\u4e8e MDETR \u548c GLIP, GLIPv2 \u4f7f\u7528\u5206\u7c7b\u5339\u914d\u6280\u5de7 (\u7b2c3\u8282) \u5c06\u5b9a\u4f4d\u4efb\u52a1\u8f6c\u6362\u4e3a Grounded \u89c6\u89c9\u8bed\u8a00\u4efb\u52a1. \u56e0\u6b64, GLIPv2 \u53ef\u4ee5\u4ece\u8bed\u4e49\u4e30\u5bcc\u7684\u89c6\u89c9\u8bed\u8a00\u6570\u636e\u4e2d\u5b66\u4e60, \u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u8868\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd.","title":"Localization Models \u5b9a\u4f4d\u6a21\u578b"},{"location":"Models/MultiModal/PN-2206.05836/#vision-language-understanding-models","text":"Vision-language (VL) understanding tasks such as VQA[^3], image captioning [ 11 ], and image-text retrieval [ 31 ] involve understanding visual semantics and how they are expressed in natural language. Many VL models (e.g., BUTD) [ 2 , 70 ] rely on a pre-trained localization model as their visual encoder; the downside is the pro-longed \u201clocalization->VLP\u201d pre-training pipeline [ 46 , 57 , 13 , 56 , 39 , 37 , 75 , 42 , 40 ]. In contrast, GLIPv2 simplifies the pre-training pipeline and enables grounded VL understanding for better interpretability (Section 4.4). \u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6a21\u578b\u4f8b\u5982 VQA, image captioning \u548c image-text retrieval \u6d89\u53ca\u5230\u7406\u89e3\u89c6\u89c9\u8bed\u4e49\u548c\u5982\u4f55\u4ee5\u81ea\u7136\u8bed\u8a00\u8868\u793a\u5b83\u4eec. \u8bb8\u591a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5982 BUTD \u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u5b9a\u4f4d\u6a21\u578b\u4f5c\u4e3a\u5176\u89c6\u89c9\u7f16\u7801\u5668, \u5e95\u4fa7\u662f\u957f\u671f\u7684 \"\u5b9a\u4f4d\u2192VLP\" \u9884\u8bad\u7ec3\u8fc7\u7a0b. \u76f8\u6bd4\u4e4b\u4e0b, GLIPv2 \u7b80\u5316\u4e86\u9884\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u4f7f\u5f97 grounded \u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6709\u4e86\u66f4\u5f3a\u7684\u89e3\u91ca\u6027.","title":"Vision-Language Understanding Models \u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6a21\u578b"},{"location":"Models/MultiModal/PN-2206.05836/#unifying-localization-and-understanding","text":"[24, 28, 66] made pioneering efforts in unifying localization and understanding. However, localization tasks are still treated as single-modality tasks, while VL tasks involve two modalities. The unification is achieved via straightforward multi-tasking: a low-level visual encoder is shared across tasks and two separate branches are designed for localization and VL understanding. Such unified models do not bring evident mutual benefit and often underperform task-specific models. In contrast, GLIPv2 identifies grounded VL understanding as a meta-task for localization and understanding. The task unification brings architecture unification: the unified grounded VL understanding model empowers a localization branch with VL capacity, arriving at a unified branch that excels at both tasks.","title":"Unifying localization and understanding"},{"location":"Models/MultiModal/PN-2206.05836/#glipv2-vs-glip","text":"GLIP shows that grounded pre-training improves localization. GLIPv2 further shows grounded pre-training improves VL understanding and thus leads to a unified model for localization and VL understanding. GLIPv2 introduces the inter-image region-word contrastive loss, which is another and stronger grounding task than the pre-training task in GLIP. The proposed loss can be viewed as a region-word level generalization of the prevalent image-level contrastive learning [38, 51, 65]. GLIPv2 outperforms GLIP on all benchmarks with the same pre-training data.","title":"GLIPv2 vs GLIP"},{"location":"Models/MultiModal/PN-2206.05836/#3-glipv2-unifying-localization-and-vl-understanding","text":"Based on the reformulation of object detection as a generalized phrase grounding task in GLIP [ 41 ], we unify both localization and VL understanding tasks as grounded vision-language tasks. A grounded vision-language task takes both image and text as inputs, and outputs region-level understanding results (e.g., detection, segmentation) and/or image-level understanding results with associated grounding/localization information (e.g., VQA, image captioning). We will present the unified grounded VL formulation and architecture in Section 3.1, the pre-training losses in Section 3.2, and transfer to downstream tasks in Section 3.3.","title":"3. GLIPv2: Unifying Localization and VL Understanding"},{"location":"Models/MultiModal/PN-2206.05836/#31-a-unified-vl-formulation-and-architecture","text":"At the center of GLIPv2 \u2019s unified formulation is theclassification-to-matchingtrick, which reformulates anytask-specific fixed-vocab classification problem as an task-agnostic open-vocabulary vision-language matchingproblem. The best example is the reformulation of image classification as image-text matching in CLIP [ 51 ], which enables the model to learn from raw image-text data directly, and achieves strong zero-shot results on open-vocabulary classification tasks. In GLIPv2 , we replace every semantic classification linear layer in traditional single-modality vision models with a vision-language matching dot-product layer. As illustrated in Figure 1, GLIPv2 \u2019s unified VL architecture is based on the generic architecture we term Architecture\u03a0. It consists of a dual encoder, denoted asEncVandEncL, and a fusion encoder, denoted asEncV L. The model takes an image-text pair(Img,Text)as input, and extract visual and text features as below: O \u030a=EncV(Img), P \u030a=EncL(Text), O, P=EncV L(O, \u030aP \u030a), (1) where(O \u030a,P \u030a)and(O, P)denote the image/text featuresbeforeandafterVL fusion, respectively.","title":"3.1. A Unified VL Formulation and Architecture"},{"location":"Models/MultiModal/PN-2206.05836/#vision-language-understanding-tasks","text":"Arch\u03a0is the most popular model architecture for VL understanding tasks. Given the cross-modality fused representationsOandP, it is straightforward to add lightweight task-specific heads for various VL tasks. For example, GLIPv2 adds a two-layer MLP on top of text featuresPas the masked language modeling (MLM) head, to perform the MLM pre-training. We provide model details of VQA and image captioning in Section 3.3.","title":"Vision-Language understanding tasks"},{"location":"Models/MultiModal/PN-2206.05836/#language-guided-object-detection-and-phrase-grounding","text":"Following GLIP [ 41 ], GLIPv2 uses the classification-to-matching trick to unify detection and grounding. More specifically, for detection, we simply replace the class logitsScls=OWT, whereWis the weight matrix of the box classifier, with a task-agnostic region-word similarity logitsSground=OPT, where text featuresPare label embeddings from a task-agnostic language encoder. As shown in Figure 1, object detection and phrase grounding share the same input/output format and model architecture. See GLIP [ 41 ] for more details. Their only difference is the input text format: (1) for object detection, the text input is a string of concatenated candidate object labels; (2) for phrase grounding, the text input is a natural language sentence. We refer to GLIP [41] for more details.","title":"(Language-guided) object detection and phrase grounding"},{"location":"Models/MultiModal/PN-2206.05836/#language-guided-instance-segmentation-and-referring-image-segmentation","text":"Given the object detection results, an instance segmentation head is added to classify each pixel within the box into a semantic class. Again, GLIPv2 uses the classification-to-matching trick to produce a unified instance segmentation head for the standard instance segmentation tasks and the referring image segmentation tasks and leverage both types of data for its pre-training. This classification-to-matching trick can also apply to many other semantic classification heads in single modality CV models (e.g., semantic segmentation) and thus transfers them to language-guided CV models.","title":"(Language-guided) instance segmentation and referring image segmentation"},{"location":"Models/MultiModal/PN-2206.05836/#32-glipv2-pre-training","text":"The GLIPv2 is pre-trained with three pre-training losses: phrase grounding lossLgroundfrom a vision-language reformulation of the object detection task, region-word contrastive lossLinterfrom a novel region-word level contrastive learning task, and the standard masked language modeling loss Lmlmproposed in BERT [17]. L GLIPv2 =Lloc+Lintra \ufe38 \ufe37\ufe37 \ufe38 Lground +Linter+Lmlm (2) Similar to losses in detection tasks, the grounding lossLgroundhas two parts: the localization lossLloc trains localization heads with bounding-box supervision, e.g., RPN loss, box regression loss and/or centerness loss [ 59 ]; the intra-image region-word alignment lossLintrais essentially the semantic classification/retrieval loss for each region.","title":"3.2. GLIPv2 Pre-training"},{"location":"Models/MultiModal/PN-2206.05836/#intra-image-region-word-alignment-loss","text":"Given one image-text pair(Img,Text), we obtain the image and text featuresaftercross-modality fusionOandP. The Intra-image region-word alignment loss is computed by Lintra=loss(OPT;T), (3) whereOPTis the similarity score between image regions and word tokens, andTis the target affinity matrix determined by the ground-truth annotations. The loss functionlossis typically a cross-entropy loss for two-stage detectors [53] and a focal loss [43] for one-stage detectors. However, as discussed in Section 1, this intra-image region-word contrastive learning is rather weak in the sense of contrastive learning, due to the limited number of phrases that can one caption can contain. GLIP [ 41 ] alleviates this problem by appending a few negative sentences to form a longer text input with more (negative) phrases. However, constrained by the maximal length of text tokens (256 in GLIP and GLIPv2 ), only a few negative sentences can be added and the number of negative phrases remains in the order of 10\u2019s. This small-negative-example problem also exists in detection data [41] when the input text cannot include all class names in a detection dataset, e.g., Objects365. Inter-image region-word contrastive loss.In GLIPv2 , we propose using phrases from other imagetext pairs in the same batch as negative examples, which effectively increases the number of negative examples to the order of 1000\u2019s, with nearly negligible additional computational cost. As in(1), given a batch of image-text pairs(Imgi,Texti)Bi=1and their ground-truth annotations (Ti)Bi=1, the model produces the image and text featuresbeforeandafterVL fusion, denoted as (O \u030ai,P \u030ai)Bi=1and(Oi, Pi)Bi=1, respectively. Then as illustrated in Figure 2 (Left), a batch-wise similarity matrixSbatchgroundand a batch-wise target affinity matrixTbatchare constructed by considering all the image regions and text phrases across this batch. Their(i, j)\u2019th blocks are obtained as below: Sbatchground[i, j] =O \u030ai(P \u030aj)T, Tbatch[i, j] = Ti, ifi=j obtained by label propagation, otherwise. The inter-image region-word contrastive loss is then defined as the standard bi-directional contrastive loss applied on all image regions and phrases in this batch: Linter=cross_entropy_loss(Sbatchground, Tbatch,axis= 0)+cross_entropy_loss(Sbatchground, Tbatch,axis= 1). (5) Compared with that in the inter-image contrastive loss(3), the number of negatives is multiplied by batch sizeBin this inter-image contrastive loss(5). We elaborate two important details in(4). (1) GLIPv2 uses the image text features(O \u030ai,P \u030ai)Bi=1before VL fusion,not(Oi, Pi)Bi=1after VL fusion, to compute the batch-wise similarity matrix in the inter-image contrastive loss(4). Otherwise, the image and text features after VL fusion would have seen the paired information(1), and thus the model can easily rule out the negatives from misaligned images/texts. (2) We cannot simply assign all regions and texts from unpaired image-text as negative pairs, as done in the standard contrastive loss in CLIP [ 51 ]. Instead, we determine the off-diagonal blocks in the target affinity matrixTbatchby label propagation. For example, as illustrated in Figure 2 (Left), if a region is annotated as \u201cperson\u201d, it should be a positive pair with all \u201cperson\u201d phrases in detection-type texts. We do not propagate positives to grounding-type texts (natural sentences) because phrases in sentences carry contexts that are unique to that image-sentence pair.","title":"Intra-image region-word alignment loss"},{"location":"Models/MultiModal/PN-2206.05836/#pre-training-with-both-detection-and-paired-image-text-data","text":"GLIPv2 pre-training data is in the image-text-target triplet format(Img,Text, T), where the target affinity matrixTcontains the box-label localization annotations. We also use massive image-text pair data(Img,Text)to pre-train GLIPv2 , by generating grounding boxesT\u02c6for phrases in the text with the GLIP pre-trained model from [ 41 ]. The human-annotated OD/grounding data provides high-fidelity localization supervision, while the massive image-text data greatly improves the concept diversity for GLIPv2 .","title":"Pre-training with both detection and paired-image-text data"},{"location":"Models/MultiModal/PN-2206.05836/#second-stage-pre-training-of-the-segmentation-head","text":"GLIPv2 performs a second-stage pre-training of the language-guided segmentation head on both instance segmentation and image referring segmentation data, while fixing all other parts of the model.","title":"Second-stage pre-training of the segmentation head"},{"location":"Models/MultiModal/PN-2206.05836/#33-transfer-glipv2-to-localization-and-vl-tasks","text":"We introduce two ways to easily transfer GLIPv2 to various downstream tasks. In addition, GLIPv2 can perform conventional VL tasks (e.g., VQA) along with localization, effectively making every task we consider a \u201cgrounded VL understanding\u201d task.","title":"3.3. Transfer GLIPv2 to Localization and VL Tasks"},{"location":"Models/MultiModal/PN-2206.05836/#one-model-architecture-for-all","text":"GLIPv2 can be transferred to downstream tasks by fine-tuning the model with an (optional) task-specific head. 1) Fordetection and segmentationtasks, no task-specific head is needed as the pre-training architecture can inherently perform detection and segmentation. 2) ForVLtasks: for VQA, a classification head is added on top of the hidden representation of the start-of-sequence token; for caption generation, we train with a unidirectional language modeling loss, which maximizes the likelihood of the next word given context. We use a unidirectional attention mask and prevent the image part from attending to the text in the fusion layers.","title":"One model architecture for all"},{"location":"Models/MultiModal/PN-2206.05836/#one-set-of-weights-for-all","text":"There is a growing interest in developing models that can be transferred to various tasks while only changing the least amount of parameters to save training time and storage cost [ 55 , 36 ]. Following GLIP, GLIPv2 can be transferred to localization tasks in azero-shotor aprompt-tuningsetting (Section 4.2). One single GLIPv2 model can serve various tasks, where each task only keeps few or no parameters. Of particular interest is the prompt tuning setting. For a certain localization task, the text prompt is the same for all input images; thus, we could directly tuneP \u030a, a small prompt embedding matrix, to adapt GLIPv2 to new tasks. Prompt tuning in a deep-fused model such as GLIPv2 is different from the conventional linear probing/prompt tuning setting [ 62 , 51 , 73 ] in shallow-interacting vision models such as CLIP. The latter can also be viewed as only tuning a small prompt/softmax embeddingP; however, tuningPonly affects the very last layer of the model while the visual representation is still frozen. In contrast, GLIP/ GLIPv2 \u2019s visual representation is conditioned on the prompt embeddingP \u030a; tuningP \u030achanges the text, visual, as well as fused embeddings. As a result, prompt tuning in GLIPv2 is highly effective, often matching the performance of fine-tuning (see Table 2). This is in contrast to the common observation in CV that linear probing lags behind fine-tuning by a large gap [25].","title":"One set of weights for all"},{"location":"Models/MultiModal/PN-2206.05836/#grounded-vl-understanding","text":"GLIPv2 also enables grounded VL understanding, where we retain the ability to perform grounding when fine-tuning the model to a downstream VL task. This increases the interpretability of the model. Specifically, we first turn the VL data of the downstream task into grounded VL data using a pre-trained GLIP model. Then we train the model with both the downstream task head and grounding head. For VQA, the model is trained to predict the answer and ground entities in the question as well as the implied entity in the answer; for captioning, the model is trained to predict the next word given the context and ground the current decoded word. By tuning localization tasks into a grounded VL task and augmenting VL tasks with grounding ability, we effectively turn every task into a grounded VL understanding task (see examples in Figure 1).","title":"Grounded VL understanding"},{"location":"Models/MultiModal/PN-2206.05836/#4-experiments","text":"In this section, we show that GLIPv2 serves as a performant and easy-to-deploy general-purpose vision system. 1)One Model Architecture for All(Section 4.1). GLIPv2 can be directly fine-tuned to both localization and VL understanding tasks with minimal architecture change. It achieves performance on par with SOTA models with specialized architectures. 2)One Model Weight for All(Section 4.2). GLIPv2 can be transferred to localization tasks in a zero-shot manner with zero Model Model Type COCO-Det ODinW(test-dev) (test) (minival)LVIS COCO-Mask(test-dev) Flickr30K PhraseCut(test) (test) (test-dev / test-std) (Karpathy-test)VQA Captioning Mask R-CNN [26] Localization 39.8 33.3 / / 37.1 DETR [9] 42.0 17.8 / DyHead-T [15] 49.7 60.8 DyHead-L [15] 60.3* VisualBERT [39] Understanding - - - - 71.33 - 70.8 / 71.0 - UNITER [12] - - - - - - 73.8 / 74.0 - VinVL [70] - - - - - - 76.5 / 76.6 130.8 GPV [24] Localization & Understanding - - - - - - 62.5 / - 102.3 UniT [28] 42.3 - - - - - 67.6 / - - MDETR [30] - - 24.2 / - - 84.3 53.7 70.6 / 70.6 - Unicorn [66] - - - - 80.4 - 69.2 / 69.4 119.1 GLIP-T [41] Localization & Understanding 55.2 64.9 85.7 GLIP-L [41] 61.5* 68.9 87.1 GLIPv2 -T (Ours) Localization & Understanding 55.5 66.5 50.6 / 41.4 53.5 / 42.0 86.5 59.4 71.6 / 71.8 122.1 GLIPv2 -B (Ours) 58.8 69.4 57.3 / 46.2 59.0 / 45.8 87.5 61.3 73.1 / 73.3 128.5 GLIPv2 -H (Ours) 60.6 (62.4*) 70.4 59.8 / 48.8 59.8 / 48.9 87.7 61.3 74.6 / 74.8 131.0 Table 1: One model architecture results. For COCO-Det test-dev, * indicates multi-scale evaluation. For LVIS, we report the numbers for bothbboxandsegmon minival to avoid data contamination due to the pre-training. For Flickr30K test, we report the metric underR@1. For COCO-Mask, we also report bothbboxandsegmon test-dev. parameter update; with prompt tuning, a single GLIPv2 model can achieve comparable performance with fully fine-tuned settings on both localization and understanding tasks. Following GLIP [41], we adopt Swin Transformer [45] as the image encoder EncV, text transformers [ 60 , 51 ] as the text encoderEncL, Dynamic Head [ 15 ] with language-aware deep fusion [ 41 ] as the fusion encoderEncV L, and Hourglass network [ 49 ] as instance segmentation head feature extractor. We train GLIPv2 at three scales: GLIPv2 -T, GLIPv2 -B, and GLIPv2 -H. GLIPv2 -Thas the same model config and initialization as GLIP-T: Swin-Tiny and BERT-Base as the dual encoder. The model is pre-trained on the following data: 1) O365, 2) GoldG as in GLIP-T (C), and 3) Cap4M, 4M image-text pairs collected from the web with boxes generated by GLIP-T [ 41 ]. GLIPv2 -B/ GLIPv2 -Hare based on Swin-Base/Swin-Huge and the pre-layernorm text transformer [ 18 ] as dual encoder, and are initialized from the UniCL [ 65 ] checkpoints. We observe much stabler training with GPT-type pre-layernorm transformer [ 18 ] than BERT-type post-layernorm transformer. The training data contain: 1) FiveODs (2.78M data)^1 ; 2) GoldG as in MDETR [ 30 ]; and 3) CC15M+SBU, 16M public image-text data with generated boxes by GLIP-L [ 41 ].Segmentation headsof GLIPv2 models are pre-trained on COCO, LVIS [ 23 ] and PhraseCut [ 63 ], with all other model parameters are frozen. NoteAll datasets above were collected by the creators (cited) and consent for any personally identifiable information (PII) was ascertained by the authors where necessary. Due to limited space, we refer to supplementary for details of training recipes and hyper-parameters.","title":"4. Experiments \u5b9e\u9a8c"},{"location":"Models/MultiModal/PN-2206.05836/#41-one-model-architecture-for-all","text":"We compare GLIPv2 to existing object detection and vision-language pre-training methods on a wide range of tasks. We fine-tune the model on 8 different downstream tasks and report the performance in Table 1. We make the following observations. GLIPv2 v.s. specialized Localization methods. GLIPv2 outperforms previous localization models on generalization to both common and rare classes and domainswith a single model architecture and pre-training stage.1) OD on common categories (COCO-Det), GLIPv2 -T achieves 5.8 improvement compared to the standard DyHead-T trained on O365 (55.5 v.s. 49.7). GLIPv2 -H reaches 62.4 AP on test-dev, and surpass the performance of the previous SoTA model GLIP-L.2) OD on rare / unseen categories (LVIS), GLIPv2 -T outperforms a supervised MDETR on thebboxby a great margin (59.8 v.s. 24.2).3) Generalization to diverse real-word tasks (ODinw), GLIPv2 -T (55.5) performs better than original GLIP-T (64.9) on the average of 13 public datasets; GLIPv2 -B outperforms GLIP-L by 0.5 AP.4) Instance segmentation (COCO-Mask & PhraseCut), for traditional instance segmentation (^1) Besides O365, it combines with 4 additional OD datasets including COCO [44], OpenImages [33], Visual Genome [34], and ImageNetBoxes [35] Model Direct Evaluation Prompt Tuning COCO-Mask ODinW LVIS-Det Flickr30K COCO-Det ODinW LVIS COCO-Mask PhraseCut (minival) (test) (minival) (minival) (test-dev) (test) (minival) (test-dev) (test) GLIP-T 46.6/\u2013 46.5 26.0 85.7 \u2013 46.5 GLIP-L 49.8/\u2013 52.1 37.3 87.1 58.8 67.9 GLIPv2 -T 47.3/35.7 48.5 29.0 86.0 53.4(-2.1) 64.8(-1.7) 49.3 / 34.8(-1.3 / -6.6) 53.2 / 41.2(-0.3 / -0.8) 49.4 GLIPv2 -B 61.9\u2020/43.4 54.2 48.5 87.2 59.0(+0.2) 67.3(-2.1) 56.8 / 41.7(-0.5 / -4.5) 58.8 / 44.9(-0.2 / -0.9) 55.9 GLIPv2 -H 64.1\u2020/47.4 55.5 50.1 87.7 60.2 / 61.9*(-0.4 / -0.5) 69.1(-1.3) 59.2 / 43.2(-0.6 / -5.7) 59.8 / 47.2(-0.0 / -1.7) 56.1 Table 2: One set of weights results v.s. Original GLIP. * indicates multi-scale evaluation. Numbers in red clearly points out the difference between the prompt tuning and full fine-tuning results (see Table 1). Numbers in gray mean that they are not inzero-shotmanner.\u2020: these two numbers are artificially high due to some overlap between COCO-minival and VisualGenome-train. FullTuning-Model Prompt Tuning GLIPv2 -H GLIP GLIPv2 v2--BT GLIP-T DyHead-T Figure 3: Data efficiency of GLIPv2 on ODinW. The X-axis is the amount of task-specific data, from zero-shot to all data. Y-axis is the average AP across 13 datasets. Model Zero-Shot 0 1 Prompt Tuning / Fine Tuning 3 5 10 All DyHead-TO365[41] 33.843.646.450.860.8Lloc+Lintra(GLIP-T) 46.5 49.951.3 53.754.9 55.556.4 56.658.4 62.464.9 Lloc+Lintra+Linter 48.4 52.151.4 55.655.3 56.756.6 58.359.5 62.966.3 Lloc+Lintra+Linter+Lmlm 48.5 52.452.8 55.655.6 57.457.4 58.859.7 64.866.5 Table 3: Zero-shot, prompt tuning, and full finetuning performance on ODinW. GLIPv2 models exhibit superior data efficiency. (i.e., COCO-Mask), GLIPv2 -H outperforms the well-known Mask R-CNN by a great margin onsegm. For language-guided segmentation (i.e., PhraseCut), compared to MDETR, GLIPv2 -T achieves an improvement of 5.7 mask AP. GLIPv2 v.s. specialized VL Understanding methods. GLIPv2 rivals with SoTA specialized models for VL tasks.1) For VQA, GLIPv2 outperforms VisualBERT and UNITER and approaches the previous SoTA model VinVL.2) For Captioning, the best GLIPv2 even surpasses VinVL (VinVL and GLIPv2 are not trained with CIDEr optimization). GLIPv2 v.s. localization and VL models.Prior works such GPV, UniT and Unicorn have also explored unifying localization and VL models (see a discussion in Section 2). GLIPv2 outperforms all previous systems on both localization and VL tasks. For the best GLIPv2 -H, it outperforms the UniT by a great margin (18.3 AP) on COCO object detection tasks. Meanwhile, it also surpasses UniT\u2019s performance on VQA by 6.9 points and GPV\u2019s peformance on Image Captioning as well. Takeaway.Most notably, GLIPv2 outperforms previous \u201cunified\u201d models (GPV, UniT, MDETR, Unicorn) by a large margin. This is the first time that a single model architecture could achieve near SoTA performance on both localization and understanding. In contrast, in prior work, there exists certain trade-off between localization and understanding: models that aim to achieve high understanding performance tend to have lower localization performance (e.g., UNiT\u2019s detection performance is limited to the DETR [ 9 ] architecture), as it is not trivial to merge a SoTA localization branch and a SoTA VL branch into a single model.","title":"4.1. One Model Architecture for All"},{"location":"Models/MultiModal/PN-2206.05836/#42-one-set-of-model-parameters-for-all","text":"GLIPv2 is pre-trained to perform grounding; thus it can be transferred to various localization tasks with changing zero or few parameters. We evaluate GLIPv2 under two such settings: 1) direct evaluation, where we transfer the model \u201cas is\u201d without any parameter change, and 2) prompt tuning, where only the prompt embedding is tuned for specific tasks (Section 3.3). Direct evaluation. The pre-trained GLIPv2 can be directly evaluated on any object detection task (by concatenating the object categories into a text prompt) and visual grounding task without any further tuning. We evaluate the models on four localization tasks: COCO, ODinW, LVIS, and Flickr30, and their results are presented in Table 2. Note that for GLIPv2 -B and GLIPv2 -H, the training sets of Flick30K and LVIS are present in the pre-training data. Thus, reported numbers on these metrics are notzero-shotevaluation (we have marked them gray). For all other evaluation results, the models are evaluated inzero-shotsettings without any further tuning. GLIPv2 can be effortlessly transferred to different localization tasks without further tuning.1) For COCO, GLIPv2 -T achieves a zero-shot performance of 47.3 without seeing any COCO training images. This surpasses well-established supervised systems (e.g., Mask R-CNN) and also outperforms GLIP-T by 0.7 AP. 2) ForODinW, GLIPv2 also shows strong zero-shot performance. GLIPv2 -T (48.5) surpasses the GLIP-T (46.5). Meanwhile, the zero-shot performance of GLIPv2 -B and GLIPv2 H even surpasses the 10-shot tuning performance of DyHead-T (to be introduced in Figure 3). 3) ForLVIS, GLIPv2 -T achieves a 3 AP improvement performance compared to the GLIP-T. 4) For Flickr30K, GLIPv2 -B achieves even higher number (87.2) compared to original GLIP-L (87.1). Prompt Tuning. Following GLIP, GLIPv2 supports efficient prompt tuning: the visual representation is heavily conditioned on the text representation due to the deep fusion block (Section 3.3); thus we could fine-tune only the prompt embedding for each task but still maintain high performance. Prompt tuning GLIPv2 achieves similar performance as full fine-tuning. When comparing the performance of each task in Table 1 and 2 at the same time, for GLIPv2 , prompt tuning performance almost matches the one model architecture results on localization tasks, without changing any of the grounding model parameters.","title":"4.2. One Set of Model Parameters for All"},{"location":"Models/MultiModal/PN-2206.05836/#43-glipv2-as-a-strong-few-shot-learner","text":"We demonstrate GLIPv2 \u2019s performance on ODinW datasets with respect to different amounts of training data in Figure 3. The performance improvement between GLIPv2 -T and GLIP-T exhibits more superior data efficiency for prompt tuning. We compare with the SoTA detector DyHead-T, pre-trained on Objects365 in Table 3. It can be seen that a zero-shot GLIPv2 -T (48.5) outperforms a outperforms 5-shot DyHead-T (46.4) while the performance of one-shot GLIPv2 -H (61.3) surpasses a all-shot fully supervised DyHead-T (60.8).","title":"4.3. GLIPv2 as a Strong Few-Shot Learner"},{"location":"Models/MultiModal/PN-2206.05836/#44-analysis","text":"Pre-training lossesTable 4 shows the performance of the downstream tasks with different variants of our method. Compared to the GLIP pre-training tasks with only intra-image region-word contrastive loss (Row 3), adding inter-image word-region loss (Row 5) substantially improves the pre-trained model performance across all the object detection tasks (COCO, ODinW, and LVIS) on both zero-shot and fine-tuned manner. Consistent with common observations from most VL understanding methods, adding MLM loss (Row4) benefits for learning the representation for understanding tasks (Flick30k, VQA, and Captioning). Furthermore, using all three losses together at the 1st stage pre-training and doing the 2nd stage pre-training without MLM on OD and GoldG data, GLIPv2 (Row6) can perform well on both the localization and VL understanding tasks. An additional stage of pre-training is applied for small models ( GLIPv2 -T and GLIPv2 -B) due to limited model capacity. In order to achieve higher performance on both localization and understanding tasks, we find that including all data (even with some noise) and MLM loss in the first stage of pre-training will benefit the model for learning a better representation of both localization and understanding capability. Since the OD tasks require the model with more accurate localization ability, in our 2nd stage of pre-training, we decide to eliminate the MLM loss. The large model ( GLIPv2 -H) does not need this additional stage because it has enough capacity to learn both wordregion alignment and MLM together in a single stage. Pre-training dataTable 5 reports the last checkpoint results on GLIPv2 when we do the scaling up of pre-training data. As more weak image-text pair data (Cap) is involved in our training, it benefits both standard/in-domain (i.e., COCO, Flickr30K) and large-domain gap (i.e., ODinW, LVIS) tasks. We also show that by adding the inter-image region-word contrastive helps when we are fixing the data at the same scale. For large-domain gap tasks, adding the inter-image region-word contrastive Row Model COCO ODinW LVISFlickr30K VQA Captioning 1 No pre-train \u2013/50.6 \u2013/60.8 \u2013 \u2013 64.6 111.5 2 +Lmlm \u2013/48.5 \u2013/37.4 \u2013 \u2013 64.6 110.9 3 +Lloc+Lintra 46.6/55.2 46.5/64.9 26.0 85.7 69.4 119.7 4 +Lloc+Lintra+Lmlm 47.0/55.2 47.6/66.2 28.5 86.5 69.8 120.7 5 +Lloc+Lintra+Linter 47.1/55.4 48.4/66.3 28.6 85.8 68.7 120.4 6 +Lloc+Lintra+Linter+Lmlm47.3/55.5 48.5/66.5 29.0 86.3 70.7 122.1 Table 4: Pre-training losses on Tiny-scale model. Involving intra-image region-word alignment lossLintra, inter-image region-word contrastive lossLinterand MLM lossLmlmwill benefit both localization and understanding tasks. Linter Pre-train Data COCO ODinW LVIS Flick30K 7 O365, GoldG 48.06 43.14 25.6 84.36 3 O365, GoldG 48.59 42.64 26.9 83.90 7 O365, GoldG, Cap4M 48.21 51.35 34.2 85.56 3 O365, GoldG, Cap4M 48.79 52.70 35.0 85.50 7 O365, GoldG, Cap12M 48.50 49.32 35.5 85.79 3 O365, GoldG, Cap12M 49.26 53.15 36.6 85.84 Table 5: Pre-train data scale up on Base-scale model. Results are reported at the last checkpoint. See supplementary for results at all checkpoints. Model B4 CIDEr SPICECOCO Caption Flickr30K GroundingR@1 R@5 R@10 GLIPv2 -T 36.5 119.8 21.6 80.8 94.4 96.5 GLIPv2 -B37.4 123.0 21.9 81.0 94.5 96.5 Table 6: GLIPv2 can perform captioning and grounding at the same time (a.k.a., grounded VL understanding). loss will further boost the model to learn better representation. For more detailed scaling-up effects on various tasks under all the checkpoints for GLIP and GLIPv2 , refer to Appendix. Note that the(Img,Text, T)data used in GLIPv2 pre-training can be just human-annotated data (Row1&2 in Table 5), with which GLIPv2 pre-training does not involve any pseudo data from a pre-trained grounding/localization model. In order to achieve the best performance, GLIPv2 uses image-text pair data with pseudo boxes (Cap) from a pre-trained GLIP model (Row3-6 in Table 4), which is trained with the same \"grounded VL understanding\" task but just with smaller data. Grounded Vision-Language Understanding GLIPv2 can be trained to perform a VL task and grounding at the same time (Section 3.3). We denote such an ability as grounded VL understanding. In Figure 1, we showcase grounded predictions of GLIPv2 on VQA and COCO captions. We also conduct quantitative evaluations (Table 6). The model achieves strong performance for both VL understanding (on COCO Caption) and localization (on Flickr30K Grounding). Such an ability to produce high-level semantic outputs (i.e., answers and captions) and supporting localization results is another appealing trait of GLIPv2 , as potential users can have a better understanding of the model behaviour. See more detailed analysis and qualitative examples in the Appendix.","title":"4.4. Analysis"},{"location":"Models/MultiModal/PN-2206.05836/#5-conclusion-and-social-impacts","text":"This paper proposes GLIPv2 , a unified framework for VL representation learning that serves both localization tasks and VL understanding tasks. We experimentally verify the effectiveness of the unified model and the novel region-word contrastive learning. Compared to existing methods, GLIPv2 achieves competitive near SoTA performance on various localization and understanding tasks. However, additional analysis of the data and the model is necessary before deploying it in practice since large-scale web data may contain unintended private information, unsuitable images/text, or some bias leakage. Further investigation may be needed for web data due to the above issues.","title":"5. Conclusion and Social Impacts"},{"location":"Models/MultiModal/PN-2206.05836/#references","text":"[1] Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.: Bottom-up and top-down attention for image captioning and visual question answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 6077\u20136086. IEEE (2018) [2] Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.: Bottom-up and top-down attention for image captioning and visual question answering. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 6077\u20136086 (2018) [3] Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.: VQA: Visual Question Answering. In: International Conference on Computer Vision (ICCV) (2015) \\ [4] Bansal, A., Sikka, K., Sharma, G., Chellappa, R., Divakaran, A.: Zero-shot object detection. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 384\u2013400 (2018) [5] Bilen, H., Vedaldi, A.: Weakly supervised deep detection networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2846\u20132854 (2016) [6] Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E., et al.: On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021) [7] Bucher, M., Vu, T.H., Cord, M., P\u00e9rez, P.: Zero-shot semantic segmentation. Advances in Neural Information Processing Systems 32 (2019) [8] Caesar, H., Uijlings, J., Ferrari, V.: Coco-stuff: Thing and stuff classes in context. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 1209\u20131218 (2018) [9] Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-to-end object detection with transformers. In: European Conference on Computer Vision. pp. 213\u2013229. Springer (2020) [10] Chen, K., Pang, J., Wang, J., Xiong, Y., Li, X., Sun, S., Feng, W., Liu, Z., Shi, J., Ouyang, W., et al.: Hybrid task cascade for instance segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4974\u20134983 (2019) [11] Chen, X., Fang, H., Lin, T.Y., Vedantam, R., Gupta, S., Doll\u00e1r, P., Zitnick, C.L.: Microsoft COCO captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325 (2015) [12] Chen, Y.C., Li, L., Yu, L., El Kholy, A., Ahmed, F., Gan, Z., Cheng, Y., Liu, J.: UNITER: Universal image-text representation learning. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 104\u2013120. Springer (2020) [13] Chen, Y.C., Li, L., Yu, L., Kholy, A.E., Ahmed, F., Gan, Z., Cheng, Y., Liu, J.: Uniter: Learning universal image-text representations. arXiv preprint arXiv:1909.11740 (2019) [14]Dai, J., Li, Y., He, K., Sun, J.: R-fcn: Object detection via region-based fully convolutional networks. In: Advances in neural information processing systems. pp. 379\u2013387 (2016) [15]Dai, X., Chen, Y., Xiao, B., Chen, D., Liu, M., Yuan, L., Zhang, L.: Dynamic head: Unifying object detection heads with attentions. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 7373\u20137382 (2021) [16]Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: ImageNet: A Large-Scale Hierarchical Image Database. In: Proceedings of the IEEE conference on computer vision and pattern recognition (2009) [17]Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018) [18]Gao, P., Geng, S., Zhang, R., Ma, T., Fang, R., Zhang, Y., Li, H., Qiao, Y.: Clip-adapter: Better vision-language models with feature adapters. arXiv preprint arXiv:2110.04544 (2021) [19]Gokberk Cinbis, R., Verbeek, J., Schmid, C.: Multi-fold mil training for weakly supervised object localization. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2409\u20132416 (2014) [20]Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 6904\u20136913 (2017) [21]Gu, X., Lin, T.Y., Kuo, W., Cui, Y.: Open-vocabulary object detection via vision and language knowledge distillation. arXiv preprint arXiv:2104.13921 (2021) [22]Gu, X., Lin, T.Y., Kuo, W., Cui, Y.: Zero-shot detection via vision and language knowledge distillation. arXiv preprint arXiv:2104.13921 (2021) [23]Gupta, A., Dollar, P., Girshick, R.: Lvis: A dataset for large vocabulary instance segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 5356\u20135364 (2019) [24]Gupta, T., Kamath, A., Kembhavi, A., Hoiem, D.: Towards general purpose vision systems. arXiv preprint arXiv:2104.00743 (2021) [25]He, K., Chen, X., Xie, S., Li, Y., Doll\u00e1r, P., Girshick, R.: Masked autoencoders are scalable vision learners. arXiv preprint arXiv:2111.06377 (2021) [26]He, K., Gkioxari, G., Doll\u00e1r, P., Girshick, R.: Mask r-cnn. In: Proceedings of the IEEE international conference on computer vision. pp. 2961\u20132969 (2017) [27]Hendrycks, D., Gimpel, K.: Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415 (2016) [28]Hu, R., Singh, A.: Unit: Multimodal multitask learning with a unified transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 1439\u20131449 (2021) [29]Hudson, D.A., Manning, C.D.: Gqa: A new dataset for real-world visual reasoning and compositional question answering. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 6700\u20136709 (2019) [30]Kamath, A., Singh, M., LeCun, Y., Synnaeve, G., Misra, I., Carion, N.: Mdetr-modulated detection for end-to-end multi-modal understanding. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 1780\u20131790 (2021) [31]Karpathy, A., Joulin, A., Fei-Fei, L.F.: Deep fragment embeddings for bidirectional image sentence mapping. Advances in neural information processing systems 27 (2014) [32]Kiros, R., Salakhutdinov, R., Zemel, R.S.: Unifying visual-semantic embeddings with multimodal neural language models. arXiv preprint arXiv:1411.2539 (2014) [33]Krasin, I., Duerig, T., Alldrin, N., Ferrari, V., Abu-El-Haija, S., Kuznetsova, A., Rom, H., Uijlings, J., Popov, S., Veit, A., et al.: Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github . com/openimages 2 (3), 18 (2017) [34]Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L.J., Shamma, D.A., et al.: Visual Genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of Computer Vision (IJCV) 123 (1), 32\u201373 (2017) [35]Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems 25 , 1097\u20131105 (2012) [36]Lester, B., Al-Rfou, R., Constant, N.: The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021) [37]Li, G., Duan, N., Fang, Y., Jiang, D., Zhou, M.: Unicoder-VL: A universal encoder for vision and language by cross-modal pre-training. arXiv preprint arXiv:1908.06066 (2019) [38]Li, J., Selvaraju, R., Gotmare, A., Joty, S., Xiong, C., Hoi, S.C.H.: Align before fuse: Vision and language representation learning with momentum distillation. Advances in Neural Information Processing Systems 34 (2021) [39]Li, L.H., Yatskar, M., Yin, D., Hsieh, C.J., Chang, K.W.: Visualbert: A simple and performant baseline for vision and language. arXiv preprint arXiv:1908.03557 (2019) [40]Li, L.H., You, H., Wang, Z., Zareian, A., Chang, S.F., Chang, K.W.: Unsupervised vision-andlanguage pre-training without parallel images and captions. arXiv preprint arXiv:2010.12831 (2020) [41]Li, L.H., Zhang, P., Zhang, H., Yang, J., Li, C., Zhong, Y., Wang, L., Yuan, L., Zhang, L., Hwang, J.N., et al.: Grounded language-image pre-training. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10965\u201310975 (2022) [42]Li, X., Yin, X., Li, C., Zhang, P., Hu, X., Zhang, L., Wang, L., Hu, H., Dong, L., Wei, F., et al.: Oscar: Object-semantics aligned pre-training for vision-language tasks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 121\u2013137. Springer (2020) [43]Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll\u00e1r, P.: Focal loss for dense object detection. In: Proceedings of the IEEE international conference on computer vision. pp. 2980\u20132988 (2017) [44]Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: European conference on computer vision. pp. 740\u2013755. Springer (2014) [45]Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B.: Swin transformer: Hierarchical vision transformer using shifted windows. arXiv preprint arXiv:2103.14030 (2021) [46]Lu, J., Batra, D., Parikh, D., Lee, S.: ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. In: Advances in Neural Information Processing Systems (NeurIPS). pp. 13\u201323 (2019) [47]Lu, J., Clark, C., Zellers, R., Mottaghi, R., Kembhavi, A.: Unified-io: A unified model for vision, language, and multi-modal tasks. arXiv preprint arXiv:2206.08916 (2022) [48]Ma, C.Y., Kalantidis, Y., AlRegib, G., Vajda, P., Rohrbach, M., Kira, Z.: Learning to generate grounded visual captions without localization supervision. In: European Conference on Computer Vision. pp. 353\u2013370. Springer (2020) [49]Newell, A., Yang, K., Deng, J.: Stacked hourglass networks for human pose estimation. In: European conference on computer vision. pp. 483\u2013499. Springer (2016) [50]Plummer, B.A., Wang, L., Cervantes, C.M., Caicedo, J.C., Hockenmaier, J., Lazebnik, S.: Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models. In: Proceedings of the IEEE international conference on computer vision. pp. 2641\u2013 2649 (2015) [51]Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al.: Learning transferable visual models from natural language supervision. In: International Conference on Machine Learning (ICML) (2021) [52]Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: Unified, real-time object detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 779\u2013788 (2016) [53]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems 28 , 91\u201399 (2015) [54]Shao, S., Li, Z., Zhang, T., Peng, C., Yu, G., Zhang, X., Li, J., Sun, J.: Objects365: A large-scale, high-quality dataset for object detection. In: Proceedings of the IEEE international conference on computer vision. pp. 8430\u20138439 (2019) [55]Shin, T., Razeghi, Y., Logan IV, R.L., Wallace, E., Singh, S.: Autoprompt: Eliciting knowledge from language models with automatically generated prompts. arXiv preprint arXiv:2010.15980 (2020) [56]Su, W., Zhu, X., Cao, Y., Li, B., Lu, L., Wei, F., Dai, J.: VL-BERT: Pre-training of generic visual-linguistic representations. arXiv preprint arXiv:1908.08530 (2019) [57]Tan, H., Bansal, M.: Lxmert: Learning cross-modality encoder representations from transformers. arXiv preprint arXiv:1908.07490 (2019) [58]Teney, D., Anderson, P., He, X., Van Den Hengel, A.: Tips and tricks for visual question answering: Learnings from the 2017 challenge. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 4223\u20134232 (2018) [59]Tian, Z., Shen, C., Chen, H., He, T.: Fcos: Fully convolutional one-stage object detection. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 9627\u20139636 (2019) [60]Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, \u0141., Polosukhin, I.: Attention is all you need. In: Advances in neural information processing systems. pp. 5998\u20136008 (2017) [61]Wang, P., Cai, Z., Yang, H., Swaminathan, G., Vasconcelos, N., Schiele, B., Soatto, S.: Omnidetr: Omni-supervised object detection with transformers. arXiv preprint arXiv:2203.16089 (2022) [62]Wang, X., Huang, T.E., Darrell, T., Gonzalez, J.E., Yu, F.: Frustratingly simple few-shot object detection. arXiv preprint arXiv:2003.06957 (2020) [63]Wu, C., Lin, Z., Cohen, S., Bui, T., Maji, S.: Phrasecut: Language-based image segmentation in the wild. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10216\u201310225 (2020) [64]Xiong, R., Yang, Y., He, D., Zheng, K., Zheng, S., Xing, C., Zhang, H., Lan, Y., Wang, L., Liu, T.: On layer normalization in the transformer architecture. In: International Conference on Machine Learning. pp. 10524\u201310533. PMLR (2020) [65]Yang, J., Li, C., Zhang, P., Xiao, B., Liu, C., Yuan, L., Gao, J.: Unified contrastive learning in image-text-label space. arXiv preprint arXiv:2204.03610 (2022) [66]Yang, Z., Gan, Z., Wang, J., Hu, X., Ahmed, F., Liu, Z., Lu, Y., Wang, L.: Crossing the format boundary of text and boxes: Towards unified vision-language modeling. arXiv preprint arXiv:2111.12085 (2021) [67]Yuan, L., Chen, D., Chen, Y.L., Codella, N., Dai, X., Gao, J., Hu, H., Huang, X., Li, B., Li, C., et al.: Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432 (2021) [68]Zareian, A., Rosa, K.D., Hu, D.H., Chang, S.F.: Open-vocabulary object detection using captions. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 14393\u201314402 (2021) [69]Zeng, Y., Zhang, X., Li, H.: Multi-grained vision language pre-training: Aligning texts with visual concepts. arXiv preprint arXiv:2111.08276 (2021) [70]Zhang, P., Li, X., Hu, X., Yang, J., Zhang, L., Wang, L., Choi, Y., Gao, J.: Vinvl: Revisiting visual representations in vision-language models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 5579\u20135588 (2021) [71]Zhang, P., Li, X., Hu, X., Yang, J., Zhang, L., Wang, L., Choi, Y., Gao, J.: Vinvl: Revisiting visual representations in vision-language models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 5579\u20135588 (June 2021) [72]Zhong, Y., Yang, J., Zhang, P., Li, C., Codella, N., Li, L.H., Zhou, L., Dai, X., Yuan, L., Li, Y., et al.: Regionclip: Region-based language-image pretraining. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 16793\u201316803 (2022) [73]Zhou, K., Yang, J., Loy, C.C., Liu, Z.: Learning to prompt for vision-language models. arXiv preprint arXiv:2109.01134 (2021) [74]Zhou, L., Palangi, H., Zhang, L., Hu, H., Corso, J., Gao, J.: Unified vision-language pre-training for image captioning and vqa. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 34, pp. 13041\u201313049 (2020) [75]Zhou, L., Palangi, H., Zhang, L., Hu, H., Corso, J.J., Gao, J.: Unified vision-language pretraining for image captioning and VQA. AAAI (2020) [76]Zhu, P., Wang, H., Saligrama, V.: Zero shot detection. IEEE Transactions on Circuits and Systems for Video Technology 30 (4), 998\u20131010 (2019) [77]Zhu, P., Wang, H., Saligrama, V.: Don\u2019t even look once: Synthesizing features for zero-shot detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 11693\u201311702 (2020)","title":"References \u53c2\u8003\u6587\u732e"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/","text":"Nikolas N\u00fcsken^1 and Lorenz Richter2,3,4 (^1) Institute of Mathematics, Universit\u00e4t Potsdam, 14476 Potsdam, Germany, nuesken@uni-potsdam.de (^2) Institute of Mathematics, Freie Universit\u00e4t Berlin, 14195 Berlin, Germany, lorenz.richter@fu-berlin.de (^3) Institute of Mathematics, Brandenburgische Technische Universit\u00e4t Cottbus-Senftenberg, 03046 Cottbus, Germany (^4) dida Datenschmiede GmbH, 10827 Berlin, Germany December 8, 2021 Abstract 1 Introduction (\u2202t+L)V(x,t) +h(x,t,V(x,t),\u03c3>\u2207V(x,t)) = 0, (x,t)\u2208\u2126\u00d7[0,T), (1a) V(x,T) =f(x), x\u2208\u2126, (1b) V(x,t) =g(x,t), (x,t)\u2208\u2202\u2126\u00d7[0,T], (1c) L= 1 2 \u2211d i,j=1 (\u03c3\u03c3>)ij(x,t)\u2202xi\u2202xj+ \u2211d i=1 bi(x,t)\u2202xi (2) is an elliptic differential operator including the coefficient functionsb\u2208C(Rd\u00d7[0,T],Rd)and\u03c3\u2208C(Rd\u00d7[0,T],Rd\u00d7d), with\u03c3assumed to be non-degenerate. We will later make use of the fact thatLis the infinitesimal generator of the diffusion process defined by the stochastic differential equation (SDE) dXs=b(Xs,s) ds+\u03c3(Xs,s) dWs, (3) whereWsis a standardd-dimensional Brownian motion. Our approach exploiting the connection between (1) and (3) extends almost effortlessly to a wide range of nonlinear elliptic PDEs (see Section 4.1) and eigenvalue problems (see Section 4.2). We also note that the terminal condition (1b) can be replaced by an initial condition without [math.NA] 7 Dec 2021 loss of generality, using a time reversal transformation. Similarly, we may replace the Dirichlet boundary condition (1c) by its Neumann counterpart, that is, constraining the normal derivative\u2202~nVon\u2202\u2126\u00d7[0,T]in (1c). A notorious challenge that appears in the numerical treatment of PDEs is thecurse of dimensionality, suggesting that the computational complexity increases exponentially in the dimension of the state space. In recent years, however, multiple numerical [19, 35, 69] as well as theoretical studies [26, 40] have indicated that a combination of Monte Carlo methods and neural networks offers a promising way to overcome this problem. This paper centers around two strategies that allow for solving quite general nonlinear PDEs: PINNs physics-informed neural networks , also known under the name DGM deep Galerkin method directly minimize the misfit between the left-hand sides and right-hand sides of (1), evaluated at appropriately chosen (random) points in the space-time domain\u2126\u00d7[0,T]and its boundary. deep BSDEs backward stochastic differential equations rely on a reformulation of (1) in terms of stochastic forward-backward dynamics, explicitly making use of the connection between the PDE (1) and the SDE (3). Deep BSDEs minimize the misfit in the terminal condition associated to the backward SDE. We review those approaches (see Section 2) and \u2013 motivated by It\u00f4\u2019s formula \u2013 introduce a novel optimization objective, called thediffusion lossLtdiffusion(see Section 3). Importantly, our construction depends on the auxiliary time parametert\u2208(0,\u221e), allowing us to recover PINNs in the limitt\u2192 0 and deep BSDEs in the limitt\u2192\u221e: PINNs t\u2192 0 \u2190\u2212\u2212\u2212\u2212\u2212\u2212Ltdiffusion t\u2192\u221e \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192deep BSDEs As will become clear below, PINNs may therefore be thought of as accumulating derivative information on the PDE solution locally (in time), whereas deep BSDEs constitute global approximation schemes (relying on entire trajectories). The diffusion loss provides an interpolation between seemingly quite distinct methods. Besides this theoretical insight, we show experimentally that an appropriate choice oftcan lead to a computationally favourable blending of PINNs and deep BSDEs, combining the advantages of both methods. In particular, the diffusion loss (witht chosen to be of moderate size) appears to perform well in scenarios where the domain\u2126has a (possibly complex) boundary and/or the PDE under consideration contains a large number of second order derivatives (for instance, when\u03c3is not sparse). We will discuss the trade-offs involved in Section 5. The curse of dimensionality, BSDEs vs. PINNs.Traditional numerical methods for solving PDEs (such as finite difference and finite volume methods, see [1]) usually require a discretization of the domain\u2126, incurring a computational cost that for a prescribed accuracy is expected to grow linearly in the number of grid points, and hence exponentially in the number of dimensions. The recently developed approaches towards beating this curse of dimensionality \u2013 BSDEs and PINNs alike^1 \u2013 replace the deterministic mesh by Monte Carlo sampling, in principle promising dimension-independent convergence rates [20]. Typically, the approximating function class is comprised of neural networks (expectantly providing adaptivity to low-dimensional latent structures [2]), although also tensor trains have shown to perform well [70]. In contrast to PINNs, methods based on BSDEs make essential use of the underlying diffusion (3) to generate the training data. According to our preliminary numerical experiments, it is not clear whether this use of structure indeed translates into computational benefits; we believe that additional research into this comparison is needed and likely to contribute both conceptually and practically to further advances in the field. The diffusion loss considered in this paper may be a first step in this direction, for a direct comparison between BSDEs and PINNs we refer to Table 1a and Table 1b below. Previous works. Attempts to approximate PDE solutions by combining Monte Carlo methods with neural networks date back to the 1990s, where some variants of residual minimizations have been suggested [41, 49, 50, 51, 73]. Recently, this idea gained popularity under the namesphysics-informed neural networks(PINNs, [68, 69]) and deep Galerkin methods(DGMs, [72]). Let us further refer to a comparable approach that has been suggested in [9], and, for the special case of solving the dynamic Schr\u00f6dinger equation, to [16]. For theoretical analyses we shall for instance mention [57], which provides upper bounds on the generalization error, [17], which states an error analysis for PINNs in the approximation of Kolmogorov-type PDEs, [59], which investigates convergences depending on whether using exact or penalized boundary terms, and [76, 77], which study convergence properties through the (^1) We note in passing that multilevel Picard approximations [7, 36, 38] represent another interesting and fairly different class of methods that however are beyond the scope of this paper. lens of neural tangent kernels. Some further numerical experiments have been conducted in [18, 56] and multiple algorithmic improvements have been suggested, e.g. in [75], which balances gradients during model training, [39], which considers adaptive activation functions to accelerate convergence, as well as [74], which investigates efficient weight-tuning. BSDEs have first been introduced in the 1970s [11] and eventually studied more systematically in the 1990s [62]. For a comprehensive introduction elaborating on their connections to both elliptic and parabolic PDEs we refer for instance to [61]. Numerical attempts to exploit this connection aiming for approximations of PDE solutions have first been approached by backward-in-time iterations, originally relying on a set of basis functions and addressing parabolic equations on unbounded domains [14, 23, 61]. Those methods have been considered and further developed with neural networks in [3, 35] and endowed with tensor trains in [70]. A variational formulation termeddeep BSDE has been first introduced in [19, 28], aiming at PDE solutions at a single point, with some variants following e.g. in [60, 67]. For an analysis of the approximation error of the deep BSDE method we refer to [29] and for a fully nonlinear version based on second-order BSDEs to [5]. An extension to elliptic PDEs on bounded domains has been suggested in [47]. There are additional works aiming to solve linear PDEs specifically, mainly by exploiting the Feynman-Kac theorem and mostly considering parabolic equations [4, 10]. For the special case of the Poisson equation, [24] considers an elliptic equation on a bounded domain. Linear PDEs often admit a variational formulation that suggests to minimize a certain energy functional \u2013 this connection has been used in [22, 44, 54] and we refer to [58] for some further analysis. Similar minimization strategies can be used when considering eigenvalue problems, where we mention [80] in the context of metastable diffusion processes. We also refer to [33, 42, 48, 65] for similar problems in quantum mechanics that often rest on particular neural network architectures. Nonlinear elliptic eigenvalue problems are addressed in [30, 65] by exploiting a connection to a parabolic PDE and a fixed point problem. For rigorous results towards the capability of neural networks to overcome the curse of dimensionality we refer to [25, 37, 40], each analyzing certain special PDE cases. Adding to the methods referred to above, let us also mention [78] as an alternative approach exploiting weak PDEs formulations, as well as [53], which approximates operators by neural networks (however relying on training data from reference solutions), where a typical application is to map an initial condition to a solution of a PDE. For further references on approximating PDE solutions with neural networks we refer to the recent review articles [6, 12, 20, 43]. Outline of the article. In Section 2 we review PINN and BSDE based approaches towards solving highdimensional (parabolic) PDEs. In Section 3 we introduce the diffusion loss, show its validity for solving PDEs of the form (1), and prove that it interpolates between the PINN and BSDE losses. Section 4 develops extensions of the proposed methodology to elliptic PDEs and eigenvalue problems. In Section 5, we discuss implementational details as well as some further modifications of the losses under consideration. In Section 6 we present numerical experiments, including a committor function example from molecular dynamics and a nonlinear eigenvalue problem motivated by quantum physics. Finally, Section 7 concludes the paper with a summary and outlook. 2 Variational formulations of boundary value problems In this section we consider boundary value problems such as (1) in a variational formulation. That is, we aim at approximating the solutionVwith some function\u03c6\u2208Fby minimizing suitableloss functionals L:F \u2192R\u2265 0 , (4) which are zero if and only if the boundary value problem is fulfilled, L(\u03c6) = 0 \u21d0\u21d2 \u03c6=V. (5) HereF \u2282C^2 ,^1 (\u2126\u00d7[0,T],R)\u2229C(\u2126\u00d7[0,T],R)refers to an appropriate function class, usually consisting of deep neural networks. With a loss function at hand we can apply gradient-descent type algorithms to minimize (estimator versions of)L, keeping in mind that different choices of losses lead to different statistical and computational properties and therefore potentially to different convergence speeds and robustness behaviours [60]. Throughout, we will work under the following assumption: Assumption 1.The following hold: The domain\u2126is either bounded with piecewise smooth boundary, or\u2126 =Rd. The boundary value problem(1)admits a unique classical solutionV\u2208C^2 ,^1 (\u2126\u00d7[0,T],R)\u2229C(\u2126\u00d7[0,T],R). Moreover, the gradient ofV satisfies a polynomial growth condition inx, that is, |\u2207V(x,t)|\u2264C(1 +|x|q), (x,t)\u2208\u2126\u00d7[0,T], (6) for someC,q > 0. Complemented with a deterministic initial condition, the SDE(3)admits a unique strong solution, globally in time. 2.1 The PINN loss Losses based on PDE residuals go back to [49, 50] and have gained recent popularity under the namephysicsinformed neural networks(PINNs, [69]) ordeep Galerkin methods(DGMs, [72]). The idea is to minimize an appropriateL^2 -error between the leftand right-hand sides of (1a)-(1c), replacingV by its approximation\u03c6. The derivatives of\u03c6are computed analytically or via automatic differentiation and the data on which\u03c6is evaluated is distributed according to some prescribed probability measure (often a uniform distribution). A precise definition is as follows: Definition 2.1(PINN loss).Let\u03c6\u2208F. ThePINN lossconsists of three terms, LPINN(\u03c6) =\u03b1intLPINN,int(\u03c6) +\u03b1TLPINN,T(\u03c6) +\u03b1bLPINN,b(\u03c6), (7) where LPINN,int(\u03c6) =E [( (\u2202t+L)\u03c6(X,t) +h(X,t,\u03c6(X,t),\u03c3>\u2207\u03c6(X,t)) ) 2 ] , (8a) LPINN,T(\u03c6) =E [( \u03c6(X(T),T)\u2212f(X(T)) ) 2 ] , (8b) LPINN,b(\u03c6) =E [( \u03c6(Xb,tb)\u2212g(Xb,tb) ) 2 ] . (8c) Here,\u03b1int,\u03b1T,\u03b1b> 0 are suitable weights balancing theinterior,terminalandboundaryconstraints, and(X,t)\u223c \u03bd\u2126\u00d7[0,T],X(T)\u223c\u03bd\u2126and(Xb,tb)\u223c\u03bd\u2202\u2126\u00d7[0,T]are distributed according to probability measures\u03bd\u2126\u00d7[0,T]\u2208 P(\u2126\u00d7 [0,T]),\u03bd\u2126\u2208P(\u2126)and\u03bd\u2202\u2126\u00d7[0,T]\u2208P(\u2202\u2126\u00d7[0,T])that are fully supported on their respective domains. While uniform distributions are canonical choices for\u03bd\u2126\u00d7[0,T],\u03bd\u2126and\u03bd\u2202\u2126\u00d7[0,T], further research might reveal promising (possibly adaptive) alternatives that focus the sampling on specific regions of interest. Remark2.2 (Generalizations).Clearly, the loss contributions (8a)-(8c) represent in one-to-one correspondence the constraints in (1a)-(1c). By that principle, the PINN loss can straightforwardly be generalized to other types of PDEs, see [43] and references therein. Let us further already mention that choosing appropriate weights \u03b1int,\u03b1T,\u03b1b > 0 is crucial for algorithmic performance, but not straightforward. We will elaborate on this aspect in Section 5. Remark2.3 (Unbounded domains).In the case when\u2126 =Rd, the boundary contribution (8c) becomes obsolete and we set\u03b1b= 0. Analogous remarks apply to the BSDE and diffusion losses introduced below. Remark2.4 (Neumann and periodic boundary conditions).Instead of the Dirichlet boundary condition (1c), Neumann or periodic boundary conditions may be considered, and the generalization of the PINN loss (as well as the diffusion loss introduced below) is straightforward. In the case of periodic boundary conditions, for instance, (8c) may be replaced by Lb(\u03c6) =E [( \u03c6(Xb)\u2212\u03c6(X b ) ) 2 ] +E [\u2223 \u2223 \u2223\u2207\u03c6(Xb)\u2212\u2207\u03c6(X b ) \u2223 \u2223 \u2223 2 ] , (9) whereXb\u223c\u03bd\u2202\u2126, andX b refers to the reflected/periodic counterpart. The BSDE loss (see Section 2.2 below) does not seem to admit a similar straightforward extension to more general boundary conditions, but [63] might provide a starting point for constructing a BSDE based method. 2.2 The BSDE loss The BSDE loss makes use of a stochastic representation of the boundary value problem (1) given by a backward stochastic differential equation (BSDE) that is rooted in the correspondence between the differential operatorL defined in (2) and the stochastic processXdefined in (3). Indeed, according to [61], the PDE (1) is related to the system dXs=b(Xs,s) ds+\u03c3(Xs,s) dWs, Xt 0 =xinit, (10a) dYs=\u2212h(Xs,s,Ys,Zs) ds+Zs\u00b7dWs, YT\u2227\u03c4=k(XT\u2227\u03c4,T\u2227\u03c4), (10b) where\u03c4= inf{t >0 :Xt\u2208/\u2126}is the first exit time from\u2126andksubsumes the boundary conditions, k(x,t) = { f(x), t=T, x\u2208\u2126, g(x,t), t\u2264T, x\u2208\u2202\u2126. (11) Owing to the fact thatXin (10a) is constrained at initial timet 0 andY in (10b) at final timeT, the processes (Xs)t 0 \u2264s\u2264Tand(Ys)t 0 \u2264s\u2264Tare referred to as forward and backward, respectively. Given appropriate growth and regularity conditions on the coefficientsb,\u03c3,handk, It\u00f4\u2019s formula implies that the backward processes satisfy Ys=V(Xs,s), Zs=\u03c3>\u2207V(Xs,s), (12) that is, they provide the solution to (1) and its derivative along the trajectories of the forward process(Xs)t 0 \u2264s\u2264T, see [79]. Aiming for the approximation\u03c6\u2248V, we substitute (12) into (10b) and replaceVby\u03c6to obtain Y \u0303T\u2227\u03c4(\u03c6) =\u03c6(Xt 0 ,t 0 )\u2212 T\u222b\u2227\u03c4 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds+ T\u222b\u2227\u03c4 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs. (13) Our notationY \u0303T\u2227\u03c4(\u03c6)emphasizes the distinction fromYT\u2227\u03c4(which refers to the solution of (10)) and highlights the dependence on the particular choice\u03c6\u2208F. The key idea is now to penalize deviations from the terminal condition in (10b) via the loss L(\u03c6) =E [( k(XT\u2227\u03c4,T\u2227\u03c4)\u2212Y \u0303T\u2227\u03c4(\u03c6) ) 2 ] , (14) see [28]. We summarize this construction as follows. Definition 2.5(BSDE loss).Let\u03c6\u2208F. TheBSDE lossis defined as LBSDE(\u03c6) =E [( f(X\u03c4\u2227T) (^1) {\u03c4\u2227T=T}+g(X\u03c4\u2227T,\u03c4\u2227T) (^1) {\u03c4\u2227T=\u03c4}\u2212\u03c6(Xt 0 ,t 0 )\u2212 \u03c4\u222b\u2227T t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs + \u03c4\u222b\u2227T t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds ) 2 ] (15) where(Xt)t 0 \u2264t\u2264\u03c4\u2227Tis a solution to (3) and\u03c4= inf{t >0 :Xt\u2208/\u2126}is the first exit time from\u2126. Furthermore, the initial condition(X 0 ,t 0 )is distributed according to a prescribed probability measure\u03bd\u2126\u00d7[0,T]with full support on \u2126\u00d7[0,T]. Remark2.6 (BSDE versus PINN).In contrast to the PINN loss (7), the BSDE loss (15) does not rely on a judicious tuning of the weights\u03b1int,\u03b1T,\u03b1b. On the other hand, implementations based on the BSDE loss face the challenge of simulating the hitting times\u03c4= inf{t >0 :Xt\u2208/\u2126}efficiently and accurately. We shall elaborate on this aspect in Section 5.1. Remark2.7 (Relationship to earlier work). The idea of approximating solutions to PDEs by solving BSDEs has been studied extensively [14, 23, 61], where first approaches were regression based, relying on iterations backwards in time. These ideas do not seem to be straightforwardly applicable to the case when\u2126is bounded, as the trajectories of the forward process (10a) are not all of the same length (but see [13] and [31]). A global variational strategy using neural networks has first been introduced in [19], where however in contrast to Definition 2.5, the initial condition (X 0 ,t 0 )is deterministic (and fixed) and only parabolic problems on\u2126 =Rdare considered. Moreover, slightly different choices for the approximations are chosen, namelyV is only approximated att 0 = 0and\u2207V instead of Vis learnt by one neural network per time point (instead of using only one neural network withtas an additional input). 3 The diffusion loss In this section we introduce a novel loss that interpolates between the PINN and BSDE losses from Section 2 using an auxiliary time parametert\u2208(0,\u221e). As for the BSDE loss, the connection between the SDE (3) and its infinitesimal generator (2) plays a major role: It\u00f4\u2019s formula V(XT,T)\u2212V(X 0 ,0) = \u222bT 0 (\u2202s+L)V(Xs,s) ds+ \u222bT 0 \u03c3>\u2207V(Xs,s)\u00b7dWs (16) motivates the following variational formulation of the boundary value problem (1). Definition 3.1(Diffusion loss).Let\u03c6\u2208Fandt\u2208(0,\u221e). Thediffusion lossconsists of three terms, Ltdiffusion(\u03c6) =\u03b1intLtdiffusion,int(\u03c6) +\u03b1TLtdiffusion,T(\u03c6) +\u03b1bLtdiffusion,b(\u03c6), (17) where Ltdiffusion,int(\u03c6) =E [( \u03c6(XT,T)\u2212\u03c6(Xt 0 ,t 0 )\u2212 \u222bT t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs (18a) + \u222bT t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds ) 2 ] Ltdiffusion,T(\u03c6) =E [( \u03c6(X(T),T)\u2212f(X(T)) ) 2 ] , (18b) Ltdiffusion,b(\u03c6) =E [( \u03c6(Xb,tb)\u2212g(Xb,tb) ) 2 ] , (18c) encode the constraints (1a)-(1c), balanced by the weights\u03b1int,\u03b1T,\u03b1b> 0. The process(Xt)t 0 \u2264t\u2264Tis a solution to (3) with initial condition(X 0 ,t 0 )\u223c\u03bd\u2126\u00d7[0,T]and maximal trajectory lengtht> 0. The stopping timeT := (t 0 +t)\u2227\u03c4\u2227Tis a shorthand notation, referring to the (random) final time associated to a realization of the path Xas it either hits the parabolic boundary\u2202\u2126\u00d7{T}or reaches the maximal timet 0 +t. As in Definition 2.1, \u03c4= inf{t >0 :Xt\u2208/\u2126}is the exit time from\u2126, and(Xb,tb)\u223c\u03bd\u2202\u2126\u00d7[0,T],X(T)\u223c\u03bd\u2126are distributed according to probability measures that are fully supported on their respective domains. Remark3.2 (Comparison to the BSDE and PINN losses).In contrast to the PINN loss from Definition 2.1, the data inside the domain\u2126is not sampled according to a prescribed probability measure\u03bd\u2126, but along trajectories of the diffusion (3). Consequently, second derivatives of\u03c6do not have to be computed explicitly, but are approximated using the driving Brownian motion (and \u2013 implicitly \u2013 It\u00f4\u2019s formula). A main difference to the BSDE loss from Definition 2.5 is that the simulated trajectories have a maximal lengtht, which might be beneficial computationally if the final timeTor the exit time\u03c4is large (with high probability). Additionally, the sampling of extra boundary data circumvents the problem of accurately simulating those exit times (see Remark 2.6). Both aspects will be further discussed in Section 5. We refer to Figure 1 for a graphical illustration of the data required to compute the three losses. PINN loss BSDE loss, t = 0.0001 Diffusion loss, t = 0.0001, N = 50 Figure 1: We illustrate the training data used for the three losses inside the unit square\u2126 = (0,1)^2. The PINN loss in the left panel takes i.i.d. data points that are sampled from prescribed probability distributions in the domain\u2126 and on the boundary\u2202\u2126(in this case from uniform distributions). The BSDE loss (middle panel) uses trajectories associated to the SDE (3) that are started at random pointsX 0 (green points) and run until they hit the boundary (red points). The trajectories for the diffusion loss have a maximal lengthtand therefore frequently start and end inside\u2126, as displayed in the right panel. The blue points for the PINN and diffusion losses indicate the additionally sampled boundary data. The following proposition shows that the lossLtdiffusionis indeed suitable for the boundary value problem (1). Proposition 3.3.Consider the diffusion loss as defined in(17), and assume thatband\u03c3are globally Lipschitz continuous inx, uniformly int\u2208[0,T]. Furthermore, assume the following Lipschitz and boundedness conditions onf,gandh, |f(x)|\u2264C(1 +|x|p), |g(x,t)|\u2264C(1 +|x|p), |h(t,x,y,z)|\u2264C(1 +|x|p+|y|+|z|), |h(t,x,y,z)\u2212h(t,x,y\u2032,z)|\u2264C|y\u2212y\u2032|, |h(t,x,y,z)\u2212h(t,x,y,z\u2032)|\u2264C|z\u2212z\u2032|, for appropriate constantsC,p\u2265 0 and allx,y,z\u2208\u2126,t\u2208[0,T]. Finally, assume that Assumption 1 is satisfied. Then for\u03c6\u2208Fthe following are equivalent: The diffusion loss vanishes on\u03c6, Ltdiffusion(\u03c6) = 0. (19) \u03c6fulfills the boundary value problem(1). Proof.Denoting byXsthe unique strong solution to (3), an application of It\u00f4\u2019s lemma to\u03c6(Xs,s)yields \u03c6(XT,T) =\u03c6(Xt 0 ,t 0 ) + \u222bT t 0 (\u2202s+L)\u03c6(Xs,s) ds+ \u222bT t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs, (20) almost surely. Assuming that\u03c6fulfills the PDE (1a), it follows from the definition in (18a) thatLtdiffusion,int(\u03c6) = 0. Similarly, the boundary conditions (1b) and (1c) imply thatLtdiffusion,T(\u03c6) =Ltdiffusion,b(\u03c6) = 0. Consequently, we see thatLtdiffusion(\u03c6) = 0. For the converse direction, observe thatLtdiffusion(\u03c6) = 0implies that \u03c6(XT,T) =\u03c6(Xt 0 ,t 0 ) + \u222bT t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs\u2212 \u222bT t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds, (21) almost surely, and that the same holds with\u03c6replaced byV. We proceed by defining the processesY \u0303s:=\u03c6(Xs,s) andZ \u0303s:=\u03c3>\u2207\u03c6(Xs,s), as well asYs:=V(Xs,s)andZs:=\u03c3>\u2207V(Xs,s). By the assumptions on\u03c6,band \u03c3, the processesY,Z,Y \u0303andZ \u0303are progressively measurable with respect to the filtration generated by(Wt)t\u2265 0 and moreover square-integrable. Furthermore, the relation (21) shows that the pairs(Y,Z)and(Y , \u0303Z \u0303)satisfy a BSDE with terminal condition\u03be:=\u03c6(XT,T)on the random time interval[t 0 ,T]. Well-posedness of the BSDE (see [61, Theorems 1.2 and 3.2]) implies thatY =Y \u0303andZ=Z \u0303, almost surely. Conditional ont 0 andXt 0 , we also haveV(Xt 0 ,t 0 ) =YXt^0 ,t^0 =Y \u0303Xt^0 ,t^0 =\u03c6(Xt 0 ,t 0 ), where the superscripts denote conditioning on the initial timet 0 and corresponding initial conditionXt 0 , see [61, Theorems 2.4 and 4.3]. Hence, we conclude that\u03c6=V, \u03bd\u2126\u00d7[0,T]-almost surely, and the result follows from the continuity of\u03c6andVand the assumption that\u03bd\u2126\u00d7[0,T] has full support. We have noted before that the diffusion loss combines aspects from the BSDE and PINN losses. In fact, it turns out that the diffusion loss can be interpreted as a specific type of interpolation between the two. The following proposition makes this observation precise. Proposition 3.4(Relation of the diffusion loss to the PINN and BSDE losses).Let\u03c6\u2208 F. Assuming that the measures\u03bd\u2126\u00d7[0,T]in Definitions 2.1 and 3.1 coincide, we have that Ltdiffusion,int(\u03c6) t^2 \u2192LPINN,int(\u03c6), (22) ast\u2192 0. Moreover, if\u03bd\u2126\u00d7[0,T]refers to the same measure in Definitions 2.1 and 2.5, then Ltdiffusion,int(\u03c6)\u2192LBSDE(\u03c6), (23) ast\u2192\u221e. Proof.It\u00f4\u2019s formula shows thatLtdiffusion,intcan be expressed as Ltdiffusion,int(\u03c6) =E \uf8ee \uf8ef \uf8f0 \uf8eb \uf8ed \u222bT t 0 (\u2202s+L)\u03c6(Xs,s) ds+ \u222bT t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds \uf8f6 \uf8f8 2 \uf8f9 \uf8fa \uf8fb, (24) which implies the limit (22) by dominated convergence, noting thatT \u2192t 0 ast\u2192 0 , almost surely. The relation (23) follows immediately from the definition ofLBSDEby noting thatT \u2192\u03c4\u2227Tast\u2192\u221e, almost surely. 4 \u2212\u2192 \u2202\u2126xt:= \u2126\u00d7{T}\u222a\u2202\u2126\u00d7[0,T], and the augmented variablez= (x,t)>\u2208\u2126\u00d7[0,T]. Then problem (1) can be presented as AV(z) +h(z,V(z),\u03c3>\u2207xV(z)) = 0, z\u2208\u2126xt, (25a) V(z) =k(z), z\u2208 \u2212\u2192 \u2202\u2126xt, (25b) withkdefined as in (11). Relying on (25), we can equivalently define the BSDE loss as LBSDE(\u03c6) =E [( k(X\u03c4xt,\u03c4xt)\u2212\u03c6(Xt 0 ,t 0 )\u2212 \u222b\u03c4xt t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs+ \u222b\u03c4xt t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds ) 2 ] (26) where\u03c4xt= inf{t >0 :Xt\u2208/\u2126xt}is the first exit time from\u2126xt. The PINN and diffusion losses can similarly be rewritten in terms of the space-time domain\u2126xtand exit time\u03c4xt. (^2) We notice in passing that the (ordinary) topological boundary of\u2126xtis given by\u2202\u2126xt= \u2126\u00d7 { 0 , T} \u222a\u2202\u2126\u00d7[0, T], so that \u2202\u2126xt=\u2212\u2192\u2202\u2126xt\u222a{ 0 }\u00d7\u2126. 4.1 Elliptic boundary value problems Removing the time dependence from the solution (and from the coefficientsband\u03c3determiningL) we obtain the elliptic boundary value problem LV(x) +h(x,V(x),\u03c3>\u2207V(x)) = 0, x\u2208\u2126, (27a) V(x) =g(x), x\u2208\u2202\u2126, (27b) with the nonlinearityh\u2208C(Rd\u00d7R\u00d7Rd,R). In analogy to (10), the corresponding backward equation is given by dYs=\u2212h(Xs,Ys,Zs) ds+Zs\u00b7dWs, Y\u03c4=g(X\u03c4), (28) where\u03c4={t >0 :Xt\u2208/\u2126}is the first exit time from\u2126. Given suitable boundedness and regularity assumptions on hand assuming that\u03c4is almost surely finite, one can show existence and uniqueness of solutionsY andZ, which, as before, represent the solutionV and its gradient along trajectories of the forward process [61, Theorem 4.6]. Therefore, the BSDE, PINN and diffusion losses can be applied to (27) with minor modifications: Owing to the fact that there is no terminal condition, we setf= 0in (15), as well as\u03b1T= 0in (7) and (17), making (8b) and (18b) obsolete. With the same reasoning, we setT=\u221e, incurring\u03c4\u2227T=\u03c4andT = (t 0 +t)\u2227\u03c4; these simplifications are relevant for the expressions (15) and (18a). Proposition 3.3 and its proof can straightforwardly be generalized to the elliptic setting. An algorithm for solving elliptic PDEs of the type (27) in the spirit of the BSDE loss has been suggested in [47], using the same approximation framework as in [19] (cf. Remark 2.7). We note that the solutions to linear elliptic PDEs often admit alternative variational characterizations in terms of energy functionals [22]. An approach using the Feynman-Kac formula has been considered in [24]. 4.2 Elliptic eigenvalue problems We can extend the algorithmic approaches from Sections 2 and 3 to eigenvalue problems of the form LV(x) =\u03bbV(x), x\u2208\u2126, (29a) V(x) = 0, x\u2208\u2202\u2126, (29b) corresponding to the choiceh(x,y,z) =\u2212\u03bbyin the elliptic PDE (27). Note, however, thathnow depends on the unknown eigenvalue\u03bb\u2208R. Furthermore, we can consider nonlinear eigenvalue problems, LV(x) +h(x,V(x),\u03c3>\u2207V(x)) =\u03bbV(x), x\u2208\u2126, (30a) V(x) = 0, x\u2208\u2202\u2126, (30b) with a general nonlinearityh\u2208C(Rd\u00d7R\u00d7Rd,R). For the linear problem (29) it is known that, given suitable boundedness and regularity assumption onband\u03c3, there exists a unique principal eigenvalue with strictly positive eigenfunction in\u2126, see [8, Theorem 2.3]. This motivates us to consider the above losses, now depending on\u03bb, as well as enhanced with an additional term, preventing the trivial solutionV\u2261 0. We define Leigen(\u03c6,\u03bb) =L\u03bb(\u03c6) +\u03b1cLc(\u03c6), (31) whereL\u03bb(\u03c6)stands for either the PINN, the BSDE, or the diffusion loss (with the nonlinearityhdepending on \u03bb),Lc(\u03c6) = (\u03c6(xc)\u22121)^2 , and\u03b1c> 0 is a weight. Herexc\u2208\u2126is chosen deterministically, preferably not too close to the boundary\u2202\u2126. Clearly, the termLcencourages\u03c6(xc) = 1, thus discouraging\u03c6\u2261 0. We note that V(xc) = 1can be imposed on solutions to (29) without loss of generality, since the eigenfunctions are determined up to a multiplicative constant only. Avoiding\u03c6\u2261 0 for nonlinear eigenvalue problems of the form (30) needs to be addressed on a case-by-case basis; we present an example in Section 6.4.2. The idea is now to minimizeLeigen(\u03c6,\u03bb)with respect to\u03c6\u2208 Fand\u03bb\u2208Rsimultaneously, while constraining the function\u03c6to be non-negative. According to following proposition this is a valid strategy to determine the first eigenpair. Proposition 4.2.Let\u2126be bounded, and assume thatLis uniformly elliptic, that is, there exist constantsc 0 ,C 0 > 0 such that c 0 |\u03be|^2 \u2264 \u2211d i,j=1 (\u03c3\u03c3>)(x)\u03bei\u03bej\u2264C 0 |\u03be|^2 , (32) for all\u03be\u2208Rd. Moreover, assume thatbis bounded. Let\u03c6\u2208Fwith\u03c6\u2265 0 and assume thatL\u03bb(\u03c6) = 0if and only if(29)is satisfied. Then the following are equivalent: \u03c6is the principal eigenfunction for(29)with principal eigenvalue\u03bband normalization\u03c6(xc) = 1. Leigen(\u03c6,\u03bb)vanishes on the pair(\u03c6,\u03bb), Leigen(\u03c6,\u03bb) = 0. (33) Remark4.3.The assumption thatL\u03bb(\u03c6)is equivalent to (29) is satisfied for any \u2018reasonable\u2019 loss function. For the diffusion loss, Proposition 3.3 establishes this condition whenever the coefficients in (29) are regular enough. Proof.It is clear that 1. implies 2. by the construction of (31). For the converse direction, notice that (33) implies \u03c6(xc) = 1as well as (29), that is,\u03c6is an eigenfunction with eigenvalue\u03bb. In conjunction with the constraint\u03c6\u2265 0 , it follows by [8, Theorem 2.3] that\u03c6is the principal eigenfunction. An alternative approach towards (29) can be found in [30], where the eigenvalue problem is connected to a parabolic PDE and formulated as a fixed point problem. 5 From losses to algorithms In this section we discuss some details regarding implementational aspects. For convenience, let us start by stating a prototypical algorithm based on the losses introduced in Sections 2 and 3: Algorithm 1:Approximation of the solutionVto the boundary value problem (1). Choose a parametrizationRp 3 \u03b87\u2192\u03c6\u03b8. Initialize\u03c6\u03b8(with a parameter vector\u03b8\u2208Rp). Choose an optimization methoddescent, a batch sizeK\u2208Nand a learning rate\u03b7 > 0. For PINN and diffusion losses choose weights\u03b1int,\u03b1b,\u03b1T> 0 and batch sizesKb,KT\u2208N. For BSDE and diffusion losses choose a step-size\u2206t > 0 , for the diffusion loss choose a trajectory lengtht> 0. repeat Choose a loss functionLfrom either (7), (15) or (17). Simulate data according to the chosen loss. ComputeL\u0302(\u03c6\u03b8)as a Monte Carlo version ofL. Compute\u2207\u03b8L\u0302(\u03c6\u03b8)using automatic differentiation. Update parameters:\u03b8\u2190\u03b8\u2212\u03b7descent(\u2207\u03b8L\u0302(\u03c6\u03b8)). until convergence; Result:\u03c6\u03b8\u2248V. Function approximation.In this paper, we rely on neural networks to provide the parametrizationRp 3 \u03b87\u2192\u03c6\u03b8 referred to in Algorithm 1 (but note that alternative function classes might offer specific benefits, see, for instance [70]). Standard feed-forward neural networks are given by \u03c6\u03b8:Rd\u2192R, \u03c6\u03b8(x) =AL%(AL\u2212 1 %(\u00b7\u00b7\u00b7%(A 1 x+b 1 )\u00b7\u00b7\u00b7) +bL\u2212 1 ) +bL, (34) with a collection of matricesAl \u2208Rnl\u00d7nl\u2212^1 and vectorsbl \u2208Rnl comprising the learnable parameters, \u03b8 = (Al,bl) 1 \u2264l\u2264L. HereLdenotes the depth of the network, and we haven 0 =das well asnL = 1. The nonlinear activation function%:R\u2192Ris to be applied componentwise. Additionally, we define theDenseNet[22, 34] as a variant of the feed-forward neural network (34), containing additional skip connections, \u03c6DenseNet\u03b8 (x) =ALxL+bL, (35) wherexLis specified recursively as yl+1=%(Alxl+bl), xl+1= (xl,yl+1)>, x 1 =x, (36) withAl\u2208Rnl\u00d7 \u2211l\u2212 1 i=0niandbl\u2208Rlfor 1 \u2264l\u2264L\u2212 1 ,n 0 =d. Again, the collection of matricesAland vectorsbl comprises the learnable parameters. Comparison of the losses (practical challenges). The PINN, BSDE and diffusion losses differ in the way training data is generated (see Figure 1 and Table 1a); hence, the corresponding implementations face different challenges (see Table 1b). Table 1: Comparison of the different losses. PINN BSDE Diffusion SDE simulation 7 7 boundary data 7 7 (a) The three losses can be characterized by how training data is generated. PINN BSDE Diffusion Hesse computations 7 boundary issues 7 weight tuning 7 7 long runtimes 7 discretization 7 7 (b) In this table we list potential challenges and drawbacks for the corresponding losses. First, the BSDE and diffusion losses rely on trajectorial data obtained from the SDE (3), in contrast to the PINN loss (cf. the first row in Table 1a). As a consequence, the BSDE and diffusion losses do not require the computation of second-order derivatives, as those are approximated implicitly using It\u00f4\u2019s formula and the SDE (3), cf. the first row in Table 1a. From a computational perspective, the PINN loss therefore faces a significant overhead in high dimensions when the diffusion coefficient\u03c3is not sparse (as the expression (8a) involvesd^2 second-order partial derivatives). We notice in passing that an approach similar to the diffusion loss circumventing this problem has been proposed in [72, Section 3]. On the other hand, evaluating the BSDE and diffusion losses requires discretizing the SDE (3), incurring additional numerical errors (cf. the last row in Table 1b and the discussion below in Section 5.1). Second, the PINN and diffusion losses incorporate boundary and final time constraints (see (1c) and (1b)) explicitly by sampling additional boundary data (see (8b), (8c), (18b), (18c) and cf. the second row in Table 1a). On the one hand, this approach necessitates choosing the weights\u03b1int,\u03b1b,\u03b1T> 0 ; it is by now well established that while algorithmic performance depends quite sensitively on a judicious tuning of these weights, general and principled guidelines to address this issue are not straightforward (see, however, [74, 75, 76, 77]). Weight-tuning, on the other hand, is not required for implementations relying on the BSDE loss, as the boundary data is accounted for implicitly by the hitting event{(Xt,t)\u2208/\u2126\u00d7[0,T)}and the corresponding first two terms on the right-hand side of (15). The hitting times\u03c4= inf{t >0 :Xt\u2208/\u2126}may however be large, leading to a computational overhead in the generation of the training data (but see 5.2.1), and are generally hard to compute accurately (but see Section 5.1). 5.1 Simulation of diffusions and their exit times The BSDE and diffusion losses rely on trajectorial data obtained from the stochastic process defined in (3). In practice, we approximate this SDE on a time gridt 0 \u2264t 1 \u2264 \u00b7\u00b7\u00b7 \u2264tN, for instance using the Euler-Maruyama scheme [46] X \u0303n+1=X \u0303n+b(X \u0303n,tn)\u2206t+\u03c3(X \u0303n,tn) \u221a \u2206t\u03ben+1, (37) or, to be precise, by its stopped version X\u0302n+1=X\u0302n+ ( b(X\u0302n,tn)\u2206t+\u03c3(X\u0302n,tn) \u221a \u2206t\u03ben+1 ) (^1) Cn+1 (38) with step conditionCn:= { X \u0303n\u2208\u2126 } \u2228{tn\u2264T}and time-incrementtn+1=tn+ \u2206t (^1) Cn+1, where\u2206tis the stepsize and\u03ben+1\u223c N(0,Idd\u00d7d)are standard normally distributed random variables. We can then straightforwardly construct Monte Carlo estimator versions of either the BSDE or the diffusion loss. For example, the discrete version of the domain part of the diffusion loss (18a) reads L\u0302(diffusionK,N) ,int(\u03c6) =^1 K \u2211K k=1 ( \u03c6(X\u0302(Nk),t(Nk))\u2212\u03c6(X\u0302 0 (k),t( 0 k))\u2212 N\u2211\u2212 1 n=0 \u03c3>\u2207\u03c6(X\u0302n(k),t(nk))\u00b7\u03be(nk+1) \u221a \u2206t (^1) Cn(k) (39a) + N\u2211\u2212 1 n=0 h ( X\u0302n(k),t(nk),\u03c6(X\u0302n(k),t(nk)),\u03c3>\u2207\u03c6(X\u0302n(k),t(nk)) ) \u2206t (^1) C(nk) ) 2 , (39b) whereKis the sample size,N=\u2206ttis the maximal discrete-time trajectory length, and(X\u0302n(k))kn=1=1...K...Nare independent copies of the iterates from (38). The Monte Carlo version of the BSDE loss can be formed analogously. Given suitable growth and regularity assumptions on the coefficients, the discretization errors of the forward and backward processes are of order \u221a \u2206t[46, 79], cf. also [29] for a numerical analysis on the original version of the BSDE loss. However, the stopped Euler-Maruyama scheme (38) incurs additional errors due to the approximation of the first exit times from\u2126. In the two left panels of Figure 2 we illustrate this problem by displaying multiple \u201clast locations\u201d obtained according to (38), using two different step-sizes\u2206t. Clearly, all these points should in principle lie on the boundary, (naively) requiring a computationally costly small step-size. boundary points, t = 0.001 boundary points, t = 0.0001 trajectories, t = 0.001 reversed trajectories, t = 0.001 Figure 2: Illustration of the boundary data in the BSDE method. Sophisticated approaches towards the accurate simulation of exit times for diffusions discretizing exit times have been put forward, see, e.g. [15, 32]. For our purposes, however, it is not essential to compute the exit times, as long as the simulated trajectories are stopped accurately. We therefore suggest the following two attempts that aim at improving the sampling of boundary data: Rescaling: StartX 0 randomly in\u2126, simulate the trajectory and stop once the boundary has been crossed, however scale the last time step in such a way that the trajectory exactly ends on\u2202\u2126. Time-reversal: StartX 0 on the boundary\u2202\u2126and simulate the trajectory for a given timeT(unless it hits the boundary again before timeT, in this case stop the trajectory accordingly or resimulate). Then reverse the process such that the reversed process exactly ends on the boundary. An illustration of these two strategies can be found in the two right panels of Figure 2. In our numerical experiments we have found that both rescaling and time-reversal improves the performance of the BSDE method somewhat, but further research is needed. 5.2 Further modifications of the losses In the following we discuss modifications of the PINN, BSDE and diffusion losses, relating also to versions that have appeared in the literature before. 5.2.1 Forward control We can modify the SDE-based BSDE and diffusion losses by including control termsv\u2208C(Rd\u00d7[0,T],Rd)in the forward process (3), yielding the controlled diffusion dXvs= (b(Xsv,s) +\u03c3(Xvs,s)v(Xsv,s)) ds+\u03c3(Xsv,s) dWs. (40) Applying It\u00f4\u2019s formula we may obtain losses similar to those considered in Section 2 and 3. For instance, alternative versions of the diffusion loss take the form Ltdiffusion,int,v (\u03c6) =E [( \u03c6(XTv,T)\u2212\u03c6(Xtv 0 ,t 0 )\u2212 \u222bT t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs + \u222bT t 0 [ h(Xsv,s,\u03c6(Xvs,s),\u03c3>\u2207\u03c6(Xsv,s))\u2212v(Xsv,s)\u00b7\u03c3>\u2207\u03c6(Xsv,s) ] ds ) 2 ] (41) replacing (18a). We note in passing that Proposition 3.3 extends straightforwardly toLtdiffusion,int,v under the assumption thatvsatisfies appropriate Lipschitz and growth conditions. Similar considerations apply for the BSDE loss, noting that for solutions to the generalized BSDE system [60] dXsv= (b(Xsv,s) +\u03c3(Xsv,s)v(Xvs,s)) ds+\u03c3(Xsv,s) dWs, Xtv 0 =xinit, (42a) dYsv=\u2212h(Xsv,s,Ysv,Zsv) ds+v(Xsv,s)\u00b7Zvsds+Zsv\u00b7dWs, YTv=k(XvT\u2227\u03c4,T\u2227\u03c4), (42b) we still have the relations Ysv=V(Xsv,s), Zsv=\u2207V(Xsv,s) (43) for suitablev\u2208C(Rd\u00d7[0,T],Rd), analogously to (12). This immediately incurs the family of losses LvBSDE(\u03c6) =E [( f(X\u03c4v\u2227T) (^1) \u03c4\u2227T=T+g(X\u03c4v\u2227T,\u03c4\u2227T) (^1) \u03c4\u2227T=\u03c4\u2212\u03c6(Xtv 0 ,t 0 )\u2212 \u03c4\u222b\u2227T t 0 \u03c3>\u2207\u03c6(Xsv,s)\u00b7dWs + \u03c4\u222b\u2227T t 0 ( h(Xvs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s))\u2212v(Xsv,s)\u00b7\u03c3>\u2207\u03c6(Xsv,s) ) ds ) 2 ] (44) parametrized byv\u2208C(Rd\u00d7[0,T],Rd). Adding a control to the forward process can be understood as driving the data generating process into regions of interest, for instance possibly alleviating the problem that exit times might be large (see Table 1b and the corresponding discussion). Identifying suitable forward controls might be an interesting topic for future research (we refer to [60] for some systematic approaches in this respect relating to Hamilton-Jacobi-Bellman PDEs). 5.2.2 Approximating the gradient of the solution The constraints imposed by the BSDE system (10) can be enforced by losses that slightly different from Definition 2.5. Going back to [19], we can for instance use the fact that the backward processY can be written in a forward way, yielding the discrete-time process Y\u0302n+1=Y\u0302n\u2212h(X\u0302n,tn,Y\u0302n,Z\u0302n)\u2206t+Z\u0302n\u00b7\u03ben+1 \u221a \u2206t. (45) The scheme (45) is explicit, the unknowns beingY\u0302 0 andZ\u0302n, forn\u2208{ 0 ,...,N\u2212 1 }. This motivates approximating the single parametery 0 \u2248Y\u0302 0 \u2208Ras well as the vector fields\u03c6\u2248\u03c3>\u2207V\u2208C(Rd\u00d7[0,T],Rd), rather thanVdirectly. This approach gives rise to the loss LBSDE\u2212 2 (\u03c6,y 0 ) =E [( f(X\u03c4\u2227T) (^1) \u03c4\u2227T=T+g(X\u03c4\u2227T,\u03c4\u2227T) (^1) \u03c4\u2227T=\u03c4\u2212y 0 \u2212 \u03c4\u222b\u2227T 0 \u03c6(Xs,s)\u00b7dWs + \u03c4\u222b\u2227T 0 h(Xs,s,Ys,\u03c6(Xs,s)) ds ) 2 ] (46) In this settingX 0 has to be chosen deterministically; we note that a potential drawback is thus that the solution is only expected to be approximated accurately in regions that can be reached by the forward processXt(starting at X 0 ) with sufficiently high probability. It has been shown in [60] that alternative losses (like the log-variance loss) can be considered whenever the nonlinearityhonly depends on the solution through its gradient, in which case the extra parametery 0 can be omitted. 5.2.3 Penalizing deviations from the discrete scheme Another approach that is rooted in the discrete-time backward process (45) has been suggested in [67] for problems on unbounded domains. It relies on the idea to penalize deviations from (45), for eachn\u2208 { 0 ,...,N\u2212 1 }(cf. also [35, 70], where however an implicit scheme and backward iterations are used). Aiming forY\u0302n\u2248\u03c6(X\u0302n,tn), Z\u0302n\u2248\u03c3>\u2207\u03c6(X\u0302n,tn), this motivates the loss L\u0302(K,N) BSDE\u2212 3 (\u03c6) =\u03b1int L\u0302(K,N) BSDE\u2212 3 ,int(\u03c6) +\u03b1b L\u0302(K,N) BSDE\u2212 3 ,b(\u03c6) (47) with interior part L\u0302(K,N) BSDE\u2212 3 ,int(\u03c6) = 1 K \u2211K k=1 N\u2211\u2212 1 n=0 ( \u03c6(X\u0302n(k+1))\u2212\u03c6(X\u0302n(k)) +h ( X\u0302(nk),\u03c6(X\u0302(nk)),\u03c3>\u2207\u03c6(X\u0302(nk)) ) \u2206t\u2212\u03c3>\u2207\u03c6(X\u0302n(k))\u03ben+1 \u221a \u2206t ) 2 (48) and boundary term L\u0302(K,N) BSDE\u2212 3 ,b(\u03c6) = 1 K \u2211K k=1 ( \u03c6(X\u0302 (k) N )\u2212g( X\u0302(k) N ) ) 2 . (49) A generalization to equations posed on bounded domains is straightforward. We also note that in contrast to the diffusion loss, (47) does not seem to naturally derive from a continuous-time formulation. Interestingly,L\u0302(BSDEK,N)\u2212 3 can be related to the diffusion loss via Jensen\u2019s inequality, L\u0302(K,N) diffusion,int(\u03c6)\u2264N L\u0302(K,N) BSDE\u2212 3 ,int(\u03c6). (50) Yet another approach that is based on a discrete backward scheme is the following. Let us initializeY\u0302 0 =\u03c6(X\u0302 0 ,0) and simulate Y\u0302n+1=Y\u0302n\u2212h(X\u0302n,Y\u0302n,\u03c3>\u2207\u03c6(X\u0302n,tn))\u2206t+\u03c3>\u2207\u03c6(X\u0302n,tn)\u00b7\u03ben+1 \u221a \u2206t, (51) forn\u2208{ 0 ,...,N\u2212 1 }, where, similarly to (46), but in in contrast to (48), onlyZ\u0302nis replaced by its approximation \u03c3>\u2207\u03c6(X\u0302n,tn)whileY\u0302nis retained from previous iteration steps. Again penalizing deviations from the discrete-time scheme, we can now introduce the loss L\u0302(BSDEK,N)\u2212 4 (\u03c6) =\u03b1^1 K \u2211K k=1 \u2211N n=0 ( \u03c6(X\u0302n(k),tn)\u2212Y\u0302n(k) ) 2 + \u03b1 2 K \u2211K k=1 ( \u03c6(Xb(k))\u2212g(Xb(k)) ) 2 . (52) Both inLBSDE\u2212 3 andLBSDE\u2212 4 the deterministic initial conditionX\u0302 0 att= 0can be replaced by random choices (X\u0302t 0 ,t 0 )\u223c\u03bd\u2126\u00d7[0,T], adjusting the sums in (48) and (52) accordingly. 6 Numerical experiments In this section we provide several numerical examples of high-dimensional parabolic and elliptic PDEs that shall demonstrate the performances of Algorithm 1 using the different loss functions introduced before. We focus on the PINN, BSDE and diffusion losses from Sections 2 and 3 since their modified versions from Section 5.2 in general led to similar or worse performances. If not specified otherwise, the approximation of\u03c6relies on a DenseNet architecture defined in (35) with ReLU activation function and four hidden layers withd+ 20,d,d,dunits respectively (recall thatdspecifies the dimension). The optimization is carried out using the Adam optimizer [45] with standard parameters and learning rate\u03b7= 0. 001. Throughout, we takeKint= 200samples inside the domain\u2126and (for the PINN and diffusion losses)Kb= 50samples on the boundary, per gradient step. For the SDE discretization we choose a step-size of\u2206t= 0. 001. The weight configurations for the PINN and diffusion losses are optimized manually; we then only report the results for the optimal settings (see the discussion on weight-tuning in Section 5). We refer to the code at https://github.com/lorenzrichter/path-space-PDE-solver . 6.1 Nonlinear toy problems Let us start with a nonlinear toy problem for which analytical reference solutions are available. Throughout this subsection, the domain of interest is taken to be the unit ball\u2126 ={x\u2208Rd:|x|< 1 }. 6.1.1 Elliptic problem with Dirichlet boundary data We first consider an elliptic boundary value problem of the form (27). Let\u03b3\u2208Rand choose b(x,t) = 0 , \u03c3(x,t) = \u221a 2 Idd\u00d7d, g(x) =e\u03b3, (53a) h(x,y,z) =\u2212 2 \u03b3y(\u03b3|x|^2 +d) + sin ( e^2 \u03b3|x| 2 \u2212y^2 ) . (53b) It is straightforward to verify that V(x) =e\u03b3|x| 2 (54) is the unique solution to (27). We considerd= 50and set\u03b3= 1. For the PINN and diffusion losses the optimized weights are given by\u03b1int= 10\u2212^5 , \u03b1b= 1and\u03b1int= 0. 1 ,\u03b1b= 1, respectively. We sample the data uniformly and take a maximal (discrete-time) trajectory length ofN= 20for the diffusion loss. In Figure 3 (left panel) we display the average relative errors |\u03c6(x)\u2212V(x)| V(x) as a function ofr=|x|. Due to volume distortion in high dimensions, very few samples are drawn close to the center of the ball, and hence the numerical results appear to be unreliable forr\u2264 0. 8. While this effect could be alleviated by changing the measure\u03bd\u2126accordingly, we content ourselves here with a comparison forr\u2208[0. 8 ,1]. In the right panel we display theL^2 error during the training iterations evaluated on uniformly sampled test data. We observe that the PINN and diffusion losses yield similar results and that the BSDE loss performs worse, in particular close to the boundary. We attribute this effect to the challenges inherent in the simulation of hitting times, see Section 5.1. 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000 r 0.005 0.006 0.007 0.008 0.009 0.010 0.011 Relative error on test data PINN loss BSDE loss Diffusion loss 0 50000 100000 150000 200000 gradient steps 103 102 101 100 L^2 test error Figure 3: Left: Average relative errors as a function ofr=|x|evaluated on uniformly sampled data for the three losses smoothed with a moving average over 500 data points. Right:L^2 error during the training iterations evaluated on uniformly sampled test data. In the diffusion loss as stated in Definition 3.1 we are free to choose the lengthtof the forward trajectories, which affects the generated training data. Let us therefore investigate how different choices oftinfluence the performance of Algorithm 1. To this end, we consider again the elliptic problem from Section 6.1.1 and varyt. To be precise, let us fix different step-sizes\u2206tand vary the Euler stepsN(recalling thatt=N\u2206t), once choosing the weight \u03b1int= 0. 1 , as before, and once by considering\u03b1int= 10. For the former choice we can see in Figure 4a that larger trajectories tend to be better until a plateau is reached, whereas for the latter it turns out that there seems to be an optimal choice of the trajectory length, as displayed in Figure 4b. 0 20 40 60 80 100 N 103 104 Diffusion test error depending on the trajectory length t = 0.001 t = 0.0005 (a) Weight\u03b1int= 0. 1. 0 5 10 15 20 25 30 35 40 N 103 104 Diffusion test error depending on the trajectory length t = 0.001 t = 0.0005 (b) Weight\u03b1int= 10. Figure 4: We display theL^2 error that one attains when using different choices of the maximal Euler stepsNin the diffusion loss for different discretization step-sizes\u2206t. 6.1.2 Elliptic problem requiring full Hessian matrix We consider the setting specified in (53), replacing however the diffusion coefficient and the nonlinearity by \u03c3(x,t) = \u221a 2 d \uf8eb \uf8ec \uf8ed 1 \u00b7\u00b7\u00b7 1 1 \u00b7\u00b7\u00b7 1 \uf8f6 \uf8f7 \uf8f8, h(x,y,z) =\u2212^2 \u03b3y \uf8eb \uf8ed\u03b3 \u2211d i,j=1 xixj+d \uf8f6 \uf8f8+ sin ( e^2 \u03b3|x| 2 \u2212y^2 ) , (55) respectively. Again, we can check thatV(x) =e\u03b3|x| 2 is the unique solution to the corresponding boundary value problem. Since\u03c3is not diagonal anymore, the differential operator (2) contains the full Hessian matrix of secondorder derivatives of the candidate solution\u03c6. As discussed in Section 5 (see Table 1b) this particularly impacts the runtime of the PINN method since all derivatives need to be computed explicitly. For the BSDE and diffusion losses, on the other hand, second-order derivatives are implicitly approximated using the underlying Brownian motion and we therefore do not expect significantly longer runtimes. Let us considerd= 20and\u03b3= 1. In Figure 5 we display theL^2 error during the training process, plotted against the number of gradient steps (left panel) and against the runtime (right panel). As expected, the PINN loss takes significantly longer. This effect should become even more pronounced with growing state space dimensiond. 0 10000 20000 30000 40000 50000 60000 gradient steps 103 102 101 100 L^2 test error PINN loss BSDE loss Diffusion loss 0 20000 40000 60000 80000100000120000140000 runtime in seconds 103 102 101 100 L^2 test error Figure 5:L^2 error during the training process evaluated on test data for the three losses, plotted against the number of gradient steps (left panel) and against the runtime (right panel). 6.1.3 Parabolic problem with Neumann boundary data Let us now consider the parabolic problem (1), with the Dirichlet boundary condition (1c) replaced by its Neumann counterpart \u2202~nV(x,t) =gN(x,t), (x,t)\u2208\u2202\u2126\u00d7[0,T]. (56) Here,\u2202~nV:=\u2207V\u00b7~nrefers to the (outward facing) normal derivative at the boundary\u2202\u2126. We take b(x,t) = 0 , \u03c3(x,t) = \u221a 2 Idd\u00d7d, f(x) =e\u03b3|x| (^2) +T , gN(x,t) = 2\u03b3e\u03b3+t, (57a) h(x,t,y,z) =\u2212y(2\u03b3(2\u03b3|x|^2 +d) + 1) + sin ( e^2 \u03b3|x| (^2) +2t \u2212y^2 ) . (57b) In this case, V(x,t) =e\u03b3|x| (^2) +t (58) provides the unique solution. We choosed= 20and\u03b3= 1. In the left and central panels of Figure 6 we display the approximated solutions along the curve { (\u03ba,...,\u03ba)>:\u03ba\u2208[\u2212 1 / \u221a d, 1 / \u221a d] } for two different times. We can see that both the diffusion and the PINN loss work well, with small advantages for the PINN loss. The right panel displays theL^2 test error over the iterations and confirms this observation. 0.2 0.1 0.0 0.1 0.2 1.5 2.0 2.5 3.0 t = 0.2 PINN loss Diffusion reference 0.2 0.1 0.0 0.1 0.2 3 4 5 6 t = 0.8 0 50000 100000 150000 200000 gradient steps 103 102 101 100 101 L (^2) test loss \u03ba \u03ba Figure 6: Left and central panel: Approximations along a curve for two different times using the diffusion and PINN losses. Right:L^2 test error along the training iterations. 6.2 Committor functions Committor functions are important quantities in molecular dynamics as they specify likely transition pathways as well as transition rates between (potentially metastable) regions or conformations of interest [21, 55]. Since for most practical applications those functions are high-dimensional and hard to compute, there have been recent attempts to approach this problem using neural networks [44, 52, 71]. Based on the fact that committor functions fulfill elliptic boundary value problems, we can rely on the methods discussed in this paper. For anRd-valued stochastic process(Xt)t\u2265 0 with continuous sample paths and two disjoint open setsA,B\u2282Rd, the committor functionVcomputes the probability ofXhittingAbeforeBwhen starting inx\u2208R, that is, V(x) =P(\u03c4B< \u03c4A|X 0 =x) =E[ (^1) B(X\u03c4)|X 0 =x]. (59) Here,\u03c4A= inf{t >0 :Xt\u2208A}and\u03c4B= inf{t >0 :Xt\u2208B}refer to the hitting times corresponding to the sets AandB. In the case when(Xt)t\u2265 0 is given as the unique strong solution to the SDE (3), it can be shown via the Kolmogorov backward PDE [64, Section 2.5] thatV fulfills the elliptic boundary value problem LV= 0, V|\u2202A= 0, V|\u2202B= 1, (60) whereLas in (2) refers to the associated infinitesimal generator, see, for instance, [21]. In the notation of (27) we have\u2126 =Rd(A\u222aB),h= 0andg(x) = (^1) B(x). Following [31, Section V.A], we consider(Xt)t\u2265 0 to be a standard Brownian motion starting atx\u2208Rd, that is, Xt=x+Wt, corresponding tob= 0 and\u03c3= Idd\u00d7din (3). The setsAandBare defined as A={x\u2208Rd:|x|< a}, B={x\u2208Rd:|x|> b}, (61) withb > a > 0. Hence, in this case the committor function describes the statistics of leaving a spherical shell through one of its boundaries. The solution takes the form V(x) = a^2 \u2212|x|^2 \u2212da^2 a^2 \u2212b^2 \u2212da^2 , (62) ford\u2265 3. Let us considerd= 10as well asa= 1,b= 2. We take a DenseNet withtanhas activation function and compare the three losses against each other. In Figure 7 we display the approximated solutions along a curve{ (\u03ba,...,\u03ba)>:\u03ba\u2208[a/ \u221a d,b/ \u221a d] } in the left panel, realizing that in particular the PINN and diffusion losses lead to good approximations. This can also be observed in the right panel, where we plot a moving average of theL^2 error on test data based on a moving window of length 200. The BSDE loss appears to be especially error-prone close to the left end-point of the curve displayed in Figure 7, that is, close to the inner shell. Due to the volume distortion in high dimensions, few samples are drawn according to\u03bd\u2126for small values of|x|, see Figure 8. We hence conclude that in this example, the BSDE loss suffers particularly from the relative sparsity of the samples, possibly in conjunction with numerical errors made while estimating the hitting times at the inner shell (see Section 5.1). 0.35 0.40 0.45 0.50 0.55 0.60 0.0 0.2 0.4 0.6 0.8 1.0 Evaluation along curve PINN loss BSDE Diffusion loss reference solution 0 1000020000300004000050000600007000080000 runtime in seconds 104 103 102 101 L^2 test error during training \u03ba Figure 7: Left: approximations of the 10 -dimensional committor function evaluated along a curve. Right: moving average of the testL^2 error along the training iterations. 1.0 1.2 1.4 1.6 1.8 2.0 r 0.0 0.2 0.4 0.6 0.8 1.0 PINN loss 1.0 1.2 1.4 1.6 1.8 2.0 r 0.0 0.2 0.4 0.6 0.8 1.0 BSDE 1.0 1.2 1.4 1.6 1.8 2.0 r 0.0 0.2 0.4 0.6 0.8 1.0 Diffusion loss Figure 8: We plot the approximated committor functions evaluated at 10000 points uniformly sampled from the domain\u2126(blue dots) and compare those to the reference solution (orange line) as a function ofr=|x|. 6.3 Parabolic Allen-Cahn equation on an unbounded domain The Allen-Cahn equation ind= 100has been suggested as a benchmark problem in [19]. It is an example of a parabolic PDE posed on an unbounded domain, (\u2202t+L)V(x,t) +V(x,t)\u2212V^3 (x,t) = 0, (x,t)\u2208Rd\u00d7[0,T], (63) V(x,T) =f(x), x\u2208Rd, (64) withf(x) = ( 2 +^25 |x|^2 )\u2212 1 andT= 103. We restrict attention to the ball{x\u2208Rd:|x|< r}with radiusr= 7. Instead of using the uniform distribution on this set, we consider sampling uniformly on a box around the origin with side length 2 and multiplying each data pointxby|rx|. In contrast to uniform sampling, this approach generates more samples close to the origin, which we observe to slightly improve the accuracy of the obtained solutions. We compare our approximations to a reference solution atx 0 = (0,...,0)>for different timest\u2208[0,T]that is provided by a branching diffusion method specified in [19]. In Figure 9 we see that all three attempts match this reference solution, with very minor advantages (for instance at the right end point) for the PINN and diffusion losses. In Table 2 we display the computation times until convergence, realizing that the BSDE loss needs significantly longer. We note that the computation times are longer in comparison to e.g. [19] since we aim for a solution on a given domain, whereas other attempts only strive for approximating the solution at a single point. 0.00 0.05 0.10 0.15 0.20 0.25 0.30 t 0.1 0.2 0.3 0.4 0.5 PINN loss BDSE loss Diffusion loss reference solution Allen-Cahn equation, d = 100 Figure 9: Approximation of the solution to an AllenCahn equation ind= 100using different losses compared to a reference solution atx 0 = (0,...,0)>for different timest\u2208[0,T]. Computation time PINN loss 325. 46 min BSDE loss 4280. 68 min Diffusion loss 194. 38 min Table 2: Computation times until convergence. 6.4 Elliptic eigenvalue problems In this section we provide two examples for the approximation of principal eigenvalues and corresponding eigenfunctions. The first one is a linear problem and therefore Proposition 4.2 assures that the minimization of an appropriate loss as in (31) leads to the desired solution. The second example is a nonlinear eigenvalue problem, for which we can numerically show that our algorithm still provides the correct solution. 6.4.1 Fokker-Planck equation As suggested in [30], we aim at computing the principal eigenpair associated to a Fokker-Planck operator, defined by LV=\u2212\u2206V\u2212\u2207\u00b7(V\u2207\u03a8), (65) forV : \u2126\u2192Ron the domain\u2126 = [0, 2 \u03c0]d, and where\u03a8(x) = sin (\u2211 d i=1cicos(xi) ) is a potential with constants ci\u2208[0. 1 ,1], assuming periodic boundary conditions. This results in the eigenvalue problem \u2206V(x) +\u2207\u03a8(x)\u00b7\u2207V(x) + \u2206\u03a8(x)V(x) =\u2212\u03bbV(x), (66) and V(x) =e\u2212\u03a8(x) (67) is an eigenfunction associated to the principal eigenvalue\u03bb= 0, see [64, Section 4.7]. We chooseci= 0. 1 ,i= 1,...,d, and approach this problem in dimensiond= 5following Section 4.2, i.e. by minimizing the loss (31), where for Lwe choose the diffusion loss and the periodic boundary condition is encoded via the term (9). Here and in the following eigenvalue problem the positivity of the approximating function is enforced by adding a ReLU function after the last layer of the DenseNet. In the left panel of Figure 10 we display the approximated eigenfunction along the curve { (\u03ba,...,\u03ba)>:\u03ba\u2208[0, 2 \u03c0] } and compare it to the reference solution. In the central panel we show theL^2 error w.r.t. the reference solution evaluated on uniformly sampled test data along the training iterations. The right panel displays the moving average of the absolute value of the eigenvalue taken over a moving window of 100 gradient steps (since the true value is \u03bb= 0it is not possible to compute a relative error here). We see that both the eigenfunction and the eigenvalue are approximated sufficiently well. 0 1 2 3 4 5 6 0.6 0.8 1.0 1.2 1.4 1.6 Eigenfunction approximation reference approximation 0 10000200003000040000 5000060000 gradient steps 104 103 102 L^2 error of eigenfunction 0 100002000030000 400005000060000 gradient steps 103 102 Eigenvalue approximation \u03ba Figure 10: Left: Approximation and reference of the eigenfunction corresponding to the principal eigenvalue of the Fokker-Planck operator (65). Middle:L^2 error w.r.t. test data along the training iterations. Right: Moving average of the absolute value of the approximated eigenvalue along the gradient steps. 6.4.2 Nonlinear Schr\u00f6dinger equation Let us now consider a nonlinear eigenvalue problem. Again following [30], we consider the nonlinear Schr\u00f6dinger operator including a cubic term that arises from the Gross-Pitaevskii equation for the single-particle wave function in a Bose-Einstein condensate [27, 66]. To be precise, we consider \u2206V(x)\u2212V^3 (x)\u2212\u03a8(x)V(x) =\u2212\u03bbV(x), (68) where \u03a8(x) =\u2212 1 c^2 exp ( 2 d \u2211d i=1 cosxi ) + \u2211d i=1 ( sin^2 (xi) d^2 \u2212 cosxi d ) \u2212 3. (69) One can show that V(x) = 1 c exp ( 1 d \u2211d i=1 cosxi ) (70) Ln(\u03c6) = ( E [ \u03c6(X)^2 ] \u2212 1 ) 2 , { (\u03ba,...,\u03ba)>:\u03ba\u2208[0, 2 \u03c0] } 0 1 2 3 4 5 6 0.5 1.0 1.5 2.0 2.5 Eigenfunction approximation reference approximation 0 50000 100000 150000 200000 gradient steps 107 106 105 104 103 102 L^2 error of eigenfunction 0 50000 100000 150000 200000 gradient steps 106 105 104 103 102 101 Relative error eigenvalue \u03ba Figure 11: Left: Approximation and reference of the eigenfunction corresponding to the principal eigenvalue of the nonlinear Schr\u00f6dinger operator ind= 5. Middle:L^2 error w.r.t. test data along the training iterations. Right: Relative error of the approximated eigenvalue along the gradient steps. 0 1 2 3 4 5 6 0.5 1.0 1.5 2.0 2.5 Eigenfunction approximation reference approximation 0 50000100000150000200000250000300000 gradient steps 106 105 104 103 L^2 error of eigenfunction 0 50000100000150000200000250000300000 gradient steps 104 103 102 101 Relative error eigenvalue \u03ba Figure 12: Same experiment as in Figure 11 in dimensiond= 10. 7 Conclusion and Outlook References","title":"2112.03749 Interpolating between BSDEs and PINNs DL for Elliptic and Parabolic Boundary Value Problems"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_1","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#nikolas-nusken1-and-lorenz-richter234","text":"(^1) Institute of Mathematics, Universit\u00e4t Potsdam, 14476 Potsdam, Germany, nuesken@uni-potsdam.de (^2) Institute of Mathematics, Freie Universit\u00e4t Berlin, 14195 Berlin, Germany, lorenz.richter@fu-berlin.de (^3) Institute of Mathematics, Brandenburgische Technische Universit\u00e4t Cottbus-Senftenberg, 03046 Cottbus, Germany (^4) dida Datenschmiede GmbH, 10827 Berlin, Germany","title":"Nikolas N\u00fcsken^1 and Lorenz Richter2,3,4"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#december-8-2021","text":"Abstract","title":"December 8, 2021"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1-introduction","text":"(\u2202t+L)V(x,t) +h(x,t,V(x,t),\u03c3>\u2207V(x,t)) = 0, (x,t)\u2208\u2126\u00d7[0,T), (1a) V(x,T) =f(x), x\u2208\u2126, (1b) V(x,t) =g(x,t), (x,t)\u2208\u2202\u2126\u00d7[0,T], (1c) L=","title":"1 Introduction"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1","text":"","title":"1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2","text":"\u2211d i,j=1 (\u03c3\u03c3>)ij(x,t)\u2202xi\u2202xj+ \u2211d i=1 bi(x,t)\u2202xi (2) is an elliptic differential operator including the coefficient functionsb\u2208C(Rd\u00d7[0,T],Rd)and\u03c3\u2208C(Rd\u00d7[0,T],Rd\u00d7d), with\u03c3assumed to be non-degenerate. We will later make use of the fact thatLis the infinitesimal generator of the diffusion process defined by the stochastic differential equation (SDE) dXs=b(Xs,s) ds+\u03c3(Xs,s) dWs, (3) whereWsis a standardd-dimensional Brownian motion. Our approach exploiting the connection between (1) and (3) extends almost effortlessly to a wide range of nonlinear elliptic PDEs (see Section 4.1) and eigenvalue problems (see Section 4.2). We also note that the terminal condition (1b) can be replaced by an initial condition without","title":"2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#mathna-7-dec-2021","text":"loss of generality, using a time reversal transformation. Similarly, we may replace the Dirichlet boundary condition (1c) by its Neumann counterpart, that is, constraining the normal derivative\u2202~nVon\u2202\u2126\u00d7[0,T]in (1c). A notorious challenge that appears in the numerical treatment of PDEs is thecurse of dimensionality, suggesting that the computational complexity increases exponentially in the dimension of the state space. In recent years, however, multiple numerical [19, 35, 69] as well as theoretical studies [26, 40] have indicated that a combination of Monte Carlo methods and neural networks offers a promising way to overcome this problem. This paper centers around two strategies that allow for solving quite general nonlinear PDEs: PINNs physics-informed neural networks , also known under the name DGM deep Galerkin method directly minimize the misfit between the left-hand sides and right-hand sides of (1), evaluated at appropriately chosen (random) points in the space-time domain\u2126\u00d7[0,T]and its boundary. deep BSDEs backward stochastic differential equations rely on a reformulation of (1) in terms of stochastic forward-backward dynamics, explicitly making use of the connection between the PDE (1) and the SDE (3). Deep BSDEs minimize the misfit in the terminal condition associated to the backward SDE. We review those approaches (see Section 2) and \u2013 motivated by It\u00f4\u2019s formula \u2013 introduce a novel optimization objective, called thediffusion lossLtdiffusion(see Section 3). Importantly, our construction depends on the auxiliary time parametert\u2208(0,\u221e), allowing us to recover PINNs in the limitt\u2192 0 and deep BSDEs in the limitt\u2192\u221e: PINNs t\u2192 0 \u2190\u2212\u2212\u2212\u2212\u2212\u2212Ltdiffusion t\u2192\u221e \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192deep BSDEs As will become clear below, PINNs may therefore be thought of as accumulating derivative information on the PDE solution locally (in time), whereas deep BSDEs constitute global approximation schemes (relying on entire trajectories). The diffusion loss provides an interpolation between seemingly quite distinct methods. Besides this theoretical insight, we show experimentally that an appropriate choice oftcan lead to a computationally favourable blending of PINNs and deep BSDEs, combining the advantages of both methods. In particular, the diffusion loss (witht chosen to be of moderate size) appears to perform well in scenarios where the domain\u2126has a (possibly complex) boundary and/or the PDE under consideration contains a large number of second order derivatives (for instance, when\u03c3is not sparse). We will discuss the trade-offs involved in Section 5. The curse of dimensionality, BSDEs vs. PINNs.Traditional numerical methods for solving PDEs (such as finite difference and finite volume methods, see [1]) usually require a discretization of the domain\u2126, incurring a computational cost that for a prescribed accuracy is expected to grow linearly in the number of grid points, and hence exponentially in the number of dimensions. The recently developed approaches towards beating this curse of dimensionality \u2013 BSDEs and PINNs alike^1 \u2013 replace the deterministic mesh by Monte Carlo sampling, in principle promising dimension-independent convergence rates [20]. Typically, the approximating function class is comprised of neural networks (expectantly providing adaptivity to low-dimensional latent structures [2]), although also tensor trains have shown to perform well [70]. In contrast to PINNs, methods based on BSDEs make essential use of the underlying diffusion (3) to generate the training data. According to our preliminary numerical experiments, it is not clear whether this use of structure indeed translates into computational benefits; we believe that additional research into this comparison is needed and likely to contribute both conceptually and practically to further advances in the field. The diffusion loss considered in this paper may be a first step in this direction, for a direct comparison between BSDEs and PINNs we refer to Table 1a and Table 1b below. Previous works. Attempts to approximate PDE solutions by combining Monte Carlo methods with neural networks date back to the 1990s, where some variants of residual minimizations have been suggested [41, 49, 50, 51, 73]. Recently, this idea gained popularity under the namesphysics-informed neural networks(PINNs, [68, 69]) and deep Galerkin methods(DGMs, [72]). Let us further refer to a comparable approach that has been suggested in [9], and, for the special case of solving the dynamic Schr\u00f6dinger equation, to [16]. For theoretical analyses we shall for instance mention [57], which provides upper bounds on the generalization error, [17], which states an error analysis for PINNs in the approximation of Kolmogorov-type PDEs, [59], which investigates convergences depending on whether using exact or penalized boundary terms, and [76, 77], which study convergence properties through the (^1) We note in passing that multilevel Picard approximations [7, 36, 38] represent another interesting and fairly different class of methods that however are beyond the scope of this paper. lens of neural tangent kernels. Some further numerical experiments have been conducted in [18, 56] and multiple algorithmic improvements have been suggested, e.g. in [75], which balances gradients during model training, [39], which considers adaptive activation functions to accelerate convergence, as well as [74], which investigates efficient weight-tuning. BSDEs have first been introduced in the 1970s [11] and eventually studied more systematically in the 1990s [62]. For a comprehensive introduction elaborating on their connections to both elliptic and parabolic PDEs we refer for instance to [61]. Numerical attempts to exploit this connection aiming for approximations of PDE solutions have first been approached by backward-in-time iterations, originally relying on a set of basis functions and addressing parabolic equations on unbounded domains [14, 23, 61]. Those methods have been considered and further developed with neural networks in [3, 35] and endowed with tensor trains in [70]. A variational formulation termeddeep BSDE has been first introduced in [19, 28], aiming at PDE solutions at a single point, with some variants following e.g. in [60, 67]. For an analysis of the approximation error of the deep BSDE method we refer to [29] and for a fully nonlinear version based on second-order BSDEs to [5]. An extension to elliptic PDEs on bounded domains has been suggested in [47]. There are additional works aiming to solve linear PDEs specifically, mainly by exploiting the Feynman-Kac theorem and mostly considering parabolic equations [4, 10]. For the special case of the Poisson equation, [24] considers an elliptic equation on a bounded domain. Linear PDEs often admit a variational formulation that suggests to minimize a certain energy functional \u2013 this connection has been used in [22, 44, 54] and we refer to [58] for some further analysis. Similar minimization strategies can be used when considering eigenvalue problems, where we mention [80] in the context of metastable diffusion processes. We also refer to [33, 42, 48, 65] for similar problems in quantum mechanics that often rest on particular neural network architectures. Nonlinear elliptic eigenvalue problems are addressed in [30, 65] by exploiting a connection to a parabolic PDE and a fixed point problem. For rigorous results towards the capability of neural networks to overcome the curse of dimensionality we refer to [25, 37, 40], each analyzing certain special PDE cases. Adding to the methods referred to above, let us also mention [78] as an alternative approach exploiting weak PDEs formulations, as well as [53], which approximates operators by neural networks (however relying on training data from reference solutions), where a typical application is to map an initial condition to a solution of a PDE. For further references on approximating PDE solutions with neural networks we refer to the recent review articles [6, 12, 20, 43]. Outline of the article. In Section 2 we review PINN and BSDE based approaches towards solving highdimensional (parabolic) PDEs. In Section 3 we introduce the diffusion loss, show its validity for solving PDEs of the form (1), and prove that it interpolates between the PINN and BSDE losses. Section 4 develops extensions of the proposed methodology to elliptic PDEs and eigenvalue problems. In Section 5, we discuss implementational details as well as some further modifications of the losses under consideration. In Section 6 we present numerical experiments, including a committor function example from molecular dynamics and a nonlinear eigenvalue problem motivated by quantum physics. Finally, Section 7 concludes the paper with a summary and outlook.","title":"[math.NA] 7 Dec 2021"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2-variational-formulations-of-boundary-value-problems","text":"In this section we consider boundary value problems such as (1) in a variational formulation. That is, we aim at approximating the solutionVwith some function\u03c6\u2208Fby minimizing suitableloss functionals L:F \u2192R\u2265 0 , (4) which are zero if and only if the boundary value problem is fulfilled, L(\u03c6) = 0 \u21d0\u21d2 \u03c6=V. (5) HereF \u2282C^2 ,^1 (\u2126\u00d7[0,T],R)\u2229C(\u2126\u00d7[0,T],R)refers to an appropriate function class, usually consisting of deep neural networks. With a loss function at hand we can apply gradient-descent type algorithms to minimize (estimator versions of)L, keeping in mind that different choices of losses lead to different statistical and computational properties and therefore potentially to different convergence speeds and robustness behaviours [60]. Throughout, we will work under the following assumption: Assumption 1.The following hold: The domain\u2126is either bounded with piecewise smooth boundary, or\u2126 =Rd. The boundary value problem(1)admits a unique classical solutionV\u2208C^2 ,^1 (\u2126\u00d7[0,T],R)\u2229C(\u2126\u00d7[0,T],R). Moreover, the gradient ofV satisfies a polynomial growth condition inx, that is, |\u2207V(x,t)|\u2264C(1 +|x|q), (x,t)\u2208\u2126\u00d7[0,T], (6) for someC,q > 0. Complemented with a deterministic initial condition, the SDE(3)admits a unique strong solution, globally in time.","title":"2 Variational formulations of boundary value problems"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#21-the-pinn-loss","text":"Losses based on PDE residuals go back to [49, 50] and have gained recent popularity under the namephysicsinformed neural networks(PINNs, [69]) ordeep Galerkin methods(DGMs, [72]). The idea is to minimize an appropriateL^2 -error between the leftand right-hand sides of (1a)-(1c), replacingV by its approximation\u03c6. The derivatives of\u03c6are computed analytically or via automatic differentiation and the data on which\u03c6is evaluated is distributed according to some prescribed probability measure (often a uniform distribution). A precise definition is as follows: Definition 2.1(PINN loss).Let\u03c6\u2208F. ThePINN lossconsists of three terms, LPINN(\u03c6) =\u03b1intLPINN,int(\u03c6) +\u03b1TLPINN,T(\u03c6) +\u03b1bLPINN,b(\u03c6), (7) where LPINN,int(\u03c6) =E","title":"2.1 The PINN loss"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_2","text":"(\u2202t+L)\u03c6(X,t) +h(X,t,\u03c6(X,t),\u03c3>\u2207\u03c6(X,t))","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_1","text":", (8a) LPINN,T(\u03c6) =E","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_3","text":"\u03c6(X(T),T)\u2212f(X(T))","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_2","text":", (8b) LPINN,b(\u03c6) =E","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_4","text":"\u03c6(Xb,tb)\u2212g(Xb,tb)","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_3","text":". (8c) Here,\u03b1int,\u03b1T,\u03b1b> 0 are suitable weights balancing theinterior,terminalandboundaryconstraints, and(X,t)\u223c \u03bd\u2126\u00d7[0,T],X(T)\u223c\u03bd\u2126and(Xb,tb)\u223c\u03bd\u2202\u2126\u00d7[0,T]are distributed according to probability measures\u03bd\u2126\u00d7[0,T]\u2208 P(\u2126\u00d7 [0,T]),\u03bd\u2126\u2208P(\u2126)and\u03bd\u2202\u2126\u00d7[0,T]\u2208P(\u2202\u2126\u00d7[0,T])that are fully supported on their respective domains. While uniform distributions are canonical choices for\u03bd\u2126\u00d7[0,T],\u03bd\u2126and\u03bd\u2202\u2126\u00d7[0,T], further research might reveal promising (possibly adaptive) alternatives that focus the sampling on specific regions of interest. Remark2.2 (Generalizations).Clearly, the loss contributions (8a)-(8c) represent in one-to-one correspondence the constraints in (1a)-(1c). By that principle, the PINN loss can straightforwardly be generalized to other types of PDEs, see [43] and references therein. Let us further already mention that choosing appropriate weights \u03b1int,\u03b1T,\u03b1b > 0 is crucial for algorithmic performance, but not straightforward. We will elaborate on this aspect in Section 5. Remark2.3 (Unbounded domains).In the case when\u2126 =Rd, the boundary contribution (8c) becomes obsolete and we set\u03b1b= 0. Analogous remarks apply to the BSDE and diffusion losses introduced below. Remark2.4 (Neumann and periodic boundary conditions).Instead of the Dirichlet boundary condition (1c), Neumann or periodic boundary conditions may be considered, and the generalization of the PINN loss (as well as the diffusion loss introduced below) is straightforward. In the case of periodic boundary conditions, for instance, (8c) may be replaced by Lb(\u03c6) =E","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_5","text":"\u03c6(Xb)\u2212\u03c6(X b )","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_4","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#e","text":"","title":"+E"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_6","text":"","title":"[\u2223"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_7","text":"\u2223\u2207\u03c6(Xb)\u2212\u2207\u03c6(X b )","title":"\u2223"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_8","text":"","title":"\u2223"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_9","text":"","title":"\u2223"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_10","text":"","title":"\u2223"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_5","text":"","title":"2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#9","text":"whereXb\u223c\u03bd\u2202\u2126, andX b refers to the reflected/periodic counterpart. The BSDE loss (see Section 2.2 below) does not seem to admit a similar straightforward extension to more general boundary conditions, but [63] might provide a starting point for constructing a BSDE based method.","title":", (9)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#22-the-bsde-loss","text":"The BSDE loss makes use of a stochastic representation of the boundary value problem (1) given by a backward stochastic differential equation (BSDE) that is rooted in the correspondence between the differential operatorL defined in (2) and the stochastic processXdefined in (3). Indeed, according to [61], the PDE (1) is related to the system dXs=b(Xs,s) ds+\u03c3(Xs,s) dWs, Xt 0 =xinit, (10a) dYs=\u2212h(Xs,s,Ys,Zs) ds+Zs\u00b7dWs, YT\u2227\u03c4=k(XT\u2227\u03c4,T\u2227\u03c4), (10b) where\u03c4= inf{t >0 :Xt\u2208/\u2126}is the first exit time from\u2126andksubsumes the boundary conditions, k(x,t) =","title":"2.2 The BSDE loss"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_11","text":"f(x), t=T, x\u2208\u2126, g(x,t), t\u2264T, x\u2208\u2202\u2126.","title":"{"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#11","text":"Owing to the fact thatXin (10a) is constrained at initial timet 0 andY in (10b) at final timeT, the processes (Xs)t 0 \u2264s\u2264Tand(Ys)t 0 \u2264s\u2264Tare referred to as forward and backward, respectively. Given appropriate growth and regularity conditions on the coefficientsb,\u03c3,handk, It\u00f4\u2019s formula implies that the backward processes satisfy Ys=V(Xs,s), Zs=\u03c3>\u2207V(Xs,s), (12) that is, they provide the solution to (1) and its derivative along the trajectories of the forward process(Xs)t 0 \u2264s\u2264T, see [79]. Aiming for the approximation\u03c6\u2248V, we substitute (12) into (10b) and replaceVby\u03c6to obtain Y \u0303T\u2227\u03c4(\u03c6) =\u03c6(Xt 0 ,t 0 )\u2212 T\u222b\u2227\u03c4 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds+ T\u222b\u2227\u03c4 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs. (13) Our notationY \u0303T\u2227\u03c4(\u03c6)emphasizes the distinction fromYT\u2227\u03c4(which refers to the solution of (10)) and highlights the dependence on the particular choice\u03c6\u2208F. The key idea is now to penalize deviations from the terminal condition in (10b) via the loss L(\u03c6) =E","title":"(11)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_12","text":"k(XT\u2227\u03c4,T\u2227\u03c4)\u2212Y \u0303T\u2227\u03c4(\u03c6)","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_6","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#14","text":"see [28]. We summarize this construction as follows. Definition 2.5(BSDE loss).Let\u03c6\u2208F. TheBSDE lossis defined as LBSDE(\u03c6) =E","title":", (14)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_13","text":"f(X\u03c4\u2227T) (^1) {\u03c4\u2227T=T}+g(X\u03c4\u2227T,\u03c4\u2227T) (^1) {\u03c4\u2227T=\u03c4}\u2212\u03c6(Xt 0 ,t 0 )\u2212 \u03c4\u222b\u2227T t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_14","text":"\u03c4\u222b\u2227T t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_7","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_15","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#15","text":"where(Xt)t 0 \u2264t\u2264\u03c4\u2227Tis a solution to (3) and\u03c4= inf{t >0 :Xt\u2208/\u2126}is the first exit time from\u2126. Furthermore, the initial condition(X 0 ,t 0 )is distributed according to a prescribed probability measure\u03bd\u2126\u00d7[0,T]with full support on \u2126\u00d7[0,T]. Remark2.6 (BSDE versus PINN).In contrast to the PINN loss (7), the BSDE loss (15) does not rely on a judicious tuning of the weights\u03b1int,\u03b1T,\u03b1b. On the other hand, implementations based on the BSDE loss face the challenge of simulating the hitting times\u03c4= inf{t >0 :Xt\u2208/\u2126}efficiently and accurately. We shall elaborate on this aspect in Section 5.1. Remark2.7 (Relationship to earlier work). The idea of approximating solutions to PDEs by solving BSDEs has been studied extensively [14, 23, 61], where first approaches were regression based, relying on iterations backwards in time. These ideas do not seem to be straightforwardly applicable to the case when\u2126is bounded, as the trajectories of the forward process (10a) are not all of the same length (but see [13] and [31]). A global variational strategy using neural networks has first been introduced in [19], where however in contrast to Definition 2.5, the initial condition (X 0 ,t 0 )is deterministic (and fixed) and only parabolic problems on\u2126 =Rdare considered. Moreover, slightly different choices for the approximations are chosen, namelyV is only approximated att 0 = 0and\u2207V instead of Vis learnt by one neural network per time point (instead of using only one neural network withtas an additional input).","title":"(15)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#3-the-diffusion-loss","text":"In this section we introduce a novel loss that interpolates between the PINN and BSDE losses from Section 2 using an auxiliary time parametert\u2208(0,\u221e). As for the BSDE loss, the connection between the SDE (3) and its infinitesimal generator (2) plays a major role: It\u00f4\u2019s formula","title":"3 The diffusion loss"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#vxttvx-0-0","text":"","title":"V(XT,T)\u2212V(X 0 ,0) ="},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t","text":"0 (\u2202s+L)V(Xs,s) ds+","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_1","text":"0 \u03c3>\u2207V(Xs,s)\u00b7dWs (16) motivates the following variational formulation of the boundary value problem (1). Definition 3.1(Diffusion loss).Let\u03c6\u2208Fandt\u2208(0,\u221e). Thediffusion lossconsists of three terms, Ltdiffusion(\u03c6) =\u03b1intLtdiffusion,int(\u03c6) +\u03b1TLtdiffusion,T(\u03c6) +\u03b1bLtdiffusion,b(\u03c6), (17) where Ltdiffusion,int(\u03c6) =E","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_16","text":"\u03c6(XT,T)\u2212\u03c6(Xt 0 ,t 0 )\u2212","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_2","text":"t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs (18a)","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_17","text":"","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_3","text":"t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_8","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_18","text":"Ltdiffusion,T(\u03c6) =E","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_19","text":"\u03c6(X(T),T)\u2212f(X(T))","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_9","text":", (18b) Ltdiffusion,b(\u03c6) =E","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_20","text":"\u03c6(Xb,tb)\u2212g(Xb,tb)","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_10","text":", (18c) encode the constraints (1a)-(1c), balanced by the weights\u03b1int,\u03b1T,\u03b1b> 0. The process(Xt)t 0 \u2264t\u2264Tis a solution to (3) with initial condition(X 0 ,t 0 )\u223c\u03bd\u2126\u00d7[0,T]and maximal trajectory lengtht> 0. The stopping timeT := (t 0 +t)\u2227\u03c4\u2227Tis a shorthand notation, referring to the (random) final time associated to a realization of the path Xas it either hits the parabolic boundary\u2202\u2126\u00d7{T}or reaches the maximal timet 0 +t. As in Definition 2.1, \u03c4= inf{t >0 :Xt\u2208/\u2126}is the exit time from\u2126, and(Xb,tb)\u223c\u03bd\u2202\u2126\u00d7[0,T],X(T)\u223c\u03bd\u2126are distributed according to probability measures that are fully supported on their respective domains. Remark3.2 (Comparison to the BSDE and PINN losses).In contrast to the PINN loss from Definition 2.1, the data inside the domain\u2126is not sampled according to a prescribed probability measure\u03bd\u2126, but along trajectories of the diffusion (3). Consequently, second derivatives of\u03c6do not have to be computed explicitly, but are approximated using the driving Brownian motion (and \u2013 implicitly \u2013 It\u00f4\u2019s formula). A main difference to the BSDE loss from Definition 2.5 is that the simulated trajectories have a maximal lengtht, which might be beneficial computationally if the final timeTor the exit time\u03c4is large (with high probability). Additionally, the sampling of extra boundary data circumvents the problem of accurately simulating those exit times (see Remark 2.6). Both aspects will be further discussed in Section 5. We refer to Figure 1 for a graphical illustration of the data required to compute the three losses. PINN loss BSDE loss, t = 0.0001 Diffusion loss, t = 0.0001, N = 50 Figure 1: We illustrate the training data used for the three losses inside the unit square\u2126 = (0,1)^2. The PINN loss in the left panel takes i.i.d. data points that are sampled from prescribed probability distributions in the domain\u2126 and on the boundary\u2202\u2126(in this case from uniform distributions). The BSDE loss (middle panel) uses trajectories associated to the SDE (3) that are started at random pointsX 0 (green points) and run until they hit the boundary (red points). The trajectories for the diffusion loss have a maximal lengthtand therefore frequently start and end inside\u2126, as displayed in the right panel. The blue points for the PINN and diffusion losses indicate the additionally sampled boundary data. The following proposition shows that the lossLtdiffusionis indeed suitable for the boundary value problem (1). Proposition 3.3.Consider the diffusion loss as defined in(17), and assume thatband\u03c3are globally Lipschitz continuous inx, uniformly int\u2208[0,T]. Furthermore, assume the following Lipschitz and boundedness conditions onf,gandh, |f(x)|\u2264C(1 +|x|p), |g(x,t)|\u2264C(1 +|x|p), |h(t,x,y,z)|\u2264C(1 +|x|p+|y|+|z|), |h(t,x,y,z)\u2212h(t,x,y\u2032,z)|\u2264C|y\u2212y\u2032|, |h(t,x,y,z)\u2212h(t,x,y,z\u2032)|\u2264C|z\u2212z\u2032|, for appropriate constantsC,p\u2265 0 and allx,y,z\u2208\u2126,t\u2208[0,T]. Finally, assume that Assumption 1 is satisfied. Then for\u03c6\u2208Fthe following are equivalent: The diffusion loss vanishes on\u03c6, Ltdiffusion(\u03c6) = 0. (19) \u03c6fulfills the boundary value problem(1). Proof.Denoting byXsthe unique strong solution to (3), an application of It\u00f4\u2019s lemma to\u03c6(Xs,s)yields \u03c6(XT,T) =\u03c6(Xt 0 ,t 0 ) +","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_4","text":"t 0 (\u2202s+L)\u03c6(Xs,s) ds+","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_5","text":"t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs, (20) almost surely. Assuming that\u03c6fulfills the PDE (1a), it follows from the definition in (18a) thatLtdiffusion,int(\u03c6) = 0. Similarly, the boundary conditions (1b) and (1c) imply thatLtdiffusion,T(\u03c6) =Ltdiffusion,b(\u03c6) = 0. Consequently, we see thatLtdiffusion(\u03c6) = 0. For the converse direction, observe thatLtdiffusion(\u03c6) = 0implies that \u03c6(XT,T) =\u03c6(Xt 0 ,t 0 ) +","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_6","text":"t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs\u2212","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_7","text":"t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds, (21) almost surely, and that the same holds with\u03c6replaced byV. We proceed by defining the processesY \u0303s:=\u03c6(Xs,s) andZ \u0303s:=\u03c3>\u2207\u03c6(Xs,s), as well asYs:=V(Xs,s)andZs:=\u03c3>\u2207V(Xs,s). By the assumptions on\u03c6,band \u03c3, the processesY,Z,Y \u0303andZ \u0303are progressively measurable with respect to the filtration generated by(Wt)t\u2265 0 and moreover square-integrable. Furthermore, the relation (21) shows that the pairs(Y,Z)and(Y , \u0303Z \u0303)satisfy a BSDE with terminal condition\u03be:=\u03c6(XT,T)on the random time interval[t 0 ,T]. Well-posedness of the BSDE (see [61, Theorems 1.2 and 3.2]) implies thatY =Y \u0303andZ=Z \u0303, almost surely. Conditional ont 0 andXt 0 , we also haveV(Xt 0 ,t 0 ) =YXt^0 ,t^0 =Y \u0303Xt^0 ,t^0 =\u03c6(Xt 0 ,t 0 ), where the superscripts denote conditioning on the initial timet 0 and corresponding initial conditionXt 0 , see [61, Theorems 2.4 and 4.3]. Hence, we conclude that\u03c6=V, \u03bd\u2126\u00d7[0,T]-almost surely, and the result follows from the continuity of\u03c6andVand the assumption that\u03bd\u2126\u00d7[0,T] has full support. We have noted before that the diffusion loss combines aspects from the BSDE and PINN losses. In fact, it turns out that the diffusion loss can be interpreted as a specific type of interpolation between the two. The following proposition makes this observation precise. Proposition 3.4(Relation of the diffusion loss to the PINN and BSDE losses).Let\u03c6\u2208 F. Assuming that the measures\u03bd\u2126\u00d7[0,T]in Definitions 2.1 and 3.1 coincide, we have that Ltdiffusion,int(\u03c6) t^2 \u2192LPINN,int(\u03c6), (22) ast\u2192 0. Moreover, if\u03bd\u2126\u00d7[0,T]refers to the same measure in Definitions 2.1 and 2.5, then Ltdiffusion,int(\u03c6)\u2192LBSDE(\u03c6), (23) ast\u2192\u221e. Proof.It\u00f4\u2019s formula shows thatLtdiffusion,intcan be expressed as Ltdiffusion,int(\u03c6) =E","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_21","text":"","title":"\uf8ee"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_22","text":"","title":"\uf8ef"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_23","text":"","title":"\uf8f0"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_24","text":"","title":"\uf8eb"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_25","text":"","title":"\uf8ed"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_8","text":"t 0 (\u2202s+L)\u03c6(Xs,s) ds+","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_9","text":"t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_26","text":"","title":"\uf8f6"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_27","text":"","title":"\uf8f8"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_11","text":"","title":"2 \uf8f9"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_28","text":"","title":"\uf8fa"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#24","text":"which implies the limit (22) by dominated convergence, noting thatT \u2192t 0 ast\u2192 0 , almost surely. The relation (23) follows immediately from the definition ofLBSDEby noting thatT \u2192\u03c4\u2227Tast\u2192\u221e, almost surely.","title":"\uf8fb, (24)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#4","text":"","title":"4"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_29","text":"\u2202\u2126xt:= \u2126\u00d7{T}\u222a\u2202\u2126\u00d7[0,T], and the augmented variablez= (x,t)>\u2208\u2126\u00d7[0,T]. Then problem (1) can be presented as AV(z) +h(z,V(z),\u03c3>\u2207xV(z)) = 0, z\u2208\u2126xt, (25a) V(z) =k(z), z\u2208","title":"\u2212\u2192"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_30","text":"\u2202\u2126xt, (25b) withkdefined as in (11). Relying on (25), we can equivalently define the BSDE loss as LBSDE(\u03c6) =E","title":"\u2212\u2192"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_31","text":"k(X\u03c4xt,\u03c4xt)\u2212\u03c6(Xt 0 ,t 0 )\u2212 \u222b\u03c4xt t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs+ \u222b\u03c4xt t 0 h(Xs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s)) ds","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_12","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_32","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#26","text":"where\u03c4xt= inf{t >0 :Xt\u2208/\u2126xt}is the first exit time from\u2126xt. The PINN and diffusion losses can similarly be rewritten in terms of the space-time domain\u2126xtand exit time\u03c4xt. (^2) We notice in passing that the (ordinary) topological boundary of\u2126xtis given by\u2202\u2126xt= \u2126\u00d7 { 0 , T} \u222a\u2202\u2126\u00d7[0, T], so that \u2202\u2126xt=\u2212\u2192\u2202\u2126xt\u222a{ 0 }\u00d7\u2126.","title":"(26)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#41-elliptic-boundary-value-problems","text":"Removing the time dependence from the solution (and from the coefficientsband\u03c3determiningL) we obtain the elliptic boundary value problem LV(x) +h(x,V(x),\u03c3>\u2207V(x)) = 0, x\u2208\u2126, (27a) V(x) =g(x), x\u2208\u2202\u2126, (27b) with the nonlinearityh\u2208C(Rd\u00d7R\u00d7Rd,R). In analogy to (10), the corresponding backward equation is given by dYs=\u2212h(Xs,Ys,Zs) ds+Zs\u00b7dWs, Y\u03c4=g(X\u03c4), (28) where\u03c4={t >0 :Xt\u2208/\u2126}is the first exit time from\u2126. Given suitable boundedness and regularity assumptions on hand assuming that\u03c4is almost surely finite, one can show existence and uniqueness of solutionsY andZ, which, as before, represent the solutionV and its gradient along trajectories of the forward process [61, Theorem 4.6]. Therefore, the BSDE, PINN and diffusion losses can be applied to (27) with minor modifications: Owing to the fact that there is no terminal condition, we setf= 0in (15), as well as\u03b1T= 0in (7) and (17), making (8b) and (18b) obsolete. With the same reasoning, we setT=\u221e, incurring\u03c4\u2227T=\u03c4andT = (t 0 +t)\u2227\u03c4; these simplifications are relevant for the expressions (15) and (18a). Proposition 3.3 and its proof can straightforwardly be generalized to the elliptic setting. An algorithm for solving elliptic PDEs of the type (27) in the spirit of the BSDE loss has been suggested in [47], using the same approximation framework as in [19] (cf. Remark 2.7). We note that the solutions to linear elliptic PDEs often admit alternative variational characterizations in terms of energy functionals [22]. An approach using the Feynman-Kac formula has been considered in [24].","title":"4.1 Elliptic boundary value problems"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#42-elliptic-eigenvalue-problems","text":"We can extend the algorithmic approaches from Sections 2 and 3 to eigenvalue problems of the form LV(x) =\u03bbV(x), x\u2208\u2126, (29a) V(x) = 0, x\u2208\u2202\u2126, (29b) corresponding to the choiceh(x,y,z) =\u2212\u03bbyin the elliptic PDE (27). Note, however, thathnow depends on the unknown eigenvalue\u03bb\u2208R. Furthermore, we can consider nonlinear eigenvalue problems, LV(x) +h(x,V(x),\u03c3>\u2207V(x)) =\u03bbV(x), x\u2208\u2126, (30a) V(x) = 0, x\u2208\u2202\u2126, (30b) with a general nonlinearityh\u2208C(Rd\u00d7R\u00d7Rd,R). For the linear problem (29) it is known that, given suitable boundedness and regularity assumption onband\u03c3, there exists a unique principal eigenvalue with strictly positive eigenfunction in\u2126, see [8, Theorem 2.3]. This motivates us to consider the above losses, now depending on\u03bb, as well as enhanced with an additional term, preventing the trivial solutionV\u2261 0. We define Leigen(\u03c6,\u03bb) =L\u03bb(\u03c6) +\u03b1cLc(\u03c6), (31) whereL\u03bb(\u03c6)stands for either the PINN, the BSDE, or the diffusion loss (with the nonlinearityhdepending on \u03bb),Lc(\u03c6) = (\u03c6(xc)\u22121)^2 , and\u03b1c> 0 is a weight. Herexc\u2208\u2126is chosen deterministically, preferably not too close to the boundary\u2202\u2126. Clearly, the termLcencourages\u03c6(xc) = 1, thus discouraging\u03c6\u2261 0. We note that V(xc) = 1can be imposed on solutions to (29) without loss of generality, since the eigenfunctions are determined up to a multiplicative constant only. Avoiding\u03c6\u2261 0 for nonlinear eigenvalue problems of the form (30) needs to be addressed on a case-by-case basis; we present an example in Section 6.4.2. The idea is now to minimizeLeigen(\u03c6,\u03bb)with respect to\u03c6\u2208 Fand\u03bb\u2208Rsimultaneously, while constraining the function\u03c6to be non-negative. According to following proposition this is a valid strategy to determine the first eigenpair. Proposition 4.2.Let\u2126be bounded, and assume thatLis uniformly elliptic, that is, there exist constantsc 0 ,C 0 > 0 such that c 0 |\u03be|^2 \u2264 \u2211d i,j=1 (\u03c3\u03c3>)(x)\u03bei\u03bej\u2264C 0 |\u03be|^2 , (32) for all\u03be\u2208Rd. Moreover, assume thatbis bounded. Let\u03c6\u2208Fwith\u03c6\u2265 0 and assume thatL\u03bb(\u03c6) = 0if and only if(29)is satisfied. Then the following are equivalent: \u03c6is the principal eigenfunction for(29)with principal eigenvalue\u03bband normalization\u03c6(xc) = 1. Leigen(\u03c6,\u03bb)vanishes on the pair(\u03c6,\u03bb), Leigen(\u03c6,\u03bb) = 0. (33) Remark4.3.The assumption thatL\u03bb(\u03c6)is equivalent to (29) is satisfied for any \u2018reasonable\u2019 loss function. For the diffusion loss, Proposition 3.3 establishes this condition whenever the coefficients in (29) are regular enough. Proof.It is clear that 1. implies 2. by the construction of (31). For the converse direction, notice that (33) implies \u03c6(xc) = 1as well as (29), that is,\u03c6is an eigenfunction with eigenvalue\u03bb. In conjunction with the constraint\u03c6\u2265 0 , it follows by [8, Theorem 2.3] that\u03c6is the principal eigenfunction. An alternative approach towards (29) can be found in [30], where the eigenvalue problem is connected to a parabolic PDE and formulated as a fixed point problem.","title":"4.2 Elliptic eigenvalue problems"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#5-from-losses-to-algorithms","text":"In this section we discuss some details regarding implementational aspects. For convenience, let us start by stating a prototypical algorithm based on the losses introduced in Sections 2 and 3: Algorithm 1:Approximation of the solutionVto the boundary value problem (1). Choose a parametrizationRp 3 \u03b87\u2192\u03c6\u03b8. Initialize\u03c6\u03b8(with a parameter vector\u03b8\u2208Rp). Choose an optimization methoddescent, a batch sizeK\u2208Nand a learning rate\u03b7 > 0. For PINN and diffusion losses choose weights\u03b1int,\u03b1b,\u03b1T> 0 and batch sizesKb,KT\u2208N. For BSDE and diffusion losses choose a step-size\u2206t > 0 , for the diffusion loss choose a trajectory lengtht> 0. repeat Choose a loss functionLfrom either (7), (15) or (17). Simulate data according to the chosen loss. ComputeL\u0302(\u03c6\u03b8)as a Monte Carlo version ofL. Compute\u2207\u03b8L\u0302(\u03c6\u03b8)using automatic differentiation. Update parameters:\u03b8\u2190\u03b8\u2212\u03b7descent(\u2207\u03b8L\u0302(\u03c6\u03b8)). until convergence; Result:\u03c6\u03b8\u2248V. Function approximation.In this paper, we rely on neural networks to provide the parametrizationRp 3 \u03b87\u2192\u03c6\u03b8 referred to in Algorithm 1 (but note that alternative function classes might offer specific benefits, see, for instance [70]). Standard feed-forward neural networks are given by \u03c6\u03b8:Rd\u2192R, \u03c6\u03b8(x) =AL%(AL\u2212 1 %(\u00b7\u00b7\u00b7%(A 1 x+b 1 )\u00b7\u00b7\u00b7) +bL\u2212 1 ) +bL, (34) with a collection of matricesAl \u2208Rnl\u00d7nl\u2212^1 and vectorsbl \u2208Rnl comprising the learnable parameters, \u03b8 = (Al,bl) 1 \u2264l\u2264L. HereLdenotes the depth of the network, and we haven 0 =das well asnL = 1. The nonlinear activation function%:R\u2192Ris to be applied componentwise. Additionally, we define theDenseNet[22, 34] as a variant of the feed-forward neural network (34), containing additional skip connections, \u03c6DenseNet\u03b8 (x) =ALxL+bL, (35) wherexLis specified recursively as yl+1=%(Alxl+bl), xl+1= (xl,yl+1)>, x 1 =x, (36) withAl\u2208Rnl\u00d7 \u2211l\u2212 1 i=0niandbl\u2208Rlfor 1 \u2264l\u2264L\u2212 1 ,n 0 =d. Again, the collection of matricesAland vectorsbl comprises the learnable parameters. Comparison of the losses (practical challenges). The PINN, BSDE and diffusion losses differ in the way training data is generated (see Figure 1 and Table 1a); hence, the corresponding implementations face different challenges (see Table 1b). Table 1: Comparison of the different losses. PINN BSDE Diffusion SDE simulation 7 7 boundary data 7 7 (a) The three losses can be characterized by how training data is generated. PINN BSDE Diffusion Hesse computations 7 boundary issues 7 weight tuning 7 7 long runtimes 7 discretization 7 7 (b) In this table we list potential challenges and drawbacks for the corresponding losses. First, the BSDE and diffusion losses rely on trajectorial data obtained from the SDE (3), in contrast to the PINN loss (cf. the first row in Table 1a). As a consequence, the BSDE and diffusion losses do not require the computation of second-order derivatives, as those are approximated implicitly using It\u00f4\u2019s formula and the SDE (3), cf. the first row in Table 1a. From a computational perspective, the PINN loss therefore faces a significant overhead in high dimensions when the diffusion coefficient\u03c3is not sparse (as the expression (8a) involvesd^2 second-order partial derivatives). We notice in passing that an approach similar to the diffusion loss circumventing this problem has been proposed in [72, Section 3]. On the other hand, evaluating the BSDE and diffusion losses requires discretizing the SDE (3), incurring additional numerical errors (cf. the last row in Table 1b and the discussion below in Section 5.1). Second, the PINN and diffusion losses incorporate boundary and final time constraints (see (1c) and (1b)) explicitly by sampling additional boundary data (see (8b), (8c), (18b), (18c) and cf. the second row in Table 1a). On the one hand, this approach necessitates choosing the weights\u03b1int,\u03b1b,\u03b1T> 0 ; it is by now well established that while algorithmic performance depends quite sensitively on a judicious tuning of these weights, general and principled guidelines to address this issue are not straightforward (see, however, [74, 75, 76, 77]). Weight-tuning, on the other hand, is not required for implementations relying on the BSDE loss, as the boundary data is accounted for implicitly by the hitting event{(Xt,t)\u2208/\u2126\u00d7[0,T)}and the corresponding first two terms on the right-hand side of (15). The hitting times\u03c4= inf{t >0 :Xt\u2208/\u2126}may however be large, leading to a computational overhead in the generation of the training data (but see 5.2.1), and are generally hard to compute accurately (but see Section 5.1).","title":"5 From losses to algorithms"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#51-simulation-of-diffusions-and-their-exit-times","text":"The BSDE and diffusion losses rely on trajectorial data obtained from the stochastic process defined in (3). In practice, we approximate this SDE on a time gridt 0 \u2264t 1 \u2264 \u00b7\u00b7\u00b7 \u2264tN, for instance using the Euler-Maruyama scheme [46] X \u0303n+1=X \u0303n+b(X \u0303n,tn)\u2206t+\u03c3(X \u0303n,tn)","title":"5.1 Simulation of diffusions and their exit times"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_33","text":"\u2206t\u03ben+1, (37) or, to be precise, by its stopped version X\u0302n+1=X\u0302n+","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_34","text":"b(X\u0302n,tn)\u2206t+\u03c3(X\u0302n,tn)","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_35","text":"\u2206t\u03ben+1","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_36","text":"(^1) Cn+1 (38) with step conditionCn:=","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_37","text":"X \u0303n\u2208\u2126","title":"{"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_38","text":"\u2228{tn\u2264T}and time-incrementtn+1=tn+ \u2206t (^1) Cn+1, where\u2206tis the stepsize and\u03ben+1\u223c N(0,Idd\u00d7d)are standard normally distributed random variables. We can then straightforwardly construct Monte Carlo estimator versions of either the BSDE or the diffusion loss. For example, the discrete version of the domain part of the diffusion loss (18a) reads L\u0302(diffusionK,N) ,int(\u03c6) =^1 K","title":"}"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k","text":"k=1","title":"\u2211K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_39","text":"\u03c6(X\u0302(Nk),t(Nk))\u2212\u03c6(X\u0302 0 (k),t( 0 k))\u2212","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#n-1","text":"n=0 \u03c3>\u2207\u03c6(X\u0302n(k),t(nk))\u00b7\u03be(nk+1)","title":"N\u2211\u2212 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_40","text":"\u2206t (^1) Cn(k) (39a)","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_41","text":"","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#n-1_1","text":"n=0 h","title":"N\u2211\u2212 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_42","text":"X\u0302n(k),t(nk),\u03c6(X\u0302n(k),t(nk)),\u03c3>\u2207\u03c6(X\u0302n(k),t(nk))","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_43","text":"\u2206t (^1) C(nk)","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_13","text":", (39b) whereKis the sample size,N=\u2206ttis the maximal discrete-time trajectory length, and(X\u0302n(k))kn=1=1...K...Nare independent copies of the iterates from (38). The Monte Carlo version of the BSDE loss can be formed analogously. Given suitable growth and regularity assumptions on the coefficients, the discretization errors of the forward and backward processes are of order","title":") 2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_44","text":"\u2206t[46, 79], cf. also [29] for a numerical analysis on the original version of the BSDE loss. However, the stopped Euler-Maruyama scheme (38) incurs additional errors due to the approximation of the first exit times from\u2126. In the two left panels of Figure 2 we illustrate this problem by displaying multiple \u201clast locations\u201d obtained according to (38), using two different step-sizes\u2206t. Clearly, all these points should in principle lie on the boundary, (naively) requiring a computationally costly small step-size. boundary points, t = 0.001 boundary points, t = 0.0001 trajectories, t = 0.001 reversed trajectories, t = 0.001 Figure 2: Illustration of the boundary data in the BSDE method. Sophisticated approaches towards the accurate simulation of exit times for diffusions discretizing exit times have been put forward, see, e.g. [15, 32]. For our purposes, however, it is not essential to compute the exit times, as long as the simulated trajectories are stopped accurately. We therefore suggest the following two attempts that aim at improving the sampling of boundary data: Rescaling: StartX 0 randomly in\u2126, simulate the trajectory and stop once the boundary has been crossed, however scale the last time step in such a way that the trajectory exactly ends on\u2202\u2126. Time-reversal: StartX 0 on the boundary\u2202\u2126and simulate the trajectory for a given timeT(unless it hits the boundary again before timeT, in this case stop the trajectory accordingly or resimulate). Then reverse the process such that the reversed process exactly ends on the boundary. An illustration of these two strategies can be found in the two right panels of Figure 2. In our numerical experiments we have found that both rescaling and time-reversal improves the performance of the BSDE method somewhat, but further research is needed.","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#52-further-modifications-of-the-losses","text":"In the following we discuss modifications of the PINN, BSDE and diffusion losses, relating also to versions that have appeared in the literature before. 5.2.1 Forward control We can modify the SDE-based BSDE and diffusion losses by including control termsv\u2208C(Rd\u00d7[0,T],Rd)in the forward process (3), yielding the controlled diffusion dXvs= (b(Xsv,s) +\u03c3(Xvs,s)v(Xsv,s)) ds+\u03c3(Xsv,s) dWs. (40) Applying It\u00f4\u2019s formula we may obtain losses similar to those considered in Section 2 and 3. For instance, alternative versions of the diffusion loss take the form Ltdiffusion,int,v (\u03c6) =E","title":"5.2 Further modifications of the losses"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_45","text":"\u03c6(XTv,T)\u2212\u03c6(Xtv 0 ,t 0 )\u2212","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_10","text":"t 0 \u03c3>\u2207\u03c6(Xs,s)\u00b7dWs","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_46","text":"","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#t_11","text":"t 0","title":"\u222bT"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_47","text":"h(Xsv,s,\u03c6(Xvs,s),\u03c3>\u2207\u03c6(Xsv,s))\u2212v(Xsv,s)\u00b7\u03c3>\u2207\u03c6(Xsv,s)","title":"["},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_48","text":"ds","title":"]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_14","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_49","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#41","text":"replacing (18a). We note in passing that Proposition 3.3 extends straightforwardly toLtdiffusion,int,v under the assumption thatvsatisfies appropriate Lipschitz and growth conditions. Similar considerations apply for the BSDE loss, noting that for solutions to the generalized BSDE system [60] dXsv= (b(Xsv,s) +\u03c3(Xsv,s)v(Xvs,s)) ds+\u03c3(Xsv,s) dWs, Xtv 0 =xinit, (42a) dYsv=\u2212h(Xsv,s,Ysv,Zsv) ds+v(Xsv,s)\u00b7Zvsds+Zsv\u00b7dWs, YTv=k(XvT\u2227\u03c4,T\u2227\u03c4), (42b) we still have the relations Ysv=V(Xsv,s), Zsv=\u2207V(Xsv,s) (43) for suitablev\u2208C(Rd\u00d7[0,T],Rd), analogously to (12). This immediately incurs the family of losses LvBSDE(\u03c6) =E","title":"(41)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_50","text":"f(X\u03c4v\u2227T) (^1) \u03c4\u2227T=T+g(X\u03c4v\u2227T,\u03c4\u2227T) (^1) \u03c4\u2227T=\u03c4\u2212\u03c6(Xtv 0 ,t 0 )\u2212 \u03c4\u222b\u2227T t 0 \u03c3>\u2207\u03c6(Xsv,s)\u00b7dWs","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_51","text":"\u03c4\u222b\u2227T t 0","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_52","text":"h(Xvs,s,\u03c6(Xs,s),\u03c3>\u2207\u03c6(Xs,s))\u2212v(Xsv,s)\u00b7\u03c3>\u2207\u03c6(Xsv,s)","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_53","text":"ds","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_15","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_54","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#44","text":"parametrized byv\u2208C(Rd\u00d7[0,T],Rd). Adding a control to the forward process can be understood as driving the data generating process into regions of interest, for instance possibly alleviating the problem that exit times might be large (see Table 1b and the corresponding discussion). Identifying suitable forward controls might be an interesting topic for future research (we refer to [60] for some systematic approaches in this respect relating to Hamilton-Jacobi-Bellman PDEs). 5.2.2 Approximating the gradient of the solution The constraints imposed by the BSDE system (10) can be enforced by losses that slightly different from Definition 2.5. Going back to [19], we can for instance use the fact that the backward processY can be written in a forward way, yielding the discrete-time process Y\u0302n+1=Y\u0302n\u2212h(X\u0302n,tn,Y\u0302n,Z\u0302n)\u2206t+Z\u0302n\u00b7\u03ben+1","title":"(44)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_55","text":"\u2206t. (45) The scheme (45) is explicit, the unknowns beingY\u0302 0 andZ\u0302n, forn\u2208{ 0 ,...,N\u2212 1 }. This motivates approximating the single parametery 0 \u2248Y\u0302 0 \u2208Ras well as the vector fields\u03c6\u2248\u03c3>\u2207V\u2208C(Rd\u00d7[0,T],Rd), rather thanVdirectly. This approach gives rise to the loss LBSDE\u2212 2 (\u03c6,y 0 ) =E","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_56","text":"f(X\u03c4\u2227T) (^1) \u03c4\u2227T=T+g(X\u03c4\u2227T,\u03c4\u2227T) (^1) \u03c4\u2227T=\u03c4\u2212y 0 \u2212 \u03c4\u222b\u2227T 0 \u03c6(Xs,s)\u00b7dWs","title":"[("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_57","text":"\u03c4\u222b\u2227T 0 h(Xs,s,Ys,\u03c6(Xs,s)) ds","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_16","text":"","title":") 2 ]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_58","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#46","text":"In this settingX 0 has to be chosen deterministically; we note that a potential drawback is thus that the solution is only expected to be approximated accurately in regions that can be reached by the forward processXt(starting at X 0 ) with sufficiently high probability. It has been shown in [60] that alternative losses (like the log-variance loss) can be considered whenever the nonlinearityhonly depends on the solution through its gradient, in which case the extra parametery 0 can be omitted. 5.2.3 Penalizing deviations from the discrete scheme Another approach that is rooted in the discrete-time backward process (45) has been suggested in [67] for problems on unbounded domains. It relies on the idea to penalize deviations from (45), for eachn\u2208 { 0 ,...,N\u2212 1 }(cf. also [35, 70], where however an implicit scheme and backward iterations are used). Aiming forY\u0302n\u2248\u03c6(X\u0302n,tn), Z\u0302n\u2248\u03c3>\u2207\u03c6(X\u0302n,tn), this motivates the loss L\u0302(K,N) BSDE\u2212 3 (\u03c6) =\u03b1int","title":"(46)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#lkn","text":"BSDE\u2212 3 ,int(\u03c6) +\u03b1b","title":"L\u0302(K,N)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#lkn_1","text":"BSDE\u2212 3 ,b(\u03c6) (47) with interior part","title":"L\u0302(K,N)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#lkn_2","text":"BSDE\u2212 3 ,int(\u03c6) =","title":"L\u0302(K,N)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_1","text":"","title":"1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k_1","text":"","title":"K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k_2","text":"k=1","title":"\u2211K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#n-1_2","text":"n=0","title":"N\u2211\u2212 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_59","text":"\u03c6(X\u0302n(k+1))\u2212\u03c6(X\u0302n(k)) +h","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_60","text":"X\u0302(nk),\u03c6(X\u0302(nk)),\u03c3>\u2207\u03c6(X\u0302(nk))","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_61","text":"\u2206t\u2212\u03c3>\u2207\u03c6(X\u0302n(k))\u03ben+1","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_62","text":"\u2206t","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_17","text":"","title":") 2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#48","text":"and boundary term","title":"(48)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#lkn_3","text":"BSDE\u2212 3 ,b(\u03c6) =","title":"L\u0302(K,N)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_2","text":"","title":"1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k_3","text":"","title":"K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k_4","text":"k=1","title":"\u2211K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_63","text":"\u03c6(X\u0302 (k) N )\u2212g( X\u0302(k) N )","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_18","text":"","title":") 2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#49","text":"A generalization to equations posed on bounded domains is straightforward. We also note that in contrast to the diffusion loss, (47) does not seem to naturally derive from a continuous-time formulation. Interestingly,L\u0302(BSDEK,N)\u2212 3 can be related to the diffusion loss via Jensen\u2019s inequality, L\u0302(K,N) diffusion,int(\u03c6)\u2264N","title":". (49)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#lkn_4","text":"BSDE\u2212 3 ,int(\u03c6). (50) Yet another approach that is based on a discrete backward scheme is the following. Let us initializeY\u0302 0 =\u03c6(X\u0302 0 ,0) and simulate Y\u0302n+1=Y\u0302n\u2212h(X\u0302n,Y\u0302n,\u03c3>\u2207\u03c6(X\u0302n,tn))\u2206t+\u03c3>\u2207\u03c6(X\u0302n,tn)\u00b7\u03ben+1","title":"L\u0302(K,N)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_64","text":"\u2206t, (51) forn\u2208{ 0 ,...,N\u2212 1 }, where, similarly to (46), but in in contrast to (48), onlyZ\u0302nis replaced by its approximation \u03c3>\u2207\u03c6(X\u0302n,tn)whileY\u0302nis retained from previous iteration steps. Again penalizing deviations from the discrete-time scheme, we can now introduce the loss L\u0302(BSDEK,N)\u2212 4 (\u03c6) =\u03b1^1 K","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k_5","text":"k=1","title":"\u2211K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#n","text":"n=0","title":"\u2211N"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_65","text":"\u03c6(X\u0302n(k),tn)\u2212Y\u0302n(k)","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_19","text":"","title":") 2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_66","text":"\u03b1 2 K","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#k_6","text":"k=1","title":"\u2211K"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_67","text":"\u03c6(Xb(k))\u2212g(Xb(k))","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_20","text":"","title":") 2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#52","text":"Both inLBSDE\u2212 3 andLBSDE\u2212 4 the deterministic initial conditionX\u0302 0 att= 0can be replaced by random choices (X\u0302t 0 ,t 0 )\u223c\u03bd\u2126\u00d7[0,T], adjusting the sums in (48) and (52) accordingly.","title":". (52)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#6-numerical-experiments","text":"In this section we provide several numerical examples of high-dimensional parabolic and elliptic PDEs that shall demonstrate the performances of Algorithm 1 using the different loss functions introduced before. We focus on the PINN, BSDE and diffusion losses from Sections 2 and 3 since their modified versions from Section 5.2 in general led to similar or worse performances. If not specified otherwise, the approximation of\u03c6relies on a DenseNet architecture defined in (35) with ReLU activation function and four hidden layers withd+ 20,d,d,dunits respectively (recall thatdspecifies the dimension). The optimization is carried out using the Adam optimizer [45] with standard parameters and learning rate\u03b7= 0. 001. Throughout, we takeKint= 200samples inside the domain\u2126and (for the PINN and diffusion losses)Kb= 50samples on the boundary, per gradient step. For the SDE discretization we choose a step-size of\u2206t= 0. 001. The weight configurations for the PINN and diffusion losses are optimized manually; we then only report the results for the optimal settings (see the discussion on weight-tuning in Section 5). We refer to the code at https://github.com/lorenzrichter/path-space-PDE-solver .","title":"6 Numerical experiments"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#61-nonlinear-toy-problems","text":"Let us start with a nonlinear toy problem for which analytical reference solutions are available. Throughout this subsection, the domain of interest is taken to be the unit ball\u2126 ={x\u2208Rd:|x|< 1 }. 6.1.1 Elliptic problem with Dirichlet boundary data We first consider an elliptic boundary value problem of the form (27). Let\u03b3\u2208Rand choose b(x,t) = 0 , \u03c3(x,t) =","title":"6.1 Nonlinear toy problems"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_68","text":"2 Idd\u00d7d, g(x) =e\u03b3, (53a) h(x,y,z) =\u2212 2 \u03b3y(\u03b3|x|^2 +d) + sin","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_69","text":"e^2 \u03b3|x| 2 \u2212y^2","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_70","text":". (53b) It is straightforward to verify that V(x) =e\u03b3|x| 2 (54) is the unique solution to (27). We considerd= 50and set\u03b3= 1. For the PINN and diffusion losses the optimized weights are given by\u03b1int= 10\u2212^5 , \u03b1b= 1and\u03b1int= 0. 1 ,\u03b1b= 1, respectively. We sample the data uniformly and take a maximal (discrete-time) trajectory length ofN= 20for the diffusion loss. In Figure 3 (left panel) we display the average relative errors |\u03c6(x)\u2212V(x)| V(x) as a function ofr=|x|. Due to volume distortion in high dimensions, very few samples are drawn close to the center of the ball, and hence the numerical results appear to be unreliable forr\u2264 0. 8. While this effect could be alleviated by changing the measure\u03bd\u2126accordingly, we content ourselves here with a comparison forr\u2208[0. 8 ,1]. In the right panel we display theL^2 error during the training iterations evaluated on uniformly sampled test data. We observe that the PINN and diffusion losses yield similar results and that the BSDE loss performs worse, in particular close to the boundary. We attribute this effect to the challenges inherent in the simulation of hitting times, see Section 5.1. 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000 r 0.005 0.006 0.007 0.008 0.009 0.010 0.011 Relative error on test data PINN loss BSDE loss Diffusion loss 0 50000 100000 150000 200000 gradient steps 103 102 101 100 L^2 test error Figure 3: Left: Average relative errors as a function ofr=|x|evaluated on uniformly sampled data for the three losses smoothed with a moving average over 500 data points. Right:L^2 error during the training iterations evaluated on uniformly sampled test data. In the diffusion loss as stated in Definition 3.1 we are free to choose the lengthtof the forward trajectories, which affects the generated training data. Let us therefore investigate how different choices oftinfluence the performance of Algorithm 1. To this end, we consider again the elliptic problem from Section 6.1.1 and varyt. To be precise, let us fix different step-sizes\u2206tand vary the Euler stepsN(recalling thatt=N\u2206t), once choosing the weight \u03b1int= 0. 1 , as before, and once by considering\u03b1int= 10. For the former choice we can see in Figure 4a that larger trajectories tend to be better until a plateau is reached, whereas for the latter it turns out that there seems to be an optimal choice of the trajectory length, as displayed in Figure 4b. 0 20 40 60 80 100 N 103 104 Diffusion test error depending on the trajectory length t = 0.001 t = 0.0005 (a) Weight\u03b1int= 0. 1. 0 5 10 15 20 25 30 35 40 N 103 104 Diffusion test error depending on the trajectory length t = 0.001 t = 0.0005 (b) Weight\u03b1int= 10. Figure 4: We display theL^2 error that one attains when using different choices of the maximal Euler stepsNin the diffusion loss for different discretization step-sizes\u2206t. 6.1.2 Elliptic problem requiring full Hessian matrix We consider the setting specified in (53), replacing however the diffusion coefficient and the nonlinearity by \u03c3(x,t) =","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_71","text":"","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_21","text":"d","title":"2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_72","text":"","title":"\uf8eb"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_73","text":"","title":"\uf8ec"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_74","text":"","title":"\uf8ed"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1-1","text":"","title":"1 \u00b7\u00b7\u00b7 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_75","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_76","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_77","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_78","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_79","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_80","text":"","title":""},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1-1_1","text":"","title":"1 \u00b7\u00b7\u00b7 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_81","text":"","title":"\uf8f6"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_82","text":"\uf8f8, h(x,y,z) =\u2212^2 \u03b3y","title":"\uf8f7"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_83","text":"\uf8ed\u03b3 \u2211d i,j=1 xixj+d","title":"\uf8eb"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_84","text":"\uf8f8+ sin","title":"\uf8f6"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_85","text":"e^2 \u03b3|x| 2 \u2212y^2","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_86","text":"","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#55","text":"respectively. Again, we can check thatV(x) =e\u03b3|x| 2 is the unique solution to the corresponding boundary value problem. Since\u03c3is not diagonal anymore, the differential operator (2) contains the full Hessian matrix of secondorder derivatives of the candidate solution\u03c6. As discussed in Section 5 (see Table 1b) this particularly impacts the runtime of the PINN method since all derivatives need to be computed explicitly. For the BSDE and diffusion losses, on the other hand, second-order derivatives are implicitly approximated using the underlying Brownian motion and we therefore do not expect significantly longer runtimes. Let us considerd= 20and\u03b3= 1. In Figure 5 we display theL^2 error during the training process, plotted against the number of gradient steps (left panel) and against the runtime (right panel). As expected, the PINN loss takes significantly longer. This effect should become even more pronounced with growing state space dimensiond. 0 10000 20000 30000 40000 50000 60000 gradient steps 103 102 101 100 L^2 test error PINN loss BSDE loss Diffusion loss 0 20000 40000 60000 80000100000120000140000 runtime in seconds 103 102 101 100 L^2 test error Figure 5:L^2 error during the training process evaluated on test data for the three losses, plotted against the number of gradient steps (left panel) and against the runtime (right panel). 6.1.3 Parabolic problem with Neumann boundary data Let us now consider the parabolic problem (1), with the Dirichlet boundary condition (1c) replaced by its Neumann counterpart \u2202~nV(x,t) =gN(x,t), (x,t)\u2208\u2202\u2126\u00d7[0,T]. (56) Here,\u2202~nV:=\u2207V\u00b7~nrefers to the (outward facing) normal derivative at the boundary\u2202\u2126. We take b(x,t) = 0 , \u03c3(x,t) =","title":", (55)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_87","text":"2 Idd\u00d7d, f(x) =e\u03b3|x| (^2) +T , gN(x,t) = 2\u03b3e\u03b3+t, (57a) h(x,t,y,z) =\u2212y(2\u03b3(2\u03b3|x|^2 +d) + 1) + sin","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_88","text":"e^2 \u03b3|x| (^2) +2t \u2212y^2","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_89","text":". (57b) In this case, V(x,t) =e\u03b3|x| (^2) +t (58) provides the unique solution. We choosed= 20and\u03b3= 1. In the left and central panels of Figure 6 we display the approximated solutions along the curve","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_90","text":"(\u03ba,...,\u03ba)>:\u03ba\u2208[\u2212 1 /","title":"{"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_91","text":"d, 1 /","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_92","text":"d]","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_93","text":"for two different times. We can see that both the diffusion and the PINN loss work well, with small advantages for the PINN loss. The right panel displays theL^2 test error over the iterations and confirms this observation. 0.2 0.1 0.0 0.1 0.2 1.5 2.0 2.5 3.0 t = 0.2 PINN loss Diffusion reference 0.2 0.1 0.0 0.1 0.2 3 4 5 6 t = 0.8 0 50000 100000 150000 200000 gradient steps 103 102 101 100 101 L (^2) test loss \u03ba \u03ba Figure 6: Left and central panel: Approximations along a curve for two different times using the diffusion and PINN losses. Right:L^2 test error along the training iterations.","title":"}"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#62-committor-functions","text":"Committor functions are important quantities in molecular dynamics as they specify likely transition pathways as well as transition rates between (potentially metastable) regions or conformations of interest [21, 55]. Since for most practical applications those functions are high-dimensional and hard to compute, there have been recent attempts to approach this problem using neural networks [44, 52, 71]. Based on the fact that committor functions fulfill elliptic boundary value problems, we can rely on the methods discussed in this paper. For anRd-valued stochastic process(Xt)t\u2265 0 with continuous sample paths and two disjoint open setsA,B\u2282Rd, the committor functionVcomputes the probability ofXhittingAbeforeBwhen starting inx\u2208R, that is, V(x) =P(\u03c4B< \u03c4A|X 0 =x) =E[ (^1) B(X\u03c4)|X 0 =x]. (59) Here,\u03c4A= inf{t >0 :Xt\u2208A}and\u03c4B= inf{t >0 :Xt\u2208B}refer to the hitting times corresponding to the sets AandB. In the case when(Xt)t\u2265 0 is given as the unique strong solution to the SDE (3), it can be shown via the Kolmogorov backward PDE [64, Section 2.5] thatV fulfills the elliptic boundary value problem LV= 0, V|\u2202A= 0, V|\u2202B= 1, (60) whereLas in (2) refers to the associated infinitesimal generator, see, for instance, [21]. In the notation of (27) we have\u2126 =Rd(A\u222aB),h= 0andg(x) = (^1) B(x). Following [31, Section V.A], we consider(Xt)t\u2265 0 to be a standard Brownian motion starting atx\u2208Rd, that is, Xt=x+Wt, corresponding tob= 0 and\u03c3= Idd\u00d7din (3). The setsAandBare defined as A={x\u2208Rd:|x|< a}, B={x\u2208Rd:|x|> b}, (61) withb > a > 0. Hence, in this case the committor function describes the statistics of leaving a spherical shell through one of its boundaries. The solution takes the form V(x) = a^2 \u2212|x|^2 \u2212da^2 a^2 \u2212b^2 \u2212da^2","title":"6.2 Committor functions"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#62","text":"ford\u2265 3. Let us considerd= 10as well asa= 1,b= 2. We take a DenseNet withtanhas activation function and compare the three losses against each other. In Figure 7 we display the approximated solutions along a curve{ (\u03ba,...,\u03ba)>:\u03ba\u2208[a/","title":", (62)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_94","text":"d,b/","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_95","text":"d]","title":"\u221a"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_96","text":"in the left panel, realizing that in particular the PINN and diffusion losses lead to good approximations. This can also be observed in the right panel, where we plot a moving average of theL^2 error on test data based on a moving window of length 200. The BSDE loss appears to be especially error-prone close to the left end-point of the curve displayed in Figure 7, that is, close to the inner shell. Due to the volume distortion in high dimensions, few samples are drawn according to\u03bd\u2126for small values of|x|, see Figure 8. We hence conclude that in this example, the BSDE loss suffers particularly from the relative sparsity of the samples, possibly in conjunction with numerical errors made while estimating the hitting times at the inner shell (see Section 5.1). 0.35 0.40 0.45 0.50 0.55 0.60 0.0 0.2 0.4 0.6 0.8 1.0 Evaluation along curve PINN loss BSDE Diffusion loss reference solution 0 1000020000300004000050000600007000080000 runtime in seconds 104 103 102 101 L^2 test error during training \u03ba Figure 7: Left: approximations of the 10 -dimensional committor function evaluated along a curve. Right: moving average of the testL^2 error along the training iterations. 1.0 1.2 1.4 1.6 1.8 2.0 r 0.0 0.2 0.4 0.6 0.8 1.0 PINN loss 1.0 1.2 1.4 1.6 1.8 2.0 r 0.0 0.2 0.4 0.6 0.8 1.0 BSDE 1.0 1.2 1.4 1.6 1.8 2.0 r 0.0 0.2 0.4 0.6 0.8 1.0 Diffusion loss Figure 8: We plot the approximated committor functions evaluated at 10000 points uniformly sampled from the domain\u2126(blue dots) and compare those to the reference solution (orange line) as a function ofr=|x|.","title":"}"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#63-parabolic-allen-cahn-equation-on-an-unbounded-domain","text":"The Allen-Cahn equation ind= 100has been suggested as a benchmark problem in [19]. It is an example of a parabolic PDE posed on an unbounded domain, (\u2202t+L)V(x,t) +V(x,t)\u2212V^3 (x,t) = 0, (x,t)\u2208Rd\u00d7[0,T], (63) V(x,T) =f(x), x\u2208Rd, (64) withf(x) =","title":"6.3 Parabolic Allen-Cahn equation on an unbounded domain"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_97","text":"2 +^25 |x|^2","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_3","text":"andT= 103. We restrict attention to the ball{x\u2208Rd:|x|< r}with radiusr= 7. Instead of using the uniform distribution on this set, we consider sampling uniformly on a box around the origin with side length 2 and multiplying each data pointxby|rx|. In contrast to uniform sampling, this approach generates more samples close to the origin, which we observe to slightly improve the accuracy of the obtained solutions. We compare our approximations to a reference solution atx 0 = (0,...,0)>for different timest\u2208[0,T]that is provided by a branching diffusion method specified in [19]. In Figure 9 we see that all three attempts match this reference solution, with very minor advantages (for instance at the right end point) for the PINN and diffusion losses. In Table 2 we display the computation times until convergence, realizing that the BSDE loss needs significantly longer. We note that the computation times are longer in comparison to e.g. [19] since we aim for a solution on a given domain, whereas other attempts only strive for approximating the solution at a single point. 0.00 0.05 0.10 0.15 0.20 0.25 0.30 t 0.1 0.2 0.3 0.4 0.5 PINN loss BDSE loss Diffusion loss reference solution Allen-Cahn equation, d = 100 Figure 9: Approximation of the solution to an AllenCahn equation ind= 100using different losses compared to a reference solution atx 0 = (0,...,0)>for different timest\u2208[0,T]. Computation time PINN loss 325. 46 min BSDE loss 4280. 68 min Diffusion loss 194. 38 min Table 2: Computation times until convergence.","title":")\u2212 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#64-elliptic-eigenvalue-problems","text":"In this section we provide two examples for the approximation of principal eigenvalues and corresponding eigenfunctions. The first one is a linear problem and therefore Proposition 4.2 assures that the minimization of an appropriate loss as in (31) leads to the desired solution. The second example is a nonlinear eigenvalue problem, for which we can numerically show that our algorithm still provides the correct solution. 6.4.1 Fokker-Planck equation As suggested in [30], we aim at computing the principal eigenpair associated to a Fokker-Planck operator, defined by LV=\u2212\u2206V\u2212\u2207\u00b7(V\u2207\u03a8), (65) forV : \u2126\u2192Ron the domain\u2126 = [0, 2 \u03c0]d, and where\u03a8(x) = sin","title":"6.4 Elliptic eigenvalue problems"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_98","text":"d i=1cicos(xi)","title":"(\u2211"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_99","text":"is a potential with constants ci\u2208[0. 1 ,1], assuming periodic boundary conditions. This results in the eigenvalue problem \u2206V(x) +\u2207\u03a8(x)\u00b7\u2207V(x) + \u2206\u03a8(x)V(x) =\u2212\u03bbV(x), (66) and V(x) =e\u2212\u03a8(x) (67) is an eigenfunction associated to the principal eigenvalue\u03bb= 0, see [64, Section 4.7]. We chooseci= 0. 1 ,i= 1,...,d, and approach this problem in dimensiond= 5following Section 4.2, i.e. by minimizing the loss (31), where for Lwe choose the diffusion loss and the periodic boundary condition is encoded via the term (9). Here and in the following eigenvalue problem the positivity of the approximating function is enforced by adding a ReLU function after the last layer of the DenseNet. In the left panel of Figure 10 we display the approximated eigenfunction along the curve","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_100","text":"(\u03ba,...,\u03ba)>:\u03ba\u2208[0, 2 \u03c0]","title":"{"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_101","text":"and compare it to the reference solution. In the central panel we show theL^2 error w.r.t. the reference solution evaluated on uniformly sampled test data along the training iterations. The right panel displays the moving average of the absolute value of the eigenvalue taken over a moving window of 100 gradient steps (since the true value is \u03bb= 0it is not possible to compute a relative error here). We see that both the eigenfunction and the eigenvalue are approximated sufficiently well. 0 1 2 3 4 5 6 0.6 0.8 1.0 1.2 1.4 1.6 Eigenfunction approximation reference approximation 0 10000200003000040000 5000060000 gradient steps 104 103 102 L^2 error of eigenfunction 0 100002000030000 400005000060000 gradient steps 103 102 Eigenvalue approximation \u03ba Figure 10: Left: Approximation and reference of the eigenfunction corresponding to the principal eigenvalue of the Fokker-Planck operator (65). Middle:L^2 error w.r.t. test data along the training iterations. Right: Moving average of the absolute value of the approximated eigenvalue along the gradient steps. 6.4.2 Nonlinear Schr\u00f6dinger equation Let us now consider a nonlinear eigenvalue problem. Again following [30], we consider the nonlinear Schr\u00f6dinger operator including a cubic term that arises from the Gross-Pitaevskii equation for the single-particle wave function in a Bose-Einstein condensate [27, 66]. To be precise, we consider \u2206V(x)\u2212V^3 (x)\u2212\u03a8(x)V(x) =\u2212\u03bbV(x), (68) where \u03a8(x) =\u2212","title":"}"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_4","text":"c^2 exp","title":"1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_102","text":"","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_22","text":"d \u2211d i=1 cosxi","title":"2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_103","text":"","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_104","text":"\u2211d i=1","title":"+"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_105","text":"sin^2 (xi) d^2","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_106","text":"cosxi d","title":"\u2212"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_107","text":"","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#3-69","text":"One can show that V(x) =","title":"\u2212 3. (69)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_5","text":"c exp","title":"1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_108","text":"","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_6","text":"d \u2211d i=1 cosxi","title":"1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_109","text":"","title":")"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#70","text":"Ln(\u03c6) =","title":"(70)"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_110","text":"","title":"("},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#e_1","text":"","title":"E"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_111","text":"\u03c6(X)^2","title":"["},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_112","text":"","title":"]"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#1_7","text":"","title":"\u2212 1"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#2_23","text":",","title":") 2"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_113","text":"(\u03ba,...,\u03ba)>:\u03ba\u2208[0, 2 \u03c0]","title":"{"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#_114","text":"0 1 2 3 4 5 6 0.5 1.0 1.5 2.0 2.5 Eigenfunction approximation reference approximation 0 50000 100000 150000 200000 gradient steps 107 106 105 104 103 102 L^2 error of eigenfunction 0 50000 100000 150000 200000 gradient steps 106 105 104 103 102 101 Relative error eigenvalue \u03ba Figure 11: Left: Approximation and reference of the eigenfunction corresponding to the principal eigenvalue of the nonlinear Schr\u00f6dinger operator ind= 5. Middle:L^2 error w.r.t. test data along the training iterations. Right: Relative error of the approximated eigenvalue along the gradient steps. 0 1 2 3 4 5 6 0.5 1.0 1.5 2.0 2.5 Eigenfunction approximation reference approximation 0 50000100000150000200000250000300000 gradient steps 106 105 104 103 L^2 error of eigenfunction 0 50000100000150000200000250000300000 gradient steps 104 103 102 101 Relative error eigenvalue \u03ba Figure 12: Same experiment as in Figure 11 in dimensiond= 10.","title":"}"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#7-conclusion-and-outlook","text":"","title":"7 Conclusion and Outlook"},{"location":"Models/PINNs/2112.03749-Interpolating%20between%20BSDEs%20and%20PINNs_DL%20for%20Elliptic%20and%20Parabolic%20Boundary%20Value%20Problems/#references","text":"","title":"References"},{"location":"Models/PINNs/PINNs/","text":"PINNs \u7cfb\u5217 2018.06 PINNs: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear PDEs ( JCP ) 2021.12 Interpolating between BSDEs and PINNs\uff1aDL for Elliptic and Parabolic Boundary Value Problems 2022.07 Adaptive Self-Supervision Algorithms for PINNs A Comprehensive Study of Non-Adaptive and Residual-Based Adaptive Sampling for PINNs 2022.10 Failure-Informed Adaptive Sampling for PINNs A Novel Adaptive Causal Sampling Method for PINNs","title":"PINNs \u7cfb\u5217"},{"location":"Models/PINNs/PINNs/#pinns","text":"","title":"PINNs \u7cfb\u5217"},{"location":"Models/PINNs/PINNs/#201806","text":"PINNs: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear PDEs ( JCP )","title":"2018.06"},{"location":"Models/PINNs/PINNs/#202112","text":"Interpolating between BSDEs and PINNs\uff1aDL for Elliptic and Parabolic Boundary Value Problems","title":"2021.12"},{"location":"Models/PINNs/PINNs/#202207","text":"Adaptive Self-Supervision Algorithms for PINNs A Comprehensive Study of Non-Adaptive and Residual-Based Adaptive Sampling for PINNs","title":"2022.07"},{"location":"Models/PINNs/PINNs/#202210","text":"Failure-Informed Adaptive Sampling for PINNs A Novel Adaptive Causal Sampling Method for PINNs","title":"2022.10"},{"location":"Models/PINNs/PN-2112.03749/","text":"Interpolating between BSDEs and PINNs: Deep Learning for Elliptic and Parabolic Boundary Value Problems \u692d\u5706\u578b/\u629b\u7269\u578b\u8fb9\u503c\u95ee\u9898\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff1a \u5728 BSDEs \u548c PINNs \u4e4b\u95f4\u63d2\u503c \u4f5c\u8005: Nikolas N\u00fcsken | Lorenz Richter \u673a\u6784: \u65f6\u95f4: 2021-12-07 \u9884\u5370: arXiv:2112.03749v1 \u9886\u57df: #\u6570\u5b66 \u6807\u7b7e: #PINN \u5f15\u7528: 80 \u7bc7 \u9875\u6570: 25 \u9875 Abstract \u6458\u8981 Solving high-dimensional partial differential equations is a recurrent challenge in economics, science and engineering. In recent years, a great number of computational approaches have been developed, most of them relying on a combination of Monte Carlo sampling and deep learning based approximation. For elliptic and parabolic problems, existing methods can broadly be classified into those resting on reformulations in terms ofbackward stochastic differential equations(BSDEs) and those aiming to minimize a regression-typeL^2 -error (physics-informed neural networks, PINNs). In this paper, we review the literature and suggest a methodology based on the noveldiffusion lossthat interpolates between BSDEs and PINNs. Our contribution opens the door towards a unified understanding of numerical approaches for high-dimensional PDEs, as well as for implementations that combine the strengths of BSDEs and PINNs. We also provide generalizations to eigenvalue problems and perform extensive numerical studies, including calculations of the ground state for nonlinear Schr\u00f6dinger operators and committor functions relevant in molecular dynamics. \u6c42\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u662f\u7ecf\u6d4e\u5b66\u3001\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u4e2d\u4e00\u4e2a\u7ecf\u5e38\u9047\u5230\u7684\u6311\u6218\u3002\u8fd1\u5e74\u6765\uff0c\u4eba\u4eec\u53d1\u5c55\u4e86\u5927\u91cf\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u662f\u57fa\u4e8e\u8499\u7279\u5361\u7f57\u91c7\u6837\u548c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8fd1\u4f3c\u65b9\u6cd5\u7684\u7ed3\u5408\u3002\u5bf9\u4e8e\u692d\u5706\u578b\u548c\u629b\u7269\u578b\u95ee\u9898\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u5927\u81f4\u53ef\u4ee5\u5206\u4e3a\u57fa\u4e8e\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u91cd\u6784\u7684\u65b9\u6cd5\uff08BSDEs\uff09\u548c\u65e8\u5728\u6700\u5c0f\u5316\u56de\u5f52\u578b \\(L^2\\) \u8bef\u5dee\u7684\u65b9\u6cd5\uff08\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc PINNs\uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u56de\u987e\u4e86\u76f8\u5173\u6587\u732e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b0\u7684\u6269\u6563\u635f\u5931\u7684\u65b9\u6cd5\uff0c\u5373\u5728 BSDEs \u548c PINNs \u4e4b\u95f4\u63d2\u503c\u3002\u6211\u4eec\u7684\u8d21\u732e\u4e3a\u7edf\u4e00\u7406\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u65b9\u6cd5\u4ee5\u53ca\u7ed3\u5408 BSDEs \u548c PINNs \u4f18\u52bf\u7684\u5b9e\u73b0\u6253\u5f00\u4e86\u5927\u95e8\u3002\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u7279\u5f81\u503c\u95ee\u9898\u7684\u63a8\u5e7f\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6570\u503c\u7814\u7a76\uff0c\u5305\u62ec\u8ba1\u7b97\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u7b97\u5b50\u7684\u57fa\u6001\u548c\u5206\u5b50\u52a8\u529b\u5b66\u76f8\u5173\u7684 committor \u51fd\u6570\u3002 1. \u4ecb\u7ecd In this article, we consider approaches towards solving high-dimensional partial differential equations (PDEs) that are based on minimizing appropriate loss functions in the spirit of machine learning. For example, we aim at identifying approximate solutions to nonlinear parabolic boundary value problems of the form \u672c\u6587\u8003\u8651\u7528\u4e8e\u6c42\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b (PDEs) \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u601d\u60f3\u5373\u6700\u5c0f\u5316\u8fd1\u4f3c\u635f\u5931\u51fd\u6570\u7684\u65b9\u6cd5\u3002\u4f8b\u5982\u627e\u5230\u5982\u4e0b\u5f62\u5f0f\u975e\u7ebf\u6027\u629b\u7269\u578b\u8fb9\u503c\u95ee\u9898\u7684\u89e3\uff1a \\[ \\begin{aligned} &(\\partial_t+L)V(x,t)+h(x,t,V(x,t),\\sigma^\\mathsf{T}\\nabla V(x,t))=0, &(x,t)\\in\\Omega\\times [0,T),\\\\ &V(x,T)=f(x), &x\\in\\Omega,\\\\ &V(x,t)=g(x,t), &(x,t)\\in\\partial\\Omega\\times[0,T], \\end{aligned} \\] on a spatial domain\\Omega\u2282Rdand time interval[0,T], whereh\u2208C(Rd\u00d7[0,T]\u00d7R\u00d7Rd,R)specifies the nonlinearity, andf\u2208C(Rd,R)as well asg\u2208C(Rd\u00d7[0,T],R)are given functions defining the terminal and boundary conditions. Moreover, \u5176\u4e2d\u7a7a\u95f4\u5b9a\u4e49\u57df \\(\\Omega\\subset\\mathbb{R}^d\\) \uff0c\u65f6\u95f4\u533a\u95f4 \\([0,T]\\) \uff0c\u51fd\u6570 \\(h\\in C(\\mathbb{R}^d\\times [0,T]\\times\\mathbb{R}\\times\\mathbb{R}^d,\\mathbb{R})\\) \u4e3a\u975e\u7ebf\u6027\u90e8\u5206\uff0c \\(f\\in C(\\mathbb{R}^d,\\mathbb{R})\\) \u548c \\(g\\in C(\\mathbb{R}^d\\times[0,T],\\mathbb{R})\\) \u662f\u7ed9\u5b9a\u7684\u51fd\u6570\uff0c\u5206\u522b\u5b9a\u4e49\u4e86\u7ec8\u503c\u6761\u4ef6\u548c\u8fb9\u503c\u6761\u4ef6\u3002\u6b64\u5916 \\[ L=\\frac{1}{2}\\sum_{i,j=1}^d(\\sigma\\sigma^\\mathsf{T})_{ij}(x,t)\\partial_{x_i}\\partial_{x_j}+\\sum_{i=1}^d b_i(x,t)\\partial_{t_i}, \\] \u662f\u692d\u5706\u5fae\u5206\u7b97\u5b50\uff0c\u5305\u542b\u4e86\u7cfb\u6570\u51fd\u6570 \\(b\\in C(\\mathbb{R}^d\\times[0,T],\\mathbb{R})\\) \u548c \\(\\sigma\\in C(\\mathbb{R}^d\\times[0,T],\\mathbb{R}^{d\\times d})\\) \uff0c\u5047\u8bbe \\(\\sigma\\) \u662f\u975e\u9000\u5316\u7684\u3002 \u4e4b\u540e\u4f1a\u4f7f\u7528 \\(L\\) \u662f\u7531\u5982\u4e0b\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u5b9a\u4e49\u7684\u6269\u6563\u8fc7\u7a0b\u7684 infinitesimal generator \u7684\u4e8b\u5b9e\uff1a $$ \\text{d}X_s = b(X_s,s)\\text{d}s+\\sigma(X_s,s)\\text{d}W_s, $$ \u5176\u4e2d \\(W_s\\) \u662f\u6807\u51c6 \\(d\\) \u7ef4\u5e03\u6717\u8fd0\u52a8\u3002 \u672c\u6587\u7b97\u6cd5\u5229\u7528\u4e86\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u8054\u7cfb\u51e0\u4e4e\u6beb\u4e0d\u8d39\u529b\u5730\u63a8\u5e7f\u5230\u5f88\u5927\u8303\u56f4\u7684\u975e\u7ebf\u6027\u692d\u5706\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u7279\u5f81\u503c\u95ee\u9898\u3002\u6b64\u5916\u9700\u8981\u6ce8\u610f\u7684\u662f\u4e0d\u5931\u4e00\u822c\u6027\uff0c\u53ef\u4ee5\u4f7f\u7528\u65f6\u95f4\u9006\u8f6c\u53d8\u6362\u5c06\u7ec8\u503c\u6761\u4ef6\u66ff\u6362\u4e3a\u521d\u503c\u6761\u4ef6\u3002\u7c7b\u4f3c\u5730\uff0c\u53ef\u4ee5\u5c06 Dirichlet \u8fb9\u754c\u6761\u4ef6\u66ff\u6362\u4e3a\u76f8\u5e94\u7684 Neumann \u8fb9\u754c\u6761\u4ef6\uff0c\u5373\u5728 \\(\\partial\\Omega\\times[0,T]\\) \u4e0a\u7ea6\u675f\u6cd5\u5411\u5bfc\u6570 \\(\\partial_{\\vec{n}}V\\) \u3002 \u5728\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u5904\u7406\u4e2d\u51fa\u73b0\u7684\u4e00\u4e2a\u81ed\u540d\u662d\u8457\u7684\u6311\u6218\u662f\u7ef4\u6570\u707e\u96be\uff0c\u5b83\u8868\u660e\u8ba1\u7b97\u7684\u590d\u6742\u6027\u5728\u72b6\u6001\u7a7a\u95f4\u7684\u7ef4\u5ea6\u4e2d\u5448\u6307\u6570\u589e\u957f\u3002\u7136\u800c\uff0c\u8fd1\u5e74\u6765\uff0c\u591a\u79cd\u6570\u503c[19,35,69]\u4ee5\u53ca\u7406\u8bba\u7814\u7a76[26,40]\u8868\u660e\uff0c\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u5408\u4e3a\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u6cd5\u3002\u672c\u6587\u56f4\u7ed5\u4e24\u4e2a\u7b56\u7565\u6765\u89e3\u51b3\u76f8\u5f53\u4e00\u822c\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b: \u2022 PINNs physics-informed neural networks \uff0c\u4e5f\u79f0\u4e3a DGM deep Galerkin method \uff0c\u76f4\u63a5\u6700\u5c0f\u5316(1)\u7684\u5de6\u53f3\u4e24\u8fb9\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\uff0c\u5728\u65f6\u7a7a\u57df \\Omega \u00d7 [0\uff0ct ]\u53ca\u5176\u8fb9\u754c\u4e0a\u9009\u62e9\u5408\u9002\u7684(\u968f\u673a)\u70b9\u8fdb\u884c\u6c42\u89e3\u3002\u2022\u6df1\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b[19]\u4f9d\u8d56\u4e8e\u968f\u673a\u6b63\u5012\u5411\u52a8\u529b\u5b66(1)\u7684\u91cd\u65b0\u8868\u8ff0\uff0c\u660e\u786e\u5229\u7528\u504f\u5fae\u5206\u65b9\u7a0b(1)\u548c\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b(3)\u4e4b\u95f4\u7684\u8054\u7cfb\u3002\u6df1\u5c42 bsde \u6700\u5c0f\u5316\u4e0e\u540e\u5411 SDE \u76f8\u5173\u7684\u7ec8\u7aef\u6761\u4ef6\u4e2d\u7684\u4e0d\u5339\u914d\u3002 \u6211\u4eec\u56de\u987e\u4e86\u8fd9\u4e9b\u65b9\u6cd5(\u89c1\u7b2c2\u8282) \uff0c\u5e76\u5728\u4f0a\u85e4\u516c\u5f0f\u7684\u6fc0\u52b1\u4e0b\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u4f18\u5316\u76ee\u6807\uff0c\u79f0\u4e3a\u6269\u6563\u635f\u5931\u7684\u6269\u6563(\u89c1\u7b2c3\u8282)\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u7684\u6784\u9020\u4f9d\u8d56\u4e8e\u8f85\u52a9\u65f6\u95f4\u53c2\u6570 t \u2208(0\uff0c\u221e) \uff0c\u5141\u8bb8\u6211\u4eec\u6062\u590d\u6781\u9650 t \u21920\u7684 PINNs \u548c\u6781\u9650 t \u2192\u221e : PINNst \u21920\u2190--Ltdiffusiont \u2192\u221e\u2192\u6df1 BSDEs\u3002\u6269\u6563\u635f\u5931\u63d0\u4f9b\u4e86\u4e00\u4e2a\u63d2\u503c\u4e4b\u95f4\u4f3c\u4e4e\u76f8\u5f53\u4e0d\u540c\u7684\u65b9\u6cd5\u3002\u9664\u4e86\u8fd9\u4e2a\u7406\u8bba\u4e0a\u7684\u89c1\u89e3\uff0c\u6211\u4eec\u5b9e\u9a8c\u8868\u660e\uff0c\u9002\u5f53\u7684 t \u9009\u62e9\u53ef\u4ee5\u5bfc\u81f4\u8ba1\u7b97\u4e0a\u6709\u5229\u7684 PINNs \u548c\u6df1 BSDEs \u7684\u6df7\u5408\uff0c\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u70b9\u3002\u7279\u522b\u662f\uff0c\u5728\u533a\u57df \\Omega \u6709\u4e00\u4e2a(\u53ef\u80fd\u662f\u590d\u6742\u7684)\u8fb9\u754c\u548c/\u6216\u6b63\u5728\u8003\u8651\u7684 PDE \u5305\u542b\u5927\u91cf\u4e8c\u9636\u5bfc\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u635f\u5931(\u9009\u62e9 t \u4e3a\u4e2d\u7b49\u5927\u5c0f)\u4f3c\u4e4e\u8868\u73b0\u826f\u597d(\u4f8b\u5982\uff0c\u5f53 \u03c3 \u4e0d\u7a00\u758f\u65f6)\u3002\u6211\u4eec\u5c06\u8ba8\u8bba\u7b2c5\u8282\u4e2d\u6d89\u53ca\u7684\u6743\u8861\u95ee\u9898\u3002\u7ef4\u6570\u707e\u96be\uff0cBSDEs vs. PINNs\u3002\u4f20\u7edf\u7684\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u65b9\u6cd5(\u4f8b\u5982\u5dee\u5206\u6cd5\u548c\u6709\u9650\u4f53\u79ef\u6cd5\uff0c\u53c2\u89c1\u6587\u732e[1])\u901a\u5e38\u9700\u8981\u5c06\u533a\u57df \\Omega \u79bb\u6563\u5316\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u589e\u52a0\uff0c\u4e3a\u4e86\u8fbe\u5230\u89c4\u5b9a\u7684\u7cbe\u5ea6\uff0c\u9700\u8981\u5728\u7f51\u683c\u70b9\u6570\u4e0a\u7ebf\u6027\u589e\u957f\uff0c\u56e0\u6b64\u5728\u7ef4\u6570\u4e0a\u5448\u6307\u6570\u589e\u957f\u3002\u6700\u8fd1\u53d1\u5c55\u8d77\u6765\u7684\u65b9\u6cd5\u53ef\u4ee5\u6253\u8d25\u8fd9\u4e2a\u7ef4\u6570\u707e\u96be-BSDEs \u548c PINNs alike1-\u7528\u8499\u7279\u5361\u7f57\u62bd\u6837\u53d6\u4ee3\u786e\u5b9a\u6027\u7f51\u683c\uff0c\u539f\u5219\u4e0a\u6709\u671b\u5b9e\u73b0\u7ef4\u6570\u65e0\u5173\u7684\u6536\u655b\u901f\u5ea6[20]\u3002\u901a\u5e38\uff0c\u8fd1\u4f3c\u51fd\u6570\u7c7b\u7531\u795e\u7ecf\u7f51\u7edc\u7ec4\u6210(\u671f\u671b\u63d0\u4f9b\u5bf9\u4f4e\u7ef4\u6f5c\u5728\u7ed3\u6784\u7684\u81ea\u9002\u5e94\u80fd\u529b[2]) \uff0c\u867d\u7136\u5f20\u91cf\u5217\u8f66\u4e5f\u8868\u73b0\u826f\u597d[70]\u3002\u4e0e pinn \u76f8\u53cd\uff0c\u57fa\u4e8e BSDEs \u7684\u65b9\u6cd5\u5229\u7528\u57fa\u672c\u7684\u6269\u6563(3)\u6765\u751f\u6210\u8bad\u7ec3\u6570\u636e\u3002\u6839\u636e\u6211\u4eec\u7684\u521d\u6b65\u6570\u503c\u5b9e\u9a8c\uff0c\u76ee\u524d\u8fd8\u4e0d\u6e05\u695a\u8fd9\u79cd\u7ed3\u6784\u7684\u4f7f\u7528\u662f\u5426\u771f\u6b63\u8f6c\u5316\u4e3a\u8ba1\u7b97\u7684\u597d\u5904; \u6211\u4eec\u8ba4\u4e3a\u9700\u8981\u5bf9\u8fd9\u79cd\u6bd4\u8f83\u8fdb\u884c\u66f4\u591a\u7684\u7814\u7a76\uff0c\u5e76\u4e14\u53ef\u80fd\u5728\u6982\u5ff5\u4e0a\u548c\u5b9e\u8df5\u4e0a\u5bf9\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u8fdb\u5c55\u4f5c\u51fa\u8d21\u732e\u3002\u672c\u6587\u6240\u8003\u8651\u7684\u6269\u6563\u635f\u5931\u53ef\u80fd\u662f\u671d\u8fd9\u4e2a\u65b9\u5411\u8fc8\u51fa\u7684\u7b2c\u4e00\u6b65\uff0c\u5bf9\u4e8e BSDEs \u548c pinn \u4e4b\u95f4\u7684\u76f4\u63a5\u6bd4\u8f83\uff0c\u6211\u4eec\u53c2\u89c1\u4e0b\u9762\u7684\u88681a \u548c\u88681b\u3002 \u8fc7\u5f80\u4f5c\u54c1\u3002\u5c06\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\u76f8\u7ed3\u5408\u6765\u8fd1\u4f3c PDE \u89e3\u7684\u5c1d\u8bd5\u53ef\u4ee5\u8ffd\u6eaf\u523020\u4e16\u7eaa90\u5e74\u4ee3\uff0c\u5176\u4e2d\u6709\u4eba\u63d0\u51fa\u4e86\u4e00\u4e9b\u6b8b\u5dee\u6700\u5c0f\u5316\u7684\u53d8\u4f53[41,49,50,51,73]\u3002\u6700\u8fd1\uff0c\u8fd9\u4e2a\u60f3\u6cd5\u5728\u7269\u7406\u5b66\u77e5\u8bc6\u7684\u795e\u7ecf\u7f51\u7edc(PINNs\uff0c[68,69])\u548c\u6df1\u5c42\u4f3d\u8fbd\u91d1\u65b9\u6cd5(DGMs\uff0c[72])\u4e0b\u83b7\u5f97\u4e86\u666e\u53ca\u3002\u8ba9\u6211\u4eec\u8fdb\u4e00\u6b65\u53c2\u8003\u6587\u732e[9]\u4e2d\u63d0\u51fa\u7684\u7c7b\u4f3c\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u89e3\u51b3\u52a8\u6001\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u53c2\u8003\u6587\u732e[16]\u3002\u5bf9\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u6211\u4eec\u5c06\u4e3e\u4f8b\u63d0\u5230[57] \uff0c\u5b83\u63d0\u4f9b\u4e86\u6cdb\u5316\u8bef\u5dee\u7684\u4e0a\u754c\uff0c[17] \uff0c\u5b83\u9648\u8ff0\u4e86 pinn \u5728 kolmogorov \u578b\u504f\u5fae\u5206\u65b9\u7a0b\u8fd1\u4f3c\u4e0b\u7684\u8bef\u5dee\u5206\u6790\uff0c[59] \uff0c\u5b83\u6839\u636e\u662f\u5426\u4f7f\u7528\u7cbe\u786e\u7684\u6216\u7f3a\u9677\u7684\u8fb9\u754c\u6761\u4ef6\u6765\u7814\u7a76\u6536\u655b\u6027\uff0c[76,77] \uff0c\u5b83\u901a\u8fc7\u795e\u7ecf\u5207\u7ebf\u7684\u900f\u955c\u6765\u7814\u7a76\u6536\u655b\u6027\u3002\u5728[18,56]\u4e2d\u8fdb\u884c\u4e86\u8fdb\u4e00\u6b65\u7684\u6570\u503c\u5b9e\u9a8c\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u79cd\u7b97\u6cd5\u6539\u8fdb\uff0c\u4f8b\u5982\u5728[75]\u4e2d\uff0c\u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u5e73\u8861\u4e86\u68af\u5ea6\uff0c[39]\u8003\u8651\u4e86\u81ea\u9002\u5e94\u6fc0\u6d3b\u51fd\u6570\u4ee5\u52a0\u901f\u6536\u655b\uff0c[74]\u5219\u7814\u7a76\u4e86\u6709\u6548\u7684\u6743\u91cd\u8c03\u6574\u3002 \u751f\u7269\u540c\u4f4d\u7d20\u884d\u751f\u7269\u6700\u65e9\u662f\u572820\u4e16\u7eaa70\u5e74\u4ee3\u5f15\u5165\u7684\uff0c\u6700\u7ec8\u572820\u4e16\u7eaa90\u5e74\u4ee3\u5f97\u5230\u4e86\u66f4\u7cfb\u7edf\u7684\u7814\u7a76\u3002\u5bf9\u4e8e\u4e00\u4e2a\u5168\u9762\u7684\u4ecb\u7ecd\uff0c\u8be6\u7ec6\u9610\u8ff0\u4e86\u5b83\u4eec\u4e0e\u692d\u5706\u578b\u548c\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8054\u7cfb\uff0c\u6211\u4eec\u53c2\u8003\u4e86\u4f8b\u5982[61]\u3002\u6570\u503c\u8bd5\u56fe\u5229\u7528\u8fd9\u79cd\u8054\u7cfb\uff0c\u4ee5\u903c\u8fd1\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u89e3\u51b3\u65b9\u6848\u5df2\u9996\u5148\u5904\u7406\u540e\u5411\u65f6\u95f4\u8fed\u4ee3\uff0c\u6700\u521d\u4f9d\u8d56\u4e8e\u4e00\u7ec4\u57fa\u672c\u51fd\u6570\u548c\u89e3\u51b3\u629b\u7269\u65b9\u7a0b\u5728\u65e0\u754c\u533a\u57df[14,23,61]\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5728[3,35]\u4e2d\u5df2\u7ecf\u88ab\u8003\u8651\uff0c\u5e76\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f97\u5230\u8fdb\u4e00\u6b65\u53d1\u5c55\uff0c\u5728[70]\u4e2d\u88ab\u8d4b\u4e88\u4e86\u5f20\u91cf\u5e8f\u5217\u3002\u5728\u6587\u732e[19,28]\u4e2d\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u4e2a\u53d8\u5206\u516c\u5f0f\uff0c\u79f0\u4e3a\u6df1\u5ea6\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u5176\u76ee\u7684\u662f\u5728\u4e00\u4e2a\u70b9\u4e0a\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u3002 [60,67].\u5bf9\u4e8e\u6df1\u5c42 BSDE \u65b9\u6cd5\u7684\u903c\u8fd1\u8bef\u5dee\u5206\u6790\uff0c\u6211\u4eec\u53c2\u8003\u4e86[29]\u548c\u57fa\u4e8e\u4e8c\u9636 BSDE \u7684\u5b8c\u5168\u975e\u7ebf\u6027\u65b9\u6cd5\u3002\u5728\u6587[47]\u4e2d\u63d0\u51fa\u4e86\u6709\u754c\u533a\u57df\u4e0a\u692d\u5706\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u4e00\u4e2a\u63a8\u5e7f\u3002\u8fd8\u6709\u4e00\u4e9b\u4e13\u95e8\u9488\u5bf9\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u5de5\u4f5c\uff0c\u4e3b\u8981\u662f\u5229\u7528 Feynman-Kac \u5b9a\u7406\u548c\u4e3b\u8981\u8003\u8651\u629b\u7269\u578b\u65b9\u7a0b[4,10]\u3002\u5bf9\u4e8e Poisson \u65b9\u7a0b\u7684\u7279\u6b8a\u60c5\u51b5\uff0c[24]\u8003\u8651\u4e86\u6709\u754c\u533a\u57df\u4e0a\u7684\u692d\u5706\u578b\u65b9\u7a0b\u3002\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u901a\u5e38\u5305\u542b\u4e00\u4e2a\u53d8\u5206\u516c\u5f0f\uff0c\u8fd9\u4e2a\u53d8\u5206\u516c\u5f0f\u5efa\u8bae\u6700\u5c0f\u5316\u67d0\u4e2a\u80fd\u91cf\u6cdb\u51fd\u2014\u2014\u8fd9\u79cd\u8054\u7cfb\u5728[22,44,54]\u4e2d\u5df2\u7ecf\u4f7f\u7528\u8fc7\uff0c\u6211\u4eec\u53c2\u8003[58]\u4f5c\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u3002\u5f53\u8003\u8651\u7279\u5f81\u503c\u95ee\u9898\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c\u7684\u6781\u5c0f\u5316\u7b56\u7565\uff0c\u6211\u4eec\u5728\u4e9a\u7a33\u6269\u6563\u8fc7\u7a0b\u4e2d\u63d0\u5230\u4e86[80]\u3002\u6211\u4eec\u4e5f\u53c2\u8003\u4e86[33,42,48,65]\u5173\u4e8e21\u91cf\u5b50\u529b\u5b66\u7684\u7c7b\u4f3c\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002\u6587[30,65]\u4e2d\u5229\u7528\u4e00\u4e2a\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u4e00\u4e2a\u4e0d\u52a8\u70b9\u95ee\u9898\u7684\u8054\u7cfb\u6765\u5904\u7406\u975e\u7ebf\u6027\u692d\u5706\u7279\u5f81\u503c\u95ee\u9898\u3002 \u5173\u4e8e\u795e\u7ecf\u7f51\u7edc\u514b\u670d\u7ef4\u6570\u707e\u96be\u7684\u80fd\u529b\u7684\u4e25\u683c\u7ed3\u679c\uff0c\u6211\u4eec\u53c2\u8003\u4e86\u6587\u732e[25,37,40] \uff0c\u6bcf\u4e00\u4e2a\u90fd\u5206\u6790\u4e86\u7279\u5b9a\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u60c5\u51b5\u3002\u9664\u4e86\u4e0a\u9762\u63d0\u5230\u7684\u65b9\u6cd5\u4e4b\u5916\uff0c\u6211\u4eec\u8fd8\u8981\u63d0\u5230[78]\u4f5c\u4e3a\u5229\u7528\u5f31\u504f\u5fae\u5206\u65b9\u7a0b\u5f0f\u7684\u4e00\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff0c\u4ee5\u53ca[53] \uff0c\u5176\u4e2d\u7684\u5178\u578b\u5e94\u7528\u662f\u5c06\u521d\u59cb\u6761\u4ef6\u6620\u5c04\u5230\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u89e3\uff0c\u7528\u795e\u7ecf\u7f51\u7edc(\u4f46\u662f\u4f9d\u8d56\u4e8e\u53c2\u8003\u89e3\u4e2d\u7684\u8bad\u7ec3\u6570\u636e)\u903c\u8fd1\u7b97\u5b50\u3002\u5173\u4e8e\u7528\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7684\u8fdb\u4e00\u6b65\u53c2\u8003\u6587\u732e\uff0c\u6211\u4eec\u53c2\u8003\u4e86\u6700\u8fd1\u7684\u8bc4\u8bba\u6587\u7ae0[6,12,20,43]\u3002\u5728\u7b2c\u4e8c\u90e8\u5206\uff0c\u6211\u4eec\u56de\u987e\u4e86\u57fa\u4e8e PINN \u548c BSDE \u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u9ad8\u7ef4(\u629b\u7269\u7ebf)\u504f\u5fae\u5206\u65b9\u7a0b\u3002\u7b2c\u4e09\u90e8\u5206\u4ecb\u7ecd\u4e86\u6269\u6563\u635f\u8017\uff0c\u8bc1\u660e\u4e86\u5b83\u5728\u6c42\u89e3\u5f62\u5f0f(1)\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5b83\u4ecb\u4e8e PINN \u548c BSDE \u635f\u8017\u4e4b\u95f4\u3002\u7b2c4\u8282\u6269\u5c55\u4e86\u63d0\u51fa\u7684\u65b9\u6cd5\u5b66\u7684\u692d\u5706\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u7279\u5f81\u503c\u95ee\u9898\u3002\u5728\u7b2c5\u8282\u4e2d\uff0c\u6211\u4eec\u8ba8\u8bba\u5b9e\u65bd\u7ec6\u8282\u4ee5\u53ca\u4e00\u4e9b\u6b63\u5728\u8003\u8651\u7684\u635f\u5931\u7684\u8fdb\u4e00\u6b65\u4fee\u6539\u3002\u5728\u7b2c6\u90e8\u5206\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6570\u503c\u5b9e\u9a8c\uff0c\u5305\u62ec\u4e00\u4e2a\u6765\u81ea\u5206\u5b50\u52a8\u529b\u5b66\u7684\u51fd\u6570\u4f8b\u5b50\u548c\u4e00\u4e2a\u7531\u91cf\u5b50\u7269\u7406\u5b66\u6fc0\u53d1\u7684\u975e\u7ebf\u6027\u672c\u5f81\u503c\u95ee\u9898\u3002\u6700\u540e\uff0c\u7b2c\u4e03\u90e8\u5206\u5bf9\u5168\u6587\u8fdb\u884c\u4e86\u603b\u7ed3\u548c\u5c55\u671b\u3002 2. Variational Formulations of Boundary Value Problems \u8fb9\u503c\u95ee\u9898\u7684\u53d8\u5206\u5f62\u5f0f In this section we consider boundary value problems such as (1) in a variational formulation. That is, we aim at approximating the solution \\(V\\) with some function \\(\\varphi\\in\\mathcal{F}\\) by minimizing suitable loss functionals \\[ \\mathcal{L}: \\mathcal{F} \\to \\mathbb{R}_{\\geq 0},\\tag{4} \\] which are zero if and only if the boundary value problem is fulfilled, \\[ \\mathcal{L}(\\varphi) = 0 \u21d0\u21d2 \\varphi = V.\\tag{5} \\] Here \\(\\mathcal{F}\\subset C^{2,1}(\\Omega\\times [0, T], \\mathbb{R})\\cap C(\\bar{\\Omega}\\times [0, T], \\mathbb{R})\\) refers to an appropriate function class, usually consisting of deep neural networks. With a loss function at hand we can apply gradient-descent type algorithms to minimize (estimator versions of) \\(\\mathcal{L}\\) , keeping in mind that different choices of losses lead to different statistical and computational properties and therefore potentially to different convergence speeds and robustness behaviours [60]. Throughout, we will work under the following assumption: Assumption 1. The following hold: The domain \\(\\Omega\\) is either bounded with picewise smooth boundary, or \\(\\Omega=\\mathbb{R}^d\\) . 2. 2.1 The PINN Loss \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u51fd\u6570 2.2 The BSDE \u635fLoss \u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u635f\u5931\u51fd\u6570 3. The Diffusion Loss \u6269\u6563\u635f\u5931 In this section we introduce a novel loss that interpolates between the PINN and BSDE losses from Section 2 using an auxiliary time parameter \\(\\mathfrak{t}\\in (0, \\infty)\\) . As for the BSDE loss, the connection between the SDE (3) and its infinitesimal generator (2) plays a major role: It\u00f4\u2019s formula motivates the following variational formulation of the boundary value problem (1) . \\[ V(X_T, T) - V(X_0, 0) = \\int_0^T (\\partial_s+L) V(X_s,s)\\text{d}s + \\int_0^T \\sigma^\\mathsf{T}\\nabla V(X_s, s)\\cdot \\text{d}W_s \\] Definition 3.1 (Diffusion Loss) Let \\(\\varphi\\in\\mathcal{F}\\) and \\(\\mathfrak{t}\\in(0,\\infty)\\) . The diffusion loss consists of three terms, \\[ \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion}}(\\varphi) = \\alpha_{\\text{int}}\\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion,int}}(\\varphi)+\\alpha_T\\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion,T}}(\\varphi) + \\alpha_b \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, b}}(\\varphi) \\] where \\[ \\begin{aligned} \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, int}}(\\varphi)&= \\mathbb{E}[(\\varphi(X_{\\mathcal{T}}, \\mathcal{T}) - \\varphi(X_{t_0}, t_0) - \\int_{t_0}^\\mathcal{T} \\sigma^\\mathsf{T}\\nabla\\varphi(X_s,s)\\cdot\\text{d}W_s + \\int_{t_0}^\\mathcal{T} h(X_s,s,\\varphi(X_s,s),\\sigma^\\mathsf{T}\\nabla \\varphi(X_s, s)) \\text{d}s)^2]\\\\ \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, T}}(\\varphi)&=\\mathbb{E}[(\\varphi(X^{T},T) - f(X^{T}))^2]\\\\ \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, b}}(\\varphi)&=\\mathbb{E}[(\\varphi(X^{\\text{b}},t^{\\text{b}}) - g(X^{\\text{b}},t^{\\text{b}}))^2] \\end{aligned} \\] encode the constraints (1a)-(1c), balanced by the weights \\(\\alpha_\\text{int}, \\alpha_{\\text{T}}, \\alpha_{\\text{b}}>0\\) . The process \\((X_t)_{t_0\\leq t\\leq \\mathcal{T}}\\) is a solution to (3) with initial condition \\((X_0, t_0)\\sim \u03bd_{\\Omega\\times[0,T]}\\) and maximal trajectory length \\(\\mathfrak{t}>0\\) . The stopping time \\(\\mathcal{T}:=(t_0+ \\mathfrak{t}) \u2227 \\tau \u2227 T\\) is a shorthand notation, referring to the (random) final time associated to a realization of the path X as it either hits the parabolic boundary \u2202\u2126 \u00d7 {T} or reaches the maximal time t0+ t. As in Definition 2.1,\u03c4 = inf{t > 0 : Xt/\u2208 \u2126} is the exit time from \u2126, and (Xb, tb) \u223c \u03bd\u2202\u2126\u00d7[0,T ], X(T )\u223c \u03bd\u2126are distributed according to probability measures that are fully supported on their respective domains. Remark 3.2 (Comparison to the BSDE and PINN losses). In contrast to the PINN loss from Definition 2.1, the data inside the domain \u2126 is not sampled according to a prescribed probability measure \u03bd\u2126, but along trajectories of the diffusion (3). Consequently, second derivatives of \u03d5 do not have to be computed explicitly, but are approximated using the driving Brownian motion (and \u2013 implicitly \u2013 It\u00f4\u2019s formula). A main difference to the BSDE loss from Definition 2.5 is that the simulated trajectories have a maximal length t, which might be beneficial computationally if the final time T or the exit time \u03c4 is large (with high probability). Additionally, the sampling of extra boundary data circumvents the problem of accurately simulating those exit times (see Remark 2.6). Both aspects will be further discussed in Section 5. We refer to Figure 1 for a graphical illustration of the data required to compute the three losses. The following proposition shows that the loss Ltdiffusionis indeed suitable for the boundary value problem (1). Proposition 3.3. Consider the diffusion loss as defined in (17), and assume that b and \u03c3 are globally Lipschitz continuous in x, uniformly in t \u2208 [0, T]. Furthermore, assume the following Lipschitz and boundedness conditions on f, g and h,|f(x)| \u2264 C(1 + |x|p),|g(x, t)| \u2264 C(1 + |x|p),|h(t, x, y, z)| \u2264 C(1 + |x|p+ |y| + |z|),|h(t, x, y, z) \u2212 h(t, x, y0, z)| \u2264 C|y \u2212 y0|,|h(t, x, y, z) \u2212 h(t, x, y, z0)| \u2264 C|z \u2212 z0|,for appropriate constants C, p \u2265 0 and all x, y, z \u2208 \u2126, t \u2208 [0, T]. Finally, assume that Assumption 1 is satisfied. Then for \u03d5 \u2208 F the following are equivalent: The diffusion loss vanishes on \u03d5,Ltdiffusion(\u03d5) = 0.(19) \u03d5 fulfills the boundary value problem (1). Proof. Denoting by Xsthe unique strong solution to (3), an application of It\u00f4\u2019s lemma to \u03d5(Xs, s) yields\u03d5(XT, T ) = \u03d5(Xt0, t0) +T Z t0(\u2202s+ L)\u03d5(Xs, s) ds +T Z t0\u03c3>\u2207\u03d5(Xs, s) \u00b7 dWs,(20)almost surely. Assuming that \u03d5 fulfills the PDE (1a), it follows from the definition in (18a) that Ltdiffusion,int(\u03d5) = 0.Similarly, the boundary conditions (1b) and (1c) imply that Ltdiffusion,T(\u03d5) = Ltdiffusion,b(\u03d5) = 0. Consequently, we see that Ltdiffusion(\u03d5) = 0.For the converse direction, observe that Ltdiffusion(\u03d5) = 0 implies that\u03d5(XT, T ) = \u03d5(Xt0, t0) +T Z t0\u03c3>\u2207\u03d5(Xs, s) \u00b7 dWs\u2212T Z t0h(Xs, s, \u03d5(Xs, s), \u03c3>\u2207\u03d5(Xs, s)) ds,(21)7almost surely, and that the same holds with \u03d5 replaced by V . We proceed by defining the processes e Ys:= \u03d5(Xs, s)and e Zs:= \u03c3>\u2207\u03d5(Xs, s), as well as Ys:= V (Xs, s) and Zs:= \u03c3>\u2207V (Xs, s). By the assumptions on \u03d5, b and\u03c3, the processes Y , Z, eY and e Z are progressively measurable with respect to the filtration generated by (Wt)t\u22650and moreover square-integrable. Furthermore, the relation (21) shows that the pairs (Y, Z) and (eY , eZ) satisfy a BSDE with terminal condition \u03be := \u03d5(XT, T ) on the random time interval [t0, T ]. Well-posedness of the BSDE(see [61, Theorems 1.2 and 3.2]) implies that Y = eY and Z = eZ, almost surely. Conditional on t0and Xt0, we also have V (Xt0, t0) = YXt0,t0= eYXt0,t0= \u03d5(Xt0, t0), where the superscripts denote conditioning on the initial time t0and corresponding initial condition Xt0, see [61, Theorems 2.4 and 4.3]. Hence, we conclude that \u03d5 = V ,\u03bd\u2126\u00d7 [0, T]-almost surely, and the result follows from the continuity of \u03d5 and V and the assumption that \u03bd\u2126\u00d7[0,T ]has full support. We have noted before that the diffusion loss combines aspects from the BSDE and PINN losses. In fact, it turns out that the diffusion loss can be interpreted as a specific type of interpolation between the two. The following proposition makes this observation precise. Proposition 3.4 (Relation of the diffusion loss to the PINN and BSDE losses). Let \u03d5 \u2208 F. Assuming that the measures \u03bd\u2126\u00d7[0,T ]in Definitions 2.1 and 3.1 coincide, we have that Ltdiffusion,int(\u03d5)t2\u2192 LPINN,int(\u03d5),(22)as t \u2192 0. Moreover, if \u03bd\u2126\u00d7[0,T ]refers to the same measure in Definitions 2.1 and 2.5, then Ltdiffusion,int(\u03d5) \u2192 LBSDE(\u03d5),(23)as t \u2192 \u221e. Proof. It\u00f4\u2019s formula shows that Ltdiffusion,intcan be expressed as Ltdiffusion,int(\u03d5) = E\uf8ee\uf8ef\uf8f0\uf8eb\uf8edT Z t0(\u2202s+ L)\u03d5(Xs, s) ds +T Z t0h(Xs, s, \u03d5(Xs, s), \u03c3>\u2207\u03d5(Xs, s)) ds\uf8f6\uf8f82\uf8f9\uf8fa\uf8fb ,(24)which implies the limit (22) by dominated convergence, noting that T \u2192 t0as t \u2192 0, almost surely. The relation(23) follows immediately from the definition of LBSDEby noting that T \u2192 \u03c4 \u2227 T as t \u2192 \u221e, almost surely. 4. Extensions to Elliptic PDEs and Eigenvalue Problems \u63a8\u5e7f\u5230\u692d\u5706\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u4e0e\u7279\u5f81\u503c\u95ee\u9898 In this section we show that the ideas reviewed and developed in the previous sections in the context of the parabolic boundary value problem (1) can straightforwardly be extended to the treatment of elliptic PDEs and certain eigenvalue problems. To begin with, it is helpful to notice that the boundary value problem (1) can be written in the following slightly more abstract form: Remark4.1 (Compact Notation). Consider the operator \\(\\mathcal{A}:=\\partial_t+L\\) , the space-time domain \\(\\Omega_{xt}:= \\Omega\\times[0,T)\\) with (forward) boundary \\(\\vec{\\partial}\\Omega_{xt}:=\\Omega\\times\\{T\\}\\cup\\partial\\Omega\\times [0,T]\\) ( \\(\\partial\\Omega_{xt}=\\vec{\\partial}\\Omega_{xt}\\cup\\{0\\}\\times\\Omega\\) ), and the augmented variable \\(z=(x,t)^\\mathsf{T}\\in\\Omega\\times [0,T]\\) . Then problem (1) can be presented as \\[ \\begin{aligned} \\mathcal{A}V(z) + h(z,V(z),\\sigma^{\\mathsf{T}}\\nabla_x V(z))&=0, &&z\\in\\Omega_{xt}\\\\ V(z)&=k(z), &&z\\in\\vec{\\partial}\\Omega_{xt} \\end{aligned}\\tag{25} \\] with \\(k\\) defined as in (11). Relying on (25), we can equivalently define the BSDE loss as \\[ \\begin{aligned} \\mathcal{L}_{\\text{BSDE}}(\\varphi)=\\mathbb{E} \\bigg[\\Big( &k(X_{\\tau_{xt}}, \\tau_{xt})-\\varphi(X_{t_0}, t_0) - \\int_{t_0}^{\\tau_{xt}}\\sigma^\\mathsf{T}\\nabla\\varphi(X_s,s)\\cdot\\text{d}W_s \\\\ &+ \\int_{t_0}^{\\tau_{xt}} h(X_s,s,\\varphi(X_s,s), \\sigma^\\mathsf{T}\\nabla\\varphi(X_s, s))\\text{d}s \\Big)^2\\bigg] \\end{aligned} \\tag{26} \\] where \\(\\tau_{xt}=\\inf\\{t>0,X_t\\notin\\Omega_{xt}\\}\\) is the first exit time from \\(\\Omega_{xt}\\) . The PINN and diffusion losses can similarly be rewritten in terms of the space-time domain \\(\\Omega_{xt}\\) and exit time \\(\\tau_{xt}\\) . 4.1 Elliptic Boundary Value Problems \u692d\u5706\u578b\u8fb9\u503c\u95ee\u9898 Removing the time dependence from the solution (and from the coefficients b and \u03c3 determining L) we obtain the elliptic boundary value problem with the nonlinearity h \u2208 C(Rd\u00d7 R \u00d7 Rd, R). In analogy to (10), the corresponding backward equation is given by dYs= \u2212h(Xs, Ys, Zs) ds + Zs\u00b7 dWs,Y\u03c4= g(X\u03c4),(28)where \u03c4 = {t > 0 : Xt/\u2208 \u2126} is the first exit time from \u2126. Given suitable boundedness and regularity assumptions on h and assuming that \u03c4 is almost surely finite, one can show existence and uniqueness of solutions Y and Z, which,as before, represent the solution V and its gradient along trajectories of the forward process [61, Theorem 4.6].Therefore, the BSDE, PINN and diffusion losses can be applied to (27) with minor modifications: Owing to the fact that there is no terminal condition, we set f = 0 in (15), as well as \\alpha_T= 0 in (7) and (17), making (8b) and (18b)obsolete. With the same reasoning, we set T = \u221e, incurring \u03c4 \u2227 T = \u03c4 and T = (t0+ t) \u2227 \u03c4; these simplifications are relevant for the expressions (15) and (18a). Proposition 3.3 and its proof can straightforwardly be generalized to the elliptic setting. An algorithm for solving elliptic PDEs of the type (27) in the spirit of the BSDE loss has been suggested in [47], using the same approximation framework as in [19] (cf. Remark 2.7). We note that the solutions to linear elliptic PDEs often admit alternative variational characterizations in terms of energy functionals[22]. An approach using the Feynman-Kac formula has been considered in [24]. 4.2 Elliptic Eigenvalue Problems \u692d\u5706\u578b\u7279\u5f81\u503c\u95ee\u9898 We can extend the algorithmic approaches from Sections 2 and 3 to eigenvalue problems of the form LV (x) = \u03bbV (x),x \u2208 \u2126,(29a)V (x) = 0,x \u2208 \u2202\u2126,(29b)corresponding to the choice h(x, y, z) = \u2212\u03bby in the elliptic PDE (27). Note, however, that h now depends on the unknown eigenvalue \u03bb \u2208 R. Furthermore, we can consider nonlinear eigenvalue problems,LV (x) + h(x, V (x), \u03c3>\u2207V (x)) = \u03bbV (x),x \u2208 \u2126,(30a)V (x) = 0,x \u2208 \u2202\u2126,(30b)with a general nonlinearity h \u2208 C(Rd\u00d7 R \u00d7 Rd, R).For the linear problem (29) it is known that, given suitable boundedness and regularity assumption on b and \u03c3, there exists a unique principal eigenvalue with strictly positive eigenfunction in \u2126, see [8, Theorem 2.3]. This motivates us to consider the above losses, now depending on \u03bb, as well as enhanced with an additional term, preventing the trivial solution V \u2261 0. We define Leigen(\u03d5, \u03bb) = L\u03bb(\u03d5) + \\alpha_cLc(\u03d5),(31)where L\u03bb(\u03d5) stands for either the PINN, the BSDE, or the diffusion loss (with the nonlinearity h depending on\u03bb), Lc(\u03d5) = (\u03d5(xc) \u2212 1)2, and \\alpha_c> 0 is a weight. Here xc\u2208 \u2126 is chosen deterministically, preferably not too close to the boundary \u2202\u2126. Clearly, the term Lcencourages \u03d5(xc) = 1, thus discouraging \u03d5 \u2261 0. We note that V (xc) = 1 can be imposed on solutions to (29) without loss of generality, since the eigenfunctions are determined up to a multiplicative constant only. Avoiding \u03c6 \u2261 0 for nonlinear eigenvalue problems of the form (30) needs to be addressed on a case-by-case basis; we present an example in Section 6.4.2.The idea is now to minimize Leigen(\u03d5, \u03bb) with respect to \u03d5 \u2208 F and \u03bb \u2208 R simultaneously, while constraining the function \u03d5 to be non-negative. According to following proposition this is a valid strategy to determine the first eigenpair. Proposition 4.2. Let \u2126 be bounded, and assume that L is uniformly elliptic, that is, there exist constants c0, C0> 0such that c0|\u03be|2\u2264d X i,j=1(\u03c3\u03c3>)(x)\u03bei\u03bej\u2264 C0|\u03be|2,(32)9for all \u03be \u2208 Rd. Moreover, assume that b is bounded. Let \u03d5 \u2208 F with \u03d5 \u2265 0 and assume that L\u03bb(\u03d5) = 0 if and only if (29) is satisfied. Then the following are equivalent:1. \u03d5 is the principal eigenfunction for (29) with principal eigenvalue \u03bb and normalization \u03d5(xc) = 1.2. Leigen(\u03d5, \u03bb) vanishes on the pair (\u03d5, \u03bb),Leigen(\u03d5, \u03bb) = 0.(33)Remark 4.3. The assumption that L\u03bb(\u03d5) is equivalent to (29) is satisfied for any \u2018reasonable\u2019 loss function. For the diffusion loss, Proposition 3.3 establishes this condition whenever the coefficients in (29) are regular enough. Proof. It is clear that 1. implies 2. by the construction of (31). For the converse direction, notice that (33) implies\u03d5(xc) = 1 as well as (29), that is, \u03d5 is an eigenfunction with eigenvalue \u03bb. In conjunction with the constraint \u03d5 \u2265 0,it follows by [8, Theorem 2.3] that \u03d5 is the principal eigenfunction. An alternative approach towards (29) can be found in [30], where the eigenvalue problem is connected to a parabolic PDE and formulated as a fixed point problem. 5. From Losses to Algorithms \u4ece\u635f\u5931\u51fd\u6570\u5230\u7b97\u6cd5 In this section we discuss some details regarding implementational aspects. For convenience, let us start by stating a prototypical algorithm based on the losses introduced in Section 2 and Section 3 : Algorithm 1: Approximation of the solution \\(V\\) to the boundary value problem (1) . Choose a parametrization \\(\\theta\\in\\mathbb{R}^p\\mapsto \\varphi_\\theta\\) . Initialize \\(\\varphi_\\theta\\) (with a parameter vector \\(\\theta\\in\\mathbb{R}^p\\) ). Choose an optimization method \\(\\text{descent}\\) , a batch size \\(K\\in\\mathbb{N}\\) and a learning rate \\(\\eta>0\\) . For PINN and diffusion losses choose weights \\(\\alpha_{\\text{int}}\\) , \\(\\alpha_b\\) , \\(\\alpha_T>0\\) and batch sizes \\(K_b, K_T\\in\\mathbb{N}\\) . For BSDE and diffusion losses choose a step-size \\(\\Delta t>0\\) , for the diffusion loss choose a trajectory length \\(t > 0\\) . repeat \\(\\qquad\\) Choose a loss function \\(\\mathcal{L}\\) from either (7), (15) or (17). \\(\\qquad\\) Simulate data according to the chosen loss. \\(\\qquad\\) Compute \\(\\hat{\\mathcal{L}}(\\varphi_\\theta)\\) as a Monte Carlo version of \\(\\mathcal{L}\\) . \\(\\qquad\\) Compute \\(\\nabla_\\theta \\hat{\\mathcal{L}}(\\varphi_\\theta)\\) using automatic differentiation. \\(\\qquad\\) Update parameters: \\(\\theta \\leftarrow \\theta - \\eta\\ \\text{descent}(\\nabla_\\theta \\hat{\\mathcal{L}}(\\varphi_\\theta))\\) . until convergence; Result : \\(\\varphi_\\theta\\approx V\\) . Function Approximation \u51fd\u6570\u903c\u8fd1. In this paper, we rely on neural networks to provide the parametrization \\(\\theta\\in\\mathbb{R}^p\\mapsto\\varphi_\\theta\\) referred to in Algorithm 1 (but note that alternative function classes might offer specific benefits, see, for instance [70]). Standard feed-forward neural networks are given by Comparison of Losses (Practical Challenges) \u635f\u5931\u51fd\u6570\u7684\u6bd4\u8f83 (\u5b9e\u8df5\u6311\u6218). The PINN, BSDE and diffusion losses differ in the way training data is generated (see Figure 1 and Table 1a); hence, the corresponding implementations face different challenges (see Table 1b). First, the BSDE and diffusion losses rely on trajectorial data obtained from the SDE (3), in contrast to the PINN loss (cf. the first row in Table 1a). As a consequence, the BSDE and diffusion losses do not require the computation of second-order derivatives, as those are approximated implicitly using It\u00f4\u2019s formula and the SDE (3), cf. the first row in Table 1a. From a computational perspective, the PINN loss therefore faces a significant overhead in high dimensions when the diffusion coefficient \u03c3 is not sparse (as the expression (8a) involves d2second-order partial derivatives). We notice in passing that an approach similar to the diffusion loss circumventing this problem has been proposed in [72, Section 3]. On the other hand, evaluating the BSDE and diffusion losses requires discretizing the SDE (3), incurring additional numerical errors (cf. the last row in Table 1b and the discussion below in Section5.1). Second, the PINN and diffusion losses incorporate boundary and final time constraints (see (1c) and (1b)) explicitly by sampling additional boundary data (see (8b), (8c), (18b), (18c) and cf. the second row in Table 1a). On the one hand, this approach necessitates choosing the weights \\alpha_int, \\alpha_b, \\alpha_T> 0; it is by now well established that while algorithmic performance depends quite sensitively on a judicious tuning of these weights, general and principled guidelines to address this issue are not straightforward (see, however, [74, 75, 76, 77]). Weight-tuning, on the other hand, is not required for implementations relying on the BSDE loss, as the boundary data is accounted for implicitly by the hitting event {(Xt, t) /\u2208 \u2126\u00d7[0, T)} and the corresponding first two terms on the right-hand side of (15). The hitting times \u03c4 = inf{t > 0 : Xt/\u2208 \u2126} may however be large, leading to a computational overhead in the generation of the training data (but see 5.2.1), and are generally hard to compute accurately (but see Section 5.1). 5.1 Simulation of Diffusions and Their Exit Times \u6269\u6563\u6a21\u62df\u548c\u76f8\u5e94\u9000\u51fa\u65f6\u95f4 5.2. Further Modifications of the Losses \u635f\u5931\u51fd\u6570\u7684\u8fdb\u4e00\u6b65\u4fee\u6539 5.2.1 \u524d\u5411\u63a7\u5236 5.2.2 \u8fd1\u4f3c\u89e3\u7684\u68af\u5ea6 5.2.3 \u60e9\u7f5a\u79bb\u6563\u683c\u5f0f\u7684\u504f\u5dee 7. Conclusion and Outlook \u7ed3\u8bba\u4e0e\u5c55\u671b In this paper, we have investigated the relationship between BSDE and PINN based approximation schemes for high-dimensional PDEs through the lens of the novel diffusion loss. In particular, we have shown that the diffusion loss provides an interpolation between the aforementioned methods and demonstrated its promising numerical performance in a range of experiments, allowing us to trade-off strengths and weaknesses of BSDEs and PINNs. Although we believe that the diffusion loss may be a stepping stone towards a unified understanding of computational approaches for high-dimensional PDEs, many questions remain open: First, there is a need for principled insights into the mechanisms with which BSDE, PINN and diffusion losses can or cannot overcome the curse of dimensionality. Second, it is of great practical interest to optimize the algorithmic details, preferably according to well-understood theoretical foundations. In this regard, we mention sophisticated (possibly adaptive) choices of the weights \\(\\alpha_{\\text{int}},\\alpha_b,\\alpha_T\\) and the measures \\(\u03bd_{\\Omega\\times [0,T]},\u03bd_{\\Omega},\u03bd_{\\partial_\\Omega\\times [0,T]}\\) as well as variance reduction techniques for estimator versions of the losses (see, for instance, [60] [Remark 4.7]). Last but not least, we expect that the concepts explored in this paper may be fruitfully extended to the setting of parameter-dependent PDEs. \u672c\u6587\u901a\u8fc7\u65b0\u7684\u6269\u6563\u635f\u8017\u900f\u955c\u7814\u7a76\u4e86\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u7684 BSDE \u548c\u57fa\u4e8e PINN \u7684\u8fd1\u4f3c\u683c\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u5df2\u7ecf\u8868\u660e\uff0c\u6269\u6563\u635f\u5931\u63d0\u4f9b\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u4e4b\u95f4\u7684\u63d2\u503c\uff0c\u5e76\u5728\u4e00\u7cfb\u5217\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u5e0c\u671b\u7684\u6570\u503c\u6027\u80fd\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u6743\u8861 BSDE \u548c PINN \u7684\u4f18\u7f3a\u70b9\u3002\u5c3d\u7ba1\u6211\u4eec\u76f8\u4fe1\u6269\u6563\u635f\u5931\u53ef\u80fd\u662f\u7edf\u4e00\u7406\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u8ba1\u7b97\u65b9\u6cd5\u7684\u4e00\u5757\u8e0f\u811a\u77f3\uff0c\u4f46\u8bb8\u591a\u95ee\u9898\u4ecd\u7136\u60ac\u800c\u672a\u51b3: \u9996\u5148\uff0c\u9700\u8981\u5bf9 BSDE\u3001 PINN \u548c\u6269\u6563\u635f\u5931\u80fd\u5426\u514b\u670d\u7ef4\u6570\u707e\u96be\u7684\u673a\u5236\u6709\u539f\u5219\u6027\u7684\u8ba4\u8bc6\u3002\u5176\u6b21\uff0c\u4f18\u5316\u7b97\u6cd5\u7684\u7ec6\u8282\uff0c\u6700\u597d\u662f\u6839\u636e\u4f17\u6240\u5468\u77e5\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5177\u6709\u5f88\u5927\u7684\u5b9e\u9645\u610f\u4e49\u3002\u5728\u8fd9\u65b9\u9762\uff0c\u6211\u4eec\u63d0\u5230\u4e86\u6743\u91cd\u548c\u5ea6\u91cf\u7684\u590d\u6742(\u53ef\u80fd\u662f\u81ea\u9002\u5e94\u7684)\u9009\u62e9\uff0c\u4ee5\u53ca\u635f\u5931\u4f30\u8ba1\u91cf\u7248\u672c\u7684\u65b9\u5dee\u51cf\u5c11\u6280\u672f(\u53c2\u89c1\uff0c\u4f8b\u5982\uff0c[60][\u6ce84.7])\u3002\u6700\u540e\uff0c\u6211\u4eec\u671f\u671b\u672c\u6587\u63a2\u8ba8\u7684\u6982\u5ff5\u80fd\u591f\u6709\u6548\u5730\u63a8\u5e7f\u5230\u4f9d\u8d56\u4e8e\u53c2\u6570\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8bbe\u7f6e\u3002 \u53c2\u8003\u6587\u732e [1] W. F. Ames. Numerical Methods for Partial Differential Equations. Academic press, 2014. [2] F. Bach. Breaking the Curse of Dimensionality with Convex Neural Networks. The Journal of Machine Learning Research, 18(1):629\u2013681, 2017. [3] C. Beck, S. Becker, P. Cheridito, A. Jentzen, and A. Neufeld. Deep Splitting Method for Parabolic PDEs. SIAM Journal on Scientific Computing, 43(5):A3135\u2013A3154, 2021. [4] C. Beck, S. Becker, P. Grohs, N. Jaafari, and A. Jentzen. Solving stochastic differential equations and Kolmogorov equations by means of deep learning.arXiv:1806.00421, 2018. [5] C. Beck, W. E, and A. Jentzen. Machine Learning Approximation Algorithms for High-Dimensional Fully Nonlinear Partial Differential Equations and Second-Order Backward Stochastic Differential Equations.Journal of Nonlinear Science, 29(4):1563\u20131619, 2019. [6] C. Beck, M. Hutzenthaler, A. Jentzen, and B. Kuckuck. An Overview on Deep Learning-Based Approximation Methods for Partial Differential Equations. arXiv preprint arXiv:2012.12348, 2020. [7] S. Becker, R. Braunwarth, M. Hutzenthaler, A. Jentzen, and P. von Wurstemberger. Numerical simulations for full history recursive multilevel Picard approximations for systems of high-dimensional partial differential equations.arXiv preprint arXiv:2005.10206, 2020. [8] H. Berestycki, L. Nirenberg, and S. S. Varadhan. The principal eigenvalue and maximum principle for secondorder elliptic operators in general domains.Communications on Pure and Applied Mathematics, 47(1):47\u201392, 1994. [9] J. Berg and K. Nystr\u00f6m. A unified deep artificial neural network approach to partial differential equations in complex geometries.Neurocomputing, 317:28\u201341, 2018. [10] J. Berner, P. Grohs, and A. Jentzen. Analysis of the generalization error: empirical risk minimization over deep artificial neural networks overcomes the curse of dimensionality in the numerical approximation of Black\u2013 Scholes partial differential equations.SIAM Journal on Mathematics of Data Science, 2(3):631\u2013657, 2020. [11] J.-M. Bismut. Conjugate convex functions in optimal stochastic control.Journal of Mathematical Analysis and Applications, 44(2):384\u2013404, 1973. [12] J. Blechschmidt and O. G. Ernst. Three ways to solve partial differential equations with neural networks\u2014a review.GAMM-Mitteilungen:e202100006, 2021. [13] B. Bouchard, S. Menozzi, et al. Strong approximations of BSDEs in a domain.Bernoulli, 15(4):1117\u20131147, 2009. [14] B. Bouchard and N. Touzi. Discrete-time approximation and Monte-Carlo simulation of backward stochastic differential equations.Stochastic Processes and their applications, 111(2):175\u2013206, 2004. [15] F. Buchmann and W. Petersen. Solving Dirichlet problems numerically using the Feynman-Kac representation. BIT Numerical Mathematics, 43(3):519\u2013540, 2003. [16] G. Carleo and M. Troyer. Solving the quantum many-body problem with artificial neural networks.Science, 355(6325):602\u2013606, 2017. [17] T. De Ryck and S. Mishra. Error analysis for physics informed neural networks (PINNs) approximating Kolmogorov PDEs.arXiv preprint arXiv:2106.14473, 2021. [18] T. Dockhorn. A discussion on solving partial differential equations using neural networks.arXiv preprint arXiv:1904.07200, 2019. [19] W. E, J. Han, and A. Jentzen. Deep learning-based numerical methods for high-dimensional parabolic partial differential equations and backward stochastic differential equations.Communications in Mathematics and Statistics, 5(4):349\u2013380, 2017. [20] W. E, J. Han, A. Jentzen, et al. Algorithms for solving high dimensional PDEs: from nonlinear Monte Carlo to machine learning.arXiv preprint arXiv:2008.13333, 2020. [21] W. E and E. Vanden-Eijnden. Towards a theory of transition paths.Journal of statistical physics, 123(3):503\u2013 523, 2006. [22] W. E and B. Yu. The deep Ritz method: a deep learning-based numerical algorithm for solving variational problems.Communications in Mathematics and Statistics, 6(1):1\u201312, 2018. [23] E. Gobet, J.-P. Lemor, X. Warin, et al. A regression-based Monte Carlo method to solve backward stochastic differential equations.The Annals of Applied Probability, 15(3):2172\u20132202, 2005. [24] P. Grohs and L. Herrmann. Deep neural network approximation for high-dimensional elliptic PDEs with boundary conditions.arXiv preprint arXiv:2007.05384, 2020. [25] P. Grohs, F. Hornung, A. Jentzen, and P. Von Wurstemberger. A proof that artificial neural networks overcome the curse of dimensionality in the numerical approximation of Black-Scholes partial differential equations. arXiv preprint arXiv:1809.02362, 2018. [26] P. Grohs, A. Jentzen, and D. Salimova. Deep neural network approximations for Monte Carlo algorithms. arXiv:1908.10828, 2019. [27] E. P. Gross. Structure of a quantized vortex in boson systems.Il Nuovo Cimento (1955-1965), 20(3):454\u2013477, 1961. [28] J. Han, A. Jentzen, and W. E. Solving high-dimensional partial differential equations using deep learning. Proceedings of the National Academy of Sciences, 115(34):8505\u20138510, 2018. [29] J. Han and J. Long. Convergence of the deep BSDE method for coupled FBSDEs.Probability, Uncertainty and Quantitative Risk, 5(1):1\u201333, 2020. [30] J. Han, J. Lu, and M. Zhou. Solving high-dimensional eigenvalue problems using deep neural networks: a diffusion Monte Carlo like approach.Journal of Computational Physics, 423:109792, 2020. [31] C. Hartmann, O. Kebiri, L. Neureither, and L. Richter. Variational approach to rare event simulation using least-squares regression.Chaos: An Interdisciplinary Journal of Nonlinear Science, 29(6):063107, 2019. [32] E. Hausenblas. A numerical scheme using It\u00f4 excursions for simulating local time resp. stochastic differential equations with reflection.Osaka journal of mathematics, 36(1):105\u2013137, 1999. [33] J. Hermann, Z. Sch\u00e4tzle, and F. No\u00e9. Deep-neural-network solution of the electronic Schr\u00f6dinger equation. Nature Chemistry, 12(10):891\u2013897, 2020. [34] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700\u20134708, 2017. [35] C. Hur\u00e9, H. Pham, and X. Warin. Deep backward schemes for high-dimensional nonlinear PDEs.Mathematics of Computation, 89(324):1547\u20131579, 2020. [36] M. Hutzenthaler, A. Jentzen, T. Kruse, T. Anh Nguyen, and P. von Wurstemberger. Overcoming the curse of dimensionality in the numerical approximation of semilinear parabolic partial differential equations.Proceedings of the Royal Society A, 476(2244):20190630, 2020. [37] M. Hutzenthaler, A. Jentzen, T. Kruse, and T. A. Nguyen. A proof that rectified deep neural networks overcome the curse of dimensionality in the numerical approximation of semilinear heat equations.SN partial differential equations and applications, 1(2):1\u201334, 2020. [38] M. Hutzenthaler, A. Jentzen, T. Kruse, et al. Multilevel Picard iterations for solving smooth semilinear parabolic heat equations.arXiv preprint arXiv:1607.03295, 2016. [39] A. D. Jagtap, K. Kawaguchi, and G. E. Karniadakis. Adaptive activation functions accelerate convergence in deep and physics-informed neural networks.Journal of Computational Physics, 404:109136, 2020. [40] A. Jentzen, D. Salimova, and T. Welti. Proof that deep artificial neural networks overcome the curse of dimensionality in the numerical approximation of Kolmogorov partial differential equations with constant diffusion and nonlinear drift coefficients.Communications in Mathematical Sciences, 19(5):1167\u20131205, 2021. [41] L. Jianyu, L. Siwei, Q. Yingjian, and H. Yaping. Numerical solution of elliptic partial differential equation using radial basis function neural networks.Neural Networks, 16(5-6):729\u2013734, 2003. [42] H. Jin, M. Mattheakis, and P. Protopapas. Unsupervised neural networks for quantum eigenvalue problems. arXiv preprint arXiv:2010.05075, 2020. [43] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, and L. Yang. Physics-informed machine learning.Nature Reviews Physics, 3(6):422\u2013440, 2021. [44] Y. Khoo, J. Lu, and L. Ying. Solving for high-dimensional committor functions using artificial neural networks. Research in the Mathematical Sciences, 6(1):1, 2019. [45] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In Y. Bengio and Y. LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.url: http://arxiv.org/abs/1412.6980 . [46] P. E. Kloeden and E. Platen. Stochastic differential equations. InNumerical Solution of Stochastic Differential Equations, pages 103\u2013160. Springer, 1992. [47] S. Kremsner, A. Steinicke, and M. Sz\u00f6lgyenyi. A deep neural network algorithm for semilinear elliptic PDEs with applications in insurance mathematics.Risks, 8(4):136, 2020. [48] I. E. Lagaris, A. Likas, and D. I. Fotiadis. Artificial neural network methods in quantum mechanics.Computer Physics Communications, 104(1-3):1\u201314, 1997. [49] I. E. Lagaris, A. Likas, and D. I. Fotiadis. Artificial neural networks for solving ordinary and partial differential equations.IEEE transactions on neural networks, 9(5):987\u20131000, 1998. [50] I. E. Lagaris, A. C. Likas, and D. G. Papageorgiou. Neural-network methods for boundary value problems with irregular boundaries.IEEE Transactions on Neural Networks, 11(5):1041\u20131049, 2000. [51] H. Lee and I. S. Kang. Neural algorithm for solving differential equations.Journal of Computational Physics, 91(1):110\u2013131, 1990. [52] Q. Li, B. Lin, and W. Ren. Computing committor functions for the study of rare events using deep learning. The Journal of Chemical Physics, 151(5):054112, 2019. [53] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar. Fourier neural operator for parametric partial differential equations.arXiv preprint arXiv:2010.08895, 2020. [54] J. Lu and Y. Lu. A priori generalization error analysis of two-layer neural networks for solving high dimensional Schr\u00f6dinger eigenvalue problems.arXiv preprint arXiv:2105.01228, 2021. [55] J. Lu and J. Nolen. Reactive trajectories and the transition path process.Probability Theory and Related Fields, 161(1):195\u2013244, 2015. [56] M. Magill, F. Qureshi, and H. W. de Haan. Neural networks trained to solve differential equations learn general representations.arXiv preprint arXiv:1807.00042, 2018. [57] S. Mishra and R. Molinaro. Estimates on the generalization error of physics informed neural networks (PINNs) for approximating PDEs.arXiv preprint arXiv:2006.16144, 2020. [58] J. M\u00fcller and M. Zeinhofer. Deep Ritz revisited.arXiv preprint arXiv:1912.03937, 2019. [59] J. M\u00fcller and M. Zeinhofer. Notes on exact boundary values in residual minimisation. arXiv preprint arXiv:2105.02550, 2021. [60] N. N\u00fcsken and L. Richter. Solving High-Dimensional Hamilton\u2013Jacobi\u2013Bellman PDEs Using Neural Networks: Perspectives from the Theory of Controlled Diffusions and Measures on Path Space.SN Partial Differential Equations and Applications, 2(4):1\u201348, 2021. [61] \u00c9. Pardoux. Backward stochastic differential equations and viscosity solutions of systems of semilinear parabolic and elliptic PDEs of second order. InStochastic Analysis and Related Topics VI, pages 79\u2013127. Springer, 1998. [62] E. Pardoux and S. Peng. Adapted solution of a backward stochastic differential equation.Systems & Control Letters, 14(1):55\u201361, 1990. [63] \u00c9. Pardoux and S. Zhang. Generalized BSDEs and nonlinear Neumann boundary value problems.Probability Theory and Related Fields, 110(4):535\u2013558, 1998. [64] G. A. Pavliotis.Stochastic processes and applications: diffusion processes, the Fokker-Planck and Langevin equations, volume 60. Springer, 2014. [65] D. Pfau, J. S. Spencer, A. G. Matthews, and W. M. C. Foulkes. Ab initio solution of the many-electron Schr\u00f6dinger equation with deep neural networks.Physical Review Research, 2(3):033429, 2020. [66] L. P. Pitaevskii. Vortex lines in an imperfect Bose gas.Sov. Phys. JETP, 13(2):451\u2013454, 1961. [67] M. Raissi. Forward-backward stochastic neural networks: deep learning of high-dimensional partial differential equations.arXiv preprint arXiv:1804.07010, 2018. [68] M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.Journal of Computational Physics, 378:686\u2013707, 2019. [69] M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics informed deep learning (part I): data-driven solutions of nonlinear partial differential equations.arXiv preprint arXiv:1711.10561, 2017. [70] L. Richter, L. Sallandt, and N. N\u00fcsken. Solving High-Dimensional Parabolic PDEs Using the Tensor Train Format. In M. Meila and T. Zhang, editors,Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 ofProceedings of Machine Learning Research, pages 8998\u20139009. PMLR, 2021.url: http://proceedings.mlr.press/v139/richter21a.html . [71] G. M. Rotskoff and E. Vanden-Eijnden. Learning with rare data: using active importance sampling to optimize objectives dominated by rare events.arXiv preprint arXiv:2008.06334, 2020. [72] J. Sirignano and K. Spiliopoulos. DGM: a deep learning algorithm for solving partial differential equations. Journal of computational physics, 375:1339\u20131364, 2018. [73] T. Uchiyama and N. Sonehara. Solving inverse problems in nonlinear PDEs by recurrent neural networks. In IEEE International Conference on Neural Networks, pages 99\u2013102. IEEE, 1993. [74] R. van der Meer, C. Oosterlee, and A. Borovykh. Optimally weighted loss functions for solving PDEs with neural networks.arXiv preprint arXiv:2002.06269, 2020. [75] S. Wang, Y. Teng, and P. Perdikaris. Understanding and mitigating gradient flow pathologies in physicsinformed neural networks.SIAM Journal on Scientific Computing, 43(5):A3055\u2013A3081, 2021. [76] S. Wang, H. Wang, and P. Perdikaris. On the eigenvector bias of Fourier feature networks: from regression to solving multi-scale PDEs with physics-informed neural networks.Computer Methods in Applied Mechanics and Engineering, 384:113938, 2021. [77] S. Wang, X. Yu, and P. Perdikaris. When and why PINNs fail to train: a neural tangent kernel perspective. Journal of Computational Physics, 449:110768, 2022. [78] Y. Zang, G. Bao, X. Ye, and H. Zhou. Weak adversarial networks for high-dimensional partial differential equations.Journal of Computational Physics, 411:109409, 2020. [79] J. Zhang.Backward stochastic differential equations. Springer, 2017. [80] W. Zhang, T. Li, and C. Sch\u00fctte. Solving eigenvalue PDEs of metastable diffusion processes using artificial neural networks.arXiv preprint arXiv:2110.14523, 2021.","title":"Interpolating between BSDEs and PINNs: Deep Learning for Elliptic and Parabolic Boundary Value Problems"},{"location":"Models/PINNs/PN-2112.03749/#interpolating-between-bsdes-and-pinns-deep-learning-for-elliptic-and-parabolic-boundary-value-problems","text":"","title":"Interpolating between BSDEs and PINNs: Deep Learning for Elliptic and Parabolic Boundary Value Problems"},{"location":"Models/PINNs/PN-2112.03749/#bsdes-pinns","text":"\u4f5c\u8005: Nikolas N\u00fcsken | Lorenz Richter \u673a\u6784: \u65f6\u95f4: 2021-12-07 \u9884\u5370: arXiv:2112.03749v1 \u9886\u57df: #\u6570\u5b66 \u6807\u7b7e: #PINN \u5f15\u7528: 80 \u7bc7 \u9875\u6570: 25 \u9875","title":"\u692d\u5706\u578b/\u629b\u7269\u578b\u8fb9\u503c\u95ee\u9898\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff1a \u5728 BSDEs \u548c PINNs \u4e4b\u95f4\u63d2\u503c"},{"location":"Models/PINNs/PN-2112.03749/#abstract","text":"Solving high-dimensional partial differential equations is a recurrent challenge in economics, science and engineering. In recent years, a great number of computational approaches have been developed, most of them relying on a combination of Monte Carlo sampling and deep learning based approximation. For elliptic and parabolic problems, existing methods can broadly be classified into those resting on reformulations in terms ofbackward stochastic differential equations(BSDEs) and those aiming to minimize a regression-typeL^2 -error (physics-informed neural networks, PINNs). In this paper, we review the literature and suggest a methodology based on the noveldiffusion lossthat interpolates between BSDEs and PINNs. Our contribution opens the door towards a unified understanding of numerical approaches for high-dimensional PDEs, as well as for implementations that combine the strengths of BSDEs and PINNs. We also provide generalizations to eigenvalue problems and perform extensive numerical studies, including calculations of the ground state for nonlinear Schr\u00f6dinger operators and committor functions relevant in molecular dynamics. \u6c42\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u662f\u7ecf\u6d4e\u5b66\u3001\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u4e2d\u4e00\u4e2a\u7ecf\u5e38\u9047\u5230\u7684\u6311\u6218\u3002\u8fd1\u5e74\u6765\uff0c\u4eba\u4eec\u53d1\u5c55\u4e86\u5927\u91cf\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u662f\u57fa\u4e8e\u8499\u7279\u5361\u7f57\u91c7\u6837\u548c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8fd1\u4f3c\u65b9\u6cd5\u7684\u7ed3\u5408\u3002\u5bf9\u4e8e\u692d\u5706\u578b\u548c\u629b\u7269\u578b\u95ee\u9898\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u5927\u81f4\u53ef\u4ee5\u5206\u4e3a\u57fa\u4e8e\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u91cd\u6784\u7684\u65b9\u6cd5\uff08BSDEs\uff09\u548c\u65e8\u5728\u6700\u5c0f\u5316\u56de\u5f52\u578b \\(L^2\\) \u8bef\u5dee\u7684\u65b9\u6cd5\uff08\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc PINNs\uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u56de\u987e\u4e86\u76f8\u5173\u6587\u732e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b0\u7684\u6269\u6563\u635f\u5931\u7684\u65b9\u6cd5\uff0c\u5373\u5728 BSDEs \u548c PINNs \u4e4b\u95f4\u63d2\u503c\u3002\u6211\u4eec\u7684\u8d21\u732e\u4e3a\u7edf\u4e00\u7406\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u65b9\u6cd5\u4ee5\u53ca\u7ed3\u5408 BSDEs \u548c PINNs \u4f18\u52bf\u7684\u5b9e\u73b0\u6253\u5f00\u4e86\u5927\u95e8\u3002\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u7279\u5f81\u503c\u95ee\u9898\u7684\u63a8\u5e7f\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6570\u503c\u7814\u7a76\uff0c\u5305\u62ec\u8ba1\u7b97\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u7b97\u5b50\u7684\u57fa\u6001\u548c\u5206\u5b50\u52a8\u529b\u5b66\u76f8\u5173\u7684 committor \u51fd\u6570\u3002","title":"Abstract \u6458\u8981"},{"location":"Models/PINNs/PN-2112.03749/#1","text":"In this article, we consider approaches towards solving high-dimensional partial differential equations (PDEs) that are based on minimizing appropriate loss functions in the spirit of machine learning. For example, we aim at identifying approximate solutions to nonlinear parabolic boundary value problems of the form \u672c\u6587\u8003\u8651\u7528\u4e8e\u6c42\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b (PDEs) \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u601d\u60f3\u5373\u6700\u5c0f\u5316\u8fd1\u4f3c\u635f\u5931\u51fd\u6570\u7684\u65b9\u6cd5\u3002\u4f8b\u5982\u627e\u5230\u5982\u4e0b\u5f62\u5f0f\u975e\u7ebf\u6027\u629b\u7269\u578b\u8fb9\u503c\u95ee\u9898\u7684\u89e3\uff1a \\[ \\begin{aligned} &(\\partial_t+L)V(x,t)+h(x,t,V(x,t),\\sigma^\\mathsf{T}\\nabla V(x,t))=0, &(x,t)\\in\\Omega\\times [0,T),\\\\ &V(x,T)=f(x), &x\\in\\Omega,\\\\ &V(x,t)=g(x,t), &(x,t)\\in\\partial\\Omega\\times[0,T], \\end{aligned} \\] on a spatial domain\\Omega\u2282Rdand time interval[0,T], whereh\u2208C(Rd\u00d7[0,T]\u00d7R\u00d7Rd,R)specifies the nonlinearity, andf\u2208C(Rd,R)as well asg\u2208C(Rd\u00d7[0,T],R)are given functions defining the terminal and boundary conditions. Moreover, \u5176\u4e2d\u7a7a\u95f4\u5b9a\u4e49\u57df \\(\\Omega\\subset\\mathbb{R}^d\\) \uff0c\u65f6\u95f4\u533a\u95f4 \\([0,T]\\) \uff0c\u51fd\u6570 \\(h\\in C(\\mathbb{R}^d\\times [0,T]\\times\\mathbb{R}\\times\\mathbb{R}^d,\\mathbb{R})\\) \u4e3a\u975e\u7ebf\u6027\u90e8\u5206\uff0c \\(f\\in C(\\mathbb{R}^d,\\mathbb{R})\\) \u548c \\(g\\in C(\\mathbb{R}^d\\times[0,T],\\mathbb{R})\\) \u662f\u7ed9\u5b9a\u7684\u51fd\u6570\uff0c\u5206\u522b\u5b9a\u4e49\u4e86\u7ec8\u503c\u6761\u4ef6\u548c\u8fb9\u503c\u6761\u4ef6\u3002\u6b64\u5916 \\[ L=\\frac{1}{2}\\sum_{i,j=1}^d(\\sigma\\sigma^\\mathsf{T})_{ij}(x,t)\\partial_{x_i}\\partial_{x_j}+\\sum_{i=1}^d b_i(x,t)\\partial_{t_i}, \\] \u662f\u692d\u5706\u5fae\u5206\u7b97\u5b50\uff0c\u5305\u542b\u4e86\u7cfb\u6570\u51fd\u6570 \\(b\\in C(\\mathbb{R}^d\\times[0,T],\\mathbb{R})\\) \u548c \\(\\sigma\\in C(\\mathbb{R}^d\\times[0,T],\\mathbb{R}^{d\\times d})\\) \uff0c\u5047\u8bbe \\(\\sigma\\) \u662f\u975e\u9000\u5316\u7684\u3002 \u4e4b\u540e\u4f1a\u4f7f\u7528 \\(L\\) \u662f\u7531\u5982\u4e0b\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u5b9a\u4e49\u7684\u6269\u6563\u8fc7\u7a0b\u7684 infinitesimal generator \u7684\u4e8b\u5b9e\uff1a $$ \\text{d}X_s = b(X_s,s)\\text{d}s+\\sigma(X_s,s)\\text{d}W_s, $$ \u5176\u4e2d \\(W_s\\) \u662f\u6807\u51c6 \\(d\\) \u7ef4\u5e03\u6717\u8fd0\u52a8\u3002 \u672c\u6587\u7b97\u6cd5\u5229\u7528\u4e86\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u8054\u7cfb\u51e0\u4e4e\u6beb\u4e0d\u8d39\u529b\u5730\u63a8\u5e7f\u5230\u5f88\u5927\u8303\u56f4\u7684\u975e\u7ebf\u6027\u692d\u5706\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u7279\u5f81\u503c\u95ee\u9898\u3002\u6b64\u5916\u9700\u8981\u6ce8\u610f\u7684\u662f\u4e0d\u5931\u4e00\u822c\u6027\uff0c\u53ef\u4ee5\u4f7f\u7528\u65f6\u95f4\u9006\u8f6c\u53d8\u6362\u5c06\u7ec8\u503c\u6761\u4ef6\u66ff\u6362\u4e3a\u521d\u503c\u6761\u4ef6\u3002\u7c7b\u4f3c\u5730\uff0c\u53ef\u4ee5\u5c06 Dirichlet \u8fb9\u754c\u6761\u4ef6\u66ff\u6362\u4e3a\u76f8\u5e94\u7684 Neumann \u8fb9\u754c\u6761\u4ef6\uff0c\u5373\u5728 \\(\\partial\\Omega\\times[0,T]\\) \u4e0a\u7ea6\u675f\u6cd5\u5411\u5bfc\u6570 \\(\\partial_{\\vec{n}}V\\) \u3002 \u5728\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u5904\u7406\u4e2d\u51fa\u73b0\u7684\u4e00\u4e2a\u81ed\u540d\u662d\u8457\u7684\u6311\u6218\u662f\u7ef4\u6570\u707e\u96be\uff0c\u5b83\u8868\u660e\u8ba1\u7b97\u7684\u590d\u6742\u6027\u5728\u72b6\u6001\u7a7a\u95f4\u7684\u7ef4\u5ea6\u4e2d\u5448\u6307\u6570\u589e\u957f\u3002\u7136\u800c\uff0c\u8fd1\u5e74\u6765\uff0c\u591a\u79cd\u6570\u503c[19,35,69]\u4ee5\u53ca\u7406\u8bba\u7814\u7a76[26,40]\u8868\u660e\uff0c\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u5408\u4e3a\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u6cd5\u3002\u672c\u6587\u56f4\u7ed5\u4e24\u4e2a\u7b56\u7565\u6765\u89e3\u51b3\u76f8\u5f53\u4e00\u822c\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b: \u2022 PINNs physics-informed neural networks \uff0c\u4e5f\u79f0\u4e3a DGM deep Galerkin method \uff0c\u76f4\u63a5\u6700\u5c0f\u5316(1)\u7684\u5de6\u53f3\u4e24\u8fb9\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\uff0c\u5728\u65f6\u7a7a\u57df \\Omega \u00d7 [0\uff0ct ]\u53ca\u5176\u8fb9\u754c\u4e0a\u9009\u62e9\u5408\u9002\u7684(\u968f\u673a)\u70b9\u8fdb\u884c\u6c42\u89e3\u3002\u2022\u6df1\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b[19]\u4f9d\u8d56\u4e8e\u968f\u673a\u6b63\u5012\u5411\u52a8\u529b\u5b66(1)\u7684\u91cd\u65b0\u8868\u8ff0\uff0c\u660e\u786e\u5229\u7528\u504f\u5fae\u5206\u65b9\u7a0b(1)\u548c\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b(3)\u4e4b\u95f4\u7684\u8054\u7cfb\u3002\u6df1\u5c42 bsde \u6700\u5c0f\u5316\u4e0e\u540e\u5411 SDE \u76f8\u5173\u7684\u7ec8\u7aef\u6761\u4ef6\u4e2d\u7684\u4e0d\u5339\u914d\u3002 \u6211\u4eec\u56de\u987e\u4e86\u8fd9\u4e9b\u65b9\u6cd5(\u89c1\u7b2c2\u8282) \uff0c\u5e76\u5728\u4f0a\u85e4\u516c\u5f0f\u7684\u6fc0\u52b1\u4e0b\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u4f18\u5316\u76ee\u6807\uff0c\u79f0\u4e3a\u6269\u6563\u635f\u5931\u7684\u6269\u6563(\u89c1\u7b2c3\u8282)\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u7684\u6784\u9020\u4f9d\u8d56\u4e8e\u8f85\u52a9\u65f6\u95f4\u53c2\u6570 t \u2208(0\uff0c\u221e) \uff0c\u5141\u8bb8\u6211\u4eec\u6062\u590d\u6781\u9650 t \u21920\u7684 PINNs \u548c\u6781\u9650 t \u2192\u221e : PINNst \u21920\u2190--Ltdiffusiont \u2192\u221e\u2192\u6df1 BSDEs\u3002\u6269\u6563\u635f\u5931\u63d0\u4f9b\u4e86\u4e00\u4e2a\u63d2\u503c\u4e4b\u95f4\u4f3c\u4e4e\u76f8\u5f53\u4e0d\u540c\u7684\u65b9\u6cd5\u3002\u9664\u4e86\u8fd9\u4e2a\u7406\u8bba\u4e0a\u7684\u89c1\u89e3\uff0c\u6211\u4eec\u5b9e\u9a8c\u8868\u660e\uff0c\u9002\u5f53\u7684 t \u9009\u62e9\u53ef\u4ee5\u5bfc\u81f4\u8ba1\u7b97\u4e0a\u6709\u5229\u7684 PINNs \u548c\u6df1 BSDEs \u7684\u6df7\u5408\uff0c\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u70b9\u3002\u7279\u522b\u662f\uff0c\u5728\u533a\u57df \\Omega \u6709\u4e00\u4e2a(\u53ef\u80fd\u662f\u590d\u6742\u7684)\u8fb9\u754c\u548c/\u6216\u6b63\u5728\u8003\u8651\u7684 PDE \u5305\u542b\u5927\u91cf\u4e8c\u9636\u5bfc\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u635f\u5931(\u9009\u62e9 t \u4e3a\u4e2d\u7b49\u5927\u5c0f)\u4f3c\u4e4e\u8868\u73b0\u826f\u597d(\u4f8b\u5982\uff0c\u5f53 \u03c3 \u4e0d\u7a00\u758f\u65f6)\u3002\u6211\u4eec\u5c06\u8ba8\u8bba\u7b2c5\u8282\u4e2d\u6d89\u53ca\u7684\u6743\u8861\u95ee\u9898\u3002\u7ef4\u6570\u707e\u96be\uff0cBSDEs vs. PINNs\u3002\u4f20\u7edf\u7684\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u65b9\u6cd5(\u4f8b\u5982\u5dee\u5206\u6cd5\u548c\u6709\u9650\u4f53\u79ef\u6cd5\uff0c\u53c2\u89c1\u6587\u732e[1])\u901a\u5e38\u9700\u8981\u5c06\u533a\u57df \\Omega \u79bb\u6563\u5316\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u589e\u52a0\uff0c\u4e3a\u4e86\u8fbe\u5230\u89c4\u5b9a\u7684\u7cbe\u5ea6\uff0c\u9700\u8981\u5728\u7f51\u683c\u70b9\u6570\u4e0a\u7ebf\u6027\u589e\u957f\uff0c\u56e0\u6b64\u5728\u7ef4\u6570\u4e0a\u5448\u6307\u6570\u589e\u957f\u3002\u6700\u8fd1\u53d1\u5c55\u8d77\u6765\u7684\u65b9\u6cd5\u53ef\u4ee5\u6253\u8d25\u8fd9\u4e2a\u7ef4\u6570\u707e\u96be-BSDEs \u548c PINNs alike1-\u7528\u8499\u7279\u5361\u7f57\u62bd\u6837\u53d6\u4ee3\u786e\u5b9a\u6027\u7f51\u683c\uff0c\u539f\u5219\u4e0a\u6709\u671b\u5b9e\u73b0\u7ef4\u6570\u65e0\u5173\u7684\u6536\u655b\u901f\u5ea6[20]\u3002\u901a\u5e38\uff0c\u8fd1\u4f3c\u51fd\u6570\u7c7b\u7531\u795e\u7ecf\u7f51\u7edc\u7ec4\u6210(\u671f\u671b\u63d0\u4f9b\u5bf9\u4f4e\u7ef4\u6f5c\u5728\u7ed3\u6784\u7684\u81ea\u9002\u5e94\u80fd\u529b[2]) \uff0c\u867d\u7136\u5f20\u91cf\u5217\u8f66\u4e5f\u8868\u73b0\u826f\u597d[70]\u3002\u4e0e pinn \u76f8\u53cd\uff0c\u57fa\u4e8e BSDEs \u7684\u65b9\u6cd5\u5229\u7528\u57fa\u672c\u7684\u6269\u6563(3)\u6765\u751f\u6210\u8bad\u7ec3\u6570\u636e\u3002\u6839\u636e\u6211\u4eec\u7684\u521d\u6b65\u6570\u503c\u5b9e\u9a8c\uff0c\u76ee\u524d\u8fd8\u4e0d\u6e05\u695a\u8fd9\u79cd\u7ed3\u6784\u7684\u4f7f\u7528\u662f\u5426\u771f\u6b63\u8f6c\u5316\u4e3a\u8ba1\u7b97\u7684\u597d\u5904; \u6211\u4eec\u8ba4\u4e3a\u9700\u8981\u5bf9\u8fd9\u79cd\u6bd4\u8f83\u8fdb\u884c\u66f4\u591a\u7684\u7814\u7a76\uff0c\u5e76\u4e14\u53ef\u80fd\u5728\u6982\u5ff5\u4e0a\u548c\u5b9e\u8df5\u4e0a\u5bf9\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u8fdb\u5c55\u4f5c\u51fa\u8d21\u732e\u3002\u672c\u6587\u6240\u8003\u8651\u7684\u6269\u6563\u635f\u5931\u53ef\u80fd\u662f\u671d\u8fd9\u4e2a\u65b9\u5411\u8fc8\u51fa\u7684\u7b2c\u4e00\u6b65\uff0c\u5bf9\u4e8e BSDEs \u548c pinn \u4e4b\u95f4\u7684\u76f4\u63a5\u6bd4\u8f83\uff0c\u6211\u4eec\u53c2\u89c1\u4e0b\u9762\u7684\u88681a \u548c\u88681b\u3002 \u8fc7\u5f80\u4f5c\u54c1\u3002\u5c06\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\u76f8\u7ed3\u5408\u6765\u8fd1\u4f3c PDE \u89e3\u7684\u5c1d\u8bd5\u53ef\u4ee5\u8ffd\u6eaf\u523020\u4e16\u7eaa90\u5e74\u4ee3\uff0c\u5176\u4e2d\u6709\u4eba\u63d0\u51fa\u4e86\u4e00\u4e9b\u6b8b\u5dee\u6700\u5c0f\u5316\u7684\u53d8\u4f53[41,49,50,51,73]\u3002\u6700\u8fd1\uff0c\u8fd9\u4e2a\u60f3\u6cd5\u5728\u7269\u7406\u5b66\u77e5\u8bc6\u7684\u795e\u7ecf\u7f51\u7edc(PINNs\uff0c[68,69])\u548c\u6df1\u5c42\u4f3d\u8fbd\u91d1\u65b9\u6cd5(DGMs\uff0c[72])\u4e0b\u83b7\u5f97\u4e86\u666e\u53ca\u3002\u8ba9\u6211\u4eec\u8fdb\u4e00\u6b65\u53c2\u8003\u6587\u732e[9]\u4e2d\u63d0\u51fa\u7684\u7c7b\u4f3c\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u89e3\u51b3\u52a8\u6001\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u53c2\u8003\u6587\u732e[16]\u3002\u5bf9\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u6211\u4eec\u5c06\u4e3e\u4f8b\u63d0\u5230[57] \uff0c\u5b83\u63d0\u4f9b\u4e86\u6cdb\u5316\u8bef\u5dee\u7684\u4e0a\u754c\uff0c[17] \uff0c\u5b83\u9648\u8ff0\u4e86 pinn \u5728 kolmogorov \u578b\u504f\u5fae\u5206\u65b9\u7a0b\u8fd1\u4f3c\u4e0b\u7684\u8bef\u5dee\u5206\u6790\uff0c[59] \uff0c\u5b83\u6839\u636e\u662f\u5426\u4f7f\u7528\u7cbe\u786e\u7684\u6216\u7f3a\u9677\u7684\u8fb9\u754c\u6761\u4ef6\u6765\u7814\u7a76\u6536\u655b\u6027\uff0c[76,77] \uff0c\u5b83\u901a\u8fc7\u795e\u7ecf\u5207\u7ebf\u7684\u900f\u955c\u6765\u7814\u7a76\u6536\u655b\u6027\u3002\u5728[18,56]\u4e2d\u8fdb\u884c\u4e86\u8fdb\u4e00\u6b65\u7684\u6570\u503c\u5b9e\u9a8c\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u79cd\u7b97\u6cd5\u6539\u8fdb\uff0c\u4f8b\u5982\u5728[75]\u4e2d\uff0c\u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u5e73\u8861\u4e86\u68af\u5ea6\uff0c[39]\u8003\u8651\u4e86\u81ea\u9002\u5e94\u6fc0\u6d3b\u51fd\u6570\u4ee5\u52a0\u901f\u6536\u655b\uff0c[74]\u5219\u7814\u7a76\u4e86\u6709\u6548\u7684\u6743\u91cd\u8c03\u6574\u3002 \u751f\u7269\u540c\u4f4d\u7d20\u884d\u751f\u7269\u6700\u65e9\u662f\u572820\u4e16\u7eaa70\u5e74\u4ee3\u5f15\u5165\u7684\uff0c\u6700\u7ec8\u572820\u4e16\u7eaa90\u5e74\u4ee3\u5f97\u5230\u4e86\u66f4\u7cfb\u7edf\u7684\u7814\u7a76\u3002\u5bf9\u4e8e\u4e00\u4e2a\u5168\u9762\u7684\u4ecb\u7ecd\uff0c\u8be6\u7ec6\u9610\u8ff0\u4e86\u5b83\u4eec\u4e0e\u692d\u5706\u578b\u548c\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8054\u7cfb\uff0c\u6211\u4eec\u53c2\u8003\u4e86\u4f8b\u5982[61]\u3002\u6570\u503c\u8bd5\u56fe\u5229\u7528\u8fd9\u79cd\u8054\u7cfb\uff0c\u4ee5\u903c\u8fd1\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u89e3\u51b3\u65b9\u6848\u5df2\u9996\u5148\u5904\u7406\u540e\u5411\u65f6\u95f4\u8fed\u4ee3\uff0c\u6700\u521d\u4f9d\u8d56\u4e8e\u4e00\u7ec4\u57fa\u672c\u51fd\u6570\u548c\u89e3\u51b3\u629b\u7269\u65b9\u7a0b\u5728\u65e0\u754c\u533a\u57df[14,23,61]\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5728[3,35]\u4e2d\u5df2\u7ecf\u88ab\u8003\u8651\uff0c\u5e76\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f97\u5230\u8fdb\u4e00\u6b65\u53d1\u5c55\uff0c\u5728[70]\u4e2d\u88ab\u8d4b\u4e88\u4e86\u5f20\u91cf\u5e8f\u5217\u3002\u5728\u6587\u732e[19,28]\u4e2d\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u4e2a\u53d8\u5206\u516c\u5f0f\uff0c\u79f0\u4e3a\u6df1\u5ea6\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u5176\u76ee\u7684\u662f\u5728\u4e00\u4e2a\u70b9\u4e0a\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u3002 [60,67].\u5bf9\u4e8e\u6df1\u5c42 BSDE \u65b9\u6cd5\u7684\u903c\u8fd1\u8bef\u5dee\u5206\u6790\uff0c\u6211\u4eec\u53c2\u8003\u4e86[29]\u548c\u57fa\u4e8e\u4e8c\u9636 BSDE \u7684\u5b8c\u5168\u975e\u7ebf\u6027\u65b9\u6cd5\u3002\u5728\u6587[47]\u4e2d\u63d0\u51fa\u4e86\u6709\u754c\u533a\u57df\u4e0a\u692d\u5706\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u4e00\u4e2a\u63a8\u5e7f\u3002\u8fd8\u6709\u4e00\u4e9b\u4e13\u95e8\u9488\u5bf9\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u5de5\u4f5c\uff0c\u4e3b\u8981\u662f\u5229\u7528 Feynman-Kac \u5b9a\u7406\u548c\u4e3b\u8981\u8003\u8651\u629b\u7269\u578b\u65b9\u7a0b[4,10]\u3002\u5bf9\u4e8e Poisson \u65b9\u7a0b\u7684\u7279\u6b8a\u60c5\u51b5\uff0c[24]\u8003\u8651\u4e86\u6709\u754c\u533a\u57df\u4e0a\u7684\u692d\u5706\u578b\u65b9\u7a0b\u3002\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u901a\u5e38\u5305\u542b\u4e00\u4e2a\u53d8\u5206\u516c\u5f0f\uff0c\u8fd9\u4e2a\u53d8\u5206\u516c\u5f0f\u5efa\u8bae\u6700\u5c0f\u5316\u67d0\u4e2a\u80fd\u91cf\u6cdb\u51fd\u2014\u2014\u8fd9\u79cd\u8054\u7cfb\u5728[22,44,54]\u4e2d\u5df2\u7ecf\u4f7f\u7528\u8fc7\uff0c\u6211\u4eec\u53c2\u8003[58]\u4f5c\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u3002\u5f53\u8003\u8651\u7279\u5f81\u503c\u95ee\u9898\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c\u7684\u6781\u5c0f\u5316\u7b56\u7565\uff0c\u6211\u4eec\u5728\u4e9a\u7a33\u6269\u6563\u8fc7\u7a0b\u4e2d\u63d0\u5230\u4e86[80]\u3002\u6211\u4eec\u4e5f\u53c2\u8003\u4e86[33,42,48,65]\u5173\u4e8e21\u91cf\u5b50\u529b\u5b66\u7684\u7c7b\u4f3c\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002\u6587[30,65]\u4e2d\u5229\u7528\u4e00\u4e2a\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u4e00\u4e2a\u4e0d\u52a8\u70b9\u95ee\u9898\u7684\u8054\u7cfb\u6765\u5904\u7406\u975e\u7ebf\u6027\u692d\u5706\u7279\u5f81\u503c\u95ee\u9898\u3002 \u5173\u4e8e\u795e\u7ecf\u7f51\u7edc\u514b\u670d\u7ef4\u6570\u707e\u96be\u7684\u80fd\u529b\u7684\u4e25\u683c\u7ed3\u679c\uff0c\u6211\u4eec\u53c2\u8003\u4e86\u6587\u732e[25,37,40] \uff0c\u6bcf\u4e00\u4e2a\u90fd\u5206\u6790\u4e86\u7279\u5b9a\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u60c5\u51b5\u3002\u9664\u4e86\u4e0a\u9762\u63d0\u5230\u7684\u65b9\u6cd5\u4e4b\u5916\uff0c\u6211\u4eec\u8fd8\u8981\u63d0\u5230[78]\u4f5c\u4e3a\u5229\u7528\u5f31\u504f\u5fae\u5206\u65b9\u7a0b\u5f0f\u7684\u4e00\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff0c\u4ee5\u53ca[53] \uff0c\u5176\u4e2d\u7684\u5178\u578b\u5e94\u7528\u662f\u5c06\u521d\u59cb\u6761\u4ef6\u6620\u5c04\u5230\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u89e3\uff0c\u7528\u795e\u7ecf\u7f51\u7edc(\u4f46\u662f\u4f9d\u8d56\u4e8e\u53c2\u8003\u89e3\u4e2d\u7684\u8bad\u7ec3\u6570\u636e)\u903c\u8fd1\u7b97\u5b50\u3002\u5173\u4e8e\u7528\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7684\u8fdb\u4e00\u6b65\u53c2\u8003\u6587\u732e\uff0c\u6211\u4eec\u53c2\u8003\u4e86\u6700\u8fd1\u7684\u8bc4\u8bba\u6587\u7ae0[6,12,20,43]\u3002\u5728\u7b2c\u4e8c\u90e8\u5206\uff0c\u6211\u4eec\u56de\u987e\u4e86\u57fa\u4e8e PINN \u548c BSDE \u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u9ad8\u7ef4(\u629b\u7269\u7ebf)\u504f\u5fae\u5206\u65b9\u7a0b\u3002\u7b2c\u4e09\u90e8\u5206\u4ecb\u7ecd\u4e86\u6269\u6563\u635f\u8017\uff0c\u8bc1\u660e\u4e86\u5b83\u5728\u6c42\u89e3\u5f62\u5f0f(1)\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5b83\u4ecb\u4e8e PINN \u548c BSDE \u635f\u8017\u4e4b\u95f4\u3002\u7b2c4\u8282\u6269\u5c55\u4e86\u63d0\u51fa\u7684\u65b9\u6cd5\u5b66\u7684\u692d\u5706\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u7279\u5f81\u503c\u95ee\u9898\u3002\u5728\u7b2c5\u8282\u4e2d\uff0c\u6211\u4eec\u8ba8\u8bba\u5b9e\u65bd\u7ec6\u8282\u4ee5\u53ca\u4e00\u4e9b\u6b63\u5728\u8003\u8651\u7684\u635f\u5931\u7684\u8fdb\u4e00\u6b65\u4fee\u6539\u3002\u5728\u7b2c6\u90e8\u5206\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6570\u503c\u5b9e\u9a8c\uff0c\u5305\u62ec\u4e00\u4e2a\u6765\u81ea\u5206\u5b50\u52a8\u529b\u5b66\u7684\u51fd\u6570\u4f8b\u5b50\u548c\u4e00\u4e2a\u7531\u91cf\u5b50\u7269\u7406\u5b66\u6fc0\u53d1\u7684\u975e\u7ebf\u6027\u672c\u5f81\u503c\u95ee\u9898\u3002\u6700\u540e\uff0c\u7b2c\u4e03\u90e8\u5206\u5bf9\u5168\u6587\u8fdb\u884c\u4e86\u603b\u7ed3\u548c\u5c55\u671b\u3002","title":"1. \u4ecb\u7ecd"},{"location":"Models/PINNs/PN-2112.03749/#2-variational-formulations-of-boundary-value-problems","text":"In this section we consider boundary value problems such as (1) in a variational formulation. That is, we aim at approximating the solution \\(V\\) with some function \\(\\varphi\\in\\mathcal{F}\\) by minimizing suitable loss functionals \\[ \\mathcal{L}: \\mathcal{F} \\to \\mathbb{R}_{\\geq 0},\\tag{4} \\] which are zero if and only if the boundary value problem is fulfilled, \\[ \\mathcal{L}(\\varphi) = 0 \u21d0\u21d2 \\varphi = V.\\tag{5} \\] Here \\(\\mathcal{F}\\subset C^{2,1}(\\Omega\\times [0, T], \\mathbb{R})\\cap C(\\bar{\\Omega}\\times [0, T], \\mathbb{R})\\) refers to an appropriate function class, usually consisting of deep neural networks. With a loss function at hand we can apply gradient-descent type algorithms to minimize (estimator versions of) \\(\\mathcal{L}\\) , keeping in mind that different choices of losses lead to different statistical and computational properties and therefore potentially to different convergence speeds and robustness behaviours [60]. Throughout, we will work under the following assumption: Assumption 1. The following hold: The domain \\(\\Omega\\) is either bounded with picewise smooth boundary, or \\(\\Omega=\\mathbb{R}^d\\) . 2.","title":"2. Variational Formulations of Boundary Value Problems  \u8fb9\u503c\u95ee\u9898\u7684\u53d8\u5206\u5f62\u5f0f"},{"location":"Models/PINNs/PN-2112.03749/#21-the-pinn-loss","text":"","title":"2.1 The PINN Loss  \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u51fd\u6570"},{"location":"Models/PINNs/PN-2112.03749/#22-the-bsde-loss","text":"","title":"2.2 The BSDE \u635fLoss  \u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u635f\u5931\u51fd\u6570"},{"location":"Models/PINNs/PN-2112.03749/#3-the-diffusion-loss","text":"In this section we introduce a novel loss that interpolates between the PINN and BSDE losses from Section 2 using an auxiliary time parameter \\(\\mathfrak{t}\\in (0, \\infty)\\) . As for the BSDE loss, the connection between the SDE (3) and its infinitesimal generator (2) plays a major role: It\u00f4\u2019s formula motivates the following variational formulation of the boundary value problem (1) . \\[ V(X_T, T) - V(X_0, 0) = \\int_0^T (\\partial_s+L) V(X_s,s)\\text{d}s + \\int_0^T \\sigma^\\mathsf{T}\\nabla V(X_s, s)\\cdot \\text{d}W_s \\] Definition 3.1 (Diffusion Loss) Let \\(\\varphi\\in\\mathcal{F}\\) and \\(\\mathfrak{t}\\in(0,\\infty)\\) . The diffusion loss consists of three terms, \\[ \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion}}(\\varphi) = \\alpha_{\\text{int}}\\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion,int}}(\\varphi)+\\alpha_T\\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion,T}}(\\varphi) + \\alpha_b \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, b}}(\\varphi) \\] where \\[ \\begin{aligned} \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, int}}(\\varphi)&= \\mathbb{E}[(\\varphi(X_{\\mathcal{T}}, \\mathcal{T}) - \\varphi(X_{t_0}, t_0) - \\int_{t_0}^\\mathcal{T} \\sigma^\\mathsf{T}\\nabla\\varphi(X_s,s)\\cdot\\text{d}W_s + \\int_{t_0}^\\mathcal{T} h(X_s,s,\\varphi(X_s,s),\\sigma^\\mathsf{T}\\nabla \\varphi(X_s, s)) \\text{d}s)^2]\\\\ \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, T}}(\\varphi)&=\\mathbb{E}[(\\varphi(X^{T},T) - f(X^{T}))^2]\\\\ \\mathcal{L}^{\\mathfrak{t}}_{\\text{diffusion, b}}(\\varphi)&=\\mathbb{E}[(\\varphi(X^{\\text{b}},t^{\\text{b}}) - g(X^{\\text{b}},t^{\\text{b}}))^2] \\end{aligned} \\] encode the constraints (1a)-(1c), balanced by the weights \\(\\alpha_\\text{int}, \\alpha_{\\text{T}}, \\alpha_{\\text{b}}>0\\) . The process \\((X_t)_{t_0\\leq t\\leq \\mathcal{T}}\\) is a solution to (3) with initial condition \\((X_0, t_0)\\sim \u03bd_{\\Omega\\times[0,T]}\\) and maximal trajectory length \\(\\mathfrak{t}>0\\) . The stopping time \\(\\mathcal{T}:=(t_0+ \\mathfrak{t}) \u2227 \\tau \u2227 T\\) is a shorthand notation, referring to the (random) final time associated to a realization of the path X as it either hits the parabolic boundary \u2202\u2126 \u00d7 {T} or reaches the maximal time t0+ t. As in Definition 2.1,\u03c4 = inf{t > 0 : Xt/\u2208 \u2126} is the exit time from \u2126, and (Xb, tb) \u223c \u03bd\u2202\u2126\u00d7[0,T ], X(T )\u223c \u03bd\u2126are distributed according to probability measures that are fully supported on their respective domains. Remark 3.2 (Comparison to the BSDE and PINN losses). In contrast to the PINN loss from Definition 2.1, the data inside the domain \u2126 is not sampled according to a prescribed probability measure \u03bd\u2126, but along trajectories of the diffusion (3). Consequently, second derivatives of \u03d5 do not have to be computed explicitly, but are approximated using the driving Brownian motion (and \u2013 implicitly \u2013 It\u00f4\u2019s formula). A main difference to the BSDE loss from Definition 2.5 is that the simulated trajectories have a maximal length t, which might be beneficial computationally if the final time T or the exit time \u03c4 is large (with high probability). Additionally, the sampling of extra boundary data circumvents the problem of accurately simulating those exit times (see Remark 2.6). Both aspects will be further discussed in Section 5. We refer to Figure 1 for a graphical illustration of the data required to compute the three losses. The following proposition shows that the loss Ltdiffusionis indeed suitable for the boundary value problem (1). Proposition 3.3. Consider the diffusion loss as defined in (17), and assume that b and \u03c3 are globally Lipschitz continuous in x, uniformly in t \u2208 [0, T]. Furthermore, assume the following Lipschitz and boundedness conditions on f, g and h,|f(x)| \u2264 C(1 + |x|p),|g(x, t)| \u2264 C(1 + |x|p),|h(t, x, y, z)| \u2264 C(1 + |x|p+ |y| + |z|),|h(t, x, y, z) \u2212 h(t, x, y0, z)| \u2264 C|y \u2212 y0|,|h(t, x, y, z) \u2212 h(t, x, y, z0)| \u2264 C|z \u2212 z0|,for appropriate constants C, p \u2265 0 and all x, y, z \u2208 \u2126, t \u2208 [0, T]. Finally, assume that Assumption 1 is satisfied. Then for \u03d5 \u2208 F the following are equivalent: The diffusion loss vanishes on \u03d5,Ltdiffusion(\u03d5) = 0.(19) \u03d5 fulfills the boundary value problem (1). Proof. Denoting by Xsthe unique strong solution to (3), an application of It\u00f4\u2019s lemma to \u03d5(Xs, s) yields\u03d5(XT, T ) = \u03d5(Xt0, t0) +T Z t0(\u2202s+ L)\u03d5(Xs, s) ds +T Z t0\u03c3>\u2207\u03d5(Xs, s) \u00b7 dWs,(20)almost surely. Assuming that \u03d5 fulfills the PDE (1a), it follows from the definition in (18a) that Ltdiffusion,int(\u03d5) = 0.Similarly, the boundary conditions (1b) and (1c) imply that Ltdiffusion,T(\u03d5) = Ltdiffusion,b(\u03d5) = 0. Consequently, we see that Ltdiffusion(\u03d5) = 0.For the converse direction, observe that Ltdiffusion(\u03d5) = 0 implies that\u03d5(XT, T ) = \u03d5(Xt0, t0) +T Z t0\u03c3>\u2207\u03d5(Xs, s) \u00b7 dWs\u2212T Z t0h(Xs, s, \u03d5(Xs, s), \u03c3>\u2207\u03d5(Xs, s)) ds,(21)7almost surely, and that the same holds with \u03d5 replaced by V . We proceed by defining the processes e Ys:= \u03d5(Xs, s)and e Zs:= \u03c3>\u2207\u03d5(Xs, s), as well as Ys:= V (Xs, s) and Zs:= \u03c3>\u2207V (Xs, s). By the assumptions on \u03d5, b and\u03c3, the processes Y , Z, eY and e Z are progressively measurable with respect to the filtration generated by (Wt)t\u22650and moreover square-integrable. Furthermore, the relation (21) shows that the pairs (Y, Z) and (eY , eZ) satisfy a BSDE with terminal condition \u03be := \u03d5(XT, T ) on the random time interval [t0, T ]. Well-posedness of the BSDE(see [61, Theorems 1.2 and 3.2]) implies that Y = eY and Z = eZ, almost surely. Conditional on t0and Xt0, we also have V (Xt0, t0) = YXt0,t0= eYXt0,t0= \u03d5(Xt0, t0), where the superscripts denote conditioning on the initial time t0and corresponding initial condition Xt0, see [61, Theorems 2.4 and 4.3]. Hence, we conclude that \u03d5 = V ,\u03bd\u2126\u00d7 [0, T]-almost surely, and the result follows from the continuity of \u03d5 and V and the assumption that \u03bd\u2126\u00d7[0,T ]has full support. We have noted before that the diffusion loss combines aspects from the BSDE and PINN losses. In fact, it turns out that the diffusion loss can be interpreted as a specific type of interpolation between the two. The following proposition makes this observation precise. Proposition 3.4 (Relation of the diffusion loss to the PINN and BSDE losses). Let \u03d5 \u2208 F. Assuming that the measures \u03bd\u2126\u00d7[0,T ]in Definitions 2.1 and 3.1 coincide, we have that Ltdiffusion,int(\u03d5)t2\u2192 LPINN,int(\u03d5),(22)as t \u2192 0. Moreover, if \u03bd\u2126\u00d7[0,T ]refers to the same measure in Definitions 2.1 and 2.5, then Ltdiffusion,int(\u03d5) \u2192 LBSDE(\u03d5),(23)as t \u2192 \u221e. Proof. It\u00f4\u2019s formula shows that Ltdiffusion,intcan be expressed as Ltdiffusion,int(\u03d5) = E\uf8ee\uf8ef\uf8f0\uf8eb\uf8edT Z t0(\u2202s+ L)\u03d5(Xs, s) ds +T Z t0h(Xs, s, \u03d5(Xs, s), \u03c3>\u2207\u03d5(Xs, s)) ds\uf8f6\uf8f82\uf8f9\uf8fa\uf8fb ,(24)which implies the limit (22) by dominated convergence, noting that T \u2192 t0as t \u2192 0, almost surely. The relation(23) follows immediately from the definition of LBSDEby noting that T \u2192 \u03c4 \u2227 T as t \u2192 \u221e, almost surely.","title":"3. The Diffusion Loss  \u6269\u6563\u635f\u5931"},{"location":"Models/PINNs/PN-2112.03749/#4-extensions-to-elliptic-pdes-and-eigenvalue-problems","text":"In this section we show that the ideas reviewed and developed in the previous sections in the context of the parabolic boundary value problem (1) can straightforwardly be extended to the treatment of elliptic PDEs and certain eigenvalue problems. To begin with, it is helpful to notice that the boundary value problem (1) can be written in the following slightly more abstract form: Remark4.1 (Compact Notation). Consider the operator \\(\\mathcal{A}:=\\partial_t+L\\) , the space-time domain \\(\\Omega_{xt}:= \\Omega\\times[0,T)\\) with (forward) boundary \\(\\vec{\\partial}\\Omega_{xt}:=\\Omega\\times\\{T\\}\\cup\\partial\\Omega\\times [0,T]\\) ( \\(\\partial\\Omega_{xt}=\\vec{\\partial}\\Omega_{xt}\\cup\\{0\\}\\times\\Omega\\) ), and the augmented variable \\(z=(x,t)^\\mathsf{T}\\in\\Omega\\times [0,T]\\) . Then problem (1) can be presented as \\[ \\begin{aligned} \\mathcal{A}V(z) + h(z,V(z),\\sigma^{\\mathsf{T}}\\nabla_x V(z))&=0, &&z\\in\\Omega_{xt}\\\\ V(z)&=k(z), &&z\\in\\vec{\\partial}\\Omega_{xt} \\end{aligned}\\tag{25} \\] with \\(k\\) defined as in (11). Relying on (25), we can equivalently define the BSDE loss as \\[ \\begin{aligned} \\mathcal{L}_{\\text{BSDE}}(\\varphi)=\\mathbb{E} \\bigg[\\Big( &k(X_{\\tau_{xt}}, \\tau_{xt})-\\varphi(X_{t_0}, t_0) - \\int_{t_0}^{\\tau_{xt}}\\sigma^\\mathsf{T}\\nabla\\varphi(X_s,s)\\cdot\\text{d}W_s \\\\ &+ \\int_{t_0}^{\\tau_{xt}} h(X_s,s,\\varphi(X_s,s), \\sigma^\\mathsf{T}\\nabla\\varphi(X_s, s))\\text{d}s \\Big)^2\\bigg] \\end{aligned} \\tag{26} \\] where \\(\\tau_{xt}=\\inf\\{t>0,X_t\\notin\\Omega_{xt}\\}\\) is the first exit time from \\(\\Omega_{xt}\\) . The PINN and diffusion losses can similarly be rewritten in terms of the space-time domain \\(\\Omega_{xt}\\) and exit time \\(\\tau_{xt}\\) .","title":"4. Extensions to Elliptic PDEs and Eigenvalue Problems  \u63a8\u5e7f\u5230\u692d\u5706\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u4e0e\u7279\u5f81\u503c\u95ee\u9898"},{"location":"Models/PINNs/PN-2112.03749/#41-elliptic-boundary-value-problems","text":"Removing the time dependence from the solution (and from the coefficients b and \u03c3 determining L) we obtain the elliptic boundary value problem with the nonlinearity h \u2208 C(Rd\u00d7 R \u00d7 Rd, R). In analogy to (10), the corresponding backward equation is given by dYs= \u2212h(Xs, Ys, Zs) ds + Zs\u00b7 dWs,Y\u03c4= g(X\u03c4),(28)where \u03c4 = {t > 0 : Xt/\u2208 \u2126} is the first exit time from \u2126. Given suitable boundedness and regularity assumptions on h and assuming that \u03c4 is almost surely finite, one can show existence and uniqueness of solutions Y and Z, which,as before, represent the solution V and its gradient along trajectories of the forward process [61, Theorem 4.6].Therefore, the BSDE, PINN and diffusion losses can be applied to (27) with minor modifications: Owing to the fact that there is no terminal condition, we set f = 0 in (15), as well as \\alpha_T= 0 in (7) and (17), making (8b) and (18b)obsolete. With the same reasoning, we set T = \u221e, incurring \u03c4 \u2227 T = \u03c4 and T = (t0+ t) \u2227 \u03c4; these simplifications are relevant for the expressions (15) and (18a). Proposition 3.3 and its proof can straightforwardly be generalized to the elliptic setting. An algorithm for solving elliptic PDEs of the type (27) in the spirit of the BSDE loss has been suggested in [47], using the same approximation framework as in [19] (cf. Remark 2.7). We note that the solutions to linear elliptic PDEs often admit alternative variational characterizations in terms of energy functionals[22]. An approach using the Feynman-Kac formula has been considered in [24].","title":"4.1 Elliptic Boundary Value Problems \u692d\u5706\u578b\u8fb9\u503c\u95ee\u9898"},{"location":"Models/PINNs/PN-2112.03749/#42-elliptic-eigenvalue-problems","text":"We can extend the algorithmic approaches from Sections 2 and 3 to eigenvalue problems of the form LV (x) = \u03bbV (x),x \u2208 \u2126,(29a)V (x) = 0,x \u2208 \u2202\u2126,(29b)corresponding to the choice h(x, y, z) = \u2212\u03bby in the elliptic PDE (27). Note, however, that h now depends on the unknown eigenvalue \u03bb \u2208 R. Furthermore, we can consider nonlinear eigenvalue problems,LV (x) + h(x, V (x), \u03c3>\u2207V (x)) = \u03bbV (x),x \u2208 \u2126,(30a)V (x) = 0,x \u2208 \u2202\u2126,(30b)with a general nonlinearity h \u2208 C(Rd\u00d7 R \u00d7 Rd, R).For the linear problem (29) it is known that, given suitable boundedness and regularity assumption on b and \u03c3, there exists a unique principal eigenvalue with strictly positive eigenfunction in \u2126, see [8, Theorem 2.3]. This motivates us to consider the above losses, now depending on \u03bb, as well as enhanced with an additional term, preventing the trivial solution V \u2261 0. We define Leigen(\u03d5, \u03bb) = L\u03bb(\u03d5) + \\alpha_cLc(\u03d5),(31)where L\u03bb(\u03d5) stands for either the PINN, the BSDE, or the diffusion loss (with the nonlinearity h depending on\u03bb), Lc(\u03d5) = (\u03d5(xc) \u2212 1)2, and \\alpha_c> 0 is a weight. Here xc\u2208 \u2126 is chosen deterministically, preferably not too close to the boundary \u2202\u2126. Clearly, the term Lcencourages \u03d5(xc) = 1, thus discouraging \u03d5 \u2261 0. We note that V (xc) = 1 can be imposed on solutions to (29) without loss of generality, since the eigenfunctions are determined up to a multiplicative constant only. Avoiding \u03c6 \u2261 0 for nonlinear eigenvalue problems of the form (30) needs to be addressed on a case-by-case basis; we present an example in Section 6.4.2.The idea is now to minimize Leigen(\u03d5, \u03bb) with respect to \u03d5 \u2208 F and \u03bb \u2208 R simultaneously, while constraining the function \u03d5 to be non-negative. According to following proposition this is a valid strategy to determine the first eigenpair. Proposition 4.2. Let \u2126 be bounded, and assume that L is uniformly elliptic, that is, there exist constants c0, C0> 0such that c0|\u03be|2\u2264d X i,j=1(\u03c3\u03c3>)(x)\u03bei\u03bej\u2264 C0|\u03be|2,(32)9for all \u03be \u2208 Rd. Moreover, assume that b is bounded. Let \u03d5 \u2208 F with \u03d5 \u2265 0 and assume that L\u03bb(\u03d5) = 0 if and only if (29) is satisfied. Then the following are equivalent:1. \u03d5 is the principal eigenfunction for (29) with principal eigenvalue \u03bb and normalization \u03d5(xc) = 1.2. Leigen(\u03d5, \u03bb) vanishes on the pair (\u03d5, \u03bb),Leigen(\u03d5, \u03bb) = 0.(33)Remark 4.3. The assumption that L\u03bb(\u03d5) is equivalent to (29) is satisfied for any \u2018reasonable\u2019 loss function. For the diffusion loss, Proposition 3.3 establishes this condition whenever the coefficients in (29) are regular enough. Proof. It is clear that 1. implies 2. by the construction of (31). For the converse direction, notice that (33) implies\u03d5(xc) = 1 as well as (29), that is, \u03d5 is an eigenfunction with eigenvalue \u03bb. In conjunction with the constraint \u03d5 \u2265 0,it follows by [8, Theorem 2.3] that \u03d5 is the principal eigenfunction. An alternative approach towards (29) can be found in [30], where the eigenvalue problem is connected to a parabolic PDE and formulated as a fixed point problem.","title":"4.2 Elliptic Eigenvalue Problems \u692d\u5706\u578b\u7279\u5f81\u503c\u95ee\u9898"},{"location":"Models/PINNs/PN-2112.03749/#5-from-losses-to-algorithms","text":"In this section we discuss some details regarding implementational aspects. For convenience, let us start by stating a prototypical algorithm based on the losses introduced in Section 2 and Section 3 : Algorithm 1: Approximation of the solution \\(V\\) to the boundary value problem (1) . Choose a parametrization \\(\\theta\\in\\mathbb{R}^p\\mapsto \\varphi_\\theta\\) . Initialize \\(\\varphi_\\theta\\) (with a parameter vector \\(\\theta\\in\\mathbb{R}^p\\) ). Choose an optimization method \\(\\text{descent}\\) , a batch size \\(K\\in\\mathbb{N}\\) and a learning rate \\(\\eta>0\\) . For PINN and diffusion losses choose weights \\(\\alpha_{\\text{int}}\\) , \\(\\alpha_b\\) , \\(\\alpha_T>0\\) and batch sizes \\(K_b, K_T\\in\\mathbb{N}\\) . For BSDE and diffusion losses choose a step-size \\(\\Delta t>0\\) , for the diffusion loss choose a trajectory length \\(t > 0\\) . repeat \\(\\qquad\\) Choose a loss function \\(\\mathcal{L}\\) from either (7), (15) or (17). \\(\\qquad\\) Simulate data according to the chosen loss. \\(\\qquad\\) Compute \\(\\hat{\\mathcal{L}}(\\varphi_\\theta)\\) as a Monte Carlo version of \\(\\mathcal{L}\\) . \\(\\qquad\\) Compute \\(\\nabla_\\theta \\hat{\\mathcal{L}}(\\varphi_\\theta)\\) using automatic differentiation. \\(\\qquad\\) Update parameters: \\(\\theta \\leftarrow \\theta - \\eta\\ \\text{descent}(\\nabla_\\theta \\hat{\\mathcal{L}}(\\varphi_\\theta))\\) . until convergence; Result : \\(\\varphi_\\theta\\approx V\\) . Function Approximation \u51fd\u6570\u903c\u8fd1. In this paper, we rely on neural networks to provide the parametrization \\(\\theta\\in\\mathbb{R}^p\\mapsto\\varphi_\\theta\\) referred to in Algorithm 1 (but note that alternative function classes might offer specific benefits, see, for instance [70]). Standard feed-forward neural networks are given by Comparison of Losses (Practical Challenges) \u635f\u5931\u51fd\u6570\u7684\u6bd4\u8f83 (\u5b9e\u8df5\u6311\u6218). The PINN, BSDE and diffusion losses differ in the way training data is generated (see Figure 1 and Table 1a); hence, the corresponding implementations face different challenges (see Table 1b). First, the BSDE and diffusion losses rely on trajectorial data obtained from the SDE (3), in contrast to the PINN loss (cf. the first row in Table 1a). As a consequence, the BSDE and diffusion losses do not require the computation of second-order derivatives, as those are approximated implicitly using It\u00f4\u2019s formula and the SDE (3), cf. the first row in Table 1a. From a computational perspective, the PINN loss therefore faces a significant overhead in high dimensions when the diffusion coefficient \u03c3 is not sparse (as the expression (8a) involves d2second-order partial derivatives). We notice in passing that an approach similar to the diffusion loss circumventing this problem has been proposed in [72, Section 3]. On the other hand, evaluating the BSDE and diffusion losses requires discretizing the SDE (3), incurring additional numerical errors (cf. the last row in Table 1b and the discussion below in Section5.1). Second, the PINN and diffusion losses incorporate boundary and final time constraints (see (1c) and (1b)) explicitly by sampling additional boundary data (see (8b), (8c), (18b), (18c) and cf. the second row in Table 1a). On the one hand, this approach necessitates choosing the weights \\alpha_int, \\alpha_b, \\alpha_T> 0; it is by now well established that while algorithmic performance depends quite sensitively on a judicious tuning of these weights, general and principled guidelines to address this issue are not straightforward (see, however, [74, 75, 76, 77]). Weight-tuning, on the other hand, is not required for implementations relying on the BSDE loss, as the boundary data is accounted for implicitly by the hitting event {(Xt, t) /\u2208 \u2126\u00d7[0, T)} and the corresponding first two terms on the right-hand side of (15). The hitting times \u03c4 = inf{t > 0 : Xt/\u2208 \u2126} may however be large, leading to a computational overhead in the generation of the training data (but see 5.2.1), and are generally hard to compute accurately (but see Section 5.1).","title":"5. From Losses to Algorithms \u4ece\u635f\u5931\u51fd\u6570\u5230\u7b97\u6cd5"},{"location":"Models/PINNs/PN-2112.03749/#51-simulation-of-diffusions-and-their-exit-times","text":"","title":"5.1 Simulation of Diffusions and Their Exit Times  \u6269\u6563\u6a21\u62df\u548c\u76f8\u5e94\u9000\u51fa\u65f6\u95f4"},{"location":"Models/PINNs/PN-2112.03749/#52-further-modifications-of-the-losses","text":"","title":"5.2. Further Modifications of the Losses  \u635f\u5931\u51fd\u6570\u7684\u8fdb\u4e00\u6b65\u4fee\u6539"},{"location":"Models/PINNs/PN-2112.03749/#521","text":"","title":"5.2.1 \u524d\u5411\u63a7\u5236"},{"location":"Models/PINNs/PN-2112.03749/#522","text":"","title":"5.2.2 \u8fd1\u4f3c\u89e3\u7684\u68af\u5ea6"},{"location":"Models/PINNs/PN-2112.03749/#523","text":"","title":"5.2.3 \u60e9\u7f5a\u79bb\u6563\u683c\u5f0f\u7684\u504f\u5dee"},{"location":"Models/PINNs/PN-2112.03749/#7-conclusion-and-outlook","text":"In this paper, we have investigated the relationship between BSDE and PINN based approximation schemes for high-dimensional PDEs through the lens of the novel diffusion loss. In particular, we have shown that the diffusion loss provides an interpolation between the aforementioned methods and demonstrated its promising numerical performance in a range of experiments, allowing us to trade-off strengths and weaknesses of BSDEs and PINNs. Although we believe that the diffusion loss may be a stepping stone towards a unified understanding of computational approaches for high-dimensional PDEs, many questions remain open: First, there is a need for principled insights into the mechanisms with which BSDE, PINN and diffusion losses can or cannot overcome the curse of dimensionality. Second, it is of great practical interest to optimize the algorithmic details, preferably according to well-understood theoretical foundations. In this regard, we mention sophisticated (possibly adaptive) choices of the weights \\(\\alpha_{\\text{int}},\\alpha_b,\\alpha_T\\) and the measures \\(\u03bd_{\\Omega\\times [0,T]},\u03bd_{\\Omega},\u03bd_{\\partial_\\Omega\\times [0,T]}\\) as well as variance reduction techniques for estimator versions of the losses (see, for instance, [60] [Remark 4.7]). Last but not least, we expect that the concepts explored in this paper may be fruitfully extended to the setting of parameter-dependent PDEs. \u672c\u6587\u901a\u8fc7\u65b0\u7684\u6269\u6563\u635f\u8017\u900f\u955c\u7814\u7a76\u4e86\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u7684 BSDE \u548c\u57fa\u4e8e PINN \u7684\u8fd1\u4f3c\u683c\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u5df2\u7ecf\u8868\u660e\uff0c\u6269\u6563\u635f\u5931\u63d0\u4f9b\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u4e4b\u95f4\u7684\u63d2\u503c\uff0c\u5e76\u5728\u4e00\u7cfb\u5217\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u5e0c\u671b\u7684\u6570\u503c\u6027\u80fd\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u6743\u8861 BSDE \u548c PINN \u7684\u4f18\u7f3a\u70b9\u3002\u5c3d\u7ba1\u6211\u4eec\u76f8\u4fe1\u6269\u6563\u635f\u5931\u53ef\u80fd\u662f\u7edf\u4e00\u7406\u89e3\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u8ba1\u7b97\u65b9\u6cd5\u7684\u4e00\u5757\u8e0f\u811a\u77f3\uff0c\u4f46\u8bb8\u591a\u95ee\u9898\u4ecd\u7136\u60ac\u800c\u672a\u51b3: \u9996\u5148\uff0c\u9700\u8981\u5bf9 BSDE\u3001 PINN \u548c\u6269\u6563\u635f\u5931\u80fd\u5426\u514b\u670d\u7ef4\u6570\u707e\u96be\u7684\u673a\u5236\u6709\u539f\u5219\u6027\u7684\u8ba4\u8bc6\u3002\u5176\u6b21\uff0c\u4f18\u5316\u7b97\u6cd5\u7684\u7ec6\u8282\uff0c\u6700\u597d\u662f\u6839\u636e\u4f17\u6240\u5468\u77e5\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5177\u6709\u5f88\u5927\u7684\u5b9e\u9645\u610f\u4e49\u3002\u5728\u8fd9\u65b9\u9762\uff0c\u6211\u4eec\u63d0\u5230\u4e86\u6743\u91cd\u548c\u5ea6\u91cf\u7684\u590d\u6742(\u53ef\u80fd\u662f\u81ea\u9002\u5e94\u7684)\u9009\u62e9\uff0c\u4ee5\u53ca\u635f\u5931\u4f30\u8ba1\u91cf\u7248\u672c\u7684\u65b9\u5dee\u51cf\u5c11\u6280\u672f(\u53c2\u89c1\uff0c\u4f8b\u5982\uff0c[60][\u6ce84.7])\u3002\u6700\u540e\uff0c\u6211\u4eec\u671f\u671b\u672c\u6587\u63a2\u8ba8\u7684\u6982\u5ff5\u80fd\u591f\u6709\u6548\u5730\u63a8\u5e7f\u5230\u4f9d\u8d56\u4e8e\u53c2\u6570\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8bbe\u7f6e\u3002","title":"7. Conclusion and Outlook \u7ed3\u8bba\u4e0e\u5c55\u671b"},{"location":"Models/PINNs/PN-2112.03749/#_1","text":"[1] W. F. Ames. Numerical Methods for Partial Differential Equations. Academic press, 2014. [2] F. Bach. Breaking the Curse of Dimensionality with Convex Neural Networks. The Journal of Machine Learning Research, 18(1):629\u2013681, 2017. [3] C. Beck, S. Becker, P. Cheridito, A. Jentzen, and A. Neufeld. Deep Splitting Method for Parabolic PDEs. SIAM Journal on Scientific Computing, 43(5):A3135\u2013A3154, 2021. [4] C. Beck, S. Becker, P. Grohs, N. Jaafari, and A. Jentzen. Solving stochastic differential equations and Kolmogorov equations by means of deep learning.arXiv:1806.00421, 2018. [5] C. Beck, W. E, and A. Jentzen. Machine Learning Approximation Algorithms for High-Dimensional Fully Nonlinear Partial Differential Equations and Second-Order Backward Stochastic Differential Equations.Journal of Nonlinear Science, 29(4):1563\u20131619, 2019. [6] C. Beck, M. Hutzenthaler, A. Jentzen, and B. Kuckuck. An Overview on Deep Learning-Based Approximation Methods for Partial Differential Equations. arXiv preprint arXiv:2012.12348, 2020. [7] S. Becker, R. Braunwarth, M. Hutzenthaler, A. Jentzen, and P. von Wurstemberger. Numerical simulations for full history recursive multilevel Picard approximations for systems of high-dimensional partial differential equations.arXiv preprint arXiv:2005.10206, 2020. [8] H. Berestycki, L. Nirenberg, and S. S. Varadhan. The principal eigenvalue and maximum principle for secondorder elliptic operators in general domains.Communications on Pure and Applied Mathematics, 47(1):47\u201392, 1994. [9] J. Berg and K. Nystr\u00f6m. A unified deep artificial neural network approach to partial differential equations in complex geometries.Neurocomputing, 317:28\u201341, 2018. [10] J. Berner, P. Grohs, and A. Jentzen. Analysis of the generalization error: empirical risk minimization over deep artificial neural networks overcomes the curse of dimensionality in the numerical approximation of Black\u2013 Scholes partial differential equations.SIAM Journal on Mathematics of Data Science, 2(3):631\u2013657, 2020. [11] J.-M. Bismut. Conjugate convex functions in optimal stochastic control.Journal of Mathematical Analysis and Applications, 44(2):384\u2013404, 1973. [12] J. Blechschmidt and O. G. Ernst. Three ways to solve partial differential equations with neural networks\u2014a review.GAMM-Mitteilungen:e202100006, 2021. [13] B. Bouchard, S. Menozzi, et al. Strong approximations of BSDEs in a domain.Bernoulli, 15(4):1117\u20131147, 2009. [14] B. Bouchard and N. Touzi. Discrete-time approximation and Monte-Carlo simulation of backward stochastic differential equations.Stochastic Processes and their applications, 111(2):175\u2013206, 2004. [15] F. Buchmann and W. Petersen. Solving Dirichlet problems numerically using the Feynman-Kac representation. BIT Numerical Mathematics, 43(3):519\u2013540, 2003. [16] G. Carleo and M. Troyer. Solving the quantum many-body problem with artificial neural networks.Science, 355(6325):602\u2013606, 2017. [17] T. De Ryck and S. Mishra. Error analysis for physics informed neural networks (PINNs) approximating Kolmogorov PDEs.arXiv preprint arXiv:2106.14473, 2021. [18] T. Dockhorn. A discussion on solving partial differential equations using neural networks.arXiv preprint arXiv:1904.07200, 2019. [19] W. E, J. Han, and A. Jentzen. Deep learning-based numerical methods for high-dimensional parabolic partial differential equations and backward stochastic differential equations.Communications in Mathematics and Statistics, 5(4):349\u2013380, 2017. [20] W. E, J. Han, A. Jentzen, et al. Algorithms for solving high dimensional PDEs: from nonlinear Monte Carlo to machine learning.arXiv preprint arXiv:2008.13333, 2020. [21] W. E and E. Vanden-Eijnden. Towards a theory of transition paths.Journal of statistical physics, 123(3):503\u2013 523, 2006. [22] W. E and B. Yu. The deep Ritz method: a deep learning-based numerical algorithm for solving variational problems.Communications in Mathematics and Statistics, 6(1):1\u201312, 2018. [23] E. Gobet, J.-P. Lemor, X. Warin, et al. A regression-based Monte Carlo method to solve backward stochastic differential equations.The Annals of Applied Probability, 15(3):2172\u20132202, 2005. [24] P. Grohs and L. Herrmann. Deep neural network approximation for high-dimensional elliptic PDEs with boundary conditions.arXiv preprint arXiv:2007.05384, 2020. [25] P. Grohs, F. Hornung, A. Jentzen, and P. Von Wurstemberger. A proof that artificial neural networks overcome the curse of dimensionality in the numerical approximation of Black-Scholes partial differential equations. arXiv preprint arXiv:1809.02362, 2018. [26] P. Grohs, A. Jentzen, and D. Salimova. Deep neural network approximations for Monte Carlo algorithms. arXiv:1908.10828, 2019. [27] E. P. Gross. Structure of a quantized vortex in boson systems.Il Nuovo Cimento (1955-1965), 20(3):454\u2013477, 1961. [28] J. Han, A. Jentzen, and W. E. Solving high-dimensional partial differential equations using deep learning. Proceedings of the National Academy of Sciences, 115(34):8505\u20138510, 2018. [29] J. Han and J. Long. Convergence of the deep BSDE method for coupled FBSDEs.Probability, Uncertainty and Quantitative Risk, 5(1):1\u201333, 2020. [30] J. Han, J. Lu, and M. Zhou. Solving high-dimensional eigenvalue problems using deep neural networks: a diffusion Monte Carlo like approach.Journal of Computational Physics, 423:109792, 2020. [31] C. Hartmann, O. Kebiri, L. Neureither, and L. Richter. Variational approach to rare event simulation using least-squares regression.Chaos: An Interdisciplinary Journal of Nonlinear Science, 29(6):063107, 2019. [32] E. Hausenblas. A numerical scheme using It\u00f4 excursions for simulating local time resp. stochastic differential equations with reflection.Osaka journal of mathematics, 36(1):105\u2013137, 1999. [33] J. Hermann, Z. Sch\u00e4tzle, and F. No\u00e9. Deep-neural-network solution of the electronic Schr\u00f6dinger equation. Nature Chemistry, 12(10):891\u2013897, 2020. [34] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700\u20134708, 2017. [35] C. Hur\u00e9, H. Pham, and X. Warin. Deep backward schemes for high-dimensional nonlinear PDEs.Mathematics of Computation, 89(324):1547\u20131579, 2020. [36] M. Hutzenthaler, A. Jentzen, T. Kruse, T. Anh Nguyen, and P. von Wurstemberger. Overcoming the curse of dimensionality in the numerical approximation of semilinear parabolic partial differential equations.Proceedings of the Royal Society A, 476(2244):20190630, 2020. [37] M. Hutzenthaler, A. Jentzen, T. Kruse, and T. A. Nguyen. A proof that rectified deep neural networks overcome the curse of dimensionality in the numerical approximation of semilinear heat equations.SN partial differential equations and applications, 1(2):1\u201334, 2020. [38] M. Hutzenthaler, A. Jentzen, T. Kruse, et al. Multilevel Picard iterations for solving smooth semilinear parabolic heat equations.arXiv preprint arXiv:1607.03295, 2016. [39] A. D. Jagtap, K. Kawaguchi, and G. E. Karniadakis. Adaptive activation functions accelerate convergence in deep and physics-informed neural networks.Journal of Computational Physics, 404:109136, 2020. [40] A. Jentzen, D. Salimova, and T. Welti. Proof that deep artificial neural networks overcome the curse of dimensionality in the numerical approximation of Kolmogorov partial differential equations with constant diffusion and nonlinear drift coefficients.Communications in Mathematical Sciences, 19(5):1167\u20131205, 2021. [41] L. Jianyu, L. Siwei, Q. Yingjian, and H. Yaping. Numerical solution of elliptic partial differential equation using radial basis function neural networks.Neural Networks, 16(5-6):729\u2013734, 2003. [42] H. Jin, M. Mattheakis, and P. Protopapas. Unsupervised neural networks for quantum eigenvalue problems. arXiv preprint arXiv:2010.05075, 2020. [43] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, and L. Yang. Physics-informed machine learning.Nature Reviews Physics, 3(6):422\u2013440, 2021. [44] Y. Khoo, J. Lu, and L. Ying. Solving for high-dimensional committor functions using artificial neural networks. Research in the Mathematical Sciences, 6(1):1, 2019. [45] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In Y. Bengio and Y. LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.url: http://arxiv.org/abs/1412.6980 . [46] P. E. Kloeden and E. Platen. Stochastic differential equations. InNumerical Solution of Stochastic Differential Equations, pages 103\u2013160. Springer, 1992. [47] S. Kremsner, A. Steinicke, and M. Sz\u00f6lgyenyi. A deep neural network algorithm for semilinear elliptic PDEs with applications in insurance mathematics.Risks, 8(4):136, 2020. [48] I. E. Lagaris, A. Likas, and D. I. Fotiadis. Artificial neural network methods in quantum mechanics.Computer Physics Communications, 104(1-3):1\u201314, 1997. [49] I. E. Lagaris, A. Likas, and D. I. Fotiadis. Artificial neural networks for solving ordinary and partial differential equations.IEEE transactions on neural networks, 9(5):987\u20131000, 1998. [50] I. E. Lagaris, A. C. Likas, and D. G. Papageorgiou. Neural-network methods for boundary value problems with irregular boundaries.IEEE Transactions on Neural Networks, 11(5):1041\u20131049, 2000. [51] H. Lee and I. S. Kang. Neural algorithm for solving differential equations.Journal of Computational Physics, 91(1):110\u2013131, 1990. [52] Q. Li, B. Lin, and W. Ren. Computing committor functions for the study of rare events using deep learning. The Journal of Chemical Physics, 151(5):054112, 2019. [53] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar. Fourier neural operator for parametric partial differential equations.arXiv preprint arXiv:2010.08895, 2020. [54] J. Lu and Y. Lu. A priori generalization error analysis of two-layer neural networks for solving high dimensional Schr\u00f6dinger eigenvalue problems.arXiv preprint arXiv:2105.01228, 2021. [55] J. Lu and J. Nolen. Reactive trajectories and the transition path process.Probability Theory and Related Fields, 161(1):195\u2013244, 2015. [56] M. Magill, F. Qureshi, and H. W. de Haan. Neural networks trained to solve differential equations learn general representations.arXiv preprint arXiv:1807.00042, 2018. [57] S. Mishra and R. Molinaro. Estimates on the generalization error of physics informed neural networks (PINNs) for approximating PDEs.arXiv preprint arXiv:2006.16144, 2020. [58] J. M\u00fcller and M. Zeinhofer. Deep Ritz revisited.arXiv preprint arXiv:1912.03937, 2019. [59] J. M\u00fcller and M. Zeinhofer. Notes on exact boundary values in residual minimisation. arXiv preprint arXiv:2105.02550, 2021. [60] N. N\u00fcsken and L. Richter. Solving High-Dimensional Hamilton\u2013Jacobi\u2013Bellman PDEs Using Neural Networks: Perspectives from the Theory of Controlled Diffusions and Measures on Path Space.SN Partial Differential Equations and Applications, 2(4):1\u201348, 2021. [61] \u00c9. Pardoux. Backward stochastic differential equations and viscosity solutions of systems of semilinear parabolic and elliptic PDEs of second order. InStochastic Analysis and Related Topics VI, pages 79\u2013127. Springer, 1998. [62] E. Pardoux and S. Peng. Adapted solution of a backward stochastic differential equation.Systems & Control Letters, 14(1):55\u201361, 1990. [63] \u00c9. Pardoux and S. Zhang. Generalized BSDEs and nonlinear Neumann boundary value problems.Probability Theory and Related Fields, 110(4):535\u2013558, 1998. [64] G. A. Pavliotis.Stochastic processes and applications: diffusion processes, the Fokker-Planck and Langevin equations, volume 60. Springer, 2014. [65] D. Pfau, J. S. Spencer, A. G. Matthews, and W. M. C. Foulkes. Ab initio solution of the many-electron Schr\u00f6dinger equation with deep neural networks.Physical Review Research, 2(3):033429, 2020. [66] L. P. Pitaevskii. Vortex lines in an imperfect Bose gas.Sov. Phys. JETP, 13(2):451\u2013454, 1961. [67] M. Raissi. Forward-backward stochastic neural networks: deep learning of high-dimensional partial differential equations.arXiv preprint arXiv:1804.07010, 2018. [68] M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.Journal of Computational Physics, 378:686\u2013707, 2019. [69] M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics informed deep learning (part I): data-driven solutions of nonlinear partial differential equations.arXiv preprint arXiv:1711.10561, 2017. [70] L. Richter, L. Sallandt, and N. N\u00fcsken. Solving High-Dimensional Parabolic PDEs Using the Tensor Train Format. In M. Meila and T. Zhang, editors,Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 ofProceedings of Machine Learning Research, pages 8998\u20139009. PMLR, 2021.url: http://proceedings.mlr.press/v139/richter21a.html . [71] G. M. Rotskoff and E. Vanden-Eijnden. Learning with rare data: using active importance sampling to optimize objectives dominated by rare events.arXiv preprint arXiv:2008.06334, 2020. [72] J. Sirignano and K. Spiliopoulos. DGM: a deep learning algorithm for solving partial differential equations. Journal of computational physics, 375:1339\u20131364, 2018. [73] T. Uchiyama and N. Sonehara. Solving inverse problems in nonlinear PDEs by recurrent neural networks. In IEEE International Conference on Neural Networks, pages 99\u2013102. IEEE, 1993. [74] R. van der Meer, C. Oosterlee, and A. Borovykh. Optimally weighted loss functions for solving PDEs with neural networks.arXiv preprint arXiv:2002.06269, 2020. [75] S. Wang, Y. Teng, and P. Perdikaris. Understanding and mitigating gradient flow pathologies in physicsinformed neural networks.SIAM Journal on Scientific Computing, 43(5):A3055\u2013A3081, 2021. [76] S. Wang, H. Wang, and P. Perdikaris. On the eigenvector bias of Fourier feature networks: from regression to solving multi-scale PDEs with physics-informed neural networks.Computer Methods in Applied Mechanics and Engineering, 384:113938, 2021. [77] S. Wang, X. Yu, and P. Perdikaris. When and why PINNs fail to train: a neural tangent kernel perspective. Journal of Computational Physics, 449:110768, 2022. [78] Y. Zang, G. Bao, X. Ye, and H. Zhou. Weak adversarial networks for high-dimensional partial differential equations.Journal of Computational Physics, 411:109409, 2020. [79] J. Zhang.Backward stochastic differential equations. Springer, 2017. [80] W. Zhang, T. Li, and C. Sch\u00fctte. Solving eigenvalue PDEs of metastable diffusion processes using artificial neural networks.arXiv preprint arXiv:2110.14523, 2021.","title":"\u53c2\u8003\u6587\u732e"},{"location":"Models/PINNs/PN-2207.04084/","text":"Adaptive Self-Supervision Algorithms for Physics-Informed Neural Networks \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u9002\u5e94\u81ea\u76d1\u7763\u7b97\u6cd5 \u4f5c\u8005: Shashank Subramanian | Robert M. Kirby | Michael W. Mahoney | Amir Gholami \u673a\u6784: \u65f6\u95f4: 2022-07-08 \u9884\u5370: arXiv:2207.04084v1 \u9886\u57df: \u6807\u7b7e: #PINN #\u5f00\u6e90 \u5f15\u7528: 29 \u7bc7 (\u81ea\u5f15 1 \u7bc7) \u4ee3\u7801: Github cur{ color:red; } model{ text-decoration: underline; text-decoration-color: orange; } term{ text-decoration: underline; text-decoration-color: purple; } Abstract \u6458\u8981 Physics-informed neural networks (PINNs) incorporate physical knowledge from the problem domain as a soft constraint on the loss function, but recent work has shown that this can lead to optimization difficulties. Here, we study the impact of the location of the collocation points on the trainability of these models. We find that the vanilla PINN performance can be significantly boosted by adapting the location of the collocation points as training proceeds. Specifically, we propose a novel adaptive collocation scheme which progressively allocates more collocation points (without increasing their number) to areas where the model is making higher errors (based on the gradient of the loss function in the domain). This, coupled with a judicious restarting of the training during any optimization stalls (by simply resampling the collocation points in order to adjust the loss landscape) leads to better estimates for the prediction error. We present results for several problems, including a 2D Poisson and diffusion-advection system with different forcing functions. We find that training vanilla PINNs for these problems can result in up to 70% prediction error in the solution, especially in the regime of low collocation points. In contrast, our adaptive schemes can achieve up to an order of magnitude smaller error, with similar computational complexity as the baseline. Furthermore, we find that the adaptive methods consistently perform on-par or slightly better than vanilla PINN method, even for large collocation point regimes. The code for all the experiments has been open sourced and available at Github. 1. Introduction \u4ecb\u7ecd A key aspect that distinguishes scientific ML (SciML) [4,10,14,16,23,28] from other ML tasks is that scientists typically know a great deal about the underlying physical processes that generate their data. For example, while the Ordinary Differential Equations (ODEs) or Partial Differential Equations (PDEs) used to simulate the physical phenomena may not capture every detail of a physical system,they often provide a reasonably good approximation. In some cases, we know that physical systems have to obey conservation laws (mass, energy, momentum, etc.). In other cases, we can learn these constraints, either exactly or approximately, from the data. In either case, the main challenge in SciML lies in combining such scientific prior domain-driven knowledge with large-scale data-driven methods from ML in a principled manner. One popular method to incorporate scientific prior knowledge is to incorporate them as soft-constraints throughout training, as proposed with Physics Informed Neural Networks (PINNs) [10,12,17]. These models use penalty method techniques from optimization [3] and formulate the solution of the PDE as an unconstrained optimization problem that minimizes a self-supervision loss function that incorporates the domain physics (PDEs) as a penalty (regularization) term. Formulating the problem as a soft-constraint makes it very easy to use existing auto-differentiation frameworks for SciML tasks. However, training PINNs this way can be very difficult, and it is often difficult to solve the optimization problem [6,11,25]. This could be partly because the self-supervision term typically contains complex terms such as (higher-order) derivatives of spatial functions and other nonlinearities that cause the loss term to become ill-conditioned [11]. This is very different than unit\u2018pball or other such convex functions, more commonly used as regularization terms in ML. Several solutions such as loss scaling [25], curriculum or sequence-to-sequence learning [11], tuning of loss function weights [13], and novel network architectures [19] have been proposed to address this problem. One overlooked, but very important, parameter of the training process is the way that the self-supervision is performed in PINNs, and in particular which data points in the domain are used for enforcing the physical constraints (commonly referred to as collocation points in numerical analysis). In the original work of [17],the collocation points are randomly sampled in the beginning of the training and kept constant throughout the learning process. However, we find that this is sub-optimal, and instead we propose adaptive collocation schemes. We show that these schemes can result in an order of magnitude better performance, with similar computational overhead. Background. We focus on scientific systems that have a PDE constraint of the following form:(1.1)F(u(x)) = 0,x \u2208 \u2126 \u2282 Rd,whereFis a differential operator representing the PDE,u(x) is the state variable (i.e., physical quantity of interest), \u2126 is the physical domain, andxrepresents spatial domain (2D in all of our results). To ensure existence and uniqueness of an analytical solution, there are additional constraints specified on the boundary,d\u2126, as well (such as periodic or Dirichlet boundary conditions). One possible approach to learn a representation for the solution is to incorporate the PDE as a hard constraint, and formulate a loss function that measures the prediction error on the boundary (where data points are available):(1.2)min\u03b8L(u)s.t.F(u) = 0,whereL(u) is typically a data mismatch term (this includes initial/boundary conditions but can also include observational data points), and whereFis a constraint on the residual of the PDE system (i.e.,F(u) is the residual) under consideration. Since constrained optimization is typically more difficult than unconstrained optimization [3], this constraint is typically relaxed and added as a penalty term to the loss function. This yields the following unconstrained optimization problem, namely the PINNs (soft constrained) optimization problem:(1.3)min\u03b8L(u) + \u03bbFLF. In this problem formulation, the regularization parameter,\u03bbF, controls the weight given to the PDE constraints, as compared to the data misfit term;\u03b8denotes the parameters of the model that predictsu(x),which is often taken to be a neural network; and the PDE loss functional term,LF, can be considered as a self-supervised loss, as all the information comes from the PDE system we are interested in simulating,instead of using direct observations. Typically a Euclidean loss function is used to measure the residual of the PDE for this loss function,kF(u)k22, where the\u20182norm is computed at discrete points (collocation points) that are randomly sampled from \u2126. This loss term is often the source of the training difficulty with PINNs [6, 11], which is the focus of our paper. Main contributions. Unlike other work in the literature, which has focused on changing the training method or the neural network (NN) architecture, here we focus on the self-supervision component of PINNs,and specifically on the selection of the collocation points. In particular, we make the following contributions:\u2022We study the role of the collocation points for two PDE systems: steady state diffusion (Poisson);and diffusion-advection. We find that keeping the collocation points constant throughout training is a sub-optimal strategy and is an important source of the training difficulty with PINNs. This is particularly true for cases where the PDE problem exhibits local behaviour (e.g., in presence of sharp, or very localized, features).\u2022We propose an alternative strategy of resampling the collocation points when training stalls. Although this strategy is simple, it can lead to significantly better reconstruction (see Tab. 1 and Fig. 2). Im-portantly, this approach does not increase the computational complexity, and it is easy to implement.\u2022We propose to improve the basic resampling scheme with a gradient-based adaptive scheme. This adaptive scheme is designed to help to relocate the collocation points to areas with higher loss gradient,without increasing the total number of points (see Algorithm 1 for the algorithm). In particular,we progressively relocate the points to areas of high gradient as training proceeds. This is done through a cosine-annealing that gradually changes the sampling of collocation points from uniform to adaptive through training. We find that this scheme consistently achieves better performance than the basic resampling method, and it can lead to more than 10x improvements in the prediction error(see Tab. 1, Fig. 2).\u2022We extensively test our adaptive schemes for the two PDE systems of Poisson and diffusion-advection while varying the number of collocation points for problems with both smooth or sharp features. While the resampling and adaptive schemes perform similarly in the large collocation point regime,the adaptive approach shows significant improvement when the number of collocation points is small and the forcing function is sharp (see Tab. 2). 2. Related Work \u76f8\u5173\u5de5\u4f5c There has been a large body of work studying PINNs [5,7,9,18,20,21,30] and the challenges associated with their training [6,11,24,25,26,27]. The work of [25] notes these challenges and proposes a loss scaling method to resolve the training difficulty. Similar to this approach, some works have treated the problem as a multi-objective optimization and tune the weights of the different loss terms[2,29]. A more formal approach was suggested in [13] where the weights are learned by solving a minimax optimization problem that ascends in the loss weight space and descends in the model parameter space. This approach was extended in [15] to shift the focus of the weights from the loss terms to the training data points instead, and the minimax forces the optimization to pay attention to specific regions of the domain. However, minimax optimization problems are known to be hard to optimize and introduce additional complexity and computational expense. Furthermore, it has been shown that using curriculum or sequence-to-sequence learning can ameliorate the training difficulty with PINNs [11]. More recently, the work of [24] shows that incorporating causality in time can help training for time-dependent PDEs. There is also recent work that studies the role of the collocation points. For instance, [22] refines the collocation point set without learnable weights. They propose an auxiliary NN that acts as a generative model to sample new collocation points that mimic the PDE residual. However, the auxiliary network also has to be trained in tandem with the PINN. The work of [14] proposes an adaptive collocation scheme where the points are densely sampled uniformly and trained for some number of iterations. Then the set is extended by adding points in increasing rank order of PDE residuals to refine in certain locations (of sharp fronts, for example) and the model is retrained. However, this method can increase the computational overhead, as the number of collocation points is progressively increased. Furthermore, in 1 the authors show that the latter approach can lead to excessive clustering of points throughout training. To address this, instead they propose to add points based on an underlying density function defined by the PDE residual. Both these schemes keep the original collocation set (the low residual points) and increase the training dataset sizes as the optimization proceeds. Unlike the work of [8,14], we focus on using gradient of the loss function, instead of the nominal loss value, as the proxy to guide the adaptive resampling of the collocation points. We show that this approach leads to better localization of the collocation points, especially for problems with sharp features. Furthermore, we incorporate a novel cosine-annealing scheme, which progressively incorporates adaptive sampling as training proceeds. Importantly, we also keep the number of collocation points the same. Not only does this not increase the computational overhead, but this is also easier to implement as well\uff0e 3. Methods \u65b9\u6cd5 In PINNs , we use a feedforward NN, denoted \\(NN(\\pmb{x};\\theta)\\) , that is parameterized by weights and biases, \\(\\theta\\) , takes as input values for coordinate points, \\(\\pmb{x}\\) , and outputs the solution value \\(u(\\pmb{x})\\in\\mathbb{R}\\) at these points. As described in Section 1 , the model parameters \\(\\theta\\) are optimized through the loss function: \u5728 PINNs \u4e2d, \u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u6709\u6743\u91cd\u548c\u504f\u5dee \\(\\theta\\) \u53c2\u6570\u5316\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc \\(NN(\\pmb{x};\\theta)\\) , \u8f93\u5165\u503c\u4e3a\u914d\u7f6e\u70b9 \\(\\pmb{x}\\) \u5e76\u8f93\u51fa\u89e3\u5728\u8fd9\u4e9b\u70b9\u4e0a\u7684\u503c \\(u(\\pmb{x})\\in\\mathbb{R}\\) . \u6b63\u5982\u7b2c\u4e00\u8282\u6240\u63cf\u8ff0\u7684, \u6a21\u578b\u53c2\u6570 \\(\\theta\\) \u901a\u8fc7\u4ee5\u4e0b\u635f\u5931\u51fd\u6570\u8fdb\u884c\u4f18\u5316: \\[ \\min_{\\theta}\\mathcal{L}_{\\mathcal{B}} + \\lambda_{\\mathcal{F}}\\mathcal{L}_{\\mathcal{F}}. \\tag{3.1} \\] We focus on boundary-value (steady state) problems and define the two loss terms as: \u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u8fb9\u503c (\u7a33\u6001) \u95ee\u9898\u5e76\u5b9a\u4e49\u76f8\u5e94\u7684\u4e24\u4e2a\u635f\u5931\u9879\u5982\u4e0b: \\[ \\mathcal{L}_{\\mathcal{B}} =\\frac{1}{n_b} \\sum_{i=1}^{n_b}\\|u(\\pmb{x}_b^i)-\\hat{u}(\\pmb{x}_b^i)\\|_2^2, \\tag{3.2a} \\] \\[ \\mathcal{L}_{\\mathcal{F}} =\\frac{1}{n_c} \\sum_{i=1}^{n_c}\\|\\mathcal{F}(u(\\pmb{x}_c^i))\\|_2^2, \\tag{3.2b} \\] where \\(u\\) is the model predicted solution, \\(\\hat{u}\\) is the true solution or data, \\(\\pmb{x}_b^i\\) are points on the boundary, and \\(\\pmb{x}_c^i\\) are collocation points uniformly sampled from the domain \\(\\Omega\\) . Here, \\(n_b\\) and \\(n_c\\) are the number of boundary and collocation points, respectively; and the boundary loss term \\(\\mathcal{L}_{\\mathcal{B}}\\) implements a Dirichlet boundary condition, where we assume that the solution values are known on the boundary \\(d\\Omega\\) . \u5176\u4e2d \\(u\\) \u662f\u6a21\u578b\u9884\u6d4b\u89e3, \\(\\hat{u}\\) \u662f\u771f\u89e3\u6216\u6570\u636e, \\(\\pmb{x}_b^i\\) \u662f\u8fb9\u754c\u4e0a\u7684\u70b9, \\(\\pmb{x}_c^i\\) \u662f\u4ece\u5b9a\u4e49\u57df \\(\\Omega\\) \u4e2d\u5747\u5300\u91c7\u6837\u7684\u914d\u7f6e\u70b9.\u5f0f\u5b50\u4e2d\u7684 \\(n_b\\) \u548c \\(n_c\\) \u5206\u522b\u8868\u793a\u8fb9\u754c\u70b9\u548c\u914d\u7f6e\u70b9\u7684\u6570\u91cf, \u5e76\u4e14\u8fb9\u754c\u635f\u5931\u9879 \\(\\mathcal{L}_{\\mathcal{B}}\\) \u4f7f\u7528\u4e86 Dirichlet \u8fb9\u754c\u6761\u4ef6, \u5373\u6211\u4eec\u5047\u8bbe\u89e3\u5728\u8fb9\u754c \\(d\\Omega\\) \u4e0a\u7684\u503c\u5df2\u77e5. In PINNs 2 , the collocation points used in Eq.3.2b are randomly sampled with a uniform probability over the entire space \\(\\Omega\\) in the beginning of training and then kept constant afterwards (we refer to this approach as Baseline). While a uniformly distributed collocation point set may be sufficient for simple PDEs with smooth features, we find them to be sub-optimal when the problem exhibits sharp/local features, or even fail to train. To address this, we propose the following schemes. \u5728 PINNs \u4e2d, \u4e0a\u8ff0\u516c\u5f0f\u4f7f\u7528\u7684\u914d\u7f6e\u70b9\u662f\u5728\u8bad\u7ec3\u5f00\u59cb\u662f\u5728\u6574\u4e2a\u7a7a\u95f4 \\(\\Omega\\) \u4e0a\u6839\u636e\u5747\u5300\u5206\u5e03\u8fdb\u884c\u968f\u673a\u91c7\u6837\u7684, \u7136\u540e\u5728\u4e4b\u540e\u4fdd\u6301\u4e0d\u53d8 (\u6211\u4eec\u5c06\u8fd9\u4e00\u65b9\u6cd5\u4f5c\u4e3a\u57fa\u7ebf). \u867d\u7136\u5bf9\u4e8e\u6709\u5149\u6ed1\u6027\u8d28\u7684\u7b80\u5355\u504f\u5fae\u5206\u65b9\u7a0b\u6765\u8bf4, \u4e00\u4e2a\u5747\u5300\u5206\u5e03\u7684\u914d\u7f6e\u70b9\u96c6\u53ef\u80fd\u5df2\u7ecf\u8db3\u591f\u4e86, \u6211\u4eec\u53d1\u73b0\u5f53\u95ee\u9898\u51fa\u73b0 sharp/\u5c40\u90e8\u6027\u65f6, \u53ef\u80fd\u4f1a\u51fa\u73b0\u6b21\u4f18\u89e3\u751a\u81f3\u8bad\u7ec3\u5931\u8d25. \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u5982\u4e0b\u65b9\u6848. Resampling Collocation Points \u91cd\u91c7\u6837\u914d\u7f6e\u70b9 Current PINNs are typically optimized with LBFGS . In our experiments, we found that in the baseline approach LBFGS often fails to find a descent direction and training stalls, even after hyperparamter tuning. This agrees with other results reported in the literature [6,11,25]. We find that this is partially due to the fact that the collocation points are kept constant and not changed. The simplest approach to address this is to resample the collocation points when LBFGS stalls. We refer to this approach as Resampling. As we will discuss in the next section, we find this approach to be helpful for cases with moderate to large number of collocation points. Adaptive Sampling \u81ea\u9002\u5e94\u91c7\u6837 While the Resampling method is effective for large number of collocation points, we found it to be sub-optimal in the small collocation point regime, especially for problems with sharp/localized features. In this case, the Resampling method still uses a uniform distribution with which to sample the new the collocation points; and, in the presence of a small number of collocation points and/or sharp/localized features, this is not an optimal allocation of the points. Ideally, we want to find a probability distribution, as a replacement for the uniform distribution, that can improve trainability of PINNs for a given number of collocation points and/or computational budget. There are several possibilities to define this distribution. The first intuitive approach would be to use the value of the PDE residual (Eq. 3.2b), and normalize it as a probability distribution. This could then be used to sample collocation points based on the loss values in the domain. That is, more points would be sampled in areas with with higher PDE residual, and vice versa. We refer to this approach as ADAPTIVE-R sampling (withRreferring to the PDE residual). An alternative is to use the gradient of the loss function (PDE loss termLF) w.r.t. the spatial grid, using that as the probability distribution with which to sample the collocation points. We refer to this approach as ADAPTIVE-G (withG referring to gradient of the loss). As we will show in the next section, when combined with a cosine annealing scheme (discussed next), both of these adaptive schemes consistently perform better than the Resampling scheme. Progressive Adaptive Sampling \u6e10\u8fdb\u81ea\u9002\u5e94\u91c7\u6837 Given the non-convex nature of the problem, it might be important to not overly constrain the NN to be too locally focused, as the optimization procedure could get stuck in a local minima. However, this can be addressed by progressively incorporating adaptive sampling as training proceeds. In particular, we use a cosine annealing strategy. This allows the NN to periodically alternate between focusing on regions of high error as well as uniformly covering larger parts of the sample space, over a period of iterations. Specifically, in each annealing period, we start with a full uniform sampling, and progressively incorporate adaptively sampled points using a cosine schedule rule of \\(\\eta=\\dfrac{1}{2}(1+\\cos\\pi\\dfrac{T_c}{T})\\) , where \\(\\eta\\) is the fraction of points uniformly sampled, \\(T_c\\) is the number of epochs since the last restart, and \\(T\\) is the length of the cosine schedule. We use this schedule to resample the collocation every \\(e\\) epochs. Given the periodic nature of the cosine annealing, that approach balances local adaptivity without losing global information. We outline the adaptive sampling Algorithm 1 . Algorithm 1. Adaptive Sampling for Self-Supervision in PINNs Require : Loss \\(\\mathcal{L}\\) , NN model, number of collocation points \\(n_c\\) , PDE regularization \\(\\lambda_{\\mathcal{F}}\\) , \\(T\\) , \\(s_w\\) , momentum \\(\\gamma\\) , max epochs \\(i_{max}\\) 1: \\(i\\leftarrow 0\\) 2: while \\(i\\leq i_{max}\\) do 3: \\(\\qquad\\) Compute proxy function as the loss gradient ( ADAPTIVE-G ) or PDE residual ( ADAPTIVE-R ) 4: \\(\\qquad\\) Current proxy \\(\\mathcal{P}_i\\leftarrow\\mathcal{P} + \\gamma\\mathcal{P}_{i-1}\\) 5: \\(\\qquad\\) \\(T_c\\leftarrow i \\mod T\\) 6: \\(\\qquad\\) \\(\\eta \\leftarrow\\) cosine-schedule \\((T_c, T)\\) 7: \\(\\qquad\\) if \\(i \\mod e\\) is true then 8: \\(\\qquad\\qquad\\) Sample \\(\\eta n_c\\) points \\(\\pmb{x}_u\\) uniformly 9: \\(\\qquad\\qquad\\) Sample \\((1 - \\eta)n_c\\) points \\(\\pmb{x}_a\\) using proxy function \\(\\mathcal{P}_i\\) 10: \\(\\qquad\\) end if 11: \\(\\qquad\\) \\(\\pmb{x}_c\\leftarrow \\pmb{x}_u\\cup \\pmb{x}_a\\) 12: \\(\\qquad\\) Input \\(\\pmb{x}\\leftarrow\\pmb{x}_b\\cup\\pmb{x}_c\\) where \\(\\pmb{x}_b\\) are boundary points 13: \\(\\qquad\\) \\(u \\leftarrow NN(\\pmb{x}; \\theta)\\) 14: \\(\\qquad\\) \\(\\mathcal{L} \\leftarrow \\mathcal{L}_\\mathcal{B}+ \\lambda_\\mathcal{F}\\mathcal{L}_\\mathcal{F}\\) 15: \\(\\qquad\\) \\(\\theta \\leftarrow\\) optimizer-update \\((\\theta, \\mathcal{L})\\) 16: \\(\\qquad\\) if stopping-criterion is true then 17: \\(\\qquad\\qquad\\) reset cosine scheduler \\(T_c\\leftarrow 0\\) 18: \\(\\qquad\\) end if 19: \\(\\qquad\\) \\(i \\leftarrow i + 1\\) 20: end while 4. Experiments \u5b9e\u9a8c In this section, we show examples that highlight the prediction error improvement using our adaptive self-supervision method on two PDE systems: Poisson\u2019s equation \u00a74.1 and (steady state)diffusion-advection \u00a74.2.Problem setup. We use the same problem set up as in [11,17,25] for the NN model, which is a feed forward model with hyperbolic tangent activation function, trained with LBFGS optimizer. We focus on2D spatial domains in \u2126 = [0,1]2. The training data set contains points that are randomly sampled from a uniform 2562mesh on \u2126. The testing data set is the set of all 2562points, along with the true solution of the PDE\u02c6u(x) at these points. Furthermore, we use a constant regularization parameter of\u03bbF= 1e-4 for all the runs, which we found to be a good balance between the boundary term and the PDE residual. To ensure a fair comparison, we tune the rest of the hyperparameters both for the baseline model as well as for the adaptive schemes. For tuning the parameters, we use the validation loss computed by calculating the total loss over randomly sampled points in the domain (30K points for all the experiments). Note that we do not use any signal from the analytical solution, and instead only use the loss in Eq. 3.1.Metrics. We train the optimizer for 5000 epochs with a stall criterion when the loss does not change for 10 epochs. We keep track of the minimum validation loss in order to get the final model parameters for testing. We compute our prediction error using two metrics: the\u20182relative error,\u00b51=ku \u2212 \u02c6uk2/k\u02c6ukand the\u20181error\u00b52=ku \u2212 \u02c6uk1, whereuis the model prediction solution from the best validation loss epoch and\u02c6uis the true solution. All runs are trained on an A100 NVIDIA GPU on the Perlmutter supercomputer. 4.1. 2D Poisson's Equation \u4e8c\u7ef4\u6cca\u677e\u65b9\u7a0b Problem Formulation \u95ee\u9898\u5f62\u5f0f\u5316 We consider a prototypical elliptic system defined by the Poisson\u2019s equation with source function f(x). This system represents a steady state diffusion equation: \\[ (4.1)\u2212 div K\u2207u = f(x),x \u2208 \u2126, \\] whereKdenotes the diffusion tensor. For homogeneous diffusion tensors, the solution of the poisson\u2019s equation with doubly-periodic boundary conditions can be computed using the fast Fourier transform on a discrete grid as:(4.2)\u02c6u = F\u22121\ufffd\u22121\u2212(k2xk11+ k2yk22+ 2kxkyk12)F(f(x))\ufffd,whereFis the Fourier transform,kx, kyare the frequencies in the Fourier domain, andk11, k22, k12are the diagonal and off-diagonal coefficients of the diffusion tensorK. We enforce the boundary conditions as Dirichlet boundary conditions using the true solution to circumvent the ill-posedness of the doubly-periodic Poisson\u2019s equation.1We use a Gaussian function as the source with standard deviation\u03c3fand consider the diffusion tensork11= 1, k22= 8, k12= 4 to make the problem anisotropic. We consider two test-cases:(i) TC1: smooth source function with\u03c3f= 0.1 (ii) TC2: sharp source function with\u03c3f= 0.01. We show these source functions and the corresponding target solutions in Fig. 1. For any experiment, we sweep over all the hyperparameters and select the ones that show the lowest/best validation loss for the final model. Observations. We start by examining the performance of the difference methods for the relatively small number of collocation points ofnc= 1,000 (which corresponds to 1.5% of the 256\u00d7256 domain \u2126). We report the errors\u00b51and\u00b52for the different schemes in Tab. 1. We also visualize the predicted solution for each method in Fig. 2, along with the location of the collocation points overlayed for the final model. We can clearly see that the baseline model does not converge (despite hyperparameter tuning) due to the optimizer stalls. However, Resampling achieves significantly better errors, especially for the smooth source function setup (TC1). However, for the sharp source experiment (TC2), the resampling does not help and shows an error of about 50%.Overall, the adaptive schemes show much better (or comparable) prediction errors for both test-cases. In particular, ADAPTIVE-R and ADAPTIVE-G achieve about 2\u20135% relative error (\u00b51) for both TC1 and TC2. The visual reconstruction shown in Fig. 2 also shows the clearly improved prediction with the adaptive schemes (last two columns), as compared to the baseline with/without resampling (first two columns). Note that the ADAPTIVE-G method assigns more collocation points around the sharp features. This is due to the fact that it uses the gradient information for its probability distribution, instead of the residual of the PDE which is used in ADAPTIVE-R method. To show the effect of the scheduler, we show an ablation study with the cosine-annealing scheduler in the appendix (see Fig. A.4).We then repeat the same experiment, but now varying the number of collocation points,nc, from 500to 8K, and we report the relative error (\u00b51) in Tab. 2. We observe a consistent trend, where the Baseline(PINN training without resampling) does not converge to a good solution, whereas ADAPTIVE-G consistently achieves up to an order of magnitude better error. Also, note that the performance of the Resampling method significantly improves and becomes on par with ADAPTIVE-G as we increasenc. This is somewhat expected since at large number of collocation points resampling will have the chance to sample points near the areas with sharp features. In Fig. A.1, we show the errors for every test-case as a function of number of collocation points using 10 different random seed values to quantify the variance in the different methods. We observe that the adaptive schemes additionally show smaller variances across seeds, especially for the test-cases with sharp sources. 4.2. 2D Diffusion-Advection Equation We next look at a steady-state 2D diffusion-advection equation with source function f(x), diffusion tensor K, and velocity vector v: For homogeneous diffusion tensors and velocity vectors, the solution of the advection-diffusion equation with doubly-periodic boundary conditions can also be computed using the fast Fourier transform on a discrete grid as: \u02c6u = F\u22121\ufffd\u22121 g1\u2212 g2 F(f(x))\ufffd, g1= \u2212(k2xk11+ k2yk22+ 2kxkyk12), g2= ikxv1+ ikyv2, (4.4) whereFis the Fourier transform,i=\u221a\u22121,kx, kyare the frequencies in the Fourier domain,k11, k22, k12are the diagonal and off-diagonal coefficients of the diffusion tensorK, andv1, v2are the velocity components. As before, we enforce the boundary conditions as Dirichlet boundary conditions using the true solution,and we consider a Gaussian function as the source with standard deviation\u03c3f. We use a diffusion tensor k11= 1, k22= 8, k12= 4 and velocity vectorv1= 40, v2= 10 to simulate sufficient advection. We consider two test-cases as before: (i) TC3: smooth source function with\u03c3f= 0.1 (ii) TC4: sharp source function with \u03c3f= 0.01. We show the source functions and the target solutions in Fig. 3.Observations. We observe a very similar behaviour for the reconstruction errors as in the previous experiments. As before, we start withnc= 1,000 collocation points, and we report the results in Tab. 3and Fig. 4. Here, the baseline achieves slightly better performance for TC3 (14%) but completely fails (100%error) for the TC4 test case, which includes a sharper forcing function. However, the Resampling achieves better results for both cases. Furthermore, the best performance is achieved by the adaptive methods. Finally, in Tab. 4 we report the relative errors for the baseline and adaptive schemes with various numbers of collocation pointsnc. Similar to the Poisson system, larger values ofncshow good performance, but the baselines underperform in the low data regime for sharp sources. The resampling achieves better errors, while the adaptive methods once again consistently achieve the best performance for both data regimes. 5. Conclusions \u7ed3\u8bba We studied the impact of the location of the collocation points in training SciML models, focusing on the popular class of PINN models, and we showed that the vanilla PINN strategy of keeping the collocation points fixed throughout training often results in suboptimal solutions. This is particularly the case for PDE systems with sharp (or very localized) features. We showed that a simple strategy of resampling collocation points during optimization stalls can significantly improve the reconstruction error, especially for moderately large number of collocation points. We also proposed adaptive collocation schemes to obtain a better allocation of the collocation points. This is done by constructing a probability distribution derived from either the PDE residual ( ADAPTIVE-R ) or its gradient w.r.t. the input ( ADAPTIVE-G ). We found that by progressively incorporating the adaptive schemes, we can achieve up to an order of magnitude better solutions, as compared to the baseline, especially for the regime of a small number of collocation points and with problems that exhibit sharp (or very localized) features. Some limitations of this current work include the following: we did not change the NN architecture (it was fixed as a feed forward NN) or tune hyperparameters relating to the architecture (which can be a significant factor in any analysis); and we only focused on 2D spatial systems (it is known that time-dependent or 3D or higher-dimensional systems can show different behaviours and may benefit from different kinds of adaptivity in space and time). We leave these directions to future work. However, we expect that techniques such as those we used here that aim to combine in a more principled way domain-driven scientific methods and data-driven ML methods will help in these cases as well. Reference \u53c2\u8003\u6587\u732e [2] Rafael Bischof and Michael Kraus. Multi-Objective Loss Balancing for Physics-Informed Deep Learning. arXiv preprint arXiv:2110.09813, 2021. [3] (Book) Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge university press, 2004. [4] Steven L Brunton, Bernd R Noack, and Petros Koumoutsakos. Machine learning for fluid mechanics. Annual Review of Fluid Mechanics, 52:477\u2013508, 2020. [5] Yuyao Chen, Lu Lu, George Em Karniadakis, and Luca Dal Negro. Physics-informed neural networks for inverse problems in nano-optics and metamaterials. Optics express, 28(8):11618\u201311633, 2020. [6] C. Edwards. Neural networks learn to speed up simulations. Communications of the ACM, 65(5):27\u201329,2022. [7] Nicholas Geneva and Nicholas Zabaras. Modeling the dynamics of pde systems with physics-constrained deep auto-regressive networks. Journal of Computational Physics, 403:109056, 2020. [9] Xiaowei Jin, Shengze Cai, Hui Li, and George Em Karniadakis. Nsfnets (navier-stokes flow nets): Physics-informed neural networks for the incompressible navier-stokes equations. Journal of Computational Physics, 426:109951, 2021. [10] George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning. Nature Reviews Physics, 3(6):422\u2013440, 2021. [11] Aditi Krishnapriyan, Amir Gholami, Shandian Zhe, Robert Kirby, and Michael W Mahoney. Characterizing possible failure modes in physics-informed neural networks. NeurIPS 2021. [12] Isaac E Lagaris, Aristidis Likas, and Dimitrios I Fotiadis. Artificial neural networks for solving ordinary and partial differential equations. IEEE transactions on neural networks, 9(5):987\u20131000, 1998. [13] Dehao Liu and Yan Wang. A dual-dimer method for training physics-constrained neural networks with minimax architecture. Neural Networks, 136:112\u2013125, 2021. [14] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. Deepxde: A deep learning library for solving differential equations. SIAM Review, 63(1):208\u2013228, 2021. [15] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft attention mechanism. arXiv preprint arXiv:2009.04544, 2020. [16] Christopher Rackauckas, Yingbo Ma, Julius Martensen, Collin Warner, Kirill Zubov, Rohit Supekar, Dominic Skinner, Ali Ramadhan, and Alan Edelman. Universal differential equations for scientific machine learning. arXiv preprint arXiv:2001.04385, 2020. [18] Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations. Science, 367(6481):1026\u20131030, 2020. [19] Amuthan A Ramabathiran and Prabhu Ramachandran. Spinn: Sparse, physics-based, and partially interpretable neural networks for pdes. Journal of Computational Physics, 445:110600, 2021. [20] Francisco Sahli Costabal, Yibo Yang, Paris Perdikaris, Daniel E Hurtado, and Ellen Kuhl. Physics-informed neural networks for cardiac activation mapping. Frontiers in Physics, 8:42, 2020. [21] Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial differential equations. Journal of computational physics, 375:1339\u20131364, 2018. [22] Kejun Tang, Xiaoliang Wan, and Chao Yang. Das: A deep adaptive sampling method for solving partial differential equations. arXiv preprint arXiv:2112.14038, 2021. [23] Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev, Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick, Rajkumar Ramamurthy, et al. Informed machine learning\u2013a taxonomy and survey of integrating knowledge into learning systems. arXiv preprint arXiv:1903.12394,2019. [24] Sifan Wang, Shyam Sankaran, and Paris Perdikaris. Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404, 2022. Adaptive Self-supervision Algorithms for Physics-informed Neural Networks1. [25] Sifan Wang, Yujun Teng, and Paris Perdikaris. Understanding and mitigating gradient pathologies in physics-informed neural networks. arXiv preprint arXiv:2001.04536, 2020. [26] Sifan Wang, Hanwen Wang, and Paris Perdikaris. On the eigenvector bias of fourier feature networks:From regression to solving multi-scale pdes with physics-informed neural networks. arXiv preprint arXiv:2012.10047, 2020. [27] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why pinns fail to train: A neural tangent kernel perspective. arXiv preprint arXiv:2007.14527, 2020. [28] Jared Willard, Xiaowei Jia, Shaoming Xu, Michael Steinbach, and Vipin Kumar. Integrating physics-based modeling with machine learning: A survey. arXiv preprint arXiv:2003.04919, 2020. [29] Zixue Xiang, Wei Peng, Xiaohu Zheng, Xiaoyu Zhao, and Wen Yao. Self-adaptive loss balanced physics-informed neural networks for the incompressible navier-stokes equations. arXiv preprint arXiv:2104.06217,2021. [30] Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, and Paris Perdikaris. Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data. Journal of Computational Physics, 394:56\u201381, 2019. John Hanna, Jose V Aguado, Sebastien Comas-Cardona, Ramzi Askri, and Domenico Borzacchiello. Residual-based adaptivity for two-phase flow simulation in porous media using physics-informed neural networks. arXiv preprint arXiv:2109.14290, 2021. \u21a9 Maziar Raissi, Paris Perdikaris, and George E Karniadakis. Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations . JCP 2019. \u21a9","title":"Adaptive Self-Supervision Algorithms for Physics-Informed Neural Networks <br> \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u9002\u5e94\u81ea\u76d1\u7763\u7b97\u6cd5"},{"location":"Models/PINNs/PN-2207.04084/#adaptive-self-supervision-algorithms-for-physics-informed-neural-networks","text":"\u4f5c\u8005: Shashank Subramanian | Robert M. Kirby | Michael W. Mahoney | Amir Gholami \u673a\u6784: \u65f6\u95f4: 2022-07-08 \u9884\u5370: arXiv:2207.04084v1 \u9886\u57df: \u6807\u7b7e: #PINN #\u5f00\u6e90 \u5f15\u7528: 29 \u7bc7 (\u81ea\u5f15 1 \u7bc7) \u4ee3\u7801: Github cur{ color:red; } model{ text-decoration: underline; text-decoration-color: orange; } term{ text-decoration: underline; text-decoration-color: purple; }","title":"Adaptive Self-Supervision Algorithms for Physics-Informed Neural Networks  \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u9002\u5e94\u81ea\u76d1\u7763\u7b97\u6cd5"},{"location":"Models/PINNs/PN-2207.04084/#abstract","text":"Physics-informed neural networks (PINNs) incorporate physical knowledge from the problem domain as a soft constraint on the loss function, but recent work has shown that this can lead to optimization difficulties. Here, we study the impact of the location of the collocation points on the trainability of these models. We find that the vanilla PINN performance can be significantly boosted by adapting the location of the collocation points as training proceeds. Specifically, we propose a novel adaptive collocation scheme which progressively allocates more collocation points (without increasing their number) to areas where the model is making higher errors (based on the gradient of the loss function in the domain). This, coupled with a judicious restarting of the training during any optimization stalls (by simply resampling the collocation points in order to adjust the loss landscape) leads to better estimates for the prediction error. We present results for several problems, including a 2D Poisson and diffusion-advection system with different forcing functions. We find that training vanilla PINNs for these problems can result in up to 70% prediction error in the solution, especially in the regime of low collocation points. In contrast, our adaptive schemes can achieve up to an order of magnitude smaller error, with similar computational complexity as the baseline. Furthermore, we find that the adaptive methods consistently perform on-par or slightly better than vanilla PINN method, even for large collocation point regimes. The code for all the experiments has been open sourced and available at Github.","title":"Abstract \u6458\u8981"},{"location":"Models/PINNs/PN-2207.04084/#1-introduction","text":"A key aspect that distinguishes scientific ML (SciML) [4,10,14,16,23,28] from other ML tasks is that scientists typically know a great deal about the underlying physical processes that generate their data. For example, while the Ordinary Differential Equations (ODEs) or Partial Differential Equations (PDEs) used to simulate the physical phenomena may not capture every detail of a physical system,they often provide a reasonably good approximation. In some cases, we know that physical systems have to obey conservation laws (mass, energy, momentum, etc.). In other cases, we can learn these constraints, either exactly or approximately, from the data. In either case, the main challenge in SciML lies in combining such scientific prior domain-driven knowledge with large-scale data-driven methods from ML in a principled manner. One popular method to incorporate scientific prior knowledge is to incorporate them as soft-constraints throughout training, as proposed with Physics Informed Neural Networks (PINNs) [10,12,17]. These models use penalty method techniques from optimization [3] and formulate the solution of the PDE as an unconstrained optimization problem that minimizes a self-supervision loss function that incorporates the domain physics (PDEs) as a penalty (regularization) term. Formulating the problem as a soft-constraint makes it very easy to use existing auto-differentiation frameworks for SciML tasks. However, training PINNs this way can be very difficult, and it is often difficult to solve the optimization problem [6,11,25]. This could be partly because the self-supervision term typically contains complex terms such as (higher-order) derivatives of spatial functions and other nonlinearities that cause the loss term to become ill-conditioned [11]. This is very different than unit\u2018pball or other such convex functions, more commonly used as regularization terms in ML. Several solutions such as loss scaling [25], curriculum or sequence-to-sequence learning [11], tuning of loss function weights [13], and novel network architectures [19] have been proposed to address this problem. One overlooked, but very important, parameter of the training process is the way that the self-supervision is performed in PINNs, and in particular which data points in the domain are used for enforcing the physical constraints (commonly referred to as collocation points in numerical analysis). In the original work of [17],the collocation points are randomly sampled in the beginning of the training and kept constant throughout the learning process. However, we find that this is sub-optimal, and instead we propose adaptive collocation schemes. We show that these schemes can result in an order of magnitude better performance, with similar computational overhead. Background. We focus on scientific systems that have a PDE constraint of the following form:(1.1)F(u(x)) = 0,x \u2208 \u2126 \u2282 Rd,whereFis a differential operator representing the PDE,u(x) is the state variable (i.e., physical quantity of interest), \u2126 is the physical domain, andxrepresents spatial domain (2D in all of our results). To ensure existence and uniqueness of an analytical solution, there are additional constraints specified on the boundary,d\u2126, as well (such as periodic or Dirichlet boundary conditions). One possible approach to learn a representation for the solution is to incorporate the PDE as a hard constraint, and formulate a loss function that measures the prediction error on the boundary (where data points are available):(1.2)min\u03b8L(u)s.t.F(u) = 0,whereL(u) is typically a data mismatch term (this includes initial/boundary conditions but can also include observational data points), and whereFis a constraint on the residual of the PDE system (i.e.,F(u) is the residual) under consideration. Since constrained optimization is typically more difficult than unconstrained optimization [3], this constraint is typically relaxed and added as a penalty term to the loss function. This yields the following unconstrained optimization problem, namely the PINNs (soft constrained) optimization problem:(1.3)min\u03b8L(u) + \u03bbFLF. In this problem formulation, the regularization parameter,\u03bbF, controls the weight given to the PDE constraints, as compared to the data misfit term;\u03b8denotes the parameters of the model that predictsu(x),which is often taken to be a neural network; and the PDE loss functional term,LF, can be considered as a self-supervised loss, as all the information comes from the PDE system we are interested in simulating,instead of using direct observations. Typically a Euclidean loss function is used to measure the residual of the PDE for this loss function,kF(u)k22, where the\u20182norm is computed at discrete points (collocation points) that are randomly sampled from \u2126. This loss term is often the source of the training difficulty with PINNs [6, 11], which is the focus of our paper. Main contributions. Unlike other work in the literature, which has focused on changing the training method or the neural network (NN) architecture, here we focus on the self-supervision component of PINNs,and specifically on the selection of the collocation points. In particular, we make the following contributions:\u2022We study the role of the collocation points for two PDE systems: steady state diffusion (Poisson);and diffusion-advection. We find that keeping the collocation points constant throughout training is a sub-optimal strategy and is an important source of the training difficulty with PINNs. This is particularly true for cases where the PDE problem exhibits local behaviour (e.g., in presence of sharp, or very localized, features).\u2022We propose an alternative strategy of resampling the collocation points when training stalls. Although this strategy is simple, it can lead to significantly better reconstruction (see Tab. 1 and Fig. 2). Im-portantly, this approach does not increase the computational complexity, and it is easy to implement.\u2022We propose to improve the basic resampling scheme with a gradient-based adaptive scheme. This adaptive scheme is designed to help to relocate the collocation points to areas with higher loss gradient,without increasing the total number of points (see Algorithm 1 for the algorithm). In particular,we progressively relocate the points to areas of high gradient as training proceeds. This is done through a cosine-annealing that gradually changes the sampling of collocation points from uniform to adaptive through training. We find that this scheme consistently achieves better performance than the basic resampling method, and it can lead to more than 10x improvements in the prediction error(see Tab. 1, Fig. 2).\u2022We extensively test our adaptive schemes for the two PDE systems of Poisson and diffusion-advection while varying the number of collocation points for problems with both smooth or sharp features. While the resampling and adaptive schemes perform similarly in the large collocation point regime,the adaptive approach shows significant improvement when the number of collocation points is small and the forcing function is sharp (see Tab. 2).","title":"1. Introduction \u4ecb\u7ecd "},{"location":"Models/PINNs/PN-2207.04084/#2-related-work","text":"There has been a large body of work studying PINNs [5,7,9,18,20,21,30] and the challenges associated with their training [6,11,24,25,26,27]. The work of [25] notes these challenges and proposes a loss scaling method to resolve the training difficulty. Similar to this approach, some works have treated the problem as a multi-objective optimization and tune the weights of the different loss terms[2,29]. A more formal approach was suggested in [13] where the weights are learned by solving a minimax optimization problem that ascends in the loss weight space and descends in the model parameter space. This approach was extended in [15] to shift the focus of the weights from the loss terms to the training data points instead, and the minimax forces the optimization to pay attention to specific regions of the domain. However, minimax optimization problems are known to be hard to optimize and introduce additional complexity and computational expense. Furthermore, it has been shown that using curriculum or sequence-to-sequence learning can ameliorate the training difficulty with PINNs [11]. More recently, the work of [24] shows that incorporating causality in time can help training for time-dependent PDEs. There is also recent work that studies the role of the collocation points. For instance, [22] refines the collocation point set without learnable weights. They propose an auxiliary NN that acts as a generative model to sample new collocation points that mimic the PDE residual. However, the auxiliary network also has to be trained in tandem with the PINN. The work of [14] proposes an adaptive collocation scheme where the points are densely sampled uniformly and trained for some number of iterations. Then the set is extended by adding points in increasing rank order of PDE residuals to refine in certain locations (of sharp fronts, for example) and the model is retrained. However, this method can increase the computational overhead, as the number of collocation points is progressively increased. Furthermore, in 1 the authors show that the latter approach can lead to excessive clustering of points throughout training. To address this, instead they propose to add points based on an underlying density function defined by the PDE residual. Both these schemes keep the original collocation set (the low residual points) and increase the training dataset sizes as the optimization proceeds. Unlike the work of [8,14], we focus on using gradient of the loss function, instead of the nominal loss value, as the proxy to guide the adaptive resampling of the collocation points. We show that this approach leads to better localization of the collocation points, especially for problems with sharp features. Furthermore, we incorporate a novel cosine-annealing scheme, which progressively incorporates adaptive sampling as training proceeds. Importantly, we also keep the number of collocation points the same. Not only does this not increase the computational overhead, but this is also easier to implement as well\uff0e","title":"2. Related Work \u76f8\u5173\u5de5\u4f5c"},{"location":"Models/PINNs/PN-2207.04084/#3-methods","text":"In PINNs , we use a feedforward NN, denoted \\(NN(\\pmb{x};\\theta)\\) , that is parameterized by weights and biases, \\(\\theta\\) , takes as input values for coordinate points, \\(\\pmb{x}\\) , and outputs the solution value \\(u(\\pmb{x})\\in\\mathbb{R}\\) at these points. As described in Section 1 , the model parameters \\(\\theta\\) are optimized through the loss function: \u5728 PINNs \u4e2d, \u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u6709\u6743\u91cd\u548c\u504f\u5dee \\(\\theta\\) \u53c2\u6570\u5316\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc \\(NN(\\pmb{x};\\theta)\\) , \u8f93\u5165\u503c\u4e3a\u914d\u7f6e\u70b9 \\(\\pmb{x}\\) \u5e76\u8f93\u51fa\u89e3\u5728\u8fd9\u4e9b\u70b9\u4e0a\u7684\u503c \\(u(\\pmb{x})\\in\\mathbb{R}\\) . \u6b63\u5982\u7b2c\u4e00\u8282\u6240\u63cf\u8ff0\u7684, \u6a21\u578b\u53c2\u6570 \\(\\theta\\) \u901a\u8fc7\u4ee5\u4e0b\u635f\u5931\u51fd\u6570\u8fdb\u884c\u4f18\u5316: \\[ \\min_{\\theta}\\mathcal{L}_{\\mathcal{B}} + \\lambda_{\\mathcal{F}}\\mathcal{L}_{\\mathcal{F}}. \\tag{3.1} \\] We focus on boundary-value (steady state) problems and define the two loss terms as: \u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u8fb9\u503c (\u7a33\u6001) \u95ee\u9898\u5e76\u5b9a\u4e49\u76f8\u5e94\u7684\u4e24\u4e2a\u635f\u5931\u9879\u5982\u4e0b: \\[ \\mathcal{L}_{\\mathcal{B}} =\\frac{1}{n_b} \\sum_{i=1}^{n_b}\\|u(\\pmb{x}_b^i)-\\hat{u}(\\pmb{x}_b^i)\\|_2^2, \\tag{3.2a} \\] \\[ \\mathcal{L}_{\\mathcal{F}} =\\frac{1}{n_c} \\sum_{i=1}^{n_c}\\|\\mathcal{F}(u(\\pmb{x}_c^i))\\|_2^2, \\tag{3.2b} \\] where \\(u\\) is the model predicted solution, \\(\\hat{u}\\) is the true solution or data, \\(\\pmb{x}_b^i\\) are points on the boundary, and \\(\\pmb{x}_c^i\\) are collocation points uniformly sampled from the domain \\(\\Omega\\) . Here, \\(n_b\\) and \\(n_c\\) are the number of boundary and collocation points, respectively; and the boundary loss term \\(\\mathcal{L}_{\\mathcal{B}}\\) implements a Dirichlet boundary condition, where we assume that the solution values are known on the boundary \\(d\\Omega\\) . \u5176\u4e2d \\(u\\) \u662f\u6a21\u578b\u9884\u6d4b\u89e3, \\(\\hat{u}\\) \u662f\u771f\u89e3\u6216\u6570\u636e, \\(\\pmb{x}_b^i\\) \u662f\u8fb9\u754c\u4e0a\u7684\u70b9, \\(\\pmb{x}_c^i\\) \u662f\u4ece\u5b9a\u4e49\u57df \\(\\Omega\\) \u4e2d\u5747\u5300\u91c7\u6837\u7684\u914d\u7f6e\u70b9.\u5f0f\u5b50\u4e2d\u7684 \\(n_b\\) \u548c \\(n_c\\) \u5206\u522b\u8868\u793a\u8fb9\u754c\u70b9\u548c\u914d\u7f6e\u70b9\u7684\u6570\u91cf, \u5e76\u4e14\u8fb9\u754c\u635f\u5931\u9879 \\(\\mathcal{L}_{\\mathcal{B}}\\) \u4f7f\u7528\u4e86 Dirichlet \u8fb9\u754c\u6761\u4ef6, \u5373\u6211\u4eec\u5047\u8bbe\u89e3\u5728\u8fb9\u754c \\(d\\Omega\\) \u4e0a\u7684\u503c\u5df2\u77e5. In PINNs 2 , the collocation points used in Eq.3.2b are randomly sampled with a uniform probability over the entire space \\(\\Omega\\) in the beginning of training and then kept constant afterwards (we refer to this approach as Baseline). While a uniformly distributed collocation point set may be sufficient for simple PDEs with smooth features, we find them to be sub-optimal when the problem exhibits sharp/local features, or even fail to train. To address this, we propose the following schemes. \u5728 PINNs \u4e2d, \u4e0a\u8ff0\u516c\u5f0f\u4f7f\u7528\u7684\u914d\u7f6e\u70b9\u662f\u5728\u8bad\u7ec3\u5f00\u59cb\u662f\u5728\u6574\u4e2a\u7a7a\u95f4 \\(\\Omega\\) \u4e0a\u6839\u636e\u5747\u5300\u5206\u5e03\u8fdb\u884c\u968f\u673a\u91c7\u6837\u7684, \u7136\u540e\u5728\u4e4b\u540e\u4fdd\u6301\u4e0d\u53d8 (\u6211\u4eec\u5c06\u8fd9\u4e00\u65b9\u6cd5\u4f5c\u4e3a\u57fa\u7ebf). \u867d\u7136\u5bf9\u4e8e\u6709\u5149\u6ed1\u6027\u8d28\u7684\u7b80\u5355\u504f\u5fae\u5206\u65b9\u7a0b\u6765\u8bf4, \u4e00\u4e2a\u5747\u5300\u5206\u5e03\u7684\u914d\u7f6e\u70b9\u96c6\u53ef\u80fd\u5df2\u7ecf\u8db3\u591f\u4e86, \u6211\u4eec\u53d1\u73b0\u5f53\u95ee\u9898\u51fa\u73b0 sharp/\u5c40\u90e8\u6027\u65f6, \u53ef\u80fd\u4f1a\u51fa\u73b0\u6b21\u4f18\u89e3\u751a\u81f3\u8bad\u7ec3\u5931\u8d25. \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u5982\u4e0b\u65b9\u6848.","title":"3. Methods \u65b9\u6cd5"},{"location":"Models/PINNs/PN-2207.04084/#resampling-collocation-points","text":"Current PINNs are typically optimized with LBFGS . In our experiments, we found that in the baseline approach LBFGS often fails to find a descent direction and training stalls, even after hyperparamter tuning. This agrees with other results reported in the literature [6,11,25]. We find that this is partially due to the fact that the collocation points are kept constant and not changed. The simplest approach to address this is to resample the collocation points when LBFGS stalls. We refer to this approach as Resampling. As we will discuss in the next section, we find this approach to be helpful for cases with moderate to large number of collocation points.","title":"Resampling Collocation Points \u91cd\u91c7\u6837\u914d\u7f6e\u70b9"},{"location":"Models/PINNs/PN-2207.04084/#adaptive-sampling","text":"While the Resampling method is effective for large number of collocation points, we found it to be sub-optimal in the small collocation point regime, especially for problems with sharp/localized features. In this case, the Resampling method still uses a uniform distribution with which to sample the new the collocation points; and, in the presence of a small number of collocation points and/or sharp/localized features, this is not an optimal allocation of the points. Ideally, we want to find a probability distribution, as a replacement for the uniform distribution, that can improve trainability of PINNs for a given number of collocation points and/or computational budget. There are several possibilities to define this distribution. The first intuitive approach would be to use the value of the PDE residual (Eq. 3.2b), and normalize it as a probability distribution. This could then be used to sample collocation points based on the loss values in the domain. That is, more points would be sampled in areas with with higher PDE residual, and vice versa. We refer to this approach as ADAPTIVE-R sampling (withRreferring to the PDE residual). An alternative is to use the gradient of the loss function (PDE loss termLF) w.r.t. the spatial grid, using that as the probability distribution with which to sample the collocation points. We refer to this approach as ADAPTIVE-G (withG referring to gradient of the loss). As we will show in the next section, when combined with a cosine annealing scheme (discussed next), both of these adaptive schemes consistently perform better than the Resampling scheme.","title":"Adaptive Sampling \u81ea\u9002\u5e94\u91c7\u6837"},{"location":"Models/PINNs/PN-2207.04084/#progressive-adaptive-sampling","text":"Given the non-convex nature of the problem, it might be important to not overly constrain the NN to be too locally focused, as the optimization procedure could get stuck in a local minima. However, this can be addressed by progressively incorporating adaptive sampling as training proceeds. In particular, we use a cosine annealing strategy. This allows the NN to periodically alternate between focusing on regions of high error as well as uniformly covering larger parts of the sample space, over a period of iterations. Specifically, in each annealing period, we start with a full uniform sampling, and progressively incorporate adaptively sampled points using a cosine schedule rule of \\(\\eta=\\dfrac{1}{2}(1+\\cos\\pi\\dfrac{T_c}{T})\\) , where \\(\\eta\\) is the fraction of points uniformly sampled, \\(T_c\\) is the number of epochs since the last restart, and \\(T\\) is the length of the cosine schedule. We use this schedule to resample the collocation every \\(e\\) epochs. Given the periodic nature of the cosine annealing, that approach balances local adaptivity without losing global information. We outline the adaptive sampling Algorithm 1 . Algorithm 1. Adaptive Sampling for Self-Supervision in PINNs Require : Loss \\(\\mathcal{L}\\) , NN model, number of collocation points \\(n_c\\) , PDE regularization \\(\\lambda_{\\mathcal{F}}\\) , \\(T\\) , \\(s_w\\) , momentum \\(\\gamma\\) , max epochs \\(i_{max}\\) 1: \\(i\\leftarrow 0\\) 2: while \\(i\\leq i_{max}\\) do 3: \\(\\qquad\\) Compute proxy function as the loss gradient ( ADAPTIVE-G ) or PDE residual ( ADAPTIVE-R ) 4: \\(\\qquad\\) Current proxy \\(\\mathcal{P}_i\\leftarrow\\mathcal{P} + \\gamma\\mathcal{P}_{i-1}\\) 5: \\(\\qquad\\) \\(T_c\\leftarrow i \\mod T\\) 6: \\(\\qquad\\) \\(\\eta \\leftarrow\\) cosine-schedule \\((T_c, T)\\) 7: \\(\\qquad\\) if \\(i \\mod e\\) is true then 8: \\(\\qquad\\qquad\\) Sample \\(\\eta n_c\\) points \\(\\pmb{x}_u\\) uniformly 9: \\(\\qquad\\qquad\\) Sample \\((1 - \\eta)n_c\\) points \\(\\pmb{x}_a\\) using proxy function \\(\\mathcal{P}_i\\) 10: \\(\\qquad\\) end if 11: \\(\\qquad\\) \\(\\pmb{x}_c\\leftarrow \\pmb{x}_u\\cup \\pmb{x}_a\\) 12: \\(\\qquad\\) Input \\(\\pmb{x}\\leftarrow\\pmb{x}_b\\cup\\pmb{x}_c\\) where \\(\\pmb{x}_b\\) are boundary points 13: \\(\\qquad\\) \\(u \\leftarrow NN(\\pmb{x}; \\theta)\\) 14: \\(\\qquad\\) \\(\\mathcal{L} \\leftarrow \\mathcal{L}_\\mathcal{B}+ \\lambda_\\mathcal{F}\\mathcal{L}_\\mathcal{F}\\) 15: \\(\\qquad\\) \\(\\theta \\leftarrow\\) optimizer-update \\((\\theta, \\mathcal{L})\\) 16: \\(\\qquad\\) if stopping-criterion is true then 17: \\(\\qquad\\qquad\\) reset cosine scheduler \\(T_c\\leftarrow 0\\) 18: \\(\\qquad\\) end if 19: \\(\\qquad\\) \\(i \\leftarrow i + 1\\) 20: end while","title":"Progressive Adaptive Sampling \u6e10\u8fdb\u81ea\u9002\u5e94\u91c7\u6837"},{"location":"Models/PINNs/PN-2207.04084/#4-experiments","text":"In this section, we show examples that highlight the prediction error improvement using our adaptive self-supervision method on two PDE systems: Poisson\u2019s equation \u00a74.1 and (steady state)diffusion-advection \u00a74.2.Problem setup. We use the same problem set up as in [11,17,25] for the NN model, which is a feed forward model with hyperbolic tangent activation function, trained with LBFGS optimizer. We focus on2D spatial domains in \u2126 = [0,1]2. The training data set contains points that are randomly sampled from a uniform 2562mesh on \u2126. The testing data set is the set of all 2562points, along with the true solution of the PDE\u02c6u(x) at these points. Furthermore, we use a constant regularization parameter of\u03bbF= 1e-4 for all the runs, which we found to be a good balance between the boundary term and the PDE residual. To ensure a fair comparison, we tune the rest of the hyperparameters both for the baseline model as well as for the adaptive schemes. For tuning the parameters, we use the validation loss computed by calculating the total loss over randomly sampled points in the domain (30K points for all the experiments). Note that we do not use any signal from the analytical solution, and instead only use the loss in Eq. 3.1.Metrics. We train the optimizer for 5000 epochs with a stall criterion when the loss does not change for 10 epochs. We keep track of the minimum validation loss in order to get the final model parameters for testing. We compute our prediction error using two metrics: the\u20182relative error,\u00b51=ku \u2212 \u02c6uk2/k\u02c6ukand the\u20181error\u00b52=ku \u2212 \u02c6uk1, whereuis the model prediction solution from the best validation loss epoch and\u02c6uis the true solution. All runs are trained on an A100 NVIDIA GPU on the Perlmutter supercomputer.","title":"4. Experiments \u5b9e\u9a8c"},{"location":"Models/PINNs/PN-2207.04084/#41-2d-poissons-equation","text":"","title":"4.1. 2D Poisson's Equation \u4e8c\u7ef4\u6cca\u677e\u65b9\u7a0b"},{"location":"Models/PINNs/PN-2207.04084/#problem-formulation","text":"We consider a prototypical elliptic system defined by the Poisson\u2019s equation with source function f(x). This system represents a steady state diffusion equation: \\[ (4.1)\u2212 div K\u2207u = f(x),x \u2208 \u2126, \\] whereKdenotes the diffusion tensor. For homogeneous diffusion tensors, the solution of the poisson\u2019s equation with doubly-periodic boundary conditions can be computed using the fast Fourier transform on a discrete grid as:(4.2)\u02c6u = F\u22121\ufffd\u22121\u2212(k2xk11+ k2yk22+ 2kxkyk12)F(f(x))\ufffd,whereFis the Fourier transform,kx, kyare the frequencies in the Fourier domain, andk11, k22, k12are the diagonal and off-diagonal coefficients of the diffusion tensorK. We enforce the boundary conditions as Dirichlet boundary conditions using the true solution to circumvent the ill-posedness of the doubly-periodic Poisson\u2019s equation.1We use a Gaussian function as the source with standard deviation\u03c3fand consider the diffusion tensork11= 1, k22= 8, k12= 4 to make the problem anisotropic. We consider two test-cases:(i) TC1: smooth source function with\u03c3f= 0.1 (ii) TC2: sharp source function with\u03c3f= 0.01. We show these source functions and the corresponding target solutions in Fig. 1. For any experiment, we sweep over all the hyperparameters and select the ones that show the lowest/best validation loss for the final model. Observations. We start by examining the performance of the difference methods for the relatively small number of collocation points ofnc= 1,000 (which corresponds to 1.5% of the 256\u00d7256 domain \u2126). We report the errors\u00b51and\u00b52for the different schemes in Tab. 1. We also visualize the predicted solution for each method in Fig. 2, along with the location of the collocation points overlayed for the final model. We can clearly see that the baseline model does not converge (despite hyperparameter tuning) due to the optimizer stalls. However, Resampling achieves significantly better errors, especially for the smooth source function setup (TC1). However, for the sharp source experiment (TC2), the resampling does not help and shows an error of about 50%.Overall, the adaptive schemes show much better (or comparable) prediction errors for both test-cases. In particular, ADAPTIVE-R and ADAPTIVE-G achieve about 2\u20135% relative error (\u00b51) for both TC1 and TC2. The visual reconstruction shown in Fig. 2 also shows the clearly improved prediction with the adaptive schemes (last two columns), as compared to the baseline with/without resampling (first two columns). Note that the ADAPTIVE-G method assigns more collocation points around the sharp features. This is due to the fact that it uses the gradient information for its probability distribution, instead of the residual of the PDE which is used in ADAPTIVE-R method. To show the effect of the scheduler, we show an ablation study with the cosine-annealing scheduler in the appendix (see Fig. A.4).We then repeat the same experiment, but now varying the number of collocation points,nc, from 500to 8K, and we report the relative error (\u00b51) in Tab. 2. We observe a consistent trend, where the Baseline(PINN training without resampling) does not converge to a good solution, whereas ADAPTIVE-G consistently achieves up to an order of magnitude better error. Also, note that the performance of the Resampling method significantly improves and becomes on par with ADAPTIVE-G as we increasenc. This is somewhat expected since at large number of collocation points resampling will have the chance to sample points near the areas with sharp features. In Fig. A.1, we show the errors for every test-case as a function of number of collocation points using 10 different random seed values to quantify the variance in the different methods. We observe that the adaptive schemes additionally show smaller variances across seeds, especially for the test-cases with sharp sources.","title":"Problem Formulation \u95ee\u9898\u5f62\u5f0f\u5316"},{"location":"Models/PINNs/PN-2207.04084/#42-2d-diffusion-advection-equation","text":"We next look at a steady-state 2D diffusion-advection equation with source function f(x), diffusion tensor K, and velocity vector v: For homogeneous diffusion tensors and velocity vectors, the solution of the advection-diffusion equation with doubly-periodic boundary conditions can also be computed using the fast Fourier transform on a discrete grid as: \u02c6u = F\u22121\ufffd\u22121 g1\u2212 g2 F(f(x))\ufffd, g1= \u2212(k2xk11+ k2yk22+ 2kxkyk12), g2= ikxv1+ ikyv2, (4.4) whereFis the Fourier transform,i=\u221a\u22121,kx, kyare the frequencies in the Fourier domain,k11, k22, k12are the diagonal and off-diagonal coefficients of the diffusion tensorK, andv1, v2are the velocity components. As before, we enforce the boundary conditions as Dirichlet boundary conditions using the true solution,and we consider a Gaussian function as the source with standard deviation\u03c3f. We use a diffusion tensor k11= 1, k22= 8, k12= 4 and velocity vectorv1= 40, v2= 10 to simulate sufficient advection. We consider two test-cases as before: (i) TC3: smooth source function with\u03c3f= 0.1 (ii) TC4: sharp source function with \u03c3f= 0.01. We show the source functions and the target solutions in Fig. 3.Observations. We observe a very similar behaviour for the reconstruction errors as in the previous experiments. As before, we start withnc= 1,000 collocation points, and we report the results in Tab. 3and Fig. 4. Here, the baseline achieves slightly better performance for TC3 (14%) but completely fails (100%error) for the TC4 test case, which includes a sharper forcing function. However, the Resampling achieves better results for both cases. Furthermore, the best performance is achieved by the adaptive methods. Finally, in Tab. 4 we report the relative errors for the baseline and adaptive schemes with various numbers of collocation pointsnc. Similar to the Poisson system, larger values ofncshow good performance, but the baselines underperform in the low data regime for sharp sources. The resampling achieves better errors, while the adaptive methods once again consistently achieve the best performance for both data regimes.","title":"4.2. 2D Diffusion-Advection Equation"},{"location":"Models/PINNs/PN-2207.04084/#5-conclusions","text":"We studied the impact of the location of the collocation points in training SciML models, focusing on the popular class of PINN models, and we showed that the vanilla PINN strategy of keeping the collocation points fixed throughout training often results in suboptimal solutions. This is particularly the case for PDE systems with sharp (or very localized) features. We showed that a simple strategy of resampling collocation points during optimization stalls can significantly improve the reconstruction error, especially for moderately large number of collocation points. We also proposed adaptive collocation schemes to obtain a better allocation of the collocation points. This is done by constructing a probability distribution derived from either the PDE residual ( ADAPTIVE-R ) or its gradient w.r.t. the input ( ADAPTIVE-G ). We found that by progressively incorporating the adaptive schemes, we can achieve up to an order of magnitude better solutions, as compared to the baseline, especially for the regime of a small number of collocation points and with problems that exhibit sharp (or very localized) features. Some limitations of this current work include the following: we did not change the NN architecture (it was fixed as a feed forward NN) or tune hyperparameters relating to the architecture (which can be a significant factor in any analysis); and we only focused on 2D spatial systems (it is known that time-dependent or 3D or higher-dimensional systems can show different behaviours and may benefit from different kinds of adaptivity in space and time). We leave these directions to future work. However, we expect that techniques such as those we used here that aim to combine in a more principled way domain-driven scientific methods and data-driven ML methods will help in these cases as well.","title":"5. Conclusions \u7ed3\u8bba"},{"location":"Models/PINNs/PN-2207.04084/#reference","text":"[2] Rafael Bischof and Michael Kraus. Multi-Objective Loss Balancing for Physics-Informed Deep Learning. arXiv preprint arXiv:2110.09813, 2021. [3] (Book) Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge university press, 2004. [4] Steven L Brunton, Bernd R Noack, and Petros Koumoutsakos. Machine learning for fluid mechanics. Annual Review of Fluid Mechanics, 52:477\u2013508, 2020. [5] Yuyao Chen, Lu Lu, George Em Karniadakis, and Luca Dal Negro. Physics-informed neural networks for inverse problems in nano-optics and metamaterials. Optics express, 28(8):11618\u201311633, 2020. [6] C. Edwards. Neural networks learn to speed up simulations. Communications of the ACM, 65(5):27\u201329,2022. [7] Nicholas Geneva and Nicholas Zabaras. Modeling the dynamics of pde systems with physics-constrained deep auto-regressive networks. Journal of Computational Physics, 403:109056, 2020. [9] Xiaowei Jin, Shengze Cai, Hui Li, and George Em Karniadakis. Nsfnets (navier-stokes flow nets): Physics-informed neural networks for the incompressible navier-stokes equations. Journal of Computational Physics, 426:109951, 2021. [10] George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning. Nature Reviews Physics, 3(6):422\u2013440, 2021. [11] Aditi Krishnapriyan, Amir Gholami, Shandian Zhe, Robert Kirby, and Michael W Mahoney. Characterizing possible failure modes in physics-informed neural networks. NeurIPS 2021. [12] Isaac E Lagaris, Aristidis Likas, and Dimitrios I Fotiadis. Artificial neural networks for solving ordinary and partial differential equations. IEEE transactions on neural networks, 9(5):987\u20131000, 1998. [13] Dehao Liu and Yan Wang. A dual-dimer method for training physics-constrained neural networks with minimax architecture. Neural Networks, 136:112\u2013125, 2021. [14] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. Deepxde: A deep learning library for solving differential equations. SIAM Review, 63(1):208\u2013228, 2021. [15] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft attention mechanism. arXiv preprint arXiv:2009.04544, 2020. [16] Christopher Rackauckas, Yingbo Ma, Julius Martensen, Collin Warner, Kirill Zubov, Rohit Supekar, Dominic Skinner, Ali Ramadhan, and Alan Edelman. Universal differential equations for scientific machine learning. arXiv preprint arXiv:2001.04385, 2020. [18] Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations. Science, 367(6481):1026\u20131030, 2020. [19] Amuthan A Ramabathiran and Prabhu Ramachandran. Spinn: Sparse, physics-based, and partially interpretable neural networks for pdes. Journal of Computational Physics, 445:110600, 2021. [20] Francisco Sahli Costabal, Yibo Yang, Paris Perdikaris, Daniel E Hurtado, and Ellen Kuhl. Physics-informed neural networks for cardiac activation mapping. Frontiers in Physics, 8:42, 2020. [21] Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial differential equations. Journal of computational physics, 375:1339\u20131364, 2018. [22] Kejun Tang, Xiaoliang Wan, and Chao Yang. Das: A deep adaptive sampling method for solving partial differential equations. arXiv preprint arXiv:2112.14038, 2021. [23] Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev, Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick, Rajkumar Ramamurthy, et al. Informed machine learning\u2013a taxonomy and survey of integrating knowledge into learning systems. arXiv preprint arXiv:1903.12394,2019. [24] Sifan Wang, Shyam Sankaran, and Paris Perdikaris. Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404, 2022. Adaptive Self-supervision Algorithms for Physics-informed Neural Networks1. [25] Sifan Wang, Yujun Teng, and Paris Perdikaris. Understanding and mitigating gradient pathologies in physics-informed neural networks. arXiv preprint arXiv:2001.04536, 2020. [26] Sifan Wang, Hanwen Wang, and Paris Perdikaris. On the eigenvector bias of fourier feature networks:From regression to solving multi-scale pdes with physics-informed neural networks. arXiv preprint arXiv:2012.10047, 2020. [27] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why pinns fail to train: A neural tangent kernel perspective. arXiv preprint arXiv:2007.14527, 2020. [28] Jared Willard, Xiaowei Jia, Shaoming Xu, Michael Steinbach, and Vipin Kumar. Integrating physics-based modeling with machine learning: A survey. arXiv preprint arXiv:2003.04919, 2020. [29] Zixue Xiang, Wei Peng, Xiaohu Zheng, Xiaoyu Zhao, and Wen Yao. Self-adaptive loss balanced physics-informed neural networks for the incompressible navier-stokes equations. arXiv preprint arXiv:2104.06217,2021. [30] Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, and Paris Perdikaris. Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data. Journal of Computational Physics, 394:56\u201381, 2019. John Hanna, Jose V Aguado, Sebastien Comas-Cardona, Ramzi Askri, and Domenico Borzacchiello. Residual-based adaptivity for two-phase flow simulation in porous media using physics-informed neural networks. arXiv preprint arXiv:2109.14290, 2021. \u21a9 Maziar Raissi, Paris Perdikaris, and George E Karniadakis. Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations . JCP 2019. \u21a9","title":"Reference \u53c2\u8003\u6587\u732e"},{"location":"Models/PINNs/PN-2207.10289/","text":"A Comprehensive Study of Non-Adaptive and Residual-Based Adaptive Sampling for Physics-Informed Neural Networks \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u81ea\u9002\u5e94\u91c7\u6837\u548c\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u91c7\u6837\u7684\u7efc\u5408\u7814\u7a76 \u4f5c\u8005: Chenxi Wu1,\u2020, Min Zhu1,\u2020, Qinyang Tan^2 , Yadhu Kartha^3 , and Lu Lu1,* \u673a\u6784: College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, USA \u65f6\u95f4: 2022-07-21 \u9884\u5370: arXiv:2207.10289v1 \u9886\u57df: physics.comp-ph \u6807\u7b7e: \u504f\u5fae\u5206\u65b9\u7a0b, \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc, \u6b8b\u5dee\u70b9\u5206\u5e03, \u975e\u81ea\u9002\u5e94\u5747\u5300\u91c7\u6837, \u5e26\u91cd\u91c7\u6837\u7684\u5747\u5300\u91c7\u6837, \u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u91c7\u6837 \u5f15\u7528: 47 \u7bc7 Abstract Physics-informed neural networks (PINNs) have shown to be an effective tool for solving both forward and inverse problems of partial differential equations (PDEs). PINNs embed the PDEs into the loss of the neural network using automatic differentiation, and this PDE loss is evaluated at a set of scattered spatio-temporal points (called residual points). The location and distribution of these residual points are highly important to the performance of PINNs. However, in the existing studies on PINNs, only a few simple residual point sampling methods have mainly been used. Here, we present a comprehensive study of two categories of sampling for PINNs: non-adaptive uniform sampling and adaptive nonuniform sampling. We consider six uniform sampling methods, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) Latin hypercube sampling, (4) Halton sequence, (5) Hammersley sequence, and (6) Sobol sequence. We also consider a resampling strategy for uniform sampling. To improve the sampling efficiency and the accuracy of PINNs, we propose two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D), which dynamically improve the distribution of residual points based on the PDE residuals during training. Hence, we have considered a total of 10 different sampling methods, including six non-adaptive uniform sampling, uniform sampling with resampling, two proposed adaptive sampling, and an existing adaptive sampling. We extensively tested the performance of these sampling methods for four forward problems and two inverse problems in many setups. Our numerical results presented in this study are summarized from more than 6000 simulations of PINNs. We show that the proposed adaptive sampling methods of RAD and RAR-D significantly improve the accuracy of PINNs with fewer residual points for both forward and inverse problems. The results obtained in this study can also be used as a practical guideline in choosing sampling methods. 1 Introduction Physics-informed neural networks (PINNs) [1] have emerged in recent years and quickly became a powerful tool for solving both forward and inverse problems of partial differential equations (PDEs) via deep neural networks (DNNs) [2, 3, 4]. PINNs embed the PDEs into the loss of the neural network using automatic differentiation. Compared with traditional numerical PDE solvers, such as the finite difference method (FDM) and the finite element method (FEM), PINNs are mesh free and therefore highly flexible. Moreover, PINNs can easily incorporate both physics-based constraints and data measurements into the loss function. PINNs have been applied to tackle diverse problems in computational science and engineering, such as inverse problems in nanooptics, metamaterials [5], and fluid dynamics [2], parameter estimation in systems biology [6, 7], and problems of inverse design and topology optimization [8]. In addition to standard PDEs, PINNs have also been extended to solve other types of PDEs, including integro-differential equations [3], fractional PDEs [9], and stochastic PDEs [10]. Despite the past success, addressing a wide range of PDE problems with increasing levels of complexity can be theoretically and practically challenging, and thus many aspects of PINNs still require further improvements to achieve more accurate prediction, higher computational efficiency, and training robustness [4]. A series of extensions to the vanilla PINN have been proposed to boost the performance of PINNs from various aspects. For example, better loss functions have been discovered via meta-learning [11], and gradient-enhanced PINNs (gPINNs) have been developed to embed the gradient information of the PDE residual into the loss [12]. In PINNs, the total loss is a weighted summation of multiple loss terms corresponding to the PDE and initial/boundary conditions, and different methods have been developed to automatically tune these weights and balance the losses [13, 14, 15]. Moreover, a different weight for each loss term could be set at every training point [16, 17, 8, 18]. For problems in a large domain, decomposition of the spatiotemporal domain accelerates the training of PINNs and improves their accuracy [19, 20, 21]. For time-dependent problems, it is usually helpful to first train PINNs within a short time domain and then gradually expand the time intervals of training until the entire time domain is covered [22, 23, 24, 25, 26]. In addition to these general methods, other problem-specific techniques have also been developed, e.g., enforcing Dirichlet or periodic boundary conditions exactly by constructing special neural network architectures [27, 28, 8]. PINNs are mainly optimized against the PDE loss, which guarantees that the trained network is consistent with the PDE to be solved. PDE loss is evaluated at a set of scattered residual points. Intuitively, the effect of residual points on PINNs is similar to the effect of mesh points on FEM, and thus the location and distribution of these residual points should be highly important to the performance of PINNs. However, in previous studies on PINNs, two simple residual point sampling methods (i.e., an equispaced uniform grid and uniformly random sampling) have mainly been used, and the importance of residual point sampling has largely been overlooked. 1.1 Related work and our contributions Different residual point sampling methods can be classified into two categories: uniform sampling and nonuniform sampling. Uniform sampling can be obtained in multiple ways. For example, we could use the nodes of an equispaced uniform grid as the residual points or randomly sample the points according to a continuous uniform distribution in the computational domain. Although these two sampling methods are simple and widely used, alternative sampling methods may be applied. The Latin hypercube sampling (LHS) [29, 30] was used in Ref. [1], and the Sobol sequence [31] was first used for PINNs in Ref. [9]. The Sobol sequence is one type of quasi random low-discrepancy sequences among other sequences, such as the Halton sequence [32], and the Hammersley sequence [33]. Low-discrepancy sequences usually perform better than uniformly distributed random numbers in many applications such as numerical integration; hence, a comprehensive comparison of these methods for PINNs is required. However, very few comparisons [34, 35] have been performed. In this study, we extensively compared the performance of different uniform sampling methods, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) LHS, (4) Sobol sequence, (5) Halton sequence, and (6) Hammersley sequence. In supervised learning, the dataset is fixed during training, but in PINNs, we can select residual points at any location. Hence, instead of using the same residual points during training, in each optimization iteration, we could select a new set of residual points, as first emphasized in Ref. [3]. While this strategy has been used in some works, it has not yet been systematically tested. Thus, in this study, we tested the performance of such a resampling strategy and investigated the effect of the number of residual points and the resampling period for the first time. Uniform sampling works well for some simple PDEs, but it may not be efficient for those that are more complicated. To improve the accuracy, we could manually select the residual points in a nonuniform way, as was done in Ref. [36] for high-speed flows, but this approach is highly problem-dependent and usually tedious and time-consuming. In this study, we focus on automatic and adaptive nonuniform sampling. Motivated by the adaptive mesh refinement in FEM, Lu et al. [3] proposed the first adaptive nonuniform sampling for PINNs in 2019, the residual-based adaptive refinement (RAR) method, which adds new residual points in the locations with large PDE residuals. In 2021, another sampling strategy [37] was developed, where all the residual points were resampled according to a probability density function (PDF) proportional to the PDE residual. In this study, motivated by these two ideas, we proposed two new sampling strategies: residual-based adaptive distribution (RAD), where the PDF for sampling is a nonlinear func- tion of the PDE residual; residual-based adaptive refinement with distribution (RAR-D), which is a hybrid method of RAR and RAD, i.e., the new residual points are added according to a PDF. During the preparation of this paper, a few new studies appeared [38, 39, 40, 41, 42, 43, 44] that also proposed modified versions of RAR or PDF-based resampling. Most of these methods are special cases of the proposed RAD and RAR-D, and our methods can achieve better performance. We include a detailed comparison of these strategies in Section 2.4, after introducing several notations and our new proposed methods. In this study, we have considered a total of 10 different sampling methods, including seven non-adaptive sampling methods (six different uniform samplings and one uniform sampling with resampling) and three adaptive sampling approaches (RAR, RAD, and RAR-D). We compared the performance of these sampling methods for four forward problems of PDEs and investigated the effect of the number of residual points. We also compared their performance for two inverse problems that have not yet been consid- ered in the literature. We performed more than 6000 simulations of PINNs to obtain all the results shown in this study. 1.2 Organization This paper is organized as follows. In Section 2, after providing a brief overview of PINNs and different non-adaptive sampling strategies, two new adaptive nonuniform sampling strategies (RAD and RAR-D) are proposed. In Section 3, we compare the performance of 10 different methods for six different PDE problems, including four forward problems and two inverse problems. Section 4 summarizes the findings and concludes the paper. 2 Methods This section briefly reviews physics-informed neural networks (PINNs) in solving forward and inverse partial differential equations (PDEs). Then different types of uniformly sampling are introduced. Next, two nonuniform residual-based adaptive sampling methods are proposed to enhance the accuracy and training efficiency of PINNs. Finally, a comparison of related methods is presented. 2.1 PINNs in solving forward and inverse PDEs We consider the PDE parameterized by\u03bbdefined on a domain \u2126\u2282Rd, f(x;u(x)) =f ( x; \u2202u \u2202x 1 \u2202u \u2202xd \u2202^2 u \u2202x 1 \u2202x 1 \u2202^2 u \u2202x 1 \u2202xd ;...;\u03bb ) = 0, x= (x 1 ,...,xd)\u2208\u2126, with boundary conditions on\u2202\u2126 B(u,x) = 0, andu(x) denotes the solution atx. In PINNs, the initial condition is treated as the Dirichlet boundary condition. A forward problem is aimed to obtain the solutionu across the entire domain, where the model parameters\u03bbare known. In practice, the model parameters\u03bbmight be unknown, but some observations from the solutionuare available, which lead to an inverse problem. An inverse problem is aimed to discover parameters\u03bbthat best describe the observed data from the solution. PINNs are capable of addressing both forward and inverse problems. To solve a forward problem, the solutionuis represented with a neural network \u02c6u(x;\u03b8). The network parameters\u03b8are trained to approximate the solutionu, such that the loss function is minimized [1, 3]: L(\u03b8;T) =wfLf(\u03b8;Tf) +wbLb(\u03b8;Tb), where Lf(\u03b8;Tf) = 1 |Tf| \u2211 x\u2208Tf \u2223\u2223 \u2223\u2223f(x; \u2202u\u02c6 \u2202x 1 \u2202\u02c6u \u2202xd \u2202^2 u\u02c6 \u2202x 1 \u2202x 1 \u2202^2 u\u02c6 \u2202x 1 \u2202xd ;...;\u03bb) \u2223\u2223 \u2223\u2223 2 , (1) Lb(\u03b8;Tb) = 1 |Tb| \u2211 x\u2208Tb |B(\u02c6u,x)|^2 , andwfandwbare the weights. Two sets of points are samples both inside the domain (Tf) and on the boundaries (Tb). Here,TfandTbare referred to as the sets of \u201cresidual points\u201d, andT=Tf\u222aTb. To solve the inverse problem, an additional loss term corresponding to the misfit of the observed data at the locationsTi, defined as Li(\u03b8,\u03bb;Ti) = 1 |Ti| \u2211 x\u2208Ti |u\u02c6(x)\u2212u(x)|^2 , is added to the loss function. The loss function is then defined as L(\u03b8,\u03bb;T) =wfLf(\u03b8,\u03bb;Tf) +wbLb(\u03b8,\u03bb;Tb) +wiLi(\u03b8,\u03bb;Ti), with an additional weightwi. Then the network parameters\u03b8are trained simultaneously with\u03bb. For certain PDE problems, it is possible to enforce boundary conditions directly by constructing a special network architecture [27, 28, 8, 12], which eliminates the loss term of boundary conditions. In this study, the boundary conditions are enforced exactly and automatically. Hence, for a forward problem, the loss function is L(\u03b8,\u03bb;T) =Lf(\u03b8,\u03bb;Tf). For an inverse problem, the loss function is L(\u03b8,\u03bb;T) =wfLf(\u03b8,\u03bb;Tf) +wiLi(\u03b8,\u03bb;Ti), where we choosewf=wi= 1 for the diffusion-reaction equation in Section 3.6, andwf= 1,wi= 1000 for the Korteweg-de Vries equation in Section 3.7. 2.2 Uniformly-distributed non-adaptive sampling The training of PINNs requires a set of residual points (Tf). The sampling strategy ofTf plays a vital role in promoting the accuracy and computational efficiency of PINNs. Here, we discuss several sampling approaches. 2.2.1 Fixed residual points In most studies of PINNs, we specify the residual points at the beginning of training and never change them during the training process. Two simple sampling methods (equispaced uniform grids and uniformly random sampling) have been commonly used. Other sampling methods, such as the Latin hypercube sampling (LHS) [29, 30] and the Sobol sequence [31], have also been used in some studies [1, 9, 34]. The Sobol sequence is one type of quasi-random low-discrepancy sequences. Low-discrepancy sequences are commonly used as a replacement for uniformly distributed random numbers and usually perform better in many applications such as numerical integration. This study also considers other low-discrepancy sequences, including the Halton sequence [32] and the Hammersley sequence [33]. We list the six uniform sampling methods as follows, and the examples of 400 points generated in [0,1]^2 using different methods are shown in Fig. 1. Equispaced uniform grid (Grid): The residual points are chosen as the nodes of an equispaced uniform grid of the computational domain. Uniformly random sampling (Random): The residual points are randomly sampled according to a continuous uniform distribution over the domain. In practice, this is usually done using pseudo-random number generators such as the PCG-64 algorithm [45]. Latin hypercube sampling LHS : The LHS is a stratified Monte Carlo sampling method that generates random samples that occur within intervals on the basis of equal probability and with normal distribution for each range. Quasi-random low-discrepancy sequences: (a)Halton sequence Halton : The Halton samples are generated according to the reversing or flipping the base conversion of numbers using primes. (b)Hammersley sequence Hammersley : The Hammersley sequence is the same as the Halton sequence, except in the first dimension where points are located equidistant from each other. (c) Sobol sequence Sobol : The Sobol sequence is a base-2 digital sequence that fills in a highly uniform manner. Figure 1: Examples of 400 points generated in[0,1]^2 using different uniform sampling methods in Section 2.2.1. 2.2.2 Uniform points with resampling In PINNs, a point at any location can be used to evaluate the PDE loss. Instead of using the fixed residual points during training, we could also select a new set of residual points in every certain optimization iteration [3]. The specific method to sample the points each time can be chosen from those methods discussed in Section 2.2.1. We can even use different sampling methods at different times, so many possible implementations make it impossible to be completely covered in this study. In this study, we only consider Random sampling with resampling (Random-R). The RandomR method is the same as the Random method, except that the residual points are resampled for everyNiteration. Theresampling periodNis also an important hyperparameter for accuracy, as we demonstrate in our empirical experiments in Section 3. 2.3 Nonuniform adaptive sampling Although the uniform sampling strategies were predominantly employed, recent studies on the nonuniform adaptive sampling strategies [3, 37] have demonstrated promising improvement in the distribution of residual points during the training processes and achieved better accuracy. 2.3.1 Residual-based adaptive refinement with greed (RAR-G) The first adaptive sampling method for PINNs is the residual-based adaptive refinement method (RAR) proposed in Ref. [3]. RAR aims to improve the distribution of residual points during the training process by sampling more points in the locations where the PDE residual is large. Specifically, after every certain iteration, RAR adds new points in the locations with large PDE residuals (Algorithm 1). RAR only focuses on the points with large residual, and thus it is a greedy algorithm. To better distinguish from the other sampling methods, the RAR method is referred to as RAR-G in this study. Algorithm 1: RAR-G [3]. 1 Sample the initial residual pointsT using one of the methods in Section 2.2.1; 2 Train the PINN for a certain number of iterations; 3 repeat 4 Sample a set of dense pointsS 0 using one of the methods in Section 2.2.1; 5 Compute the PDE residuals for the points inS 0 ; 6 S \u2190mpoints with the largest residuals inS 0 ; 7 T \u2190T \u222aS; 8 Train the PINN for a certain number of iterations; 9 untilthe total number of iterations or the total number of residual points reaches the limit; 2.3.2 Residual-based adaptive distribution (RAD) RAR-G significantly improves the performance of PINNs when solving certain PDEs of solutions with steep gradients [3, 12]. Nevertheless, RAR-G focuses mainly on the location where the PDE residual is largest and disregards the locations of smaller residuals. Another sampling strategy was developed later in Ref. [37], where all the residual points are resampled according to a probability density function (PDF)p(x) proportional to the PDE residual. Specifically, for any pointx, we first compute the PDE residual\u03b5(x) =|f(x; \u02c6u(x))|, and then compute a probability as p(x)\u221d\u03b5(x), i.e., p(x) = \u03b5(x) A whereA= \u222b \u2126\u03b5(x)dxis a normalizing constant. Then all the residual points are sampled according top(x). This approach works for certain PDEs, but as we show in our numerical examples, it does not work well in some cases. Following this idea, we propose an improved version called the residualbased adaptive distribution (RAD) method (Algorithm 2), where we use a new PDF defined as p(x)\u221d \u03b5k(x) E[\u03b5k(x)] +c, (2) wherek\u22650 andc\u22650 are two hyperparameters. E[\u03b5k(x)] can be approximated by a numerical integration such as Monte Carlo integration. We note that the Random-R method in Section 2.2.2 is a special case of RAD by choosingk= 0 orc\u2192\u221e. Algorithm 2: RAD. 1 Sample the initial residual pointsT using one of the methods in Section 2.2.1; 2 Train the PINN for a certain number of iterations; 3 repeat 4 T \u2190A new set of points randomly sampled according to the PDF of Eq. (2); 5 Train the PINN for a certain number of iterations; 6 untilthe total number of iterations reaches the limit; In RAD (Algorithm 2 line 4), we need to sample a set of points according top(x), which can be done in a few ways. Whenxis low-dimensional, we can sample the points approximately in the following brute-force way: Sample a set of dense pointsS 0 using one of the methods in Section 2.2.1; Computep(x) for the points inS 0 ; Define a probability mass function \u0303p(x) =p(Ax)with the normalizing constantA= \u2211 x\u2208S 0 p(x); Sample a subset of points fromS 0 according to \u0303p(x). This method is simple, easy to implement, and sufficient for many PDE problems. For more complicated cases, we can use other methods such as inverse transform sampling, Markov chain Monte Carlo (MCMC) methods, and generative adversarial networks (GANs) [46]. The two hyperparameterskandcin Eq. (2) control the profile ofp(x) and thus the distribution of sampled points. We illustrate the effect ofkandcusing a simple 2D example, \u03b5(x,y) = 2^4 axa(1\u2212x)aya(1\u2212y)a, (3) witha= 10 in Fig. 2. Whenk= 0, it becomes a uniform distribution. As the value ofkincreases, more residual points will large PDE residuals are sampled. As the value ofcincreases, the residual points exhibit an inclination to be uniformly distributed. Compared with RAR, RAD provides more freedom to balance the points in the locations with large and small residuals by tuningkand c. The optimal values ofkandcare problem-dependent, and based on our numerical results, the combination ofk= 1 andc= 1 is usually a good default choice. 2.3.3 Residual-based adaptive refinement with distribution (RAR-D) We also propose a hybrid method of RAR-G and RAD, namely, residual-based adaptive refinement with distribution (RAR-D) (Algorithm 3). Similar to RAR-G, RAR-D repeatedly adds new points to the training dataset; similar to RAD, the new points are sampled based on the PDF in Eq. (2). We note that whenk\u2192 \u221e, only points with the largest PDE residual are added, which recovers RAR-G. The optimal values ofkandcare problem dependent, and based on our numerical results, the combination ofk= 2 andc= 0 is usually a good default choice. Figure 2:Examples of 1000 residual points sampled by RAD with different values ofk andcfor the PDE residual\u03b5(x,y)in Eq.(3). Algorithm 3: RAR-D. 1 Sample the initial residual pointsT using one of the methods in Section 2.2.1; 2 Train the PINN for a certain number of iterations; 3 repeat 4 S \u2190mpoints randomly sampled according to the PDF of Eq. (2); 5 T \u2190T \u222aS; 6 Train the PINN for a certain number of iterations; 7 untilthe total number of iterations or the total number of residual points reaches the limit; 2.4 Comparison with related work As discussed in Section 2.3, our proposed RAD and RAR-D are improved versions of the methods in Refs. [3, 37]. Here, we summarize the similarities between their methods and ours. Lu et al. [3] (in July 2019) proposed RAR (renamed to RAR-G here), which is a special case of RAR-D by choosing a large value ofk. The method proposed by Nabian et al. [37] (in April 2021) is a special case of RAD by choosingk= 1 andc= 0. During the preparation of this paper, a few new papers appeared [38, 39, 40, 41, 42, 43, 44] that also proposed similar methods. Here, we summarize the similarities and differences between these studies. The method proposed by Gao et al. [40] (in December 2021) is a special case of RAD by choosingc= 0. Tang et al. [41] (in December 2021) proposed two methods. One is a special case of RAD by choosingk= 2 andc= 0, and the other is a special case of RAR-D by choosingk= 2 and c= 0. Zeng et al. [43] (in April 2022) proposed a subdomain version of RAR-G. The entire domain is divided into many subdomains, and then new points are added to the several subdomains with large average PDE residual. Similar to RAR-G, Peng et al. [42] (in May 2022) proposed to add more points with large PDE residual, but they used the node generation technology proposed in Ref. [47]. We note that this method only works for a two-dimensional space. Zapf et al. [38] (in May 2022) proposed a modified version of RAR-G, where some points with small PDE residual are removed while adding points with large PDE residual. They show that compared with RAR, this reduces the computational cost, but the accuracy keeps similar. Hanna et al. [44] (in May 2022) proposed a similar method as RAR-D, but they chosep(x)\u221d max{log(\u03b5(x)/\u03b5 0 ), 0 }, where\u03b5 0 is a small tolerance. Similar to the work of Zapf et al., Daw et al. [39] (in July 2022) also proposed to remove the points with small PDE residual, but instead of adding new points with large PDE residual, they added new uniformly random sampled points. Thus all these methods are special cases of our proposed RAD and RAR-D (or with minor modification). However, in our study, two tunable variableskandcare introduced. As we show in our results, the values ofkandccould be crucial since they significantly influence the residual points distribution. By choosing proper values ofkandc, our methods would outperform the other methods. We also note that the point-wise weighting [16, 17, 8, 18] can be viewed as a special case of adaptive sampling, described as follows. When the residual points are randomly sampled from a uniform distributionU(\u2126), and the number of residual points is large, the PDE loss in Eq. (1) can be approximated byEU[\u03b5^2 (x)]. If we consider a point-wise weighting functionw(x), then the loss becomesEU[w(x)\u03b5^2 (x)], while for RAD the loss isEp[\u03b5^2 (x)]. If we choosew(x) (divided by a normalizing constant) as the PDFp(x), then the two losses are equal. 3 Results We apply PINNs with all the ten sampling methods in Section 2 to solve six forward and inverse PDE problems. In all examples, the hyperbolic tangent (tanh) is selected as the activation function. Table 1 summarizes the network width, depth, and optimizers used for each example. More details of the hyperparameters and training procedure can be found in each section of the specific problem. Table 1:The hyperparameters used for each numerical experiment.The learning rate of Adam optimizer is chosen as 0.001. Problems Depth Width Optimizer Section 3.2 Diffusion equation 4 32 Adam Section 3.3 Burgers\u2019 equation 4 64 Adam + L-BFGS Section 3.4 Allen-Cahn equation 4 64 Adam + L-BFGS Section 3.5 Wave equation 6 100 Adam + L-BFGS Section 3.6 Diffusion-reaction equation (inverse) 4 20 Adam Section 3.7 Korteweg-de Vries equation (inverse) 4 100 Adam For both forward and inverse problems, to evaluate the accuracy of the solution \u02c6u, theL^2 relative error is used: \u2016u\u02c6\u2212u\u2016 2 \u2016u\u2016 2 For inverse problems, to evaluate the accuracy of the predicted coefficients\u03bb\u02c6, the relative error is also computed: |\u03bb\u02c6\u2212\u03bb| |\u03bb| As the result of PINN has randomness due to the random sampling, network initialization, and optimization, thus, for each case, we run the same experiment at least 10 times and then compute the geometric mean and standard deviation of the errors. The code in this study is implemented by using the library DeepXDE [3] and is publicly available from the GitHub repositoryhttps: //github.com/lu-group/pinn-sampling. 3.1 Summary Here, we first present a summary of the accuracy of all the methods for the forward and inverse problems listed in Tables 2 and Table 3, respectively. A relatively small number of residual points is chosen to show the difference among different methods. In the specific section of each problem (Sections 3.2\u20133.7), we discuss all the detailed analyses, including the convergence of error during the training process, the convergence of error with respect to the number of residual points, and the effects of different hyperparameters (e.g., the period of resampling in Random-R, the values of kandcin RAD and RAR-D, and the number of new points added each time in RAR-D). We note that Random-R is a special case of RAD by choosingk= 0 orc\u2192 \u221e, and RAR-G is a special case of RAR-D by choosingk\u2192\u221e. Our main findings from the results are as follows. The proposed RAD method has always performed the best among the 10 sampling methods when solving all forward and inverse problems. For PDEs with complicated solutions, such as the Burgers\u2019 and multi-scale wave equation, the proposed RAD and RAR-D methods are predominately effective and yield errors magnitudes lower. For PDEs with smooth solutions, such as the diffusion equation and diffusion-reaction equa- tion, some uniform sampling methods, such as the Hammersley and Random-R, also produce sufficiently low errors. Compared with other uniform sampling methods, Random-R usually demonstrates better performance. Among the six uniform sampling methods with fixed residual points, the low-discrepancy sequences (Halton, Hammersley, and Sobol) generally perform better than Random and LHS, and both are better than Grid. Table 2: L^2 relative error of the PINN solution for the forward problems. Bold font indicates the smallest three errors for each problem. Underlined text indicates the smallest error for each problem. Diffusion Burgers\u2019 Allen-Cahn Wave No. of residual points 30 2000 1000 2000 Grid 0.66\u00b10.06% 13.7\u00b12.37% 93.4\u00b16.98% 81.3\u00b113.7% Random 0.74\u00b10.17% 13.3\u00b18.35% 22.2\u00b116.9% 68.4\u00b120.1% LHS 0.48\u00b10.24% 13.5\u00b19.05% 26.6\u00b115.8% 75.9\u00b133.1% Halton 0.24\u00b10.17% 4.51\u00b13.93% 0.29\u00b10.14% 60.2\u00b110.0% Hammersley 0.17\u00b10.07% 3.02\u00b12.98% 0.14\u00b10.14% 58.9\u00b18.52% Sobol 0.19\u00b10.07% 3.38\u00b13.21% 0.35\u00b10.24% 57.5\u00b114.7% Random-R 0.12\u00b10.06% 1.69\u00b11.67% 0.55\u00b10.34% 0.72\u00b10.90% RAR-G [3] 0.20\u00b10.07% 0.12\u00b10.04% 0.53\u00b10.19% 0.81\u00b10.11% RAD 0.11\u00b10.07% 0.02\u00b10.00% 0.08\u00b10.06% 0.09\u00b10.04% RAR-D 0.14\u00b10.11% 0.03\u00b10.01% 0.09\u00b10.03% 0.29\u00b10.04% 3.2 Diffusion equation We first consider the following one-dimensional diffusion equation: \u2202u \u2202t = \u2202^2 u \u2202x^2 +e\u2212t ( \u2212sin(\u03c0x) +\u03c0^2 sin(\u03c0x) ) , x\u2208[\u2212 1 ,1],t\u2208[0,1], u(x,0) = sin(\u03c0x), u(\u2212 1 ,t) =u(1,t) = 0, whereuis the concentration of the diffusing material. The exact solution isu(x,t) = sin(\u03c0x)e\u2212t. We first compare the performance of the six uniform sampling methods with fixed residual points (Fig. 3A). The number of residual points is ranged from 10 to 80 with an increment of 10 points each time. For each number of residual points, the maximum iteration is set to be 15 000 with Adam as the optimizer. When the number of points is large (e.g., more than 70), all these methods Figure 3:L^2 relative errors of different sampling methods for the diffusion equation in Section 3.2.(A) Six uniform sampling with fixed residual points. (B) Random-R with different periods of resampling when using 30 residual points. (CandD) The training trajectory of RAD with different values ofkandcwhen using 30 residual points. (C)k= 1. (D)c= 1. (EandF) RAR-D with different values ofkandc. Each time one new point is added. (E)k= 2. (F)c= The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. Table 3:L^2 relative error of the PINN solution and relative error of the inferred parameters for the inverse problems.Bold font indicates the smallest three errors for each problem. Underlined text indicates the smallest error for each problem. Diffusion-reaction Korteweg-de Vries u(x) k(x) u(x,t) \u03bb 1 \u03bb 2 No. of residual points 15 600 Grid 0.36\u00b10.12% 8.58\u00b12.14% 24.4\u00b111.1% 53.7\u00b130.7% 42.0\u00b122.3% Random 0.35\u00b10.17% 5.77\u00b12.05% 8.86\u00b12.80% 16.4\u00b17.33% 16.8\u00b17.40% LHS 0.36\u00b10.14% 7.00\u00b12.62% 10.9\u00b12.60% 22.0\u00b16.68% 22.6\u00b16.36% Halton 0.23\u00b10.08% 6.16\u00b11.08% 8.76\u00b13.33% 16.7\u00b16.16% 17.2\u00b16.20% Hammersley 0.28\u00b10.08% 6.37\u00b10.91% 4.49\u00b13.56% 5.24\u00b17.08% 5.71\u00b17.32% Sobol 0.21\u00b10.06% 3.09\u00b10.75% 8.59\u00b13.67% 15.8\u00b16.15% 15.6\u00b15.79% Random-R 0.19\u00b10.09% 3.43\u00b11.80% 0.97\u00b10.15% 0.41\u00b10.30% 1.14\u00b10.31% RAR-G [3] 1.12\u00b10.11% 15.9\u00b11.53% 8.83\u00b11.98% 15.4\u00b19.29% 14.5\u00b19.25% RAD 0.17\u00b10.09% 2.76\u00b11.32% 0.77\u00b10.11% 0.31\u00b10.19% 0.86\u00b10.25% RAR-D 0.76\u00b10.24% 10.3\u00b13.28% 2.36\u00b10.98% 3.49\u00b12.21% 3.18\u00b12.02% have similar performance. However, when the number of residual points is small such as 50, the Hammersley and Sobol sequences perform better than others, and the equispaced uniform grid and random sampling have the largest errors (about one order of magnitude larger than Hammersley and Sobol). We then test the Random-R method using 30 residual points (Fig. 3B). The accuracy of Random-R has a strong dependence on the period of resampling, and the optimal period of resampling in this problem is around 200. Compared with Random without resampling, the Random-R method always leads to lowerL^2 relative errors regardless of the period of resampling. The error can be lower by one order of magnitude by choosing a proper resampling period. Among all the non-adaptive methods, Random-R performs the best. Next, we test the performance of the nonuniform adaptive sampling methods. In Algorithms 2 and 3, the neural network is first trained using 10 000 steps of Adam. In the RAD method, we use 30 residual points and resample every 1000 iterations. The errors of RAD with different values of kandcare shown in Figs. 3C and D. We note that Random-R is a special case of RAD with either c\u2192 \u221eork= 0. Here, RAD with large values ofcor small values ofkleads to better accuracy, i.e., the points are almost uniformly distributed. For the RAR-D method (Figs. 3E and F), one residual point is added after every 1000 iterations starting from 10 points. When usingk= 2 and c= 0 (the two red lines in Figs. 3E red F), RAR-D performs the best. When using 30 residual points, the errors of all the methods are listed in Table 2. In this diffusion equation, all the methods achieve a good accuracy (<1%). Compared with Random-R (0.12%), RAD and RAR-D (0.11%) are not significantly better. The reason could be that the solution of this diffusion equation is very smooth, so uniformly distributed points are good enough. In our following examples, we show that RAD and RAR-D work significantly better and achieve an error of orders of magnitude smaller than the non-adaptive methods. 3.3 Burgers\u2019 equation The Burgers\u2019 equation is considered defined as: \u2202u \u2202t +u \u2202u \u2202x =\u03bd \u2202^2 u \u2202x^2 , x\u2208[\u2212 1 ,1],t\u2208[0,1], u(x,0) =\u2212sin(\u03c0x), u(\u2212 1 ,t) =u(1,t) = 0, whereuis the flow velocity and\u03bd is the viscosity of the fluid. In this study,\u03bdis set at 0. 01 /\u03c0. Different from the diffusion equation with a smooth solution, the solution of the Burgers\u2019 equation has a sharp front whenx= 0 andtis close to 1. We first test the uniform sampling methods by using the number of residual points ranging from 1,000 to 10,000 (Fig. 4A). The maximum iteration is 15,000 steps with Adam as optimizer followed by 15,000 steps of L-BFGS. Fig. 4A shows that the Hammersley method converges the fastest and reaches the lowestL^2 relative error among all the uniform sampling methods, while the Halton and Sobol sequences also perform adequately. Fig. 4B shows theL^2 relative error as a function of the period of resampling using the RandomR method with 2,000 residual points. Similar to the diffusion equation, the Random-R method always outperforms the Random method. However, the performance of Random-R is not sensitive to the period of resampling if the period is smaller than 100. Choosing a period of resampling too large can negatively affect its performance. When applying the nonuniform adaptive methods, the neural network is first trained using 15,000 steps of Adam and then 1,000 steps of L-BFGS. In the RAD method, we use 2000 residual points, which are resampled every 2,000 iterations (1,000 iterations using Adam followed by 1,000 iterations using L-BFGS). As indicated by Fig. 4C, the RAD method possesses significantly greater advantages over the Random-R method (a special case of RAD by choosingk= 0 orc\u2192 \u221e), whoseL^2 relative errors barely decrease during the training processes. This fact reflects that both extreme cases show worse performance. In contrast, fork= 1 andc= 1 (the red lines in Figs. 4C and D), theL^2 relative error declines rapidly and quickly reaches\u223c 2 \u00d7 10 \u2212^4. The RAD method is also effective when choosing a set ofkandcin a moderate range. For the RAR-D method, 1,000 residual points are selected in the pre-trained process, and 10 residual points are added every 2,000 iterations (1,000 iterations using Adam and 1,000 iterations using L-BFGS as optimizer) until the total number of residual points reaches 2,000. Shown by Figs. 4E and F, the optimal values forkandcare found to be 2 and 0, respectively. Since the solution of Burgers\u2019 equation has a very steep region, when using 2000 residual points, both RAD and RAR-D have competitive advantages over the uniform sampling methods in terms of accuracy and efficiency. For the following three forward PDE problems (Allen-Cahn equation in Section 3.4, wave equation in Section 3.5, and diffusion-reaction equation in Section 3.6), unless otherwise stated, the maximum iterations, the use of optimizer, and the training processes remain the same as the Burgers\u2019 equation. Table 2 summarizes theL^2 relative error for all methods when we fix the number of residual points at 2000. All uniform sampling methods fail to capture the solution well. TheL^2 relative errors given by the Halton, Hammersley, and Sobol methods (\u223c4%) are around one-fourth of that given by the Grid, Random, and LHS methods (>13%). Even though the Random-R performs the best among all uniform methods (1.69\u00b11.67%), the proposed RAD and RAR-D methods can achieve anL^2 relative error two orders of magnitude lower than that (0.02%). Figure 4:L^2 relative errors of different sampling methods for the Burgers\u2019 equation in Section 3.3.(A) Six uniform sampling with fixed residual points. (B) Random-R with different periods of resampling when using 2000 residual points. (CandD) The training trajectory of RAD with different values ofkandcwhen using 2000 residual points. (C)k= 1. (D)c= 1. (EandF) RAR-D with different values ofkandc. Each time 10 new points are added. (E)k= 2. (F)c= The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. 3.4 Allen-Cahn equation Next, we consider the Allen-Cahn equation in the following form: \u2202u \u2202t =D \u2202^2 u \u2202x^2 5(u\u2212u^3 ), x\u2208[\u2212 1 ,1],t\u2208[0,1], u(x,0) =x^2 cos(\u03c0x), u(\u2212 1 ,t) =u(1,t) =\u2212 1 , where the diffusion coefficientD= 0.001. Fig. 5 outlines theL^2 relative errors of different sampling methods for the Allen-Cahn equation. Similar patterns are found for the nonadaptive uniform sampling as in the previous examples. The Hammersley method has the best accuracy (Fig. 5A). As the number of residual points becomes significantly large, the difference between these uniform sampling methods becomes negligible. Except for the equispaced uniform grid method, other uniform sampling methods converge toL^2 relative errors of 10\u2212^3 , about the same magnitude as the number of residual points reaching 10^4. Fig. 5B shows that when using 1000 residual points for Random-R, lowerL^2 relative errors can be obtained if we select a period of resampling less than 500. We next test the performance of RAD for different values ofkandcwhen using a different number of residual points. In Figs. 5C and D, we resampled 500 residual points every 2000 iteration, while in Figs. 5E and F, we used 1000 residual points instead. For both cases, the combination of k= 1 andc= 1 (the red lines in Figs. 5C\u2013F) gives good accuracy. When fewer residual points (e.g., 500) are used, the RAD methods boost the performance of PINNs. Similarly, we also test RAR-D in Figs. 5G\u2013J. In Figs. 5G and H, we pre-train the neural network with 500 residual points and add 10 residual points after every 2000 iterations until the total number of residual points reaches 1000. In Figs. 5I and J, we pre-train the neural network using 1000 residual points and heading to 2000 residual points in the same fashion. We recognize that 2 and 0 are the bestkandcvalues for the RAR-D method for both scenarios, which outperform the RAR-G method. As proven in this example, when applying the RAD and the RAR-D methods, the optimal values ofkandcremain stable even though we choose a different number of residual points. In addition, we find that the optimalkandcfor the Burgers\u2019 and Allen Cahn equations are the same for both the RAD and the RAR-D methods. Thus, we could choose (k= 1,c= 1) for the RAD methods and (k= 2,c= 0) for the RAR-D methods by default when first applied these methods to a new PDE problem. To make a comparison across all sampling methods, Table 2 shows theL^2 relative error for the Allen-Cahn equation when we fix the number of residual points at 1000. The Grid, Random, and LHS methods are prone to substantial errors, which are all larger than 20%. Nevertheless, the other four uniform methods (Halton, Hammersley, Sobol, and Random-R) have greater performance and can achieveL^2 relative errors of less than 1%. Remarkably, the RAD and RAR-D methods we proposed can further bring down theL^2 relative error below 0.1%. Figure 5:L^2 relative errors of different sampling methods for the Allen-Cahn equation in Section 3.4.(A) Six uniform sampling with fixed residual points. (B) Random-R with different periods of resampling when using 1000 residual points. (C\u2013F) The training trajectory of RAD with different values ofkandc. (C and D) 500 residual points are used. (C)k= 1. (D)c= 1. (E and F) 1000 residual points are used. (E)k= 1. (F)c= 1. (G\u2013J) RAR-D with different values ofk andc. (G and H) The number of residual points is increased from 500 to 1000. Each time 10 new points are added. (G)k= 2. (H)c= 0. (I and J) The number of residual points is increased from 1000 to 2000. Each time 10 new points are added. (I)k= 2. (J)c= 0. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. 18 3.5 Wave equation In this example, the following one-dimensional wave equation is considered: \u2202^2 u \u2202t^2 \u2212 4 \u2202^2 u \u2202x^2 = 0, x\u2208[0,1],t\u2208[0,1], u(0,t) =u(1,t) = 0, t\u2208[0,1], u(x,0) = sin(\u03c0x) + 1 2 sin(4\u03c0x), x\u2208[0,1], \u2202u \u2202t (x,0) = 0, x\u2208[0,1], where the exact solution is given as: u(x,t) = sin(\u03c0x) cos(2\u03c0t) + 1 2 sin(4\u03c0x) cos(8\u03c0t). The solution has a multi-scale behavior in both spatial and temporal directions. When we test the six uniform sampling methods, the number of residual points are ranged from 1000 to 6000, with an increment of 1000 each time. The Hammersley method achieves the lowest L^2 relative error with the fastest rate (Fig. 6A). When the number of residual points approaches 6000, the Random, Halton, and Hammersley methods can all obtain anL^2 relative error\u223c 10 \u2212^3. To determine the effectiveness of Random-R when using different numbers of residual points, we test the following three scenarios: small (1000 points), medium (4000 points), and large (10.000) sets of residual points (Figs. 6B, C, and D). In the medium case (Fig. 6C), the Random-R attainsL^2 relative errors magnitudes lower than the Random method. However, in the small and large cases (Figs. 6B and D), the Random-R methods show no advantage over the Random method regardless of the period of resampling. This is because when the number of residual points is small, both the Random and Random-R methods fail to provide accurate predictions. On the other hand, if the number of residual points is large, the predictions by the Random method are already highly accurate, so the Random-R is unable to further improve the accuracy. Since the optimal sets ofkandcfor both RAD and RAR-D methods are found to be the same for the Burgers\u2019 and the Allen Cahn equations, in this numerical experiment, we only apply the default settings (i.e., RAD:k= 1 andc= 1; RAR-D:k= 2 andc= 0) to investigate the effect of other factors, including the number of residual points for the RAD method and the number of points added to the RAR-D method. In Fig. 6E, we compare the performance of three nonuniform adaptive sampling methods under the same number of residual points from 1000 to 10 000. We first train the network using 15 000 iterations of Adam and 1000 iterations of L-BFGS, and then after each resampling in RAD or adding new points in RAR-D/RAR-G, we train the network with 1000 iterations of L-BFGS. For the RAR-G and the RAR-D methods, we first train the network with 50% of the final number of the residual points and add 10 residual points each time until reaching the total number of residual points. As we can see from Fig. 6E, the RAD achieves much better results when the number of residual points is small. As the number of residual points increases, the RAR-D method acts more effectively and eventually reaches comparable accuracy to the RAD method. Since the RAD method is more computationally costly than the RAR-D methods with the same number of residual points, we suggest applying the RAD method when the number of residual points is small and the RAR-D method when the number of residual points is large. We next investigate the RAD method with a different number of residual points (i.e., 1000, 2000, 5000, and 10 000). Fig. 6F illustrates that if we increase the number of residual points, lower Figure 6: L^2 relative errors of different sampling methods for the wave equation in Section 3.5.(A) Six uniform sampling with fixed residual points. (B,C, andD) Random-R with different periods of resampling when using (B) 1000 residual points, (C) 4000 residual points, and (D) 10000 residual points. (E) Comparison among RAD (k= 1 andc= 1), RAR-D (k= 2 and c= 0), and RAR-G for different numbers of residual points. (F) The training trajectory of RAD (k= 1 andc= 1) uses different numbers of residual points. (GandH) Convergence of RAR-D (k= 2 andc= 0) when adding a different number of new points each time. (G) New points are added starting from 1000 residual points. (H) New points are added starting from 2500 residual points. (I) Convergence of RAR-G when adding a different number of new points each time. New points are added starting from 2500 residual points. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. L^2 relative error can be achieved but with diminishing marginal effect. We train the network for more than 500 000 iterations to see if theL^2 relative error can further decrease. However, theL^2 relative errors converge and remain relatively stable after 100 000 iterations. One important factor to consider in the RAR-D and the RAR-G methods is how new points are added. We can either add a small number of residual points each time and prolong the training process or add a large number of residual points each time and shorten the process. In Fig. 6G, we first train the network with 1000 residual points and then add new residual points at different rates until the total number of residual points reaches 2000. After adding new residual points each time, we train the network using 1000 steps of L-BFGS. Likewise, in Fig. 6H, we first train the network with 2500 residual points and add new points at different rates until the total number of residual points reaches 5000. In both cases (Figs. 6G and H) that use the RAR-D methods, we find that the best strategy is to add 10 points each time. However, shown by two red-shaded regions in Figs. 6G and H, the results are more stable when we use a larger number of residual points. Fig. 6I is set up the same way as Fig. 6H but tests the RAR-G method. The best strategy for the RAR-G is identical to that of the RAR-D. Table 2 outlines theL^2 relative error for the wave equation using all methods when the number of residual points equals 2000. All uniform methods with fixed residual points perform poorly (error >50%) and fail to approximate the truth values. Random-R, as a special case of the proposed RAD, givesL^2 relative errors of around 1%. The RAR-D method significantly enhances the prediction accuracy resulting inL^2 relative errors under 0.3%. In addition, the RAD with the default setting ofkandcconverges toL^2 relative errors under 0.1%. 3.6 Diffusion-reaction equation The first inverse problem we consider is the diffusion-reaction system as follows: \u03bb d^2 u dx^2 \u2212k(x)u=f, x\u2208[0,1], wheref = sin(2\u03c0x) is the source term. \u03bb= 0.01 is the diffusion coefficient, anduis the solute concentration. In this problem, we aim to infer the space-dependent reaction ratek(x) with given measurements on the solutionu. The exact unknown reaction rate is k(x) = 0.1 +e\u2212^0.^5 (x\u2212 0 .5)^2 (^152). We aim to learn the unknown functionk(x) and solve foru(x) by using eight observations ofu, which are uniformly distributed on the domainx\u2208[0,1], including two points on both sides of the boundaries. TheL^2 relative errors for both the solutionu(Figs. 7A, C, and E) and the unknown functionk(Figs. 7B, D, and F) are computed. The maximum number of iterations is 50 000 steps of Adam. Figs. 7A and B summarize the performance of all uniform sampling methods. We note that in 1D, the Hammersley and Halton sequences are identical and outperform other uniform methods. We fix the residual points at 15 and compare the Random method with the Random-R method. TheL^2 relative errors (Figs. 7C and D) given by the Random-R remain steady, disregarding the changes in the period of resampling, and are approximately the same as that produced by the Random method. This is because the reaction-diffusion system is fairly simple and can be easily handled by uniform sampling methods without resampling. Next, we compare the Random, RAD, RAR-G, and RAR-D methods with default settings (i.e., RAD:k= 1 andc= 1; RAR-D:k= 2 andc= 0) using a different number of residual points. For the random and RAD methods, the maximum number of iterations is 50 000 steps of Adam. For Figure 7:L^2 relative errors of different sampling methods foruandkin the diffusionreaction equation in Section 3.6.(AandB) Six uniform sampling with fixed residual points. (CandD) Random-R with different periods of resampling when using 15 residual points. (Eand F) Comparison among Random, RAD (k= 1 andc= 1), RAR-G, and RAR-D (k= 2 andc= 0) for different numbers of residual points. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. the RAR-G/RAR-D, we first train the neural network with 50% of the total number of residual points for 10 000 steps of Adam; then we add one point each time and train for 1000 steps of Adam until we meet the total number of residual points. As shown by Figs. 7E and F, the RAD method surpasses other methods and is able to produce lowL^2 relative error even when the number of residual points is very small. However, RAR-G and RAR-D are even worse than the Random sampling. To sum up, we fix the number of residual points at 15 and present theL^2 relative error for both the solution and unknown function in Table 3. The RAD yields the minimumL^2 relative error (0.17% foru(x); 2.76% fork(x)). However, due to the simplicity of this PDE problem, some uniform sampling methods, especially the Sobol and Random-R, have comparable performance to the RAD. Generally speaking, we recognize that the uniform sampling methods are adequate when solving this inverse PDE with smooth solutions. Still, the RAD method can further enhance the performance of PINNs, especially when the number of residual points is small. 3.7 Korteweg-de Vries equation The second inverse problem we solve is the Korteweg-de Vries (KdV) equation: \u2202u \u2202t +\u03bb 1 u \u2202u \u2202x +\u03bb 2 \u2202^3 u \u2202x^3 = 0, x\u2208[\u2212 1 ,1], t\u2208[0,1], where\u03bb 1 and\u03bb 2 are two unknown parameters. The exact values for\u03bb 1 and\u03bb 2 are 1 and 0.0025, respectively. The initial condition isu(x,t= 0) = cos(\u03c0x), and periodic boundary conditions are used. To infer\u03bb 1 and\u03bb 2 , we assume that we have the observations of two solution snapshots u(x,t= 0.2) andu(x,t= 0.8) at 64 uniformly distributed points at each time. In Fig. 8, the first column (Figs. 8A, D, and G) shows theL^2 relative error of the solutionu, while the second column (Figs. 8B, E, and H) and the third column (Figs. 8C, F, and I) illustrate the relative errors for\u03bb 1 and\u03bb 2 , respectively. The maximum iteration is 100 000 steps of Adam. Hammersley achieves better accuracy than the other uniform sampling methods. The Sobol and Halton methods behave comparably as these two curves (the yellow and green curves in Figs. 8A, B, and C) are almost overlapping. Shown in Figs. 8D, E and F, the Random-R method yields higher accuracy than the Random method by about one order of magnitude in all cases when using 1000 residual points. A smaller period of resampling leads to smaller errors. Figs. 8G, H, and I compare the Random-R, Random, RAD, RAR-G, and RAR-D methods using the same number of residual points and the total number of iterations. For the Random and the Random-R methods, we train the network for 100 000 steps of Adams. For the RAD methods, we first train the network using 50 000 steps of Adams; then, we resample the residual points and train for 1000 steps of Adams 50 times. In order to fix the total number of iterations for the RARG/RAR-D methods to 100 000, we accordingly adjust the number of new residual points added each time. For example, if the final number of residual points is 500, we first train the network using 250 residual points (i.e., 50% of the total number of residual points) with 50 000 steps of Adams; and we consequently add 5 points and train for 1000 steps of Adams each time. If the final number of residual points is 1000, we first train the network using 500 residual points with 50 000 steps of Adams; and then we add 10 points and train for 1000 steps of Adams each time. As demonstrated by Figs. 8G, H, and I, the RAD method is the best, while the Random-R method is also reasonably accurate. We show one example of the training process (Figs. 8J, K, and L) when the number of residual points is 600 to illustrate the convergence of the solution,\u03bb 1 , and\u03bb 2 during training. The resampling strategies, especially the RAD method, achieve the greatest success among all sampling methods. Figure 8:L^2 relative errors ofuand relative errors of\u03bb 1 and\u03bb 2 using different sampling methods for the Korteweg-de Vries equation in Section 3.7. (A,B, andC) Six uniform sampling with fixed residual points. (D,E, andF) Random-R with different periods of resampling when using 1000 residual points. (G,H, andI) Comparison among Random, Random-R, RAD (k= 1 andc= 1), RAR-G, and RAR-D (k= 2 andc= 0) for different number of residual points. (J,K, andL) Examples of the training trajectories using Random, Random-R, RAD (k= 1 and c= 1), RAR-G, and RAR-D (k= 2 andc= 0) with 600 residual points. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. Table 3 demonstrates theL^2 relative errors for the solutionu(x,t) and the relative error of two unknown parameters\u03bb 1 and\u03bb 2 , for all methods when the number of residual points is set at The lowestL^2 relative errors for uniform sampling with fixed points are given by Hammersley (\u223c 5%). The Random-R is the second-best method and providesL^2 relative errors of around 1%. With the smallest errors (<1%) and standard deviations, the RAD method has compelling advantages over all other methods in terms of accuracy and robustness. It is noteworthy that the RAR-D method provides adequate accuracy (\u223c3%) and is less expensive than the Random-R and RAD methods when the number of residual points is the same. Therefore, the RAR-D is also a valuable approach to consider. 4 Conclusions In this paper, we present a comprehensive study of two categories of sampling for physics-informed neural networks (PINNs), including non-adaptive uniform sampling and adaptive nonuniform sampling. For the non-adaptive uniform sampling, we have considered six methods: (1) equispaced uniform grid (Grid), (2) uniformly random sampling (Random), (3) Latin hypercube sampling (LHS), (4) Halton sequence (Halton), (5) Hammersley sequence (Hammersley), and (6) Sobol sequence (Sobol). We have also considered a resampling strategy for uniform sampling (Random-R). For the adaptive nonuniform sampling, motivated by the residual-based adaptive refinement with greed (RAR-G) [3], we proposed two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D). We extensively investigated the performance of these ten sampling methods in solving four forward and two inverse problems of partial differential equations (PDEs) with many setups, such as a different number of residual points. Our results show that the proposed RAD and RAR-D significantly improve the accuracy of PINNs by orders of magnitude, especially when the number of residual points is small. RAD and RAR-D also have great advantages for the PDEs with complicated solutions, e.g., the solution of the Burgers\u2019 equation with steep gradients and the solution of the wave equation with a multi-scale behavior. A summary of the comparison of these methods can be found in Section 3.1. Based on our empirical results, we summarize the following suggestions as a practical guideline in choosing sampling methods for PINNs. RAD withk= 1 andc= 1 can be chosen as the default sampling method when solving a new PDE. The hyperparameterskandccan be tuned to balance the points in the locations with large and small PDE residuals. RAR-D can achieve comparable accuracy to RAD, but RAR-D is more computationally efficient as it gradually increases the number of residual points. Hence, RAR-D (k= 2 and c= 0 by default) is preferable for the case with limited computational resources. Random-R can be used in the situation where adaptive sampling is not allowed, e.g., it is difficult to sample residual points according to a probability density function. The period of resampling should not be chosen as too small or too large. A low-discrepancy sequence (e.g., Hammersley) should be considered rather than Grid, Ran- dom, or LHS, when we have to use a fixed set of residual points, such as in PINNs with the augmented Lagrangian method (hPINNs) [8]. In this study, we sample residual points in RAD and RAR-D by using a brute-force approach, which is simple, easy to implement, and sufficient for many PDEs. However, for high-dimensional problems, we need to use other methods, such as generative adversarial networks (GANs) [46], as was done in Ref. [41]. Moreover, the probability of sampling a pointxis only considered as p(x)\u221d \u03b5 k(x) E[\u03b5k(x)]+c. While this probability works very well in this study, it is possible that there exists another better choice. We can learn a new probability density function by meta-learning, as was done for loss functions of PINNs in Ref. [11]. References [1] M. Raissi, P. Perdikaris, and G.E. Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.Journal of Computational Physics, 378:686\u2013707, 2019. [2] Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations.Science, 367(6481):1026\u20131030, 2020. [3] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. DeepXDE: A deep learning library for solving differential equations.SIAM Review, 63(1):208\u2013228, 2021. [4] George Em Karniadakis, Ioannis G. Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning.Nature Reviews Physics, 3(6):422\u2013440, 2021. [5] Yuyao Chen, Lu Lu, George Em Karniadakis, and Luca Dal Negro. Physics-informed neural networks for inverse problems in nano-optics and metamaterials.Optics Express, 28(8):11618, 2020. [6] Alireza Yazdani, Lu Lu, Maziar Raissi, and George Em Karniadakis. Systems biology informed deep learning for inferring parameters and hidden dynamics. PLOS Computational Biology, 16(11), 2020. [7] Mitchell Daneker, Zhen Zhang, George Em Kevrekidis, and Lu Lu. Systems biology: Identifiability analysis and parameter identification via systems-biology informed neural networks. arXiv preprint arXiv:2202.01723, 2022. [8] Lu Lu, Rapha \u0308el Pestourie, Wenjie Yao, Zhicheng Wang, Francesc Verdugo, and Steven G. Johnson. Physics-informed neural networks with hard constraints for inverse design. SIAM Journal on Scientific Computing, 43(6), 2021. [9] Guofei Pang, Lu Lu, and George Em Karniadakis. fPINNs: Fractional physics-informed neural networks. SIAM Journal on Scientific Computing, 41(4), 2019. [10] Dongkun Zhang, Lu Lu, Ling Guo, and George Em Karniadakis. Quantifying total uncertainty in physics-informed neural networks for solving forward and inverse stochastic problems.Journal of Computational Physics, 397:108850, 2019. [11] Apostolos F Psaros, Kenji Kawaguchi, and George Em Karniadakis. Meta-learning PINN loss functions. Journal of Computational Physics, 458:111121, 2022. [12] Jeremy Yu, Lu Lu, Xuhui Meng, and George Em Karniadakis. Gradient-enhanced physicsinformed neural networks for forward and inverse PDE problems.Computer Methods in Applied Mechanics and Engineering, 393:114823, 2022. [13] Sifan Wang, Yujun Teng, and Paris Perdikaris. Understanding and mitigating gradient flow pathologies in physics-informed neural networks. SIAM Journal on Scientific Computing, 43(5):A3055\u2013A3081, 2021. [14] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why PINNs fail to train: A neural tangent kernel perspective. Journal of Computational Physics, 449:110768, 2022. [15] Zixue Xiang, Wei Peng, Xu Liu, and Wen Yao. Self-adaptive loss balanced physics-informed neural networks.Neurocomputing, 2022. [16] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft attention mechanism.arXiv preprint arXiv:2009.04544, 2020. [17] Yiqi Gu, Haizhao Yang, and Chao Zhou. SelectNet: Self-paced learning for high-dimensional partial differential equations.Journal of Computational Physics, 441:110444, 2021. [18] Wensheng Li, Chao Zhang, Chuncheng Wang, Hanting Guan, and Dacheng Tao. Revisiting PINNs: Generative adversarial physics-informed neural networks and point-weighting method. arXiv preprint arXiv:2205.08754, 2022. [19] Xuhui Meng, Zhen Li, Dongkun Zhang, and George Em Karniadakis. PPINN: Parareal physicsinformed neural network for time-dependent pdes. Computer Methods in Applied Mechanics and Engineering, 370:113250, 2020. [20] Khemraj Shukla, Ameya D. Jagtap, and George Em Karniadakis. Parallel physics-informed neural networks via domain decomposition. Journal of Computational Physics, 447:110683, 2021. [21] Ameya D. Jagtap and George Em Karniadakis. Extended physics-informed neural networks (XPINNs): A generalized space-time domain decomposition based deep learning framework for nonlinear partial differential equations. Communications in Computational Physics, 28(5):2002\u20132041, 2020. [22] Colby L Wight and Jia Zhao. Solving Allen-Cahn and Cahn-Hilliard equations using the adaptive physics informed neural networks. arXiv preprint arXiv:2007.04542, 2020. [23] Aditi Krishnapriyan, Amir Gholami, Shandian Zhe, Robert Kirby, and Michael W Mahoney. Characterizing possible failure modes in physics-informed neural networks.Advances in Neural Information Processing Systems, 34:26548\u201326560, 2021. [24] Revanth Mattey and Susanta Ghosh. A novel sequential method to train physics informed neural networks for allen cahn and cahn hilliard equations. Computer Methods in Applied Mechanics and Engineering, 390:114474, 2022. [25] Katsiaryna Haitsiukevich and Alexander Ilin. Improved training of physics-informed neural networks with model ensembles. arXiv preprint arXiv:2204.05108, 2022. [26] Sifan Wang, Shyam Sankaran, and Paris Perdikaris. Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404, 2022. [27] Pola Lydia Lagari, Lefteri H Tsoukalas, Salar Safarkhani, and Isaac E Lagaris. Systematic construction of neural forms for solving partial differential equations inside rectangular domains, subject to initial, boundary and interface conditions. International Journal on Artificial Intelligence Tools, 29(05):2050009, 2020. [28] Suchuan Dong and Naxian Ni. A method for representing periodic functions and enforcing exactly periodic boundary conditions with deep neural networks. Journal of Computational Physics, 435:110242, 2021. [29] Michael D McKay, Richard J Beckman, and William J Conover. A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 42(1):55\u201361, 2000. [30] Michael Stein. Large sample properties of simulations using Latin hypercube sampling.Technometrics, 29(2):143\u2013151, 1987. [31] Il\u2019ya Meerovich Sobol\u2019. On the distribution of points in a cube and the approximate evaluation of integrals.Zhurnal Vychislitel\u2019noi Matematiki i Matematicheskoi Fiziki, 7(4):784\u2013802, 1967. [32] John H Halton. On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals. Numerische Mathematik, 2(1):84\u201390, 1960. [33] JM Hammersley and DC Handscomb. Monte-Carlo methods, mathuen, 1964. [34] Hongwei Guo, Xiaoying Zhuang, Xiaoyu Meng, and Timon Rabczuk. Analysis of three dimensional potential problems in non-homogeneous media with deep learning based collocation method.arXiv preprint arXiv:2010.12060, 2020. [35] Sourav Das and Solomon Tesfamariam. State-of-the-art review of design of experiments for physics-informed deep learning.arXiv preprint arXiv:2202.06416, 2022. [36] Zhiping Mao, Ameya D Jagtap, and George Em Karniadakis. Physics-informed neural networks for high-speed flows. Computer Methods in Applied Mechanics and Engineering, 360:112789, 2020. [37] Mohammad Amin Nabian, Rini Jasmine Gladstone, and Hadi Meidani. Efficient training of physics-informed neural networks via importance sampling.Computer-Aided Civil and Infrastructure Engineering, 2021. [38] Bastian Zapf, Johannes Haubner, Miroslav Kuchta, Geir Ringstad, Per Kristian Eide, and Kent-Andre Mardal. Investigating molecular transport in the human brain from MRI with physics-informed neural networks.arXiv preprint arXiv:2205.02592, 2022. [39] Arka Daw, Jie Bu, Sifan Wang, Paris Perdikaris, and Anuj Karpatne. Rethinking the importance of sampling in physics-informed neural networks. arXiv preprint arXiv:2207.02338, 2022. [40] Wenhan Gao and Chunmei Wang. Active learning based sampling for high-dimensional nonlinear partial differential equations. arXiv preprint arXiv:2112.13988, 2021. [41] Kejun Tang, Xiaoliang Wan, and Chao Yang. DAS: A deep adaptive sampling method for solving partial differential equations.arXiv preprint arXiv:2112.14038, 2021. [42] Wei Peng, Weien Zhou, Xiaoya Zhang, Wen Yao, and Zheliang Liu. RANG: a residualbased adaptive node generation method for physics-informed neural networks. arXiv preprint arXiv:2205.01051, 2022. [43] Shaojie Zeng, Zong Zhang, and Qingsong Zou. Adaptive deep neural networks methods for high-dimensional partial differential equations.Journal of Computational Physics, 463:111232, 2022. [44] John M Hanna, Jose V Aguado, Sebastien Comas-Cardona, Ramzi Askri, and Domenico Borzacchiello. Residual-based adaptivity for two-phase flow simulation in porous media using physics-informed neural networks.Computer Methods in Applied Mechanics and Engineering, 396:115100, 2022. [45] Melissa E O\u2019Neill. Pcg: A family of simple fast space-efficient statistically good algorithms for random number generation.ACM Transactions on Mathematical Software, 2014. [46] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.Advances in neural information processing systems, 27, 2014. [47] Bengt Fornberg and Natasha Flyer. Fast generation of 2-D node distributions for mesh-free pde discretizations.Computers & Mathematics with Applications, 69(7):531\u2013544, 2015.","title":"A Comprehensive Study of Non-Adaptive and Residual-Based Adaptive Sampling for Physics-Informed Neural Networks <br> \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u81ea\u9002\u5e94\u91c7\u6837\u548c\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u91c7\u6837\u7684\u7efc\u5408\u7814\u7a76"},{"location":"Models/PINNs/PN-2207.10289/#a-comprehensive-study-of-non-adaptive-and-residual-based-adaptive-sampling-for-physics-informed-neural-networks","text":"\u4f5c\u8005: Chenxi Wu1,\u2020, Min Zhu1,\u2020, Qinyang Tan^2 , Yadhu Kartha^3 , and Lu Lu1,* \u673a\u6784: College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, USA \u65f6\u95f4: 2022-07-21 \u9884\u5370: arXiv:2207.10289v1 \u9886\u57df: physics.comp-ph \u6807\u7b7e: \u504f\u5fae\u5206\u65b9\u7a0b, \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc, \u6b8b\u5dee\u70b9\u5206\u5e03, \u975e\u81ea\u9002\u5e94\u5747\u5300\u91c7\u6837, \u5e26\u91cd\u91c7\u6837\u7684\u5747\u5300\u91c7\u6837, \u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u91c7\u6837 \u5f15\u7528: 47 \u7bc7","title":"A Comprehensive Study of Non-Adaptive and Residual-Based Adaptive Sampling for Physics-Informed Neural Networks  \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u81ea\u9002\u5e94\u91c7\u6837\u548c\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u91c7\u6837\u7684\u7efc\u5408\u7814\u7a76"},{"location":"Models/PINNs/PN-2207.10289/#abstract","text":"Physics-informed neural networks (PINNs) have shown to be an effective tool for solving both forward and inverse problems of partial differential equations (PDEs). PINNs embed the PDEs into the loss of the neural network using automatic differentiation, and this PDE loss is evaluated at a set of scattered spatio-temporal points (called residual points). The location and distribution of these residual points are highly important to the performance of PINNs. However, in the existing studies on PINNs, only a few simple residual point sampling methods have mainly been used. Here, we present a comprehensive study of two categories of sampling for PINNs: non-adaptive uniform sampling and adaptive nonuniform sampling. We consider six uniform sampling methods, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) Latin hypercube sampling, (4) Halton sequence, (5) Hammersley sequence, and (6) Sobol sequence. We also consider a resampling strategy for uniform sampling. To improve the sampling efficiency and the accuracy of PINNs, we propose two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D), which dynamically improve the distribution of residual points based on the PDE residuals during training. Hence, we have considered a total of 10 different sampling methods, including six non-adaptive uniform sampling, uniform sampling with resampling, two proposed adaptive sampling, and an existing adaptive sampling. We extensively tested the performance of these sampling methods for four forward problems and two inverse problems in many setups. Our numerical results presented in this study are summarized from more than 6000 simulations of PINNs. We show that the proposed adaptive sampling methods of RAD and RAR-D significantly improve the accuracy of PINNs with fewer residual points for both forward and inverse problems. The results obtained in this study can also be used as a practical guideline in choosing sampling methods.","title":"Abstract"},{"location":"Models/PINNs/PN-2207.10289/#1-introduction","text":"Physics-informed neural networks (PINNs) [1] have emerged in recent years and quickly became a powerful tool for solving both forward and inverse problems of partial differential equations (PDEs) via deep neural networks (DNNs) [2, 3, 4]. PINNs embed the PDEs into the loss of the neural network using automatic differentiation. Compared with traditional numerical PDE solvers, such as the finite difference method (FDM) and the finite element method (FEM), PINNs are mesh free and therefore highly flexible. Moreover, PINNs can easily incorporate both physics-based constraints and data measurements into the loss function. PINNs have been applied to tackle diverse problems in computational science and engineering, such as inverse problems in nanooptics, metamaterials [5], and fluid dynamics [2], parameter estimation in systems biology [6, 7], and problems of inverse design and topology optimization [8]. In addition to standard PDEs, PINNs have also been extended to solve other types of PDEs, including integro-differential equations [3], fractional PDEs [9], and stochastic PDEs [10]. Despite the past success, addressing a wide range of PDE problems with increasing levels of complexity can be theoretically and practically challenging, and thus many aspects of PINNs still require further improvements to achieve more accurate prediction, higher computational efficiency, and training robustness [4]. A series of extensions to the vanilla PINN have been proposed to boost the performance of PINNs from various aspects. For example, better loss functions have been discovered via meta-learning [11], and gradient-enhanced PINNs (gPINNs) have been developed to embed the gradient information of the PDE residual into the loss [12]. In PINNs, the total loss is a weighted summation of multiple loss terms corresponding to the PDE and initial/boundary conditions, and different methods have been developed to automatically tune these weights and balance the losses [13, 14, 15]. Moreover, a different weight for each loss term could be set at every training point [16, 17, 8, 18]. For problems in a large domain, decomposition of the spatiotemporal domain accelerates the training of PINNs and improves their accuracy [19, 20, 21]. For time-dependent problems, it is usually helpful to first train PINNs within a short time domain and then gradually expand the time intervals of training until the entire time domain is covered [22, 23, 24, 25, 26]. In addition to these general methods, other problem-specific techniques have also been developed, e.g., enforcing Dirichlet or periodic boundary conditions exactly by constructing special neural network architectures [27, 28, 8]. PINNs are mainly optimized against the PDE loss, which guarantees that the trained network is consistent with the PDE to be solved. PDE loss is evaluated at a set of scattered residual points. Intuitively, the effect of residual points on PINNs is similar to the effect of mesh points on FEM, and thus the location and distribution of these residual points should be highly important to the performance of PINNs. However, in previous studies on PINNs, two simple residual point sampling methods (i.e., an equispaced uniform grid and uniformly random sampling) have mainly been used, and the importance of residual point sampling has largely been overlooked.","title":"1 Introduction"},{"location":"Models/PINNs/PN-2207.10289/#11-related-work-and-our-contributions","text":"Different residual point sampling methods can be classified into two categories: uniform sampling and nonuniform sampling. Uniform sampling can be obtained in multiple ways. For example, we could use the nodes of an equispaced uniform grid as the residual points or randomly sample the points according to a continuous uniform distribution in the computational domain. Although these two sampling methods are simple and widely used, alternative sampling methods may be applied. The Latin hypercube sampling (LHS) [29, 30] was used in Ref. [1], and the Sobol sequence [31] was first used for PINNs in Ref. [9]. The Sobol sequence is one type of quasi random low-discrepancy sequences among other sequences, such as the Halton sequence [32], and the Hammersley sequence [33]. Low-discrepancy sequences usually perform better than uniformly distributed random numbers in many applications such as numerical integration; hence, a comprehensive comparison of these methods for PINNs is required. However, very few comparisons [34, 35] have been performed. In this study, we extensively compared the performance of different uniform sampling methods, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) LHS, (4) Sobol sequence, (5) Halton sequence, and (6) Hammersley sequence. In supervised learning, the dataset is fixed during training, but in PINNs, we can select residual points at any location. Hence, instead of using the same residual points during training, in each optimization iteration, we could select a new set of residual points, as first emphasized in Ref. [3]. While this strategy has been used in some works, it has not yet been systematically tested. Thus, in this study, we tested the performance of such a resampling strategy and investigated the effect of the number of residual points and the resampling period for the first time. Uniform sampling works well for some simple PDEs, but it may not be efficient for those that are more complicated. To improve the accuracy, we could manually select the residual points in a nonuniform way, as was done in Ref. [36] for high-speed flows, but this approach is highly problem-dependent and usually tedious and time-consuming. In this study, we focus on automatic and adaptive nonuniform sampling. Motivated by the adaptive mesh refinement in FEM, Lu et al. [3] proposed the first adaptive nonuniform sampling for PINNs in 2019, the residual-based adaptive refinement (RAR) method, which adds new residual points in the locations with large PDE residuals. In 2021, another sampling strategy [37] was developed, where all the residual points were resampled according to a probability density function (PDF) proportional to the PDE residual. In this study, motivated by these two ideas, we proposed two new sampling strategies: residual-based adaptive distribution (RAD), where the PDF for sampling is a nonlinear func- tion of the PDE residual; residual-based adaptive refinement with distribution (RAR-D), which is a hybrid method of RAR and RAD, i.e., the new residual points are added according to a PDF. During the preparation of this paper, a few new studies appeared [38, 39, 40, 41, 42, 43, 44] that also proposed modified versions of RAR or PDF-based resampling. Most of these methods are special cases of the proposed RAD and RAR-D, and our methods can achieve better performance. We include a detailed comparison of these strategies in Section 2.4, after introducing several notations and our new proposed methods. In this study, we have considered a total of 10 different sampling methods, including seven non-adaptive sampling methods (six different uniform samplings and one uniform sampling with resampling) and three adaptive sampling approaches (RAR, RAD, and RAR-D). We compared the performance of these sampling methods for four forward problems of PDEs and investigated the effect of the number of residual points. We also compared their performance for two inverse problems that have not yet been consid- ered in the literature. We performed more than 6000 simulations of PINNs to obtain all the results shown in this study.","title":"1.1 Related work and our contributions"},{"location":"Models/PINNs/PN-2207.10289/#12-organization","text":"This paper is organized as follows. In Section 2, after providing a brief overview of PINNs and different non-adaptive sampling strategies, two new adaptive nonuniform sampling strategies (RAD and RAR-D) are proposed. In Section 3, we compare the performance of 10 different methods for six different PDE problems, including four forward problems and two inverse problems. Section 4 summarizes the findings and concludes the paper.","title":"1.2 Organization"},{"location":"Models/PINNs/PN-2207.10289/#2-methods","text":"This section briefly reviews physics-informed neural networks (PINNs) in solving forward and inverse partial differential equations (PDEs). Then different types of uniformly sampling are introduced. Next, two nonuniform residual-based adaptive sampling methods are proposed to enhance the accuracy and training efficiency of PINNs. Finally, a comparison of related methods is presented.","title":"2 Methods"},{"location":"Models/PINNs/PN-2207.10289/#21-pinns-in-solving-forward-and-inverse-pdes","text":"We consider the PDE parameterized by\u03bbdefined on a domain \u2126\u2282Rd, f(x;u(x)) =f","title":"2.1 PINNs in solving forward and inverse PDEs"},{"location":"Models/PINNs/PN-2207.10289/#_1","text":"x; \u2202u \u2202x 1","title":"("},{"location":"Models/PINNs/PN-2207.10289/#_2","text":"\u2202u \u2202xd","title":""},{"location":"Models/PINNs/PN-2207.10289/#_3","text":"\u2202^2 u \u2202x 1 \u2202x 1","title":""},{"location":"Models/PINNs/PN-2207.10289/#_4","text":"\u2202^2 u \u2202x 1 \u2202xd ;...;\u03bb","title":""},{"location":"Models/PINNs/PN-2207.10289/#_5","text":"= 0, x= (x 1 ,...,xd)\u2208\u2126, with boundary conditions on\u2202\u2126 B(u,x) = 0, andu(x) denotes the solution atx. In PINNs, the initial condition is treated as the Dirichlet boundary condition. A forward problem is aimed to obtain the solutionu across the entire domain, where the model parameters\u03bbare known. In practice, the model parameters\u03bbmight be unknown, but some observations from the solutionuare available, which lead to an inverse problem. An inverse problem is aimed to discover parameters\u03bbthat best describe the observed data from the solution. PINNs are capable of addressing both forward and inverse problems. To solve a forward problem, the solutionuis represented with a neural network \u02c6u(x;\u03b8). The network parameters\u03b8are trained to approximate the solutionu, such that the loss function is minimized [1, 3]: L(\u03b8;T) =wfLf(\u03b8;Tf) +wbLb(\u03b8;Tb), where Lf(\u03b8;Tf) =","title":")"},{"location":"Models/PINNs/PN-2207.10289/#1","text":"|Tf|","title":"1"},{"location":"Models/PINNs/PN-2207.10289/#_6","text":"x\u2208Tf","title":"\u2211"},{"location":"Models/PINNs/PN-2207.10289/#_7","text":"\u2223\u2223f(x; \u2202u\u02c6 \u2202x 1","title":"\u2223\u2223"},{"location":"Models/PINNs/PN-2207.10289/#_8","text":"\u2202\u02c6u \u2202xd","title":""},{"location":"Models/PINNs/PN-2207.10289/#_9","text":"\u2202^2 u\u02c6 \u2202x 1 \u2202x 1","title":""},{"location":"Models/PINNs/PN-2207.10289/#_10","text":"\u2202^2 u\u02c6 \u2202x 1 \u2202xd ;...;\u03bb)","title":""},{"location":"Models/PINNs/PN-2207.10289/#_11","text":"","title":"\u2223\u2223"},{"location":"Models/PINNs/PN-2207.10289/#_12","text":"2 , (1) Lb(\u03b8;Tb) =","title":"\u2223\u2223"},{"location":"Models/PINNs/PN-2207.10289/#1_1","text":"|Tb|","title":"1"},{"location":"Models/PINNs/PN-2207.10289/#_13","text":"x\u2208Tb |B(\u02c6u,x)|^2 , andwfandwbare the weights. Two sets of points are samples both inside the domain (Tf) and on the boundaries (Tb). Here,TfandTbare referred to as the sets of \u201cresidual points\u201d, andT=Tf\u222aTb. To solve the inverse problem, an additional loss term corresponding to the misfit of the observed data at the locationsTi, defined as Li(\u03b8,\u03bb;Ti) =","title":"\u2211"},{"location":"Models/PINNs/PN-2207.10289/#1_2","text":"|Ti|","title":"1"},{"location":"Models/PINNs/PN-2207.10289/#_14","text":"x\u2208Ti |u\u02c6(x)\u2212u(x)|^2 , is added to the loss function. The loss function is then defined as L(\u03b8,\u03bb;T) =wfLf(\u03b8,\u03bb;Tf) +wbLb(\u03b8,\u03bb;Tb) +wiLi(\u03b8,\u03bb;Ti), with an additional weightwi. Then the network parameters\u03b8are trained simultaneously with\u03bb. For certain PDE problems, it is possible to enforce boundary conditions directly by constructing a special network architecture [27, 28, 8, 12], which eliminates the loss term of boundary conditions. In this study, the boundary conditions are enforced exactly and automatically. Hence, for a forward problem, the loss function is L(\u03b8,\u03bb;T) =Lf(\u03b8,\u03bb;Tf). For an inverse problem, the loss function is L(\u03b8,\u03bb;T) =wfLf(\u03b8,\u03bb;Tf) +wiLi(\u03b8,\u03bb;Ti), where we choosewf=wi= 1 for the diffusion-reaction equation in Section 3.6, andwf= 1,wi= 1000 for the Korteweg-de Vries equation in Section 3.7.","title":"\u2211"},{"location":"Models/PINNs/PN-2207.10289/#22-uniformly-distributed-non-adaptive-sampling","text":"The training of PINNs requires a set of residual points (Tf). The sampling strategy ofTf plays a vital role in promoting the accuracy and computational efficiency of PINNs. Here, we discuss several sampling approaches. 2.2.1 Fixed residual points In most studies of PINNs, we specify the residual points at the beginning of training and never change them during the training process. Two simple sampling methods (equispaced uniform grids and uniformly random sampling) have been commonly used. Other sampling methods, such as the Latin hypercube sampling (LHS) [29, 30] and the Sobol sequence [31], have also been used in some studies [1, 9, 34]. The Sobol sequence is one type of quasi-random low-discrepancy sequences. Low-discrepancy sequences are commonly used as a replacement for uniformly distributed random numbers and usually perform better in many applications such as numerical integration. This study also considers other low-discrepancy sequences, including the Halton sequence [32] and the Hammersley sequence [33]. We list the six uniform sampling methods as follows, and the examples of 400 points generated in [0,1]^2 using different methods are shown in Fig. 1. Equispaced uniform grid (Grid): The residual points are chosen as the nodes of an equispaced uniform grid of the computational domain. Uniformly random sampling (Random): The residual points are randomly sampled according to a continuous uniform distribution over the domain. In practice, this is usually done using pseudo-random number generators such as the PCG-64 algorithm [45]. Latin hypercube sampling LHS : The LHS is a stratified Monte Carlo sampling method that generates random samples that occur within intervals on the basis of equal probability and with normal distribution for each range. Quasi-random low-discrepancy sequences: (a)Halton sequence Halton : The Halton samples are generated according to the reversing or flipping the base conversion of numbers using primes. (b)Hammersley sequence Hammersley : The Hammersley sequence is the same as the Halton sequence, except in the first dimension where points are located equidistant from each other. (c) Sobol sequence Sobol : The Sobol sequence is a base-2 digital sequence that fills in a highly uniform manner. Figure 1: Examples of 400 points generated in[0,1]^2 using different uniform sampling methods in Section 2.2.1. 2.2.2 Uniform points with resampling In PINNs, a point at any location can be used to evaluate the PDE loss. Instead of using the fixed residual points during training, we could also select a new set of residual points in every certain optimization iteration [3]. The specific method to sample the points each time can be chosen from those methods discussed in Section 2.2.1. We can even use different sampling methods at different times, so many possible implementations make it impossible to be completely covered in this study. In this study, we only consider Random sampling with resampling (Random-R). The RandomR method is the same as the Random method, except that the residual points are resampled for everyNiteration. Theresampling periodNis also an important hyperparameter for accuracy, as we demonstrate in our empirical experiments in Section 3.","title":"2.2 Uniformly-distributed non-adaptive sampling"},{"location":"Models/PINNs/PN-2207.10289/#23-nonuniform-adaptive-sampling","text":"Although the uniform sampling strategies were predominantly employed, recent studies on the nonuniform adaptive sampling strategies [3, 37] have demonstrated promising improvement in the distribution of residual points during the training processes and achieved better accuracy. 2.3.1 Residual-based adaptive refinement with greed (RAR-G) The first adaptive sampling method for PINNs is the residual-based adaptive refinement method (RAR) proposed in Ref. [3]. RAR aims to improve the distribution of residual points during the training process by sampling more points in the locations where the PDE residual is large. Specifically, after every certain iteration, RAR adds new points in the locations with large PDE residuals (Algorithm 1). RAR only focuses on the points with large residual, and thus it is a greedy algorithm. To better distinguish from the other sampling methods, the RAR method is referred to as RAR-G in this study. Algorithm 1: RAR-G [3]. 1 Sample the initial residual pointsT using one of the methods in Section 2.2.1; 2 Train the PINN for a certain number of iterations; 3 repeat 4 Sample a set of dense pointsS 0 using one of the methods in Section 2.2.1; 5 Compute the PDE residuals for the points inS 0 ; 6 S \u2190mpoints with the largest residuals inS 0 ; 7 T \u2190T \u222aS; 8 Train the PINN for a certain number of iterations; 9 untilthe total number of iterations or the total number of residual points reaches the limit; 2.3.2 Residual-based adaptive distribution (RAD) RAR-G significantly improves the performance of PINNs when solving certain PDEs of solutions with steep gradients [3, 12]. Nevertheless, RAR-G focuses mainly on the location where the PDE residual is largest and disregards the locations of smaller residuals. Another sampling strategy was developed later in Ref. [37], where all the residual points are resampled according to a probability density function (PDF)p(x) proportional to the PDE residual. Specifically, for any pointx, we first compute the PDE residual\u03b5(x) =|f(x; \u02c6u(x))|, and then compute a probability as p(x)\u221d\u03b5(x), i.e., p(x) = \u03b5(x) A","title":"2.3 Nonuniform adaptive sampling"},{"location":"Models/PINNs/PN-2207.10289/#_15","text":"whereA=","title":""},{"location":"Models/PINNs/PN-2207.10289/#_16","text":"\u2126\u03b5(x)dxis a normalizing constant. Then all the residual points are sampled according top(x). This approach works for certain PDEs, but as we show in our numerical examples, it does not work well in some cases. Following this idea, we propose an improved version called the residualbased adaptive distribution (RAD) method (Algorithm 2), where we use a new PDF defined as p(x)\u221d \u03b5k(x) E[\u03b5k(x)] +c, (2) wherek\u22650 andc\u22650 are two hyperparameters. E[\u03b5k(x)] can be approximated by a numerical integration such as Monte Carlo integration. We note that the Random-R method in Section 2.2.2 is a special case of RAD by choosingk= 0 orc\u2192\u221e. Algorithm 2: RAD. 1 Sample the initial residual pointsT using one of the methods in Section 2.2.1; 2 Train the PINN for a certain number of iterations; 3 repeat 4 T \u2190A new set of points randomly sampled according to the PDF of Eq. (2); 5 Train the PINN for a certain number of iterations; 6 untilthe total number of iterations reaches the limit; In RAD (Algorithm 2 line 4), we need to sample a set of points according top(x), which can be done in a few ways. Whenxis low-dimensional, we can sample the points approximately in the following brute-force way: Sample a set of dense pointsS 0 using one of the methods in Section 2.2.1; Computep(x) for the points inS 0 ; Define a probability mass function \u0303p(x) =p(Ax)with the normalizing constantA=","title":"\u222b"},{"location":"Models/PINNs/PN-2207.10289/#_17","text":"x\u2208S 0 p(x); Sample a subset of points fromS 0 according to \u0303p(x). This method is simple, easy to implement, and sufficient for many PDE problems. For more complicated cases, we can use other methods such as inverse transform sampling, Markov chain Monte Carlo (MCMC) methods, and generative adversarial networks (GANs) [46]. The two hyperparameterskandcin Eq. (2) control the profile ofp(x) and thus the distribution of sampled points. We illustrate the effect ofkandcusing a simple 2D example, \u03b5(x,y) = 2^4 axa(1\u2212x)aya(1\u2212y)a, (3) witha= 10 in Fig. 2. Whenk= 0, it becomes a uniform distribution. As the value ofkincreases, more residual points will large PDE residuals are sampled. As the value ofcincreases, the residual points exhibit an inclination to be uniformly distributed. Compared with RAR, RAD provides more freedom to balance the points in the locations with large and small residuals by tuningkand c. The optimal values ofkandcare problem-dependent, and based on our numerical results, the combination ofk= 1 andc= 1 is usually a good default choice. 2.3.3 Residual-based adaptive refinement with distribution (RAR-D) We also propose a hybrid method of RAR-G and RAD, namely, residual-based adaptive refinement with distribution (RAR-D) (Algorithm 3). Similar to RAR-G, RAR-D repeatedly adds new points to the training dataset; similar to RAD, the new points are sampled based on the PDF in Eq. (2). We note that whenk\u2192 \u221e, only points with the largest PDE residual are added, which recovers RAR-G. The optimal values ofkandcare problem dependent, and based on our numerical results, the combination ofk= 2 andc= 0 is usually a good default choice. Figure 2:Examples of 1000 residual points sampled by RAD with different values ofk andcfor the PDE residual\u03b5(x,y)in Eq.(3). Algorithm 3: RAR-D. 1 Sample the initial residual pointsT using one of the methods in Section 2.2.1; 2 Train the PINN for a certain number of iterations; 3 repeat 4 S \u2190mpoints randomly sampled according to the PDF of Eq. (2); 5 T \u2190T \u222aS; 6 Train the PINN for a certain number of iterations; 7 untilthe total number of iterations or the total number of residual points reaches the limit;","title":"\u2211"},{"location":"Models/PINNs/PN-2207.10289/#24-comparison-with-related-work","text":"As discussed in Section 2.3, our proposed RAD and RAR-D are improved versions of the methods in Refs. [3, 37]. Here, we summarize the similarities between their methods and ours. Lu et al. [3] (in July 2019) proposed RAR (renamed to RAR-G here), which is a special case of RAR-D by choosing a large value ofk. The method proposed by Nabian et al. [37] (in April 2021) is a special case of RAD by choosingk= 1 andc= 0. During the preparation of this paper, a few new papers appeared [38, 39, 40, 41, 42, 43, 44] that also proposed similar methods. Here, we summarize the similarities and differences between these studies. The method proposed by Gao et al. [40] (in December 2021) is a special case of RAD by choosingc= 0. Tang et al. [41] (in December 2021) proposed two methods. One is a special case of RAD by choosingk= 2 andc= 0, and the other is a special case of RAR-D by choosingk= 2 and c= 0. Zeng et al. [43] (in April 2022) proposed a subdomain version of RAR-G. The entire domain is divided into many subdomains, and then new points are added to the several subdomains with large average PDE residual. Similar to RAR-G, Peng et al. [42] (in May 2022) proposed to add more points with large PDE residual, but they used the node generation technology proposed in Ref. [47]. We note that this method only works for a two-dimensional space. Zapf et al. [38] (in May 2022) proposed a modified version of RAR-G, where some points with small PDE residual are removed while adding points with large PDE residual. They show that compared with RAR, this reduces the computational cost, but the accuracy keeps similar. Hanna et al. [44] (in May 2022) proposed a similar method as RAR-D, but they chosep(x)\u221d max{log(\u03b5(x)/\u03b5 0 ), 0 }, where\u03b5 0 is a small tolerance. Similar to the work of Zapf et al., Daw et al. [39] (in July 2022) also proposed to remove the points with small PDE residual, but instead of adding new points with large PDE residual, they added new uniformly random sampled points. Thus all these methods are special cases of our proposed RAD and RAR-D (or with minor modification). However, in our study, two tunable variableskandcare introduced. As we show in our results, the values ofkandccould be crucial since they significantly influence the residual points distribution. By choosing proper values ofkandc, our methods would outperform the other methods. We also note that the point-wise weighting [16, 17, 8, 18] can be viewed as a special case of adaptive sampling, described as follows. When the residual points are randomly sampled from a uniform distributionU(\u2126), and the number of residual points is large, the PDE loss in Eq. (1) can be approximated byEU[\u03b5^2 (x)]. If we consider a point-wise weighting functionw(x), then the loss becomesEU[w(x)\u03b5^2 (x)], while for RAD the loss isEp[\u03b5^2 (x)]. If we choosew(x) (divided by a normalizing constant) as the PDFp(x), then the two losses are equal.","title":"2.4 Comparison with related work"},{"location":"Models/PINNs/PN-2207.10289/#3-results","text":"We apply PINNs with all the ten sampling methods in Section 2 to solve six forward and inverse PDE problems. In all examples, the hyperbolic tangent (tanh) is selected as the activation function. Table 1 summarizes the network width, depth, and optimizers used for each example. More details of the hyperparameters and training procedure can be found in each section of the specific problem. Table 1:The hyperparameters used for each numerical experiment.The learning rate of Adam optimizer is chosen as 0.001. Problems Depth Width Optimizer Section 3.2 Diffusion equation 4 32 Adam Section 3.3 Burgers\u2019 equation 4 64 Adam + L-BFGS Section 3.4 Allen-Cahn equation 4 64 Adam + L-BFGS Section 3.5 Wave equation 6 100 Adam + L-BFGS Section 3.6 Diffusion-reaction equation (inverse) 4 20 Adam Section 3.7 Korteweg-de Vries equation (inverse) 4 100 Adam For both forward and inverse problems, to evaluate the accuracy of the solution \u02c6u, theL^2 relative error is used: \u2016u\u02c6\u2212u\u2016 2 \u2016u\u2016 2","title":"3 Results"},{"location":"Models/PINNs/PN-2207.10289/#_18","text":"For inverse problems, to evaluate the accuracy of the predicted coefficients\u03bb\u02c6, the relative error is also computed: |\u03bb\u02c6\u2212\u03bb| |\u03bb|","title":""},{"location":"Models/PINNs/PN-2207.10289/#_19","text":"As the result of PINN has randomness due to the random sampling, network initialization, and optimization, thus, for each case, we run the same experiment at least 10 times and then compute the geometric mean and standard deviation of the errors. The code in this study is implemented by using the library DeepXDE [3] and is publicly available from the GitHub repositoryhttps: //github.com/lu-group/pinn-sampling.","title":""},{"location":"Models/PINNs/PN-2207.10289/#31-summary","text":"Here, we first present a summary of the accuracy of all the methods for the forward and inverse problems listed in Tables 2 and Table 3, respectively. A relatively small number of residual points is chosen to show the difference among different methods. In the specific section of each problem (Sections 3.2\u20133.7), we discuss all the detailed analyses, including the convergence of error during the training process, the convergence of error with respect to the number of residual points, and the effects of different hyperparameters (e.g., the period of resampling in Random-R, the values of kandcin RAD and RAR-D, and the number of new points added each time in RAR-D). We note that Random-R is a special case of RAD by choosingk= 0 orc\u2192 \u221e, and RAR-G is a special case of RAR-D by choosingk\u2192\u221e. Our main findings from the results are as follows. The proposed RAD method has always performed the best among the 10 sampling methods when solving all forward and inverse problems. For PDEs with complicated solutions, such as the Burgers\u2019 and multi-scale wave equation, the proposed RAD and RAR-D methods are predominately effective and yield errors magnitudes lower. For PDEs with smooth solutions, such as the diffusion equation and diffusion-reaction equa- tion, some uniform sampling methods, such as the Hammersley and Random-R, also produce sufficiently low errors. Compared with other uniform sampling methods, Random-R usually demonstrates better performance. Among the six uniform sampling methods with fixed residual points, the low-discrepancy sequences (Halton, Hammersley, and Sobol) generally perform better than Random and LHS, and both are better than Grid. Table 2: L^2 relative error of the PINN solution for the forward problems. Bold font indicates the smallest three errors for each problem. Underlined text indicates the smallest error for each problem. Diffusion Burgers\u2019 Allen-Cahn Wave No. of residual points 30 2000 1000 2000 Grid 0.66\u00b10.06% 13.7\u00b12.37% 93.4\u00b16.98% 81.3\u00b113.7% Random 0.74\u00b10.17% 13.3\u00b18.35% 22.2\u00b116.9% 68.4\u00b120.1% LHS 0.48\u00b10.24% 13.5\u00b19.05% 26.6\u00b115.8% 75.9\u00b133.1% Halton 0.24\u00b10.17% 4.51\u00b13.93% 0.29\u00b10.14% 60.2\u00b110.0% Hammersley 0.17\u00b10.07% 3.02\u00b12.98% 0.14\u00b10.14% 58.9\u00b18.52% Sobol 0.19\u00b10.07% 3.38\u00b13.21% 0.35\u00b10.24% 57.5\u00b114.7% Random-R 0.12\u00b10.06% 1.69\u00b11.67% 0.55\u00b10.34% 0.72\u00b10.90% RAR-G [3] 0.20\u00b10.07% 0.12\u00b10.04% 0.53\u00b10.19% 0.81\u00b10.11% RAD 0.11\u00b10.07% 0.02\u00b10.00% 0.08\u00b10.06% 0.09\u00b10.04% RAR-D 0.14\u00b10.11% 0.03\u00b10.01% 0.09\u00b10.03% 0.29\u00b10.04%","title":"3.1 Summary"},{"location":"Models/PINNs/PN-2207.10289/#32-diffusion-equation","text":"We first consider the following one-dimensional diffusion equation: \u2202u \u2202t","title":"3.2 Diffusion equation"},{"location":"Models/PINNs/PN-2207.10289/#_20","text":"\u2202^2 u \u2202x^2 +e\u2212t","title":"="},{"location":"Models/PINNs/PN-2207.10289/#_21","text":"\u2212sin(\u03c0x) +\u03c0^2 sin(\u03c0x)","title":"("},{"location":"Models/PINNs/PN-2207.10289/#_22","text":", x\u2208[\u2212 1 ,1],t\u2208[0,1], u(x,0) = sin(\u03c0x), u(\u2212 1 ,t) =u(1,t) = 0, whereuis the concentration of the diffusing material. The exact solution isu(x,t) = sin(\u03c0x)e\u2212t. We first compare the performance of the six uniform sampling methods with fixed residual points (Fig. 3A). The number of residual points is ranged from 10 to 80 with an increment of 10 points each time. For each number of residual points, the maximum iteration is set to be 15 000 with Adam as the optimizer. When the number of points is large (e.g., more than 70), all these methods Figure 3:L^2 relative errors of different sampling methods for the diffusion equation in Section 3.2.(A) Six uniform sampling with fixed residual points. (B) Random-R with different periods of resampling when using 30 residual points. (CandD) The training trajectory of RAD with different values ofkandcwhen using 30 residual points. (C)k= 1. (D)c= 1. (EandF) RAR-D with different values ofkandc. Each time one new point is added. (E)k= 2. (F)c= The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. Table 3:L^2 relative error of the PINN solution and relative error of the inferred parameters for the inverse problems.Bold font indicates the smallest three errors for each problem. Underlined text indicates the smallest error for each problem. Diffusion-reaction Korteweg-de Vries u(x) k(x) u(x,t) \u03bb 1 \u03bb 2 No. of residual points 15 600 Grid 0.36\u00b10.12% 8.58\u00b12.14% 24.4\u00b111.1% 53.7\u00b130.7% 42.0\u00b122.3% Random 0.35\u00b10.17% 5.77\u00b12.05% 8.86\u00b12.80% 16.4\u00b17.33% 16.8\u00b17.40% LHS 0.36\u00b10.14% 7.00\u00b12.62% 10.9\u00b12.60% 22.0\u00b16.68% 22.6\u00b16.36% Halton 0.23\u00b10.08% 6.16\u00b11.08% 8.76\u00b13.33% 16.7\u00b16.16% 17.2\u00b16.20% Hammersley 0.28\u00b10.08% 6.37\u00b10.91% 4.49\u00b13.56% 5.24\u00b17.08% 5.71\u00b17.32% Sobol 0.21\u00b10.06% 3.09\u00b10.75% 8.59\u00b13.67% 15.8\u00b16.15% 15.6\u00b15.79% Random-R 0.19\u00b10.09% 3.43\u00b11.80% 0.97\u00b10.15% 0.41\u00b10.30% 1.14\u00b10.31% RAR-G [3] 1.12\u00b10.11% 15.9\u00b11.53% 8.83\u00b11.98% 15.4\u00b19.29% 14.5\u00b19.25% RAD 0.17\u00b10.09% 2.76\u00b11.32% 0.77\u00b10.11% 0.31\u00b10.19% 0.86\u00b10.25% RAR-D 0.76\u00b10.24% 10.3\u00b13.28% 2.36\u00b10.98% 3.49\u00b12.21% 3.18\u00b12.02% have similar performance. However, when the number of residual points is small such as 50, the Hammersley and Sobol sequences perform better than others, and the equispaced uniform grid and random sampling have the largest errors (about one order of magnitude larger than Hammersley and Sobol). We then test the Random-R method using 30 residual points (Fig. 3B). The accuracy of Random-R has a strong dependence on the period of resampling, and the optimal period of resampling in this problem is around 200. Compared with Random without resampling, the Random-R method always leads to lowerL^2 relative errors regardless of the period of resampling. The error can be lower by one order of magnitude by choosing a proper resampling period. Among all the non-adaptive methods, Random-R performs the best. Next, we test the performance of the nonuniform adaptive sampling methods. In Algorithms 2 and 3, the neural network is first trained using 10 000 steps of Adam. In the RAD method, we use 30 residual points and resample every 1000 iterations. The errors of RAD with different values of kandcare shown in Figs. 3C and D. We note that Random-R is a special case of RAD with either c\u2192 \u221eork= 0. Here, RAD with large values ofcor small values ofkleads to better accuracy, i.e., the points are almost uniformly distributed. For the RAR-D method (Figs. 3E and F), one residual point is added after every 1000 iterations starting from 10 points. When usingk= 2 and c= 0 (the two red lines in Figs. 3E red F), RAR-D performs the best. When using 30 residual points, the errors of all the methods are listed in Table 2. In this diffusion equation, all the methods achieve a good accuracy (<1%). Compared with Random-R (0.12%), RAD and RAR-D (0.11%) are not significantly better. The reason could be that the solution of this diffusion equation is very smooth, so uniformly distributed points are good enough. In our following examples, we show that RAD and RAR-D work significantly better and achieve an error of orders of magnitude smaller than the non-adaptive methods.","title":")"},{"location":"Models/PINNs/PN-2207.10289/#33-burgers-equation","text":"The Burgers\u2019 equation is considered defined as: \u2202u \u2202t +u \u2202u \u2202x =\u03bd \u2202^2 u \u2202x^2 , x\u2208[\u2212 1 ,1],t\u2208[0,1], u(x,0) =\u2212sin(\u03c0x), u(\u2212 1 ,t) =u(1,t) = 0, whereuis the flow velocity and\u03bd is the viscosity of the fluid. In this study,\u03bdis set at 0. 01 /\u03c0. Different from the diffusion equation with a smooth solution, the solution of the Burgers\u2019 equation has a sharp front whenx= 0 andtis close to 1. We first test the uniform sampling methods by using the number of residual points ranging from 1,000 to 10,000 (Fig. 4A). The maximum iteration is 15,000 steps with Adam as optimizer followed by 15,000 steps of L-BFGS. Fig. 4A shows that the Hammersley method converges the fastest and reaches the lowestL^2 relative error among all the uniform sampling methods, while the Halton and Sobol sequences also perform adequately. Fig. 4B shows theL^2 relative error as a function of the period of resampling using the RandomR method with 2,000 residual points. Similar to the diffusion equation, the Random-R method always outperforms the Random method. However, the performance of Random-R is not sensitive to the period of resampling if the period is smaller than 100. Choosing a period of resampling too large can negatively affect its performance. When applying the nonuniform adaptive methods, the neural network is first trained using 15,000 steps of Adam and then 1,000 steps of L-BFGS. In the RAD method, we use 2000 residual points, which are resampled every 2,000 iterations (1,000 iterations using Adam followed by 1,000 iterations using L-BFGS). As indicated by Fig. 4C, the RAD method possesses significantly greater advantages over the Random-R method (a special case of RAD by choosingk= 0 orc\u2192 \u221e), whoseL^2 relative errors barely decrease during the training processes. This fact reflects that both extreme cases show worse performance. In contrast, fork= 1 andc= 1 (the red lines in Figs. 4C and D), theL^2 relative error declines rapidly and quickly reaches\u223c 2 \u00d7 10 \u2212^4. The RAD method is also effective when choosing a set ofkandcin a moderate range. For the RAR-D method, 1,000 residual points are selected in the pre-trained process, and 10 residual points are added every 2,000 iterations (1,000 iterations using Adam and 1,000 iterations using L-BFGS as optimizer) until the total number of residual points reaches 2,000. Shown by Figs. 4E and F, the optimal values forkandcare found to be 2 and 0, respectively. Since the solution of Burgers\u2019 equation has a very steep region, when using 2000 residual points, both RAD and RAR-D have competitive advantages over the uniform sampling methods in terms of accuracy and efficiency. For the following three forward PDE problems (Allen-Cahn equation in Section 3.4, wave equation in Section 3.5, and diffusion-reaction equation in Section 3.6), unless otherwise stated, the maximum iterations, the use of optimizer, and the training processes remain the same as the Burgers\u2019 equation. Table 2 summarizes theL^2 relative error for all methods when we fix the number of residual points at 2000. All uniform sampling methods fail to capture the solution well. TheL^2 relative errors given by the Halton, Hammersley, and Sobol methods (\u223c4%) are around one-fourth of that given by the Grid, Random, and LHS methods (>13%). Even though the Random-R performs the best among all uniform methods (1.69\u00b11.67%), the proposed RAD and RAR-D methods can achieve anL^2 relative error two orders of magnitude lower than that (0.02%). Figure 4:L^2 relative errors of different sampling methods for the Burgers\u2019 equation in Section 3.3.(A) Six uniform sampling with fixed residual points. (B) Random-R with different periods of resampling when using 2000 residual points. (CandD) The training trajectory of RAD with different values ofkandcwhen using 2000 residual points. (C)k= 1. (D)c= 1. (EandF) RAR-D with different values ofkandc. Each time 10 new points are added. (E)k= 2. (F)c= The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted.","title":"3.3 Burgers\u2019 equation"},{"location":"Models/PINNs/PN-2207.10289/#34-allen-cahn-equation","text":"Next, we consider the Allen-Cahn equation in the following form: \u2202u \u2202t","title":"3.4 Allen-Cahn equation"},{"location":"Models/PINNs/PN-2207.10289/#d","text":"\u2202^2 u \u2202x^2 5(u\u2212u^3 ), x\u2208[\u2212 1 ,1],t\u2208[0,1], u(x,0) =x^2 cos(\u03c0x), u(\u2212 1 ,t) =u(1,t) =\u2212 1 , where the diffusion coefficientD= 0.001. Fig. 5 outlines theL^2 relative errors of different sampling methods for the Allen-Cahn equation. Similar patterns are found for the nonadaptive uniform sampling as in the previous examples. The Hammersley method has the best accuracy (Fig. 5A). As the number of residual points becomes significantly large, the difference between these uniform sampling methods becomes negligible. Except for the equispaced uniform grid method, other uniform sampling methods converge toL^2 relative errors of 10\u2212^3 , about the same magnitude as the number of residual points reaching 10^4. Fig. 5B shows that when using 1000 residual points for Random-R, lowerL^2 relative errors can be obtained if we select a period of resampling less than 500. We next test the performance of RAD for different values ofkandcwhen using a different number of residual points. In Figs. 5C and D, we resampled 500 residual points every 2000 iteration, while in Figs. 5E and F, we used 1000 residual points instead. For both cases, the combination of k= 1 andc= 1 (the red lines in Figs. 5C\u2013F) gives good accuracy. When fewer residual points (e.g., 500) are used, the RAD methods boost the performance of PINNs. Similarly, we also test RAR-D in Figs. 5G\u2013J. In Figs. 5G and H, we pre-train the neural network with 500 residual points and add 10 residual points after every 2000 iterations until the total number of residual points reaches 1000. In Figs. 5I and J, we pre-train the neural network using 1000 residual points and heading to 2000 residual points in the same fashion. We recognize that 2 and 0 are the bestkandcvalues for the RAR-D method for both scenarios, which outperform the RAR-G method. As proven in this example, when applying the RAD and the RAR-D methods, the optimal values ofkandcremain stable even though we choose a different number of residual points. In addition, we find that the optimalkandcfor the Burgers\u2019 and Allen Cahn equations are the same for both the RAD and the RAR-D methods. Thus, we could choose (k= 1,c= 1) for the RAD methods and (k= 2,c= 0) for the RAR-D methods by default when first applied these methods to a new PDE problem. To make a comparison across all sampling methods, Table 2 shows theL^2 relative error for the Allen-Cahn equation when we fix the number of residual points at 1000. The Grid, Random, and LHS methods are prone to substantial errors, which are all larger than 20%. Nevertheless, the other four uniform methods (Halton, Hammersley, Sobol, and Random-R) have greater performance and can achieveL^2 relative errors of less than 1%. Remarkably, the RAD and RAR-D methods we proposed can further bring down theL^2 relative error below 0.1%. Figure 5:L^2 relative errors of different sampling methods for the Allen-Cahn equation in Section 3.4.(A) Six uniform sampling with fixed residual points. (B) Random-R with different periods of resampling when using 1000 residual points. (C\u2013F) The training trajectory of RAD with different values ofkandc. (C and D) 500 residual points are used. (C)k= 1. (D)c= 1. (E and F) 1000 residual points are used. (E)k= 1. (F)c= 1. (G\u2013J) RAR-D with different values ofk andc. (G and H) The number of residual points is increased from 500 to 1000. Each time 10 new points are added. (G)k= 2. (H)c= 0. (I and J) The number of residual points is increased from 1000 to 2000. Each time 10 new points are added. (I)k= 2. (J)c= 0. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. 18","title":"=D"},{"location":"Models/PINNs/PN-2207.10289/#35-wave-equation","text":"In this example, the following one-dimensional wave equation is considered: \u2202^2 u \u2202t^2","title":"3.5 Wave equation"},{"location":"Models/PINNs/PN-2207.10289/#4","text":"\u2202^2 u \u2202x^2 = 0, x\u2208[0,1],t\u2208[0,1], u(0,t) =u(1,t) = 0, t\u2208[0,1], u(x,0) = sin(\u03c0x) +","title":"\u2212 4"},{"location":"Models/PINNs/PN-2207.10289/#1_3","text":"","title":"1"},{"location":"Models/PINNs/PN-2207.10289/#2","text":"sin(4\u03c0x), x\u2208[0,1], \u2202u \u2202t (x,0) = 0, x\u2208[0,1], where the exact solution is given as: u(x,t) = sin(\u03c0x) cos(2\u03c0t) +","title":"2"},{"location":"Models/PINNs/PN-2207.10289/#1_4","text":"","title":"1"},{"location":"Models/PINNs/PN-2207.10289/#2_1","text":"sin(4\u03c0x) cos(8\u03c0t). The solution has a multi-scale behavior in both spatial and temporal directions. When we test the six uniform sampling methods, the number of residual points are ranged from 1000 to 6000, with an increment of 1000 each time. The Hammersley method achieves the lowest L^2 relative error with the fastest rate (Fig. 6A). When the number of residual points approaches 6000, the Random, Halton, and Hammersley methods can all obtain anL^2 relative error\u223c 10 \u2212^3. To determine the effectiveness of Random-R when using different numbers of residual points, we test the following three scenarios: small (1000 points), medium (4000 points), and large (10.000) sets of residual points (Figs. 6B, C, and D). In the medium case (Fig. 6C), the Random-R attainsL^2 relative errors magnitudes lower than the Random method. However, in the small and large cases (Figs. 6B and D), the Random-R methods show no advantage over the Random method regardless of the period of resampling. This is because when the number of residual points is small, both the Random and Random-R methods fail to provide accurate predictions. On the other hand, if the number of residual points is large, the predictions by the Random method are already highly accurate, so the Random-R is unable to further improve the accuracy. Since the optimal sets ofkandcfor both RAD and RAR-D methods are found to be the same for the Burgers\u2019 and the Allen Cahn equations, in this numerical experiment, we only apply the default settings (i.e., RAD:k= 1 andc= 1; RAR-D:k= 2 andc= 0) to investigate the effect of other factors, including the number of residual points for the RAD method and the number of points added to the RAR-D method. In Fig. 6E, we compare the performance of three nonuniform adaptive sampling methods under the same number of residual points from 1000 to 10 000. We first train the network using 15 000 iterations of Adam and 1000 iterations of L-BFGS, and then after each resampling in RAD or adding new points in RAR-D/RAR-G, we train the network with 1000 iterations of L-BFGS. For the RAR-G and the RAR-D methods, we first train the network with 50% of the final number of the residual points and add 10 residual points each time until reaching the total number of residual points. As we can see from Fig. 6E, the RAD achieves much better results when the number of residual points is small. As the number of residual points increases, the RAR-D method acts more effectively and eventually reaches comparable accuracy to the RAD method. Since the RAD method is more computationally costly than the RAR-D methods with the same number of residual points, we suggest applying the RAD method when the number of residual points is small and the RAR-D method when the number of residual points is large. We next investigate the RAD method with a different number of residual points (i.e., 1000, 2000, 5000, and 10 000). Fig. 6F illustrates that if we increase the number of residual points, lower Figure 6: L^2 relative errors of different sampling methods for the wave equation in Section 3.5.(A) Six uniform sampling with fixed residual points. (B,C, andD) Random-R with different periods of resampling when using (B) 1000 residual points, (C) 4000 residual points, and (D) 10000 residual points. (E) Comparison among RAD (k= 1 andc= 1), RAR-D (k= 2 and c= 0), and RAR-G for different numbers of residual points. (F) The training trajectory of RAD (k= 1 andc= 1) uses different numbers of residual points. (GandH) Convergence of RAR-D (k= 2 andc= 0) when adding a different number of new points each time. (G) New points are added starting from 1000 residual points. (H) New points are added starting from 2500 residual points. (I) Convergence of RAR-G when adding a different number of new points each time. New points are added starting from 2500 residual points. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. L^2 relative error can be achieved but with diminishing marginal effect. We train the network for more than 500 000 iterations to see if theL^2 relative error can further decrease. However, theL^2 relative errors converge and remain relatively stable after 100 000 iterations. One important factor to consider in the RAR-D and the RAR-G methods is how new points are added. We can either add a small number of residual points each time and prolong the training process or add a large number of residual points each time and shorten the process. In Fig. 6G, we first train the network with 1000 residual points and then add new residual points at different rates until the total number of residual points reaches 2000. After adding new residual points each time, we train the network using 1000 steps of L-BFGS. Likewise, in Fig. 6H, we first train the network with 2500 residual points and add new points at different rates until the total number of residual points reaches 5000. In both cases (Figs. 6G and H) that use the RAR-D methods, we find that the best strategy is to add 10 points each time. However, shown by two red-shaded regions in Figs. 6G and H, the results are more stable when we use a larger number of residual points. Fig. 6I is set up the same way as Fig. 6H but tests the RAR-G method. The best strategy for the RAR-G is identical to that of the RAR-D. Table 2 outlines theL^2 relative error for the wave equation using all methods when the number of residual points equals 2000. All uniform methods with fixed residual points perform poorly (error >50%) and fail to approximate the truth values. Random-R, as a special case of the proposed RAD, givesL^2 relative errors of around 1%. The RAR-D method significantly enhances the prediction accuracy resulting inL^2 relative errors under 0.3%. In addition, the RAD with the default setting ofkandcconverges toL^2 relative errors under 0.1%.","title":"2"},{"location":"Models/PINNs/PN-2207.10289/#36-diffusion-reaction-equation","text":"The first inverse problem we consider is the diffusion-reaction system as follows: \u03bb d^2 u dx^2 \u2212k(x)u=f, x\u2208[0,1], wheref = sin(2\u03c0x) is the source term. \u03bb= 0.01 is the diffusion coefficient, anduis the solute concentration. In this problem, we aim to infer the space-dependent reaction ratek(x) with given measurements on the solutionu. The exact unknown reaction rate is k(x) = 0.1 +e\u2212^0.^5 (x\u2212 0 .5)^2 (^152). We aim to learn the unknown functionk(x) and solve foru(x) by using eight observations ofu, which are uniformly distributed on the domainx\u2208[0,1], including two points on both sides of the boundaries. TheL^2 relative errors for both the solutionu(Figs. 7A, C, and E) and the unknown functionk(Figs. 7B, D, and F) are computed. The maximum number of iterations is 50 000 steps of Adam. Figs. 7A and B summarize the performance of all uniform sampling methods. We note that in 1D, the Hammersley and Halton sequences are identical and outperform other uniform methods. We fix the residual points at 15 and compare the Random method with the Random-R method. TheL^2 relative errors (Figs. 7C and D) given by the Random-R remain steady, disregarding the changes in the period of resampling, and are approximately the same as that produced by the Random method. This is because the reaction-diffusion system is fairly simple and can be easily handled by uniform sampling methods without resampling. Next, we compare the Random, RAD, RAR-G, and RAR-D methods with default settings (i.e., RAD:k= 1 andc= 1; RAR-D:k= 2 andc= 0) using a different number of residual points. For the random and RAD methods, the maximum number of iterations is 50 000 steps of Adam. For Figure 7:L^2 relative errors of different sampling methods foruandkin the diffusionreaction equation in Section 3.6.(AandB) Six uniform sampling with fixed residual points. (CandD) Random-R with different periods of resampling when using 15 residual points. (Eand F) Comparison among Random, RAD (k= 1 andc= 1), RAR-G, and RAR-D (k= 2 andc= 0) for different numbers of residual points. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. the RAR-G/RAR-D, we first train the neural network with 50% of the total number of residual points for 10 000 steps of Adam; then we add one point each time and train for 1000 steps of Adam until we meet the total number of residual points. As shown by Figs. 7E and F, the RAD method surpasses other methods and is able to produce lowL^2 relative error even when the number of residual points is very small. However, RAR-G and RAR-D are even worse than the Random sampling. To sum up, we fix the number of residual points at 15 and present theL^2 relative error for both the solution and unknown function in Table 3. The RAD yields the minimumL^2 relative error (0.17% foru(x); 2.76% fork(x)). However, due to the simplicity of this PDE problem, some uniform sampling methods, especially the Sobol and Random-R, have comparable performance to the RAD. Generally speaking, we recognize that the uniform sampling methods are adequate when solving this inverse PDE with smooth solutions. Still, the RAD method can further enhance the performance of PINNs, especially when the number of residual points is small.","title":"3.6 Diffusion-reaction equation"},{"location":"Models/PINNs/PN-2207.10289/#37-korteweg-de-vries-equation","text":"The second inverse problem we solve is the Korteweg-de Vries (KdV) equation: \u2202u \u2202t +\u03bb 1 u \u2202u \u2202x +\u03bb 2 \u2202^3 u \u2202x^3 = 0, x\u2208[\u2212 1 ,1], t\u2208[0,1], where\u03bb 1 and\u03bb 2 are two unknown parameters. The exact values for\u03bb 1 and\u03bb 2 are 1 and 0.0025, respectively. The initial condition isu(x,t= 0) = cos(\u03c0x), and periodic boundary conditions are used. To infer\u03bb 1 and\u03bb 2 , we assume that we have the observations of two solution snapshots u(x,t= 0.2) andu(x,t= 0.8) at 64 uniformly distributed points at each time. In Fig. 8, the first column (Figs. 8A, D, and G) shows theL^2 relative error of the solutionu, while the second column (Figs. 8B, E, and H) and the third column (Figs. 8C, F, and I) illustrate the relative errors for\u03bb 1 and\u03bb 2 , respectively. The maximum iteration is 100 000 steps of Adam. Hammersley achieves better accuracy than the other uniform sampling methods. The Sobol and Halton methods behave comparably as these two curves (the yellow and green curves in Figs. 8A, B, and C) are almost overlapping. Shown in Figs. 8D, E and F, the Random-R method yields higher accuracy than the Random method by about one order of magnitude in all cases when using 1000 residual points. A smaller period of resampling leads to smaller errors. Figs. 8G, H, and I compare the Random-R, Random, RAD, RAR-G, and RAR-D methods using the same number of residual points and the total number of iterations. For the Random and the Random-R methods, we train the network for 100 000 steps of Adams. For the RAD methods, we first train the network using 50 000 steps of Adams; then, we resample the residual points and train for 1000 steps of Adams 50 times. In order to fix the total number of iterations for the RARG/RAR-D methods to 100 000, we accordingly adjust the number of new residual points added each time. For example, if the final number of residual points is 500, we first train the network using 250 residual points (i.e., 50% of the total number of residual points) with 50 000 steps of Adams; and we consequently add 5 points and train for 1000 steps of Adams each time. If the final number of residual points is 1000, we first train the network using 500 residual points with 50 000 steps of Adams; and then we add 10 points and train for 1000 steps of Adams each time. As demonstrated by Figs. 8G, H, and I, the RAD method is the best, while the Random-R method is also reasonably accurate. We show one example of the training process (Figs. 8J, K, and L) when the number of residual points is 600 to illustrate the convergence of the solution,\u03bb 1 , and\u03bb 2 during training. The resampling strategies, especially the RAD method, achieve the greatest success among all sampling methods. Figure 8:L^2 relative errors ofuand relative errors of\u03bb 1 and\u03bb 2 using different sampling methods for the Korteweg-de Vries equation in Section 3.7. (A,B, andC) Six uniform sampling with fixed residual points. (D,E, andF) Random-R with different periods of resampling when using 1000 residual points. (G,H, andI) Comparison among Random, Random-R, RAD (k= 1 andc= 1), RAR-G, and RAR-D (k= 2 andc= 0) for different number of residual points. (J,K, andL) Examples of the training trajectories using Random, Random-R, RAD (k= 1 and c= 1), RAR-G, and RAR-D (k= 2 andc= 0) with 600 residual points. The curves and shaded regions represent the geometric mean and one standard deviation of 10 runs. For clarity, only some standard deviations are plotted. Table 3 demonstrates theL^2 relative errors for the solutionu(x,t) and the relative error of two unknown parameters\u03bb 1 and\u03bb 2 , for all methods when the number of residual points is set at The lowestL^2 relative errors for uniform sampling with fixed points are given by Hammersley (\u223c 5%). The Random-R is the second-best method and providesL^2 relative errors of around 1%. With the smallest errors (<1%) and standard deviations, the RAD method has compelling advantages over all other methods in terms of accuracy and robustness. It is noteworthy that the RAR-D method provides adequate accuracy (\u223c3%) and is less expensive than the Random-R and RAD methods when the number of residual points is the same. Therefore, the RAR-D is also a valuable approach to consider.","title":"3.7 Korteweg-de Vries equation"},{"location":"Models/PINNs/PN-2207.10289/#4-conclusions","text":"In this paper, we present a comprehensive study of two categories of sampling for physics-informed neural networks (PINNs), including non-adaptive uniform sampling and adaptive nonuniform sampling. For the non-adaptive uniform sampling, we have considered six methods: (1) equispaced uniform grid (Grid), (2) uniformly random sampling (Random), (3) Latin hypercube sampling (LHS), (4) Halton sequence (Halton), (5) Hammersley sequence (Hammersley), and (6) Sobol sequence (Sobol). We have also considered a resampling strategy for uniform sampling (Random-R). For the adaptive nonuniform sampling, motivated by the residual-based adaptive refinement with greed (RAR-G) [3], we proposed two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D). We extensively investigated the performance of these ten sampling methods in solving four forward and two inverse problems of partial differential equations (PDEs) with many setups, such as a different number of residual points. Our results show that the proposed RAD and RAR-D significantly improve the accuracy of PINNs by orders of magnitude, especially when the number of residual points is small. RAD and RAR-D also have great advantages for the PDEs with complicated solutions, e.g., the solution of the Burgers\u2019 equation with steep gradients and the solution of the wave equation with a multi-scale behavior. A summary of the comparison of these methods can be found in Section 3.1. Based on our empirical results, we summarize the following suggestions as a practical guideline in choosing sampling methods for PINNs. RAD withk= 1 andc= 1 can be chosen as the default sampling method when solving a new PDE. The hyperparameterskandccan be tuned to balance the points in the locations with large and small PDE residuals. RAR-D can achieve comparable accuracy to RAD, but RAR-D is more computationally efficient as it gradually increases the number of residual points. Hence, RAR-D (k= 2 and c= 0 by default) is preferable for the case with limited computational resources. Random-R can be used in the situation where adaptive sampling is not allowed, e.g., it is difficult to sample residual points according to a probability density function. The period of resampling should not be chosen as too small or too large. A low-discrepancy sequence (e.g., Hammersley) should be considered rather than Grid, Ran- dom, or LHS, when we have to use a fixed set of residual points, such as in PINNs with the augmented Lagrangian method (hPINNs) [8]. In this study, we sample residual points in RAD and RAR-D by using a brute-force approach, which is simple, easy to implement, and sufficient for many PDEs. However, for high-dimensional problems, we need to use other methods, such as generative adversarial networks (GANs) [46], as was done in Ref. [41]. Moreover, the probability of sampling a pointxis only considered as p(x)\u221d \u03b5 k(x) E[\u03b5k(x)]+c. While this probability works very well in this study, it is possible that there exists another better choice. We can learn a new probability density function by meta-learning, as was done for loss functions of PINNs in Ref. [11].","title":"4 Conclusions"},{"location":"Models/PINNs/PN-2207.10289/#references","text":"[1] M. Raissi, P. Perdikaris, and G.E. Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.Journal of Computational Physics, 378:686\u2013707, 2019. [2] Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations.Science, 367(6481):1026\u20131030, 2020. [3] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. DeepXDE: A deep learning library for solving differential equations.SIAM Review, 63(1):208\u2013228, 2021. [4] George Em Karniadakis, Ioannis G. Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning.Nature Reviews Physics, 3(6):422\u2013440, 2021. [5] Yuyao Chen, Lu Lu, George Em Karniadakis, and Luca Dal Negro. Physics-informed neural networks for inverse problems in nano-optics and metamaterials.Optics Express, 28(8):11618, 2020. [6] Alireza Yazdani, Lu Lu, Maziar Raissi, and George Em Karniadakis. Systems biology informed deep learning for inferring parameters and hidden dynamics. PLOS Computational Biology, 16(11), 2020. [7] Mitchell Daneker, Zhen Zhang, George Em Kevrekidis, and Lu Lu. Systems biology: Identifiability analysis and parameter identification via systems-biology informed neural networks. arXiv preprint arXiv:2202.01723, 2022. [8] Lu Lu, Rapha \u0308el Pestourie, Wenjie Yao, Zhicheng Wang, Francesc Verdugo, and Steven G. Johnson. Physics-informed neural networks with hard constraints for inverse design. SIAM Journal on Scientific Computing, 43(6), 2021. [9] Guofei Pang, Lu Lu, and George Em Karniadakis. fPINNs: Fractional physics-informed neural networks. SIAM Journal on Scientific Computing, 41(4), 2019. [10] Dongkun Zhang, Lu Lu, Ling Guo, and George Em Karniadakis. Quantifying total uncertainty in physics-informed neural networks for solving forward and inverse stochastic problems.Journal of Computational Physics, 397:108850, 2019. [11] Apostolos F Psaros, Kenji Kawaguchi, and George Em Karniadakis. Meta-learning PINN loss functions. Journal of Computational Physics, 458:111121, 2022. [12] Jeremy Yu, Lu Lu, Xuhui Meng, and George Em Karniadakis. Gradient-enhanced physicsinformed neural networks for forward and inverse PDE problems.Computer Methods in Applied Mechanics and Engineering, 393:114823, 2022. [13] Sifan Wang, Yujun Teng, and Paris Perdikaris. Understanding and mitigating gradient flow pathologies in physics-informed neural networks. SIAM Journal on Scientific Computing, 43(5):A3055\u2013A3081, 2021. [14] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why PINNs fail to train: A neural tangent kernel perspective. Journal of Computational Physics, 449:110768, 2022. [15] Zixue Xiang, Wei Peng, Xu Liu, and Wen Yao. Self-adaptive loss balanced physics-informed neural networks.Neurocomputing, 2022. [16] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft attention mechanism.arXiv preprint arXiv:2009.04544, 2020. [17] Yiqi Gu, Haizhao Yang, and Chao Zhou. SelectNet: Self-paced learning for high-dimensional partial differential equations.Journal of Computational Physics, 441:110444, 2021. [18] Wensheng Li, Chao Zhang, Chuncheng Wang, Hanting Guan, and Dacheng Tao. Revisiting PINNs: Generative adversarial physics-informed neural networks and point-weighting method. arXiv preprint arXiv:2205.08754, 2022. [19] Xuhui Meng, Zhen Li, Dongkun Zhang, and George Em Karniadakis. PPINN: Parareal physicsinformed neural network for time-dependent pdes. Computer Methods in Applied Mechanics and Engineering, 370:113250, 2020. [20] Khemraj Shukla, Ameya D. Jagtap, and George Em Karniadakis. Parallel physics-informed neural networks via domain decomposition. Journal of Computational Physics, 447:110683, 2021. [21] Ameya D. Jagtap and George Em Karniadakis. Extended physics-informed neural networks (XPINNs): A generalized space-time domain decomposition based deep learning framework for nonlinear partial differential equations. Communications in Computational Physics, 28(5):2002\u20132041, 2020. [22] Colby L Wight and Jia Zhao. Solving Allen-Cahn and Cahn-Hilliard equations using the adaptive physics informed neural networks. arXiv preprint arXiv:2007.04542, 2020. [23] Aditi Krishnapriyan, Amir Gholami, Shandian Zhe, Robert Kirby, and Michael W Mahoney. Characterizing possible failure modes in physics-informed neural networks.Advances in Neural Information Processing Systems, 34:26548\u201326560, 2021. [24] Revanth Mattey and Susanta Ghosh. A novel sequential method to train physics informed neural networks for allen cahn and cahn hilliard equations. Computer Methods in Applied Mechanics and Engineering, 390:114474, 2022. [25] Katsiaryna Haitsiukevich and Alexander Ilin. Improved training of physics-informed neural networks with model ensembles. arXiv preprint arXiv:2204.05108, 2022. [26] Sifan Wang, Shyam Sankaran, and Paris Perdikaris. Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404, 2022. [27] Pola Lydia Lagari, Lefteri H Tsoukalas, Salar Safarkhani, and Isaac E Lagaris. Systematic construction of neural forms for solving partial differential equations inside rectangular domains, subject to initial, boundary and interface conditions. International Journal on Artificial Intelligence Tools, 29(05):2050009, 2020. [28] Suchuan Dong and Naxian Ni. A method for representing periodic functions and enforcing exactly periodic boundary conditions with deep neural networks. Journal of Computational Physics, 435:110242, 2021. [29] Michael D McKay, Richard J Beckman, and William J Conover. A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 42(1):55\u201361, 2000. [30] Michael Stein. Large sample properties of simulations using Latin hypercube sampling.Technometrics, 29(2):143\u2013151, 1987. [31] Il\u2019ya Meerovich Sobol\u2019. On the distribution of points in a cube and the approximate evaluation of integrals.Zhurnal Vychislitel\u2019noi Matematiki i Matematicheskoi Fiziki, 7(4):784\u2013802, 1967. [32] John H Halton. On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals. Numerische Mathematik, 2(1):84\u201390, 1960. [33] JM Hammersley and DC Handscomb. Monte-Carlo methods, mathuen, 1964. [34] Hongwei Guo, Xiaoying Zhuang, Xiaoyu Meng, and Timon Rabczuk. Analysis of three dimensional potential problems in non-homogeneous media with deep learning based collocation method.arXiv preprint arXiv:2010.12060, 2020. [35] Sourav Das and Solomon Tesfamariam. State-of-the-art review of design of experiments for physics-informed deep learning.arXiv preprint arXiv:2202.06416, 2022. [36] Zhiping Mao, Ameya D Jagtap, and George Em Karniadakis. Physics-informed neural networks for high-speed flows. Computer Methods in Applied Mechanics and Engineering, 360:112789, 2020. [37] Mohammad Amin Nabian, Rini Jasmine Gladstone, and Hadi Meidani. Efficient training of physics-informed neural networks via importance sampling.Computer-Aided Civil and Infrastructure Engineering, 2021. [38] Bastian Zapf, Johannes Haubner, Miroslav Kuchta, Geir Ringstad, Per Kristian Eide, and Kent-Andre Mardal. Investigating molecular transport in the human brain from MRI with physics-informed neural networks.arXiv preprint arXiv:2205.02592, 2022. [39] Arka Daw, Jie Bu, Sifan Wang, Paris Perdikaris, and Anuj Karpatne. Rethinking the importance of sampling in physics-informed neural networks. arXiv preprint arXiv:2207.02338, 2022. [40] Wenhan Gao and Chunmei Wang. Active learning based sampling for high-dimensional nonlinear partial differential equations. arXiv preprint arXiv:2112.13988, 2021. [41] Kejun Tang, Xiaoliang Wan, and Chao Yang. DAS: A deep adaptive sampling method for solving partial differential equations.arXiv preprint arXiv:2112.14038, 2021. [42] Wei Peng, Weien Zhou, Xiaoya Zhang, Wen Yao, and Zheliang Liu. RANG: a residualbased adaptive node generation method for physics-informed neural networks. arXiv preprint arXiv:2205.01051, 2022. [43] Shaojie Zeng, Zong Zhang, and Qingsong Zou. Adaptive deep neural networks methods for high-dimensional partial differential equations.Journal of Computational Physics, 463:111232, 2022. [44] John M Hanna, Jose V Aguado, Sebastien Comas-Cardona, Ramzi Askri, and Domenico Borzacchiello. Residual-based adaptivity for two-phase flow simulation in porous media using physics-informed neural networks.Computer Methods in Applied Mechanics and Engineering, 396:115100, 2022. [45] Melissa E O\u2019Neill. Pcg: A family of simple fast space-efficient statistically good algorithms for random number generation.ACM Transactions on Mathematical Software, 2014. [46] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.Advances in neural information processing systems, 27, 2014. [47] Bengt Fornberg and Natasha Flyer. Fast generation of 2-D node distributions for mesh-free pde discretizations.Computers & Mathematics with Applications, 69(7):531\u2013544, 2015.","title":"References"},{"location":"Models/PINNs/PN-2210.00279/","text":"Failure-Informed Adaptive Sampling for PINNs \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u5931\u8d25\u4fe1\u606f\u81ea\u9002\u5e94\u91c7\u6837","title":"Failure-Informed Adaptive Sampling for PINNs <br> \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u5931\u8d25\u4fe1\u606f\u81ea\u9002\u5e94\u91c7\u6837"},{"location":"Models/PINNs/PN-2210.00279/#failure-informed-adaptive-sampling-for-pinns","text":"","title":"Failure-Informed Adaptive Sampling for PINNs  \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u5931\u8d25\u4fe1\u606f\u81ea\u9002\u5e94\u91c7\u6837"},{"location":"Models/PINNs/PN-2210.12914/","text":"A Novel Adaptive Causal Sampling Method for PINNs \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u79cd\u65b0\u81ea\u9002\u5e94\u56e0\u679c\u91c7\u6837\u65b9\u6cd5","title":"A Novel Adaptive Causal Sampling Method for PINNs <br> \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u79cd\u65b0\u81ea\u9002\u5e94\u56e0\u679c\u91c7\u6837\u65b9\u6cd5"},{"location":"Models/PINNs/PN-2210.12914/#a-novel-adaptive-causal-sampling-method-for-pinns","text":"","title":"A Novel Adaptive Causal Sampling Method for PINNs  \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u79cd\u65b0\u81ea\u9002\u5e94\u56e0\u679c\u91c7\u6837\u65b9\u6cd5"},{"location":"Models/PINNs/PN-JCP201810045/","text":"Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations \u4f5c\u8005: \u673a\u6784: \u65f6\u95f4: 2018-06-13 \u53d1\u8868: JCP \u9886\u57df: \u6807\u7b7e: #PINN \u5f15\u7528: \u4ee3\u7801:","title":"Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations"},{"location":"Models/PINNs/PN-JCP201810045/#physics-informed-neural-networks-a-deep-learning-framework-for-solving-forward-and-inverse-problems-involving-nonlinear-partial-differential-equations","text":"\u4f5c\u8005: \u673a\u6784: \u65f6\u95f4: 2018-06-13 \u53d1\u8868: JCP \u9886\u57df: \u6807\u7b7e: #PINN \u5f15\u7528: \u4ee3\u7801:","title":"Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations"},{"location":"Models/Transformers/PN-2005.12872/","text":"DETR","title":"DETR"},{"location":"Models/Transformers/PN-2005.12872/#detr","text":"","title":"DETR"},{"location":"Models/Transformers/Transformers/","text":"Transformers \u7cfb\u5217","title":"Transformers \u7cfb\u5217"},{"location":"Models/Transformers/Transformers/#transformers","text":"","title":"Transformers \u7cfb\u5217"},{"location":"Models/Tricks/nn.init/","text":"\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u521d\u59cb\u5316 \u5747\u5300\u5206\u5e03 \\(\\mathcal{U}(a,b)\\) def uniform_(tensor: Tensor, a: float=0, b: float = 1.) -> Tensor: with torch.no_grad(): return tensor.uniform_(a, b) \u6b63\u6001\u5206\u5e03 \\(\\mathcal{N}(\\mu, \\sigma^2)\\) \u5e38\u6570 \u5168\u4e00\u5316 \u5168\u96f6\u5316 \u5355\u4f4d\u77e9\u9635 Dirac Delta \u51fd\u6570 xaiver_uniform xaiver_normal kaiming_uniform kaiming_normal trunc_normal orthogonal sparse","title":"\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u521d\u59cb\u5316"},{"location":"Models/Tricks/nn.init/#_1","text":"\u5747\u5300\u5206\u5e03 \\(\\mathcal{U}(a,b)\\) def uniform_(tensor: Tensor, a: float=0, b: float = 1.) -> Tensor: with torch.no_grad(): return tensor.uniform_(a, b) \u6b63\u6001\u5206\u5e03 \\(\\mathcal{N}(\\mu, \\sigma^2)\\) \u5e38\u6570 \u5168\u4e00\u5316 \u5168\u96f6\u5316 \u5355\u4f4d\u77e9\u9635 Dirac Delta \u51fd\u6570 xaiver_uniform xaiver_normal kaiming_uniform kaiming_normal trunc_normal orthogonal sparse","title":"\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u521d\u59cb\u5316"},{"location":"Models/Tricks/nn/","text":"\u6df1\u5ea6\u5b66\u4e60\u57fa\u672c\u8fc7\u7a0b \u6570\u636e\u90e8\u5206 \u6a21\u578b\u90e8\u5206 \u7f51\u7edc\u7ed3\u6784 \u6743\u91cd\u521d\u59cb\u5316 \u6fc0\u6d3b\u51fd\u6570 \u8bad\u7ec3\u90e8\u5206 \u53cd\u5411\u4f20\u64ad \u4f18\u5316\u5668 \u5b66\u4e60\u7387 Normalization Dropout \u63a8\u7406\u90e8\u5206","title":"\u6df1\u5ea6\u5b66\u4e60\u57fa\u672c\u8fc7\u7a0b"},{"location":"Models/Tricks/nn/#_1","text":"","title":"\u6df1\u5ea6\u5b66\u4e60\u57fa\u672c\u8fc7\u7a0b"},{"location":"Models/Tricks/nn/#_2","text":"","title":"\u6570\u636e\u90e8\u5206"},{"location":"Models/Tricks/nn/#_3","text":"\u7f51\u7edc\u7ed3\u6784 \u6743\u91cd\u521d\u59cb\u5316 \u6fc0\u6d3b\u51fd\u6570","title":"\u6a21\u578b\u90e8\u5206"},{"location":"Models/Tricks/nn/#_4","text":"\u53cd\u5411\u4f20\u64ad \u4f18\u5316\u5668 \u5b66\u4e60\u7387 Normalization Dropout","title":"\u8bad\u7ec3\u90e8\u5206"},{"location":"Models/Tricks/nn/#_5","text":"","title":"\u63a8\u7406\u90e8\u5206"},{"location":"Models/YOLOs/YOLOs/","text":"","title":"YOLOs"},{"location":"Projects/NanoDet/NanoDet%2B/","text":"NanoDet data evaluator model arch __init__.py nanodet_plus.py one_stage_detector.py backbone fpn head loss module weight_averager optim trainer util __about__.py __init__.py \u7f51\u7edc\u67b6\u6784 \u9aa8\u5e72\u7f51\u7edc Backbone \u9aa8\u5e72\u7f51\u7edc\u5b9e\u73b0: ResNet resnet18, 34, 50, 101, 152 class BasicBlock(): conv1 bn1 act conv2 bn2 downsample stride class Bottleneck(): class fill_fc_weights(layers): class ResNet(): ShuffleNetV2 \u6743\u91cd\u6587\u4ef6 shufflenetv2_0.5x, 1.0x channel_shuffle(x, groups): batch_size, num_channels, height, width = x.data.size() channels_per_group = num_channels // groups x = x.view(batch_size, groups, channels_per_group, height, width) x = torch.transpose(x, 1, 2).contiguous() x = x.view(batch_szie, -1, height, width) return x class ShuffleV2Block(): \u521d\u59cb\u5316(inp, oup, \u6b65\u957f, \u6fc0\u6d3b\u51fd\u6570): \u82e5\u6b65\u957f\u4e0d\u5728 1~3 \u4e4b\u95f4: \u8fd4\u56de\u5f02\u5e38: \u975e\u6cd5\u6b65\u957f\u503c. self.stride = \u6b65\u957f \u5206\u652f\u7279\u5f81 = oup // 2 \u65ad\u8a00: \u6b65\u957f\u5e76\u4e0d\u4e3a 1 \u6216 inp \u7b49\u4e8e\u5206\u652f\u7279\u5f81/2? \u5982\u679c\u6b65\u957f\u5927\u4e8e 1: self.branch1 = Seq( depthwise_conv(inp, inp, 3\u00d73, \u6b65\u957f, \u586b\u5145=1), BN2d(inp), Conv2d(inp, \u5206\u652f\u7279\u5f81, 1\u00d71, \u6b65\u957f=1, \u586b\u5145=0, \u504f\u5dee=0), BN2d(\u5206\u652f\u7279\u5f81), \u6fc0\u6d3b\u51fd\u6570 ) \u5426\u5219 self.branch1 = Seq() self.branch2 = Seq( Conv2d(\u6b65\u957f\u5927\u4e8e1\u65f6\u4e3a inp, \u5426\u5219\u4e3a\u5206\u652f\u7279\u5f81, \u5206\u652f\u7279\u5f81, 1\u00d71, \u6b65\u957f=1, \u586b\u5145=0, \u504f\u5dee=0), BN2d(\u5206\u652f\u7279\u5f81), \u6fc0\u6d3b\u51fd\u6570 depthwise_conv(\u5206\u652f\u7279\u5f81, \u5206\u652f\u7279\u5f81, 3\u00d73, \u6b65\u957f, \u586b\u5145=1), BN2d(\u5206\u652f\u7279\u5f81), Conv2d(\u5206\u652f\u7279\u5f81, \u5206\u652f\u7279\u5f81, 1\u00d71, \u6b65\u957f=1, \u586b\u5145=0, \u504f\u5dee=0), BN2d(\u5206\u652f\u7279\u5f81) \u6fc0\u6d3b\u51fd\u6570 ) depthwise_conv(\u8f93\u5165, \u8f93\u51fa, \u5377\u79ef\u6838, \u6b65\u957f=1, \u586b\u5145=0, bias=False): class ShuffleNetV2(): GhostNet MobileNetV2 EfficientNetLite CustomCSPNet RepVGG TIMMWrapper \u9888\u90e8\u6a21\u5757 Neck \u5934\u90e8\u6a21\u5757 Head","title":"NanoDet"},{"location":"Projects/NanoDet/NanoDet%2B/#nanodet","text":"data evaluator model arch __init__.py nanodet_plus.py one_stage_detector.py backbone fpn head loss module weight_averager optim trainer util __about__.py __init__.py","title":"NanoDet"},{"location":"Projects/NanoDet/NanoDet%2B/#_1","text":"","title":"\u7f51\u7edc\u67b6\u6784"},{"location":"Projects/NanoDet/NanoDet%2B/#backbone","text":"\u9aa8\u5e72\u7f51\u7edc\u5b9e\u73b0:","title":"\u9aa8\u5e72\u7f51\u7edc Backbone"},{"location":"Projects/NanoDet/NanoDet%2B/#resnet","text":"resnet18, 34, 50, 101, 152 class BasicBlock(): conv1 bn1 act conv2 bn2 downsample stride class Bottleneck(): class fill_fc_weights(layers): class ResNet():","title":"ResNet"},{"location":"Projects/NanoDet/NanoDet%2B/#shufflenetv2","text":"\u6743\u91cd\u6587\u4ef6 shufflenetv2_0.5x, 1.0x channel_shuffle(x, groups): batch_size, num_channels, height, width = x.data.size() channels_per_group = num_channels // groups x = x.view(batch_size, groups, channels_per_group, height, width) x = torch.transpose(x, 1, 2).contiguous() x = x.view(batch_szie, -1, height, width) return x class ShuffleV2Block(): \u521d\u59cb\u5316(inp, oup, \u6b65\u957f, \u6fc0\u6d3b\u51fd\u6570): \u82e5\u6b65\u957f\u4e0d\u5728 1~3 \u4e4b\u95f4: \u8fd4\u56de\u5f02\u5e38: \u975e\u6cd5\u6b65\u957f\u503c. self.stride = \u6b65\u957f \u5206\u652f\u7279\u5f81 = oup // 2 \u65ad\u8a00: \u6b65\u957f\u5e76\u4e0d\u4e3a 1 \u6216 inp \u7b49\u4e8e\u5206\u652f\u7279\u5f81/2? \u5982\u679c\u6b65\u957f\u5927\u4e8e 1: self.branch1 = Seq( depthwise_conv(inp, inp, 3\u00d73, \u6b65\u957f, \u586b\u5145=1), BN2d(inp), Conv2d(inp, \u5206\u652f\u7279\u5f81, 1\u00d71, \u6b65\u957f=1, \u586b\u5145=0, \u504f\u5dee=0), BN2d(\u5206\u652f\u7279\u5f81), \u6fc0\u6d3b\u51fd\u6570 ) \u5426\u5219 self.branch1 = Seq() self.branch2 = Seq( Conv2d(\u6b65\u957f\u5927\u4e8e1\u65f6\u4e3a inp, \u5426\u5219\u4e3a\u5206\u652f\u7279\u5f81, \u5206\u652f\u7279\u5f81, 1\u00d71, \u6b65\u957f=1, \u586b\u5145=0, \u504f\u5dee=0), BN2d(\u5206\u652f\u7279\u5f81), \u6fc0\u6d3b\u51fd\u6570 depthwise_conv(\u5206\u652f\u7279\u5f81, \u5206\u652f\u7279\u5f81, 3\u00d73, \u6b65\u957f, \u586b\u5145=1), BN2d(\u5206\u652f\u7279\u5f81), Conv2d(\u5206\u652f\u7279\u5f81, \u5206\u652f\u7279\u5f81, 1\u00d71, \u6b65\u957f=1, \u586b\u5145=0, \u504f\u5dee=0), BN2d(\u5206\u652f\u7279\u5f81) \u6fc0\u6d3b\u51fd\u6570 ) depthwise_conv(\u8f93\u5165, \u8f93\u51fa, \u5377\u79ef\u6838, \u6b65\u957f=1, \u586b\u5145=0, bias=False): class ShuffleNetV2(): GhostNet MobileNetV2 EfficientNetLite CustomCSPNet RepVGG TIMMWrapper","title":"ShuffleNetV2"},{"location":"Projects/NanoDet/NanoDet%2B/#neck","text":"","title":"\u9888\u90e8\u6a21\u5757 Neck"},{"location":"Projects/NanoDet/NanoDet%2B/#head","text":"","title":"\u5934\u90e8\u6a21\u5757 Head"},{"location":"Scholars/PN-2207.13266/","text":"Sparse Deep Neural Network for Nonlinear Partial Differential Equations \u4f5c\u8005: \u8bb8\u8dc3\u751f, Zeng Taishan \u94fe\u63a5: arXiv:2207.13266v1 \u65f6\u95f4: 2022-07-27 \u6807\u7b7e: Sparse Approximation, \u6df1\u5ea6\u5b66\u4e60, \u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b, Sparse Regularization, Adaptive Approximation \u76ee\u5f55 [Toc] author{ color: red; } Abstarct More competent learning models are demanded for data processing due to increasingly greater amounts of data available in applications. Data that we encounter often have certain embedded sparsity structures. That is, if they are represented in an appropriate basis, their energies can concentrate on a small number of basis functions. This paper is devoted to a numerical study of adaptive approximation of solutions of nonlinear partial differential equations whose solutions may have singularities, by deep neural networks (DNNs) with a sparse regularization with multiple parameters. Noting that DNNs have an intrinsic multi-scale structure which is favorable for adaptive representation of functions, by employing a penalty with multiple parameters, we develop DNNs with a multi-scale sparse regularization ( SDNN ) for effectively representing functions having certain singularities. We then apply the proposed SDNN to numerical solutions of the Burgers equation and the Schr\u00f6dinger equation. Numerical examples confirm that solutions generated by the proposed SDNN are sparse and accurate. \u7531\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u7528\u7684\u6570\u636e\u8d8a\u6765\u8d8a\u591a, \u56e0\u6b64\u9700\u8981\u66f4\u6709\u80fd\u529b\u7684\u5b66\u4e60\u6a21\u578b\u6765\u8fdb\u884c\u6570\u636e\u5904\u7406. \u6211\u4eec\u9047\u5230\u7684\u6570\u636e\u901a\u5e38\u5177\u6709\u67d0\u79cd\u5d4c\u5165\u5f0f\u7a00\u758f\u7ed3\u6784. \u4e5f\u5c31\u662f\u8bf4, \u5982\u679c\u7528\u9002\u5f53\u7684\u57fa\u51fd\u6570\u8868\u793a\u5b83\u4eec, \u5b83\u4eec\u7684\u80fd\u91cf\u5c31\u53ef\u4ee5\u96c6\u4e2d\u5728\u5c11\u91cf\u7684\u57fa\u51fd\u6570\u4e0a. \u672c\u6587\u5229\u7528\u5177\u6709\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc, \u5bf9\u89e3\u5177\u6709\u5947\u5f02\u6027\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7684\u81ea\u9002\u5e94\u903c\u8fd1\u8fdb\u884c\u4e86\u6570\u503c\u7814\u7a76. \u6ce8\u610f\u5230\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u5185\u5728\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784, \u6709\u5229\u4e8e\u51fd\u6570\u7684\u81ea\u9002\u5e94\u8868\u793a, \u901a\u8fc7\u4f7f\u7528\u591a\u53c2\u6570\u60e9\u7f5a, \u6211\u4eec\u5efa\u7acb\u4e86\u5177\u6709\u591a\u5c3a\u5ea6\u7a00\u758f\u6b63\u5219\u5316\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc (SDNN) \u6765\u6709\u6548\u5730\u8868\u793a\u5177\u6709\u67d0\u4e9b\u5947\u5f02\u6027\u7684\u51fd\u6570. \u7136\u540e\u6211\u4eec\u5c06\u6240\u63d0\u51fa\u7684 SDNN \u5e94\u7528\u4e8e\u6c42\u89e3 Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b\u7684\u6570\u503c\u89e3. \u6570\u503c\u7b97\u4f8b\u8868\u660e, \u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u751f\u6210\u7684\u89e3\u662f\u7a00\u758f\u4e14\u51c6\u786e\u7684. Introduction The goal of this paper is to develop a sparse regularization deep neural network model for numerical solutions of nonlinear partial differential equations whose solutions may have singularities. We will mainly focus on designing a sparse regularization model by employing multiple parameters to balance sparsity of different layers and the overall accuracy. The proposed ideas are tested in this paper numerically to confirm our intuition and more in-depth theoretical studies will be followed in a future paper. \u672c\u6587\u7684\u76ee\u7684\u662f\u5efa\u7acb\u4e00\u4e2a\u7a00\u758f\u6b63\u5219\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b, \u7528\u4e8e\u6c42\u89e3\u90a3\u4e9b\u53ef\u80fd\u5177\u6709\u5947\u5f02\u6027\u7684\u89e3\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u89e3. \u6211\u4eec\u5c06\u7740\u91cd\u4e8e\u8bbe\u8ba1\u4e00\u4e2a\u7a00\u758f\u6b63\u5219\u5316\u6a21\u578b, \u91c7\u7528\u591a\u4e2a\u53c2\u6570\u6765\u5e73\u8861\u4e0d\u540c\u5c42\u7684\u7a00\u758f\u6027\u548c\u6574\u4f53\u7cbe\u5ea6. \u4e3a\u4e86\u9a8c\u8bc1\u6211\u4eec\u7684\u76f4\u89c9, \u672c\u6587\u5bf9\u6240\u63d0\u51fa\u7684\u89c2\u70b9\u8fdb\u884c\u4e86\u6570\u503c\u5b9e\u9a8c, \u5e76\u5c06\u5728\u4eca\u540e\u7684\u8bba\u6587\u4e2d\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u7406\u8bba\u7814\u7a76. Artificial intelligence especially deep neural networks (DNN) has received great attention in many research fields. From the approximation theory point of view, a neural network is built by functional composition to approximate a continuous function with arbitrary accuracy. Deep neural networks are proven to have better approximation by practice and theory due to their relatively large number of hidden layers. Deep neural network has achieved state-of-the-art performance in a wide range of applications, including speech recognition 11 , computer vision 28 , natural language processing 14 , and finance 8 . For an overview of deep learning the readers are referred to monograph 20 . Recently, there was great interest in applying deep neural networks to the field of scientific computing, such as discovering the differential equations from observed data 34 , solving the partial differential equation (PDE) 21 29 30 35 , and problem aroused in physics 16 . Mathematical understanding of deep neural networks received much attention in the applied mathematics community. A universal approximation theory of neural network for Borel measurable function on compact domain is established in 9 . Some recent research studies the expressivity of deep neural networks for different function spaces 15 , for example, Sobolev spaces, Barron functions, and H\u00f6lder spaces. There are close connections between deep neural network and traditional approximation methods, such as splines 13 37 , compressed sensing 1 , and finite elements 22 26 . Convergence of deep neural networks and deep convolutional neural networks are studied in 40 and 41 respectively. Some work aims at understanding the training process of DNN. For instance, in paper 10 , the training process of DNN is interpreted as learning adaptive basis from data. \u4eba\u5de5\u667a\u80fd, \u7279\u522b\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5df2\u7ecf\u5728\u8bb8\u591a\u9886\u57df\u5f97\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8. \u4ece\u903c\u8fd1\u7406\u8bba\u7684\u89d2\u5ea6\u6765\u770b, \u795e\u7ecf\u7f51\u7edc\u662f\u901a\u8fc7\u51fd\u6570\u7ec4\u5408\u6765\u903c\u8fd1\u4efb\u610f\u7cbe\u5ea6\u7684\u8fde\u7eed\u51fd\u6570. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7531\u4e8e\u5176\u76f8\u5bf9\u8f83\u5927\u7684\u9690\u5c42\u6570, \u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u88ab\u8bc1\u660e\u5177\u6709\u8f83\u597d\u7684\u903c\u8fd1\u6027\u80fd. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bed\u97f3\u8bc6\u522b, \u8ba1\u7b97\u673a\u89c6\u89c9, \u81ea\u7136\u8bed\u8a00\u5904\u7406 (BERT) \u548c\u91d1\u878d\u7b49\u5e7f\u6cdb\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd. \u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u8ff0, \u8bfb\u8005\u53ef\u4ee5\u53c2\u8003\u4e13\u8457 Deep Learning . \u6700\u8fd1, \u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u5f15\u8d77\u4e86\u6781\u5927\u7684\u5174\u8da3, \u4f8b\u5982\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u53d1\u73b0\u5fae\u5206\u65b9\u7a0b, \u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b, \u4ee5\u53ca\u7269\u7406\u5b66\u4e2d\u51fa\u73b0\u7684\u76f8\u5173\u95ee\u9898. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u7406\u89e3\u5728\u5e94\u7528\u6570\u5b66\u754c\u5907\u53d7\u5173\u6ce8. \u6587\u732e 9 \u4e2d\u5efa\u7acb\u4e86\u4e00\u4e2a\u7528\u4e8e\u7d27\u81f4\u57df\u4e0a Borel \u53ef\u6d4b\u51fd\u6570\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u901a\u7528\u903c\u8fd1\u7406\u8bba. \u6700\u8fd1\u7684\u4e00\u4e9b\u5de5\u4f5c\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5bf9\u4e0d\u540c\u51fd\u6570\u7a7a\u95f4\u7684\u8868\u8fbe\u80fd\u529b, \u4f8b\u5982 Sobolev \u7a7a\u95f4, Barron \u51fd\u6570\u548c H\u00f6lder \u7a7a\u95f4. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e0e\u4f20\u7edf\u903c\u8fd1\u65b9\u6cd5\u6709\u7740\u5bc6\u5207\u7684\u8054\u7cfb, \u4f8b\u5982\u6837\u6761\u51fd\u6570, \u538b\u7f29\u611f\u77e5\u548c\u6709\u9650\u5143. \u6587\u732e 40 \u548c 41 \u4e2d\u5206\u522b\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6536\u655b\u6027. \u4e00\u4e9b\u5de5\u4f5c\u8bd5\u56fe\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b. \u4f8b\u5982, \u6587\u732e 10 \u4e2d\u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u88ab\u89e3\u91ca\u4e3a\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u81ea\u9002\u5e94\u57fa. Traditionally, deep neural networks are dense and over-parameterized. A dense network model requires more memory and other computational resources during training and inference of the model. Increasingly greater amounts of data and related model sizes demand the availability of more competent learning models. Compared to dense models, sparse deep neural networks require less memory, less computing time and have better interpretability. Hence, sparse deep neural network models are desirable. On the other hand, animal brains are found to have hierarchical and sparse structures 19 . The connectivity of an animal brain becomes sparser as the size of the brain grows larger. Therefore, it is not only necessary but also natural to design sparse networks. In fact, it was pointed out in 24 that the future of deep learning relies on sparsity. Further more, over-parameterized and dense models tend to lead to overfitting and weakening the ability to generalize over unseen examples. Sparse models can improve accuracy of approximation. Sparse regularization is a popular way to learn the sparse solutions 5 38 39 42 . The readers are referred to 25 for an overview of sparse deep learning. \u4e00\u822c\u6765\u8bf4, \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5bc6\u96c6\u4e14\u8fc7\u53c2\u6570\u5316. \u5728\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d, \u5bc6\u96c6\u7f51\u7edc\u6a21\u578b\u9700\u8981\u66f4\u591a\u7684\u5185\u5b58\u548c\u5176\u4ed6\u8ba1\u7b97\u8d44\u6e90. \u8d8a\u6765\u8d8a\u591a\u7684\u6570\u636e\u548c\u76f8\u5173\u6a21\u578b\u7684\u5927\u5c0f\u8981\u6c42\u63d0\u4f9b\u66f4\u6709\u80fd\u529b\u7684\u5b66\u4e60\u6a21\u578b. \u4e0e\u5bc6\u96c6\u6a21\u578b\u76f8\u6bd4, \u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u5185\u5b58\u66f4\u5c11, \u8ba1\u7b97\u65f6\u95f4\u66f4\u77ed, \u53ef\u89e3\u91ca\u6027\u66f4\u597d\u7b49\u4f18\u70b9. \u56e0\u6b64, \u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u662f\u53ef\u53d6\u7684. \u53e6\u4e00\u65b9\u9762, \u52a8\u7269\u7684\u5927\u8111\u88ab\u53d1\u73b0\u5177\u6709\u5c42\u6b21\u548c\u7a00\u758f\u7ed3\u6784. \u52a8\u7269\u5927\u8111\u7684\u8fde\u63a5\u6027\u968f\u7740\u5927\u8111\u5c3a\u5bf8\u7684\u589e\u5927\u800c\u53d8\u5f97\u7a00\u758f. \u56e0\u6b64\u8bbe\u8ba1\u7a00\u758f\u7f51\u7edc\u4e0d\u4ec5\u662f\u5fc5\u8981\u7684, \u800c\u4e14\u662f\u81ea\u7136\u7684. \u4e8b\u5b9e\u4e0a, \u5728\u6587\u732e 24 \u4e2d\u6307\u51fa, \u6df1\u5ea6\u5b66\u4e60\u7684\u672a\u6765\u4f9d\u8d56\u4e8e\u7a00\u758f\u6027. \u6b64\u5916, \u8fc7\u53c2\u6570\u5316\u548c\u5bc6\u96c6\u6a21\u578b\u5f80\u5f80\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u524a\u5f31\u5728\u672a\u77e5\u6837\u672c\u4e0a\u6cdb\u5316\u7684\u80fd\u529b. \u7a00\u758f\u6a21\u578b\u53ef\u4ee5\u63d0\u9ad8\u903c\u8fd1\u7cbe\u5ea6. \u7a00\u758f\u6b63\u5219\u5316\u662f\u5b66\u4e60\u7a00\u758f\u89e3\u7684\u4e00\u79cd\u6d41\u884c\u65b9\u6cd5. \u8bfb\u8005\u53ef\u53c2\u8003 25 \u4ee5\u4e86\u89e3\u7a00\u758f\u6df1\u5ea6\u5b66\u4e60. Although much progress has been made in theoretical research of deep learning, it remains a challenging issue to construct an effective neural network approximation for general function spaces using as few neuron connections or neurons as possible. Most of existing network structures are specific for a particular class of functions. In this paper, we aim to propose a multi-scale sparse regularized neural network to approximate the function effectively. A neural network with multiple hidden layers can be viewed as a multi-scale transformation from simple features to complex features. The layer-by-layer composite of functions can be seen as a generalization of wavelet transforms 7 12 33 . For neurons in different layers, corresponding to different transformation scales, the corresponding features have different levels of importance. Imposing different regularization parameters for different scales was proved to be an effective way to deal with multi-scale regularization problems 3 6 32 . Inspired by multi-scale analysis, we propose a sparse regularization network model by applying different sparse regularization penalties to the neuron connections in different layers. During the training process, the neural network adaptively learns matrix weights from given data. By sparse optimization, many weight connections are automatically zero. The remaining neural networks composed of non-zero weights form the sparse deep neural network that we desire. \u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u8bba\u7814\u7a76\u5df2\u7ecf\u53d6\u5f97\u4e86\u5f88\u5927\u7684\u8fdb\u5c55, \u4f46\u662f\u5982\u4f55\u5229\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u6216\u795e\u7ecf\u5143\u6765\u6784\u9020\u4e00\u4e2a\u6709\u6548\u7684\u7528\u4e8e\u4e00\u822c\u51fd\u6570\u7a7a\u95f4\u7684\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898. \u5927\u591a\u6570\u73b0\u6709\u7684\u7f51\u7edc\u7ed3\u6784\u90fd\u662f\u7279\u5b9a\u4e8e\u67d0\u4e00\u7c7b\u51fd\u6570\u7684. \u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u5c3a\u5ea6\u7a00\u758f\u6b63\u5219\u5316\u795e\u7ecf\u7f51\u7edc\u6765\u6709\u6548\u5730\u903c\u8fd1\u51fd\u6570. \u5177\u6709\u591a\u4e2a\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u770b\u4f5c\u662f\u7531\u7b80\u5355\u7279\u5f81\u5411\u590d\u6742\u7279\u5f81\u7684\u591a\u5c3a\u5ea6\u53d8\u6362. \u51fd\u6570\u7684\u9010\u5c42\u590d\u5408\u53ef\u4ee5\u770b\u4f5c\u662f\u5c0f\u6ce2\u53d8\u6362\u7684\u4e00\u79cd\u63a8\u5e7f. \u5bf9\u4e8e\u4e0d\u540c\u5c42\u7684\u795e\u7ecf\u5143, \u5bf9\u5e94\u4e8e\u4e0d\u540c\u7684\u53d8\u6362\u5c3a\u5ea6, \u76f8\u5e94\u7684\u7279\u5f81\u5177\u6709\u4e0d\u540c\u7ea7\u522b\u7684\u91cd\u8981\u6027. \u9488\u5bf9\u4e0d\u540c\u5c3a\u5ea6\u8bbe\u7f6e\u4e0d\u540c\u7684\u6b63\u5219\u5316\u53c2\u6570\u662f\u5904\u7406\u591a\u5c3a\u5ea6\u6b63\u5219\u5316\u95ee\u9898\u7684\u4e00\u79cd\u6709\u6548\u65b9\u6cd5. \u53d7\u591a\u5c3a\u5ea6\u5206\u6790\u7684\u542f\u53d1, \u6211\u4eec\u901a\u8fc7\u5bf9\u4e0d\u540c\u5c42\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u65bd\u52a0\u4e0d\u540c\u7684\u7a00\u758f\u6b63\u5219\u5316\u60e9\u7f5a, \u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u6a21\u578b. \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d, \u795e\u7ecf\u7f51\u7edc\u4ece\u7ed9\u5b9a\u7684\u6570\u636e\u4e2d\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u77e9\u9635\u6743\u91cd. \u901a\u8fc7\u7a00\u758f\u4f18\u5316, \u8bb8\u591a\u6743\u91cd\u8fde\u63a5\u81ea\u52a8\u4e3a\u96f6. \u5176\u4f59\u7531\u975e\u96f6\u6743\u91cd\u7ec4\u6210\u7684\u795e\u7ecf\u7f51\u7edc\u6784\u6210\u6211\u4eec\u6240\u9700\u8981\u7684\u7a00\u758f\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc. This paper is organized in five sections. In Section 2, we describe a multi-parameter regularization model for solving partial differential equations by using deep neural networks. We study in Section 3 the capacity of the proposed multi-parameter regularization in adaptive representing functions having certain singularities. In Section 4, we investigate numerical solutions of nonlinear partial differential equations by using the proposed SDNN model. Specifically, we consider two equations: the Burgers equation and the Schr\u00f6dinger equation since solutions of these two equations exhibit certain types of singularities. Finally, a conclusion is drawn in Section 5. \u672c\u6587\u5206\u4e3a\u4e94\u4e2a\u90e8\u5206. \u5728\u7b2c\u4e8c\u8282\u4e2d, \u6211\u4eec\u63cf\u8ff0\u4e86\u4e00\u4e2a\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u591a\u53c2\u6570\u6b63\u5219\u5316\u6a21\u578b. \u5728\u7b2c\u4e09\u8282\u4e2d, \u6211\u4eec\u7814\u7a76\u4e86\u6240\u63d0\u51fa\u7684\u591a\u53c2\u6570\u6b63\u5219\u5316\u6a21\u578b\u5728\u81ea\u9002\u5e94\u8868\u793a\u5177\u6709\u4e00\u5b9a\u5947\u6027\u7684\u51fd\u6570\u80fd\u529b. \u5728\u7b2c\u56db\u8282\u4e2d, \u6211\u4eec\u4f7f\u7528\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u89e3. \u5177\u4f53\u6765\u8bf4, \u6211\u4eec\u8003\u8651\u4e24\u4e2a\u65b9\u7a0b: Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b, \u56e0\u4e3a\u8fd9\u4e24\u4e2a\u65b9\u7a0b\u7684\u89e3\u663e\u793a\u51fa\u67d0\u79cd\u7c7b\u578b\u7684\u5947\u6027. \u5728\u7b2c\u4e94\u8282\u4e2d, \u5f97\u51fa\u6700\u540e\u7684\u7ed3\u8bba. A Sparse DNN Model for Solving Partial Differential Equations In this section, we propose a sparse DNN model for solving nonlinear partial differential equations (PDEs). \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u63d0\u51fa\u4e00\u4e2a\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7528\u4e8e\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b. We begin with describing the PDE and its boundary, initial conditions to be considered in this paper. Suppose that \\(\\Omega\\) is an open domain in \\(\\mathbb{R}^d\\) . By \\(\\Gamma\\) we denote the boundary of the domain \\(\\Omega\\) . Let \\(\\mathcal{F}\\) denote a nonlinear differential operator, \\(\\mathcal{I}\\) the initial condition operator, and \\(\\mathcal{B}\\) the boundary operator. We consider the following boundary/initial value problem of the nonlinear partial differential equation: \u9996\u5148\u4ece\u63cf\u8ff0\u672c\u6587\u8003\u8651\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u53ca\u5176\u521d\u8fb9\u503c\u6761\u4ef6\u5f00\u59cb. \u8bbe \\(\\Omega\\) \u662f \\(\\mathbb{R}^d\\) \u4e0a\u7684\u4e00\u4e2a\u5f00\u96c6. \u7528 \\(\\Gamma\\) \u8868\u793a\u5b9a\u4e49\u57df \\(\\Omega\\) \u7684\u8fb9\u754c. \u7528 \\(\\mathcal{F}\\) \u8868\u793a\u975e\u7ebf\u6027\u5fae\u5206\u7b97\u5b50, \\(\\mathcal{I}\\) \u8868\u793a\u521d\u59cb\u6761\u4ef6\u7b97\u5b50, \\(\\mathcal{B}\\) \u8868\u793a\u8fb9\u754c\u6761\u4ef6\u7b97\u5b50. \u6211\u4eec\u8003\u8651\u5982\u4e0b\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8fb9\u503c\u95ee\u9898: $$ \\begin{align} \\mathcal{F}(u(t,x)) &= 0, &x\\in\\Omega,\\ &t\\in [0,T],\\tag{1}\\ \\mathcal{I}(u(t,x)) &= 0, &x\\in\\Omega,\\ &t=0,\\tag{2}\\ \\mathcal{B}(u(t,x)) &= 0, &x\\in\\Gamma,\\ &t\\in [0,T],\\tag{3}\\ \\end{align} $$ where \\(T > 0\\) , the data \\(u\\) on \\(\\Gamma\\) and \\(t = 0\\) are given and \\(u\\) in \\(\\Omega\\) is the solution to be learned. The formulation (1) - (3) covers a broad range of problems including conservation laws, reaction-diffusion equations, and Navier-Stokes equations. \u5176\u4e2d \\(T>0\\) , \u5728 \\(\\Gamma\\) \u548c \\(t=0\\) \u5904\u7684\u6570\u636e \\(u\\) \u7ed9\u5b9a, \u5728 \\(\\Omega\\) \u4e0a\u7684 \\(u\\) \u662f\u9700\u8981\u5b66\u4e60\u7684\u89e3. \u516c\u5f0f 1-3 \u6db5\u76d6\u4e86\u5f88\u5927\u8303\u56f4\u7684\u95ee\u9898\u5982\u5b88\u6052\u5f8b, \u53cd\u5e94\u6269\u6563\u65b9\u7a0b, Navier-Stokes \u65b9\u7a0b\u7b49. For example, the one dimensional Burgers equation can be recognized as \u4f8b\u5982, \u4e00\u7ef4 Burgers \u65b9\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a \\[ \\mathcal{F}(u) := \\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} - \\frac{\\partial^2 u}{\\partial x^2}. \\] The goal of this paper is to develop a sparse DNN model for solving problem(1). We will conduct numerical study of the proposed model by applying it to two equations, the Burgers equation and the Schr\u00f6dinger equation, of practical importance. \u672c\u6587\u7684\u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6c42\u89e3\u95ee\u9898 (1) . \u6211\u4eec\u5c06\u901a\u8fc7\u628a\u6a21\u578b\u5e94\u7528\u5230\u4e24\u4e2a\u5177\u6709\u5b9e\u9645\u91cd\u8981\u6027\u7684\u65b9\u7a0b, Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b\u6765\u5bf9\u8fd9\u4e2a\u6a21\u578b\u8fdb\u884c\u6570\u503c\u7814\u7a76. Now, we present the sparse DNN model with multi-parameter regularization. We first recall the the feed forward neural network (FNN). A neural network can be viewed as a composition of functions. A FNN of depth \\(D\\) is defined to be a neural network with an input layer, \\(D - 1\\) hidden layers, and an output layer. A neural network with more than two hidden layers is usually called a deep neural network (DNN). Suppose that there are \\(d_i\\) neurons in the \\(i\\) -th hidden layer. Let \\(W_i\\in \\mathbb{R}^{d_i\\times d_{i-1}}\\) and \\(b_i\\in\\mathbb{R}^{d_i}\\) denote, respectively, the weight matrix and bias vector of the \\(i\\) -th layer. By \\(x_0:= x \\in \\mathbb{R}^{d_0}\\) we denote the input vector and by \\(x_{i-1}\\in \\mathbb{R}^{d_{i-1}}\\) we denote the output vector of the ( \\(i - 1\\) )-th layer. For the \\(i\\) -th hidden layer, we define the affine transform \\(L_i: \\mathbb{R}^{d_{i-1}}\\mapsto \\mathbb{R}^{d_i}\\) by \u73b0\u5728\u6211\u4eec\u4ecb\u7ecd\u5e26\u6709\u591a\u53d8\u91cf\u6b63\u5219\u5316\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b. \u6211\u4eec\u9996\u5148\u56de\u5fc6\u524d\u9988\u795e\u7ecf\u7f51\u7edc FNN. \u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u89c6\u4e3a\u51fd\u6570\u7684\u590d\u5408. \u4e00\u4e2a \\(D\\) \u5c42\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u662f\u6307\u5177\u6709\u4e00\u5c42\u8f93\u5165\u5c42, \\(D-1\\) \u5c42\u9690\u85cf\u5c42\u548c\u4e00\u5c42\u8f93\u51fa\u5c42\u7684\u795e\u7ecf\u7f51\u7edc. \u5177\u6709\u8d85\u8fc7\u4e24\u5c42\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u79f0\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc DNN. \u5047\u8bbe\u7b2c \\(i\\) \u5c42\u9690\u85cf\u5c42\u4e2d\u6709 \\(d_i\\) \u4e2a\u795e\u7ecf\u7f51\u7edc. \u7528 \\(W_i,b_i\\) \u5206\u522b\u8868\u793a\u7b2c \\(i\\) \u5c42\u7684\u6743\u91cd\u77e9\u9635\u548c\u504f\u5dee\u5411\u91cf. \\(x_0\\) \u8868\u793a\u8f93\u5165\u5411\u91cf, \\(x_{i-1}\\) \u8868\u793a\u7b2c \\(i-1\\) \u5c42\u7684\u8f93\u51fa\u5411\u91cf. \u5bf9\u4e8e\u7b2c \\(i\\) \u5c42\u9690\u85cf\u5c42, \u6211\u4eec\u5b9a\u4e49\u4eff\u5c04\u53d8\u6362 \\(L_i\\) \u5982\u4e0b: \\[ L_i(x_{i-1}) := W_i x_{i-1}+ b_i, i = 1,2,\\cdots,D. \\] For an activation function \\(\\sigma_i\\) , the output vector of the \\(i\\) -th hidden layer is defined as \u5bf9\u4e8e\u6fc0\u6d3b\u51fd\u6570 \\(\\sigma_i\\) , \u7b2c \\(i\\) \u5c42\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u5411\u91cf\u5b9a\u4e49\u4e3a \\[ x_i:= \\sigma_i(L_i(x_{i-1})). \\] Given nonlinear activation functions \\(\\sigma_i, i = 1, 2,\\cdots, D-1\\) , the feed forward neural network \\(N_\\Theta(x)\\) of depth \\(D\\) is defined as \u7ed9\u5b9a \\(D-1\\) \u4e2a\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570 \\(\\sigma_i\\) , \u6df1\u5ea6\u4e3a \\(D\\) \u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc \\(N_\\Theta(x)\\) \u5b9a\u4e49\u4e3a \\[ N_\\Theta(x) := L_D\\circ \\sigma_{D-1} \\circ L_{D-1}\\circ \\cdots\\circ \\sigma_1\\circ L_1(x),\\tag{4} \\] where \\(\\circ\\) denotes the composition operator and \\(\\Theta :=\\{W_i, b_i\\}^D_{i=1}\\) is the set of trainable parameters in the network. \u5176\u4e2d \\(\\circ\\) \u8868\u793a\u590d\u5408\u7b97\u5b50, \\(\\Theta\\) \u662f\u7f51\u7edc\u53ef\u8bad\u7ec3\u53c2\u6570\u96c6\u5408. We first describe the physics-informed neural network ( PINN ) model introduced in 35 for solving the partial differential equation (1) . We denote by \\(Loss_{PDE}\\) the loss of training data on the partial differential equation (1) . We choose \\(N_f\\) collocation points \\((t^i_f, x^i_f)\\) by randomly sampling in domain \\(\\Omega\\) using a sampling method such as Latin hypercube sampling 23 . We then evaluate \\(\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))\\) for \\(i = 1, 2,\\cdots N_f\\) and define \u6211\u4eec\u9996\u5148\u4ecb\u7ecd\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b (1) \u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc PINN. \u6211\u4eec\u4f7f\u7528\u67d0\u79cd\u91c7\u6837\u65b9\u6cd5\u5982\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837 (LHS) \u4ece\u5b9a\u4e49\u57df \\(\\Omega\\) \u4e2d\u968f\u673a\u91c7\u6837 \\(N_f\\) \u4e2a\u914d\u7f6e\u70b9, \u7136\u540e\u5728\u8fd9\u4e9b\u70b9\u4e0a\u8ba1\u7b97 \\(\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))\\) \u7684\u503c\u5e76\u5b9a\u4e49 \\[ Loss_{PDE}:= \\frac{1}{N_f} \\sum_{i=1}^{N_f} |\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))|^2, \\] where \\(\\mathcal{F}\\) is the operator for the partial differential equation (1) . \u5176\u4e2d \\(\\mathcal{F}\\) \u662f\u504f\u5fae\u5206\u65b9\u7a0b (1) \u7684\u7b97\u5b50. We next describe the loss function for the boundary/initial condition. We randomly sample \\(N_0\\) points \\(x^i_0\\) for the initial condition (2) , \\(N_b\\) points \\(\\{t^i_b, x^i_b\\}\\) for the boundary condition (3) . The loss function \\(Loss_0\\) related to the initial value condition is given by \u7136\u540e\u6211\u4eec\u4ecb\u7ecd\u8fb9\u754c\u6761\u4ef6/\u521d\u59cb\u6761\u4ef6\u7684\u635f\u5931\u51fd\u6570. \u6211\u4eec\u4e3a\u521d\u59cb\u6761\u4ef6\u968f\u673a\u91c7\u6837 \\(N_0\\) \u4e2a\u70b9, \u4e3a\u8fb9\u754c\u6761\u4ef6\u968f\u673a\u91c7\u6837 \\(N_b\\) \u4e2a\u70b9. \u7136\u540e\u4e0e\u521d\u503c\u6761\u4ef6\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570 \\(Loss_0\\) \u5b9a\u4e49\u5982\u4e0b \\[ Loss_0 := \\frac{1}{N_0} \\sum_{i=1}^{N_0} |\\mathcal{I}(\\mathcal{N}_\\Theta(0, x^i_0))|. \\] The loss function \\(Loss_b\\) pertaining to the boundary value is given as \u4e0e\u8fb9\u503c\u6761\u4ef6\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570 \\(Loss_b\\) \u5b9a\u4e49\u5982\u4e0b \\[ Loss_b := \\frac{1}{N_b} \\sum_{i=1}^{N_b}|\\mathcal{B}(\\mathcal{N}_\\Theta(t^i_b, x^i_b))|, x^i_b\\in \\Gamma. \\] Adding the three loss functions \\(Loss_{PDE}\\) , \\(Loss_0\\) , and \\(Loss_b\\) together gives rise to the PINN model \u5c06\u4e09\u4e2a\u635f\u5931\u51fd\u6570 \\(Loss_{PDE}\\) , \\(Loss_0\\) , \\(Loss_b\\) \u76f8\u52a0\u5c31\u5f97\u5230\u4e86 PINN \u6a21\u578b \\[ \\min_\\Theta\\bigg\\{\\frac{1}{N_f} \\sum_{i=1}^{N_f} |\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))|^2 + \\frac{1}{N_0} \\sum_{i=1}^{N_0} |\\mathcal{I}(\\mathcal{N}_\\Theta(0, x^i_0))| + \\frac{1}{N_b} \\sum_{i=1}^{N_b}|\\mathcal{B}(\\mathcal{N}_\\Theta(t^i_b, x^i_b))|\\bigg\\}\\tag{5} \\] where \\(\\Theta:=\\{W_i, b_i\\}^D_{i=1}\\) . \u5176\u4e2d \\(\\Theta:=\\{W_i, b_i\\}^D_{i=1}\\) . The neural network learned from (5) is often dense and may be over-parameterized. Moreover, training data are often contaminated with noise. When noise presents, over-parameterized models may overfit training data samples and result in bad generalization to the unseen samples. The problem of overfitting is often overcome by adding a regularization term: \u4ece\u4e0a\u8ff0\u635f\u5931\u51fd\u6570\u5b66\u4e60\u5230\u7684\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u662f\u5bc6\u96c6\u7684\u4e14\u53ef\u80fd\u8fc7\u53c2\u6570\u5316. \u6b64\u5916, \u8bad\u7ec3\u6570\u636e\u7ecf\u5e38\u88ab\u566a\u58f0\u6c61\u67d3. \u5f53\u566a\u58f0\u51fa\u73b0, \u8fc7\u53c2\u6570\u5316\u7684\u6a21\u578b\u53ef\u80fd\u5bf9\u8bad\u7ec3\u6570\u636e\u8fc7\u62df\u5408\u4ece\u800c\u5728\u672a\u77e5\u6837\u672c\u4e0a\u6cdb\u5316\u5f97\u5f88\u5dee. \u8fc7\u62df\u5408\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2a\u6b63\u5219\u5316\u9879\u6765\u514b\u670d. \\[ Loss := Loss_{PDE}+ \\beta (Loss_0 + Loss_b) + \\text{Regularization}. \\] The \\(l_1\\) - and \\(l_2\\) -norms are popular choices for regularization. Design of the regularization often makes use of prior information of the solution to be learned. It is known 4 17 42 that the \\(l_1\\) -norm can promote sparsity. Hence, the \\(l_1\\) -norm regularization not only has many advantages over the \\(l_2\\) -norm regularization, but also leads to sparse models which can be more easily interpreted. Therefore, we choose to use the \\(l_1\\) -norm as the regularizer in this study. Furthermore, we observe that DNNs have an intrinsic multiscale structure whose different layers represent different scales of information, which will be validated later by numerical studies. \\(l_1\\) \u8303\u6570\u548c \\(l_2\\) \u8303\u6570\u662f\u6b63\u5219\u5316\u7684\u5e38\u7528\u9009\u62e9. \u6b63\u5219\u5316\u7684\u8bbe\u8ba1\u901a\u5e38\u4f7f\u7528\u9700\u8981\u5b66\u4e60\u7684\u89e3\u7684\u5148\u9a8c\u4fe1\u606f. \u4ece\u5148\u524d\u7684\u5de5\u4f5c\u4e2d\u76f4\u5230 \\(l_1\\) \u8303\u6570\u53ef\u4ee5\u4fc3\u8fdb\u7a00\u758f\u6027. \u56e0\u6b64 \\(l_1\\) \u8303\u6570\u6b63\u5219\u5316\u4e0d\u4ec5\u6bd4 \\(l_2\\) \u8303\u6570\u6b63\u5219\u5316\u6709\u8bf8\u591a\u4f18\u70b9, \u8fd8\u80fd\u591f\u5bfc\u51fa\u66f4\u6613\u4e8e\u89e3\u91ca\u7684\u7a00\u758f\u6a21\u578b. \u56e0\u6b64\u6211\u4eec\u5728\u672c\u9879\u5de5\u4f5c\u4e2d\u9009\u62e9 \\(l_1\\) \u8303\u6570\u4f5c\u4e3a\u6b63\u5219\u5316\u9879. \u6b64\u5916, \u6211\u4eec\u89c2\u5bdf\u5230\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6709\u4e00\u4e2a\u5185\u5728\u591a\u5c3a\u5ea6\u7ed3\u6784, \u4e0d\u540c\u5c42\u8868\u793a\u4fe1\u606f\u7684\u4e0d\u540c\u5c3a\u5ea6, \u8fd9\u5c06\u5728\u4e4b\u540e\u7684\u6570\u503c\u7b97\u4f8b\u4e2d\u5f97\u5230\u9a8c\u8bc1. In fact, we will demonstrate in the next section that a smooth function or smooth parts of a function can be represented by a DNN with sparse weight matrices. This is because a smooth part of a function contains redundant information, which can be described very well by a few parameters, and only non-smooth parts of a function require more parameters to describe them. In other words, by properly choosing regularization, DNNs can lead to adaptive sparse representations of functions having certain singularities. With this understanding, we construct an adaptive representation of a function, especially for a function having certain singularity by adopting a sparse regularization model. Our idea for the adaptive representation is to impose different sparsity penalties for different layers. Specifically, we propose a multiscale-like sparse regularization using the \\(l_1\\) -norm of the weight matrix for each layer with a different parameter for a different layer. The regularization with multiple parameters allows us to represent a function in a multiscale-like neural network which is determined by sparse weight matrices having different sparsity at different layers. Such a regularization added to the loss function will enable us to robustly extract critical information of the solution of the PDE. \u5b9e\u9645\u4e0a, \u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u8282\u8bf4\u660e\u7684\u662f\u4e00\u4e2a\u5149\u6ed1\u51fd\u6570\u6216\u51fd\u6570\u7684\u5149\u6ed1\u90e8\u5206\u53ef\u4ee5\u7531\u5177\u6709\u7a00\u758f\u6743\u91cd\u77e9\u9635\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6765\u8868\u793a. \u8fd9\u662f\u56e0\u4e3a\u51fd\u6570\u7684\u5149\u6ed1\u90e8\u5206\u5305\u542b\u4e86\u5197\u4f59\u4fe1\u606f, \u80fd\u591f\u88ab\u5c11\u6570\u53c2\u6570\u63cf\u8ff0\u5f97\u5f88\u597d, \u5e76\u4e14\u53ea\u6709\u51fd\u6570\u5f97\u975e\u5149\u6ed1\u90e8\u5206\u9700\u8981\u66f4\u591a\u7684\u53c2\u6570\u53bb\u63cf\u8ff0\u5b83\u4eec. \u6362\u53e5\u8bdd\u8bf4, \u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u6b63\u5219\u5316, \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u5f97\u5230\u5e26\u6709\u5947\u6027\u7684\u51fd\u6570\u7684\u81ea\u9002\u5e94\u7a00\u758f\u8868\u793a. \u6839\u636e\u8fd9\u4e00\u8ba4\u77e5, \u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u7a00\u758f\u6b63\u5219\u5316\u6a21\u578b\u6765\u6784\u9020\u51fd\u6570, \u7279\u522b\u662f\u5e26\u6709\u67d0\u4e9b\u5947\u6027\u7684\u51fd\u6570\u7684\u81ea\u9002\u5e94\u8868\u793a. \u5173\u4e8e\u81ea\u9002\u5e94\u8868\u793a\u7684\u601d\u8def\u662f\u7ed9\u4e0d\u540c\u7684\u5c42\u4e16\u5bb6\u4e0d\u540c\u7684\u7a00\u758f\u5ea6\u60e9\u7f5a. \u5177\u4f53\u6765\u8bf4, \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7c7b\u591a\u5c3a\u5ea6\u7a00\u758f\u6b63\u5219\u5316, \u5bf9\u6bcf\u4e00\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684 \\(l_1\\) \u8303\u6570\u8d4b\u4e88\u4e0d\u540c\u7684\u53c2\u6570 \u591a\u53c2\u6570\u6b63\u5219\u5316\u4f7f\u5f97\u6211\u4eec\u80fd\u591f\u5728\u7c7b\u591a\u5c3a\u5ea6\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\u8868\u793a\u4e00\u4e2a\u51fd\u6570, \u8be5\u7f51\u7edc\u7531\u4e0d\u540c\u5c42\u4e0a\u5177\u6709\u4e0d\u540c\u7a00\u758f\u5ea6\u7684\u7a00\u758f\u6743\u91cd\u77e9\u9635\u51b3\u5b9a. \u5728\u635f\u5931\u51fd\u6570\u4e2d\u52a0\u5165\u8fd9\u79cd\u6b63\u5219\u5316, \u53ef\u4ee5\u6709\u6548\u5730\u63d0\u53d6\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7684\u5173\u952e\u4fe1\u606f. We now describe the proposed regularization. For layer \\(i\\) , we denote by \\(W^{k,j}_i\\) the \\((k, j)\\) -th entry of matrix \\(W_i\\) , the entry in the \\(k\\) -th row and the \\(j\\) -th column. For this reason, we adopt the \\(l_1\\) -norm of matrix \\(W_i\\) defined by following formula as our sparse regularization. \u6211\u4eec\u73b0\u5728\u63cf\u8ff0\u6240\u63d0\u51fa\u7684\u6b63\u5219\u5316. \u5bf9\u4e8e\u5c42 \\(i\\) , \u6211\u4eec\u7528 \\(W^{k,j}_i\\) \u8868\u793a\u77e9\u9635 \\(W_i\\) \u7684\u7b2c \\(k\\) \u884c\u7b2c \\(j\\) \u5217\u9879. \u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u77e9\u9635 \\(W_i\\) \u7684 \\(l_1\\) \u8303\u6570\u4f5c\u4e3a\u6211\u4eec\u7684\u7a00\u758f\u6b63\u5219\u5316. \\[ \\|W_i\\|_1:=\\sum_{k=1}^{d_i}\\sum_{j=1}^{d_{i-1}}|W^{k,j}_i| \\] Considering that different layers of the neural network play different roles in approximation of a function, we introduce here a multi-parameter regularization model \u8003\u8651\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u540c\u5c42\u5728\u903c\u8fd1\u4e00\u4e2a\u51fd\u6570\u65f6\u626e\u6f14\u4e0d\u540c\u7684\u89d2\u8272, \u6211\u4eec\u5f15\u5165\u5982\u4e0b\u591a\u53c2\u6570\u6b63\u5219\u5316\u6a21\u578b \\[ \\text{Regularization} :=\\sum_{i=1}^D \\alpha_i\\|W_i\\|_1 \\tag{6} \\] where \\(\\alpha_i\\) are nonnegative regularization parameters. \u5176\u4e2d \\(\\alpha_i\\) \u662f\u975e\u8d1f\u7684\u6b63\u5219\u5316\u53c2\u6570. The use of different parameters for weight matrices of different layers in the regularization term (6) allows us to penalize the weight matrices at different layers of the neural network differently in order to extract the multiscale representation of the solution to be learned. That is, for a fixed \\(i\\) , parameter \\(\\alpha_i\\) determines the sparsity of weight matrix \\(W_i\\) . The larger the parameter \\(\\alpha_i\\) , the more sparse the weight matrix \\(W_i\\) is. The regularized loss function takes the form \u5728\u6b63\u5219\u5316\u9879 (6) \u4e2d\u5bf9\u4e8e\u4e0d\u540c\u5c42\u7684\u6743\u91cd\u77e9\u9635\u4f7f\u7528\u4e0d\u540c\u53c2\u6570\u4f7f\u5f97\u6211\u4eec\u5bf9\u7f51\u7edc\u4e0d\u540c\u5c42\u7684\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u60e9\u7f5a\u4ee5\u63d0\u53d6\u6240\u9700\u5b66\u4e60\u7684\u89e3\u7684\u591a\u5c3a\u5ea6\u8868\u793a. \u5373\u5bf9\u4e8e\u4e00\u4e2a\u56fa\u5b9a\u7684 \\(i\\) , \u53c2\u6570 \\(\\alpha_i\\) \u51b3\u5b9a\u4e86\u6743\u91cd\u77e9\u9635 \\(W_i\\) \u7684\u7a00\u758f\u6027. \\(\\alpha_i\\) \u8d8a\u5927, \u6743\u91cd\u77e9\u9635 \\(W_i\\) \u8d8a\u7a00\u758f. \u6b63\u5219\u5316\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u5982\u4e0b: \\[ Loss := Loss_{PDE}+ \\beta(Loss_0+ Loss_b) +\\sum_{i=1}^D \\alpha_i\\|W_i\\|_1. \\tag{7} \\] The parameters \\(\\Theta:= \\{W_i, b_i\\}^D_{i=1}\\) of the neural network \\(\\mathcal{N}_\\Theta(t,x)\\) are learned by minimizing the loss function \u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta(t,x)\\) \u7684\u53c2\u6570 \\(\\Theta\\) \u901a\u8fc7\u6700\u5c0f\u5316\u5982\u4e0b\u635f\u5931\u51fd\u6570\u8fdb\u884c\u5b66\u4e60. \\[ \\min_\\Theta \\bigg\\{\\frac{1}{N_f} \\sum_{i=1}^{N_f} |\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))|^2 + \\beta(Loss_0+Loss_b) + \\sum_{i=1}^D \\alpha_i\\|W_i\\|_1\\bigg\\}.\\tag{8} \\] Truncating the weights of the layers close to the input layer has an impact on all subsequent layers. In practice, we usually set smaller regularization parameters in layers close to the input and larger regularization parameters in layers close to the output. The resulting neural network will exhibit denser weight matrices near the input layer and sparser weight matrices near the output layer. This network structure reflects the multi-scale nature of neural networks and is automatically learned by sparse regularization. \u622a\u65ad\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u9690\u85cf\u5c42\u7684\u6743\u91cd\u4f1a\u5bf9\u540e\u7eed\u5c42\u4ea7\u751f\u5f71\u54cd. \u5b9e\u8df5\u4e2d\u6211\u4eec\u901a\u5e38\u5bf9\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u9690\u85cf\u5c42\u8bbe\u7f6e\u66f4\u5c0f\u7684\u6b63\u5219\u5316\u53c2\u6570, \u5bf9\u9760\u8fd1\u8f93\u51fa\u5c42\u7684\u9690\u85cf\u5c42\u8bbe\u7f6e\u66f4\u5927\u7684\u6b63\u5219\u5316\u53c2\u6570. \u5f97\u5230\u7684\u795e\u7ecf\u7f51\u7edc\u4f1a\u8868\u73b0\u51fa\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u6743\u91cd\u77e9\u9635\u66f4\u5bc6\u96c6, \u9760\u8fd1\u8f93\u51fa\u5c42\u7684\u6743\u91cd\u77e9\u9635\u66f4\u7a00\u758f. \u8fd9\u6837\u7684\u7f51\u7edc\u7ed3\u6784\u53cd\u6620\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u5c3a\u5ea6\u672c\u8d28\u4e14\u81ea\u52a8\u5730\u7531\u7a00\u758f\u6b63\u5219\u5316\u5b66\u4e60\u5230. Appropriate choices of the regularization parameters are key to achieve good prediction results. We need to balance sparsity and prediction accuracy. Since there are multiple regularization parameters, the regularization parameters are chosen by grid search layer by layer in this paper. In practice, we first choose the regularization parameters close to the output layer, and then gradually choose the regularization coefficients close to the input layer. \u6b63\u5219\u5316\u53c2\u6570\u7684\u9002\u5f53\u9009\u62e9\u662f\u83b7\u5f97\u826f\u597d\u9884\u6d4b\u7ed3\u679c\u7684\u5173\u952e. \u6211\u4eec\u9700\u8981\u5e73\u8861\u7a00\u758f\u6027\u548c\u9884\u6d4b\u7cbe\u5ea6. \u56e0\u4e3a\u6709\u591a\u4e2a\u6b63\u5219\u5316\u53c2\u6570, \u6240\u4ee5\u672c\u6587\u7684\u6b63\u5219\u5316\u53c2\u6570\u901a\u8fc7\u9010\u5c42\u7f51\u683c\u641c\u7d22\u5f97\u5230. \u5b9e\u8df5\u4e2d\u6211\u4eec\u9996\u5148\u9009\u62e9\u9760\u8fd1\u8f93\u51fa\u5c42\u7684\u6b63\u5219\u5316\u53c2\u6570, \u7136\u540e\u9010\u6e10\u9009\u62e9\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u6b63\u5219\u5316\u7cfb\u6570. We refer equation (8) as to the sparse DNN ( SDNN ) model for the partial differential equation. Upon solving the minimization problem (8) , we obtain an approximate solution \\(u(t,x) := \\mathcal{N}_\\Theta(t, x)\\) with sparse weight matrices. When the regularization parameters \\(\\alpha_i\\) are all set to \\(0\\) , the SDNN model (8) reduces to the PINN model introduced in 35 . We will compare numerical performance of the proposed SDNN model with that of PINN model, for both the Burgers equation and the Schr\u00f6dinger equation. \u6211\u4eec\u5f15\u7528\u65b9\u7a0b (8) \u4f5c\u4e3a\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc ( SDNN ) \u6a21\u578b. \u57fa\u4e8e\u6c42\u89e3\u6700\u5c0f\u5316\u95ee\u9898 (8) , \u6211\u4eec\u83b7\u5f97\u4e86\u4e00\u4e2a\u5e26\u6709i\u5b66\u672f\u6743\u91cd\u77e9\u9635\u7684\u8fd1\u4f3c\u89e3 \\(u(t,x) := \\mathcal{N}_\\Theta(t, x)\\) . \u5f53\u6b63\u5219\u5316\u53c2\u6570 \\(\\alpha_i\\) \u5168\u90e8\u8bbe\u7f6e\u4e3a \\(0\\) , \u90a3\u4e48 SDNN \u6a21\u578b\u5c06\u9000\u5316\u4e3a PINN \u6a21\u578b. \u6211\u4eec\u5c06\u5728 Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b\u4e0a\u6bd4\u8f83\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u548c PINN \u7684\u6570\u503c\u8868\u73b0. Function Adaptive Approximation by the SDNN Model We explore in this section the capacity of the proposed multi-parameter regularization in adaptive representing functions that have certain singularities. We will first reveal that a DNN indeed has an intrinsic multiscale-like structure which is desirable for representing non-smooth functions. We demonstrate in our numerical studies that the proposed SDNN model can reconstruct neural networks which approximate functions in the same accuracy order with nearly the same order of network complexity, regardless the smoothness of the functions. We include in this section a numerical study of reconstruction of black holes by the proposed SDNN model. In this section, we use the rectified linear unit (ReLU) function as an activation function. \u672c\u8282\u6211\u4eec\u63a2\u7a76\u6240\u63d0\u51fa\u7684\u591a\u53c2\u6570\u6b63\u5219\u5316\u5728\u81ea\u9002\u5e94\u8868\u793a\u5e26\u6709\u67d0\u4e9b\u5947\u6027\u7684\u51fd\u6570\u7684\u80fd\u529b. \u6211\u4eec\u9996\u5148\u63ed\u793a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u786e\u5b9e\u5177\u6709\u5185\u5728\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784, \u8fd9\u79cd\u7ed3\u6784\u5bf9\u4e8e\u8868\u793a\u975e\u5149\u6ed1\u51fd\u6570\u662f\u53ef\u53d6\u7684. \u6570\u503c\u7814\u7a76\u8868\u660e, \u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u65e0\u8bba\u51fd\u6570\u7684\u5149\u6ed1\u5ea6\u5982\u4f55, \u90fd\u80fd\u4ee5\u8fd1\u4f3c\u76f8\u540c\u7684\u7f51\u7edc\u590d\u6742\u5ea6\u9636\u6570\u91cd\u6784\u51fa\u7cbe\u5ea6\u76f8\u540c\u7684\u51fd\u6570. \u5728\u8fd9\u4e00\u8282\u4e2d\u8fd8\u5305\u62ec\u4e00\u4e2a\u4f7f\u7528\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u91cd\u5efa\u9ed1\u6d1e\u7684\u6570\u503c\u7814\u7a76. \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u4f7f\u7528\u6574\u6d41\u7ebf\u6027\u5355\u4f4d\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570. \\[ \\text{ReLU}(x) := \\max\\{0, x\\}, x \\in \\mathbb{R} \\] We first describe the data fitting problem. Given training points \\((x_i, y_i), i =1, 2, \\cdots, N\\) , a non-regularized neural network is determined by minimizing the regression error, that is, \u6211\u4eec\u9996\u5148\u63cf\u8ff0\u6570\u636e\u62df\u5408\u95ee\u9898. \u7ed9\u5b9a\u8bad\u7ec3\u6837\u672c\u70b9 \\((x_i, y_i), i =1, 2, \\cdots, N\\) , \u975e\u6b63\u5219\u5316\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u6700\u5c0f\u5316\u5982\u4e0b\u56de\u5f52\u635f\u5931\u786e\u5b9a \\[ \\min_\\Theta\\frac{1}{N} \\sum_{i=1}^N |\\mathcal{N}_\\Theta(x_i) - y_i|^2.\\tag{9} \\] The multi-parameter sparse regularization DNN model for the data fitting problem reads \u7528\u4e8e\u6570\u636e\u62df\u5408\u95ee\u9898\u7684\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5219\u6700\u5c0f\u5316\u5982\u4e0b\u635f\u5931 \\[ \\min_\\Theta\\bigg\\{\\frac{1}{N}\\sum_{i=1}^N|\\mathcal{N}_\\Theta(x_i) - y_i|^2+\\sum_{i=1}^D \\alpha_i \\|W_i\\|_1\\bigg\\},\\tag{10} \\] where \\(\\alpha_i\\) are nonnegative regularization parameters and \\(W_i\\) are weight matrices. \u5176\u4e2d \\(\\alpha_i\\) \u662f\u975e\u8d1f\u6b63\u5219\u5316\u53c2\u6570, \\(W_i\\) \u662f\u6743\u91cd\u77e9\u9635. In examples to be presented in this section and the section that follows, the network structure is described by the number of neurons in each layer. Specifically, we use the notation \\([d_0, d_1,\\cdots,d_D]\\) to describe networks that have one input layer, \\(D - 1\\) hidden layers and one output layer, with \\(d_0, d_1,\\cdots, d_D\\) number of neurons, respectively. The regularization parameters, which will be presented as a vector \\(\\alpha:= [\\alpha_1, \\alpha_2,\\cdots, \\alpha_D]\\) , are chosen so that best results are obtained. We will use the relative \\(L_2\\) error to measure approximation accuracy. Suppose that \\(y_i\\) is the exact value of function \\(f\\) to be approximated at \\(x_i\\) , that is, \\(y_i= f(x_i)\\) , and suppose that \\(\\hat{y}_i:= \\mathcal{N}_\\Theta (x_i)\\) is the output of the neural network approximation of \\(f\\) . We let \\(y := [y_1, y_2,\\cdots, y_N]\\) and \\(\\hat{y} := [\\hat{y}_1, \\hat{y}_2,\\cdots, \\hat{y}_N]\\) , and define the error by \\(\\dfrac{\\|y-\\hat{y}\\|_2}{\\|y\\|_2}\\) . Sparsity of the weight matrices is measured by the percentage of zero entries in the weight matrices \\(W_i\\) . In our computation, we set a weight matrix entry \u5728\u672c\u8282\u548c\u4e4b\u540e\u7ae0\u8282\u5c55\u793a\u7684\u4f8b\u5b50\u4e2d, \u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u901a\u8fc7\u6bcf\u5c42\u795e\u7ecf\u5143\u7684\u6570\u91cf\u8fdb\u884c\u63cf\u8ff0. \u5177\u4f53\u7684, \u6211\u4eec\u4f7f\u7528 \\([d_0, d_1,\\cdots,d_D]\\) \u6765\u63cf\u8ff0\u5177\u6709\u4e00\u5c42\u8f93\u5165\u5c42, \\(D-1\\) \u5c42\u9690\u85cf\u5c42\u548c\u4e00\u5c42\u8f93\u51fa\u5c42, \u5bf9\u5e94\u795e\u7ecf\u5143\u6570\u91cf\u4e3a \\(d_0, d_1,\\cdots, d_D\\) \u7684\u795e\u7ecf\u7f51\u7edc. \u6b63\u5219\u5316\u53c2\u6570\u5c06\u8868\u793a\u4e3a\u4e00\u4e2a\u5411\u91cf \\(\\alpha:= [\\alpha_1, \\alpha_2,\\cdots, \\alpha_D]\\) , \u5c06\u9009\u62e9\u51fa\u80fd\u83b7\u5f97\u6700\u4f73\u7ed3\u679c\u7684\u53c2\u6570. \u6211\u4eec\u5c06\u4f7f\u7528\u76f8\u5bf9 \\(L_2\\) \u8bef\u5dee\u6765\u5ea6\u91cf\u903c\u8fd1\u7cbe\u5ea6. \u5047\u8bbe \\(y_i\\) \u662f\u88ab\u903c\u8fd1\u51fd\u6570 \\(f\\) \u5728 \\(x_i\\) \u7684\u7cbe\u786e\u503c, \u5373 \\(y_i=f(x_i)\\) , \u8bbe \\(\\hat{y}_i:= \\mathcal{N}_\\Theta (x_i)\\) \u662f\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c \\(f\\) \u7684\u8f93\u51fa. \u6211\u4eec\u8ba1\u7b97 \\(N\\) \u4e2a\u70b9\u4e0a\u7684 \\(y := [y_1, y_2,\\cdots, y_N]\\) \u4ee5\u53ca \\(\\hat{y} := [\\hat{y}_1, \\hat{y}_2,\\cdots, \\hat{y}_N]\\) , \u4ece\u800c\u5b9a\u4e49\u8bef\u5dee\u4e3a \\(\\dfrac{\\|y-\\hat{y}\\|_2}{\\|y\\|_2}\\) . \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u5219\u901a\u8fc7\u6743\u91cd\u77e9\u9635 \\(W_i\\) \u91cc\u96f6\u5143\u7d20\u7684\u767e\u5206\u6bd4\u8fdb\u884c\u5ea6\u91cf. \u5728\u6211\u4eec\u7684\u8ba1\u7b97\u4e2d, \u6211\u4eec\u8bbe\u7f6e\u4e00\u4e2a\u6743\u91cd\u77e9\u9635\u5143\u7d20\u4e3a \\[ W^{k,j}_i= 0,\\quad \\text{if}\\ |W^{k,j}_i| < \\epsilon, \\] where \\(\\epsilon\\) is small positive number. In our numerical examples, we set \\(\\epsilon := 0.001\\) by default. For all numerical examples, the non-smooth, non-convex optimization problem (10) is solved by the Adam algorithm, which is an improved version of the stochastic gradient descent algorithm proposed in 27 for training deep learning models. \u5176\u4e2d \\(\\epsilon\\) \u662f\u4e00\u4e2a\u8f83\u5c0f\u7684\u6574\u6570. \u5728\u6211\u4eec\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u9ed8\u8ba4\u8bbe\u7f6e \\(\\epsilon=0.001\\) . \u5bf9\u4e8e\u6240\u6709\u7684\u6570\u503c\u4f8b\u5b50, \u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u95ee\u9898 (10) \u901a\u8fc7\u7528\u4e8e\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u6539\u8fdb\u7248 Adam \u7b97\u6cd5\u8fdb\u884c\u6c42\u89e3. Intrinsic Adaptivity of the SDNN Model We first investigate whether the SDNN model (10) can generate a network that has an intrinsic adaptive representation of a function. That is, a function generated by the model has a multiscale-like structure so that the reconstructed neural networks approximate functions in the same accuracy order with nearly the same order of network complexity, regardless the smoothness of the functions. In particular, when a function is singular a sparse network with higher layers is generated to capture the higher resolution information of the function. The complexity of the network is nearly proportional to the reciprocal of the approximation error regardless whether the function is smooth or not. In this experiment, we consider two examples: (1) one-dimensional functions and (2) two-dimensional functions. \u6211\u4eec\u9996\u5148\u7814\u7a76 SDNN \u6a21\u578b (10) \u662f\u5426\u80fd\u591f\u751f\u6210\u5177\u6709\u51fd\u6570\u5185\u5728\u81ea\u9002\u5e94\u8868\u793a\u7684\u7f51\u7edc. \u7531\u8be5\u6a21\u578b\u751f\u6210\u7684\u51fd\u6570\u5177\u6709\u591a\u5c3a\u5ea6\u7ed3\u6784, \u4f7f\u5f97\u91cd\u6784\u540e\u7684\u795e\u7ecf\u7f51\u7edc\u65e0\u8bba\u51fd\u6570\u7684\u5149\u6ed1\u5ea6\u5982\u4f55, \u90fd\u80fd\u4ee5\u76f8\u540c\u7684\u7cbe\u5ea6\u9636\u903c\u8fd1\u51fd\u6570, \u800c\u7f51\u7edc\u7684\u590d\u6742\u5ea6\u9636\u51e0\u4e4e\u76f8\u540c. \u7279\u522b\u5730, \u5f53\u4e00\u4e2a\u51fd\u6570\u662f\u5947\u5f02\u7684, \u4f1a\u4ea7\u751f\u4e00\u4e2a\u5177\u6709\u66f4\u591a\u5c42\u7684\u7a00\u758f\u7f51\u7edc\u6765\u6355\u83b7\u8be5\u51fd\u6570\u7684\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u4fe1\u606f. \u4e0d\u7ba1\u51fd\u6570\u662f\u5426\u5149\u6ed1, \u7f51\u7edc\u590d\u6742\u5ea6\u51e0\u4e4e\u4e0e\u903c\u8fd1\u8bef\u5dee\u7684\u5012\u6570\u6210\u6b63\u6bd4. \u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8003\u8651\u4e24\u4e2a\u4f8b\u5b50: (1) \u4e00\u7ef4\u51fd\u6570 (2) \u4e8c\u7ef4\u51fd\u6570. In our first example, we consider approximation of the quadratic function \u5728\u7b2c\u4e00\u4e2a\u4f8b\u5b50\u4e2d, \u6211\u4eec\u4f7f\u7528 SDNN \u5bf9\u4e8c\u6b21\u51fd\u6570\u548c\u4e8c\u6b21\u5206\u6bb5\u51fd\u6570\u8fdb\u884c\u8fd1\u4f3c. \\[ f(x) := x^2, \\tag{11} \\] and the piecewise quadratic function by SDNN . \\[ f(x) = \\begin{cases} x^2 + 1, &x \\geq 0,\\\\ x^2, &x < 0, \\end{cases}\\tag{12} \\] Note that the function defined by (11) is smooth and the function by (12) has a jump discontinuity at the point \\(0\\) . We applied the sparse regularized network having the architecture \\([1, 10, 10, 10, 10, 1]\\) to learn these functions. We divide the interval \\([-2, 2]\\) by the nodes \\(x_j:= -2 + jh\\) , for \\(j := 0, 1,\\cdots, 200\\) , with \\(h := 1/50\\) , and sample the functions \\(f\\) at \\(x_j\\) . The test set is \\(\\{(x_k, f(x_k))\\}\\) , where \\(x_k:= -2 + kh, h := 1/30, k = 0, 1,\\cdots, 120\\) . The network is trained by the Adam algorithm with epochs \\(20,000\\) and initial learning rate \\(0.001\\) . For function (11) , regularization parameters are set to be \\([0, 10^{-4}, 10^{-4}, 10^{-3},10^{-3}]\\) . We obtain the prediction error \\(5.94\\times10^{-3}\\) for the test set. Sparsity of the resulting weight matrices is \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) and the number of nonzero weight matrix entries is \\(31\\) . Left of Figure 1 shows the reconstructed SDNN for the function defined by (11) . \u6ce8\u610f\u7531 (11) \u5b9a\u4e49\u7684\u51fd\u6570\u662f\u5149\u6ed1\u7684, (12) \u5b9a\u4e49\u7684\u51fd\u6570\u5728\u70b9 \\(0\\) \u5904\u662f\u8df3\u8dc3\u95f4\u65ad\u7684. \u6211\u4eec\u4f7f\u7528\u7f51\u7edc\u67b6\u6784\u4e3a \\([1, 10, 10, 10, 10, 1]\\) \u7684\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u6765\u5b66\u4e60\u8fd9\u4e9b\u51fd\u6570. \u6211\u4eec\u5c06\u533a\u95f4 \\([-2,2]\\) \u8fdb\u884c\u4e24\u767e\u7b49\u5206, \u5e76\u5728\u8fd9\u4e9b\u70b9\u4e0a\u91c7\u6837 \\(f\\) . \u6d4b\u8bd5\u96c6\u5219\u662f\u5c06\u533a\u95f4\u4e00\u767e\u4e8c\u5341\u7b49\u5206. \u7f51\u7edc\u901a\u8fc7 Adam \u7b97\u6cd5\u8bad\u7ec3 \\(20,000\\) \u4e2a epochs, \u521d\u59cb\u5b66\u4e60\u7387\u4e3a \\(0.001\\) . \u5bf9\u4e8e\u51fd\u6570 (11) , \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([0, 10^{-4}, 10^{-4}, 10^{-3},10^{-3}]\\) . \u6211\u4eec\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u4e86 \\(5.94\\times10^{-3}\\) \u7684\u9884\u6d4b\u8bef\u5dee. \u5f97\u5230\u7684\u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) , \u6743\u91cd\u77e9\u9635\u5143\u7d20\u975e\u96f6\u6570\u91cf\u4e3a \\(31\\) . \u56fe 1 \u7684\u5de6\u56fe\u5c55\u793a\u4e86\u903c\u8fd1\u51fd\u6570 (11) \u7684 SDNN \u7684\u91cd\u6784\u7ed3\u679c. For function (12) the regularization parameters are chosen as \\([10^{-5}, 10^{-4}, 10^{-4},10^{-4}, 10^{-3}]\\) . We obtain the prediction error \\(5.42\\times10^{-3}\\) for the test set. Sparsity of the resulting weight matrices is \\([50\\%, 93.0\\%, 88.0\\%, 93.0\\%, 90.0\\%]\\) and the number of nonzero weight matrix entries is 32. The reconstructed function is shown in Right of Figure 1 . \u5bf9\u4e8e\u51fd\u6570 (12) , \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([10^{-5}, 10^{-4}, 10^{-4},10^{-4}, 10^{-3}]\\) . \u6211\u4eec\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u4e86 \\(5.42\\times10^{-3}\\) \u7684\u9884\u6d4b\u8bef\u5dee. \u5f97\u5230\u7684\u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) , \u6743\u91cd\u77e9\u9635\u5143\u7d20\u975e\u96f6\u6570\u91cf\u4e3a \\(32\\) . \u56fe 1 \u7684\u53f3\u56fe\u5c55\u793a\u4e86\u903c\u8fd1\u51fd\u6570 (12) \u7684 SDNN \u7684\u91cd\u6784\u7ed3\u679c. Figure 1 : Numerical results of SDNN : for function (11) (Left); for function (12) (Right) Numerical results for both functions (11) and (12) are summarized in Table 1 . These results demonstrate that even though the function (12) has a jump discontinuity at the point \\(0\\) , the proposed SDNN model can generate a network with nearly the same number of nonzero weight matrix entries and with the same accuracy as those for the smooth function (11) . This shows that the proposed SDNN model has a good adaptive approximation property. \u8868\u683c 1 \u603b\u7ed3\u4e86 (11) \u548c (12) \u7684\u6570\u503c\u7ed3\u679c. \u8fd9\u4e9b\u7ed3\u679c\u8bf4\u660e\u4e86\u5c3d\u7ba1\u51fd\u6570 (12) \u5728 \\(0\\) \u5904\u8df3\u8dc3\u95f4\u65ad, \u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u80fd\u591f\u751f\u6210\u548c\u903c\u8fd1\u5149\u6ed1\u51fd\u6570 (11) \u65f6\u975e\u96f6\u6743\u91cd\u77e9\u9635\u5143\u7d20\u6570\u91cf\u51e0\u4e4e\u76f8\u540c\u4e14\u7cbe\u5ea6\u76f8\u540c\u7684\u7f51\u7edc. \u8fd9\u8bf4\u660e\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u6709\u826f\u597d\u7684\u81ea\u9002\u5e94\u903c\u8fd1\u6027\u8d28. Results for function (11) (12) Regularization parameters \\([0, 10^{-4}, 10^{-4}, 10^{-3}, 10^{-3}]\\) \\([10^{-5}, 10^{-4}, 10^{-4}, 10^{-4}, 10^{-3}]\\) Relative \\(L_2\\) error \\(5.94\\times10^{-3}\\) \\(5.42\\times10^{-3}\\) Sparsity of weight matrices \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) \\([50\\%, 93.0\\%, 88.0\\%, 93.0\\%, 90.0\\%]\\) No. of nonzero entries 31 32 Table 1 : Numerical result for quadratic function (11) and piecewise quadratic function (12) with network structure \\([1, 10, 10, 10, 10, 1]\\) . In our second example, we consider approximation of two-dimensional functions, once again one smooth function and one discontinuous function. We study smooth function \u5728\u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8003\u8651\u4e8c\u7ef4\u51fd\u6570, \u540c\u6837\u662f\u4e00\u4e2a\u5149\u6ed1\u51fd\u6570, \u4e00\u4e2a\u662f\u4e0d\u8fde\u7eed\u51fd\u6570. \u5149\u6ed1\u51fd\u6570\u7684\u56fe\u50cf\u5728\u56fe 2 \u5de6\u56fe\u5c55\u793a, \u5206\u6bb5\u51fd\u6570\u7684\u56fe\u50cf\u5728\u56fe 3 \u5de6\u56fe\u5c55\u793a. \\[ g(x, y) := e^{2x+y^2},\\tag{13} \\] whose image is illustrated in Figure 2 (Left), and piecewise function \\[ g_d(x, y) = \\begin{cases} e^{2x+y^2} + 1, &x \\geq 0,\\\\ e^{2x+y^2}, &x < 0,\\\\ \\end{cases}\\tag{14} \\] whose image is illustrated in Figure 3 (Left). Note that function (13) is smooth and function (14) has a jump discontinuity along \\(x = 0\\) . \u6ce8\u610f\u51fd\u6570 (13) \u662f\u5149\u6ed1\u7684, \u51fd\u6570 (14) \u6cbf\u7740 \\(x=0\\) \u6709\u8df3\u8dc3\u95f4\u65ad. For these two functions, the training data set is composed of grid points \\([-1, 1]\\times[-1, 1]\\) uniformly discretized with step size \\(1/200\\) on \\(x\\) and \\(y\\) direction, and the test set is composed of grid points \\([-1, 1]\\times[-1, 1]\\) uniformly discretized with step size \\(1/300\\) on the \\(x\\) and \\(y\\) directions. The network has \\(2\\) inputs, \\(4\\) hidden layers, and \\(1\\) output, with the architecture \\([2, 20, 20, 20, 20, 1]\\) . For each hidden layer, there are \\(20\\) neurons. The initial learning rate for Adam is set to \\(0.001\\) . The batch size is equal to \\(1024\\) . \u5bf9\u4e8e\u8fd9\u4e24\u4e2a\u51fd\u6570, \u8bad\u7ec3\u6570\u636e\u7531\u5bf9\u5b9a\u4e49\u57df \\([-1, 1]\\times[-1, 1]\\) \u5728 \\(x\\) \\(y\\) \u4e24\u4e2a\u65b9\u5411\u6b65\u957f\u4e3a \\(1/200\\) \u5f97\u5230\u7684\u7f51\u683c\u70b9\u7ec4\u6210, \u6d4b\u8bd5\u96c6\u5219\u8fdb\u884c\u4e09\u767e\u7b49\u5206. \u7f51\u7edc\u6709\u4e24\u4e2a\u8f93\u5165, \u56db\u5c42\u9690\u85cf\u5c42\u548c\u4e00\u4e2a\u8f93\u51fa, \u7f51\u7edc\u7ed3\u6784\u4e3a \\([2, 20, 20, 20, 20, 1]\\) . \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u9690\u85cf\u5c42, \u90fd\u6709\u4e8c\u5341\u4e2a\u795e\u7ecf\u5143. Adam \u521d\u59cb\u5b66\u4e60\u7387\u4e3a 0.001. \u6279\u91cf\u5927\u5c0f\u53d6 1024. For function (13) we set the sparse regularization parameters as \\([0, 10^{-6}, 10^{-4},10^{-4}, 10^{-4}]\\) . After \\(10,000\\) epochs training, the sparsity of weight matrices is \\([0.0\\%, 68.5\\%, 95.75\\%, 97.75\\%, 80.0\\%]\\) and the number of nonzero weight matrix entries is \\(178\\) . The prediction error for the test set is \\(4.38\\times10^{-3}\\) . For function (14) , the regularization parameters are set to be \\([10^{-4}, 10^{-5}, 10^{-5}, 10^{-4}, 10^{-4}]\\) . The sparsity of weight matrices after regularization are \\([60.0\\%, 71.75\\%, 81.75\\%, 97.5\\%, 90.0\\%]\\) and the number of nonzero weight matrix entries is \\(206\\) . The prediction error for sparse regularized deep neural network is \\(4.27\\times10^{-3}\\) , which is even slightly better than that for function (13) . The images of the reconstructed functions are shown respectively in Figures 2 , Figure 3 (Right). Numerical results for this example are reported in Table 2 . \u5bf9\u4e8e\u51fd\u6570 (13) , \u6211\u4eec\u8bbe\u7f6e\u7a00\u758f\u6b63\u5219\u5316\u53c2\u6570\u4e3a \\([0, 10^{-6}, 10^{-4},10^{-4}, 10^{-4}]\\) . \u5728 \\(10,000\\) \u4e2a epochs \u8bad\u7ec3\u540e, \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([0.0\\%, 68.5\\%, 95.75\\%, 97.75\\%, 80.0\\%]\\) \u4e14\u975e\u96f6\u6743\u91cd\u77e9\u9635\u5143\u7d20\u6570\u91cf\u4e3a \\(178\\) . \u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(4.38\\times10^{-3}\\) . \u5bf9\u4e8e\u51fd\u6570 (14) , \u6211\u4eec\u8bbe\u7f6e\u7a00\u758f\u6b63\u5219\u5316\u53c2\u6570\u4e3a \\([10^{-4}, 10^{-5}, 10^{-5}, 10^{-4}, 10^{-4}]\\) . \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([60.0\\%, 71.75\\%, 81.75\\%, 97.5\\%, 90.0\\%]\\) \u4e14\u975e\u96f6\u6743\u91cd\u77e9\u9635\u5143\u7d20\u6570\u91cf\u4e3a \\(206\\) . \u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(4.27\\times10^{-3}\\) , \u751a\u81f3\u6bd4\u51fd\u6570 (13) \u7684\u7ed3\u679c\u8fd8\u7a0d\u5fae\u597d\u4e00\u70b9. \u91cd\u6784\u7684\u51fd\u6570\u56fe\u50cf\u5206\u522b\u5728\u56fe 2 \u53f3\u56fe\u548c\u56fe 3 \u53f3\u56fe\u5c55\u793a. \u8868\u683c 2 \u62a5\u544a\u4e86\u8fd9\u4e2a\u4f8b\u5b50\u7684\u6570\u503c\u7ed3\u679c. Figure 2 : Left: image of function \\(e^{2x+y^2}\\) . Right: predicted by fully connected neural network. Figure 3 : image of piecewise discontinuous function (14) . Right: predicted by sparse regularized neural network. Results for function (13) (14) Regularization parameters \\([0, 10^{-6}, 10^{-4}, 10^{-4}, 10^{-4}]\\) \\([10^{-4}, 10^{-5}, 10^{-5}, 10^{-4}, 10^{-4}]\\) Relative \\(L_2\\) error \\(4.38\\times10^{-3}\\) \\(4.27\\times10^{-3}\\) Sparsity of weight matrices \\([0.0\\%, 68.5\\%, 95.75\\%, 97.75\\%, 80.0\\%]\\) \\([60.0\\%, 71.75\\%, 81.75\\%, 97.5\\%, 90.0\\%]\\) No. of nonzero entries 178 206 Table 2 : Numerical result for two dimensional function (13) and (14) with network structure \\([2,20, 20, 20, 20, 1]\\) . The numerical results presented in this subsection indicate that indeed the proposed SDNN model has an excellent adaptivity property in the sense that it generates networks with nearly the same number of nonzero weight matrix entries and the same order of approximation accuracy for functions regardless their smoothness. \u8fd9\u4e00\u5c0f\u8282\u5c55\u793a\u7684\u6570\u503c\u7ed3\u679c\u6307\u51fa\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u786e\u5b9e\u6709\u4f18\u79c0\u7684\u81ea\u9002\u5e94\u6027\u8d28, \u5373\u4e0d\u7ba1\u51fd\u6570\u5149\u6ed1\u6027\u5982\u4f55, \u6a21\u578b\u751f\u6210\u7684\u7f51\u7edc\u5177\u6709\u51e0\u4e4e\u76f8\u540c\u7684\u6743\u91cd\u533a\u95f4\u975e\u96f6\u8881\u672f\u6570\u91cf\u548c\u76f8\u540c\u8fd1\u4f3c\u7cbe\u5ea6\u7684\u9636\u6570. An Example of Adaptive Function Approximation by the SDNN Model The second experiment is designed to test the sparsity of the network learned from the SDNN model (10) and the model\u2019s generalization ability. Specifically, in this example, we demonstrate that the sparse model (10) leads to a sparse DNN with higher accuracy in comparison to the standard DNN model (9) . We consider the absolute value function \u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u65e8\u5728\u6d4b\u8bd5\u4ece SDNN \u6a21\u578b\u5b66\u4e60\u5230\u7684\u7f51\u7edc\u7684\u7a00\u758f\u6027\u548c\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b. \u5177\u4f53\u5730, \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\u6211\u4eec\u8bc1\u660e\u4e86\u7a00\u758f\u6a21\u578b\u80fd\u591f\u5bfc\u51fa\u76f8\u6bd4\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u9ad8\u7cbe\u5ea6\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc. \u6211\u4eec\u8003\u8651\u7edd\u5bf9\u503c\u51fd\u6570 \\[ y = f(x) := |x|, \\text{for} x \\in \\mathbb{R}. \\] Note that function \\(f\\) is not differentiable at \\(x = 0\\) . \u6ce8\u610f\u51fd\u6570 \\(f\\) \u5728 \\(x=0\\) \u5904\u4e0d\u53ef\u5fae. We adopt the same network architecture, that is, \\(1\\) input layer, \\(2\\) hidden layers, \\(1\\) output layer and each hidden layer containing \\(5\\) neurons, for both the standard DNN model (9) and the SDNN model (10) . The training set is composed of equal-distance grid points laying in \\([-2, 2]\\) with step size \\(0.01\\) . The test set is composed of equal-distance grid points in \\([-5, 5]\\) with step size \\(0.1\\) . For the sparse regularized network, the regularization parameters are set as \\([10^{-4}, 10^{-3}, 10^{-3}]\\) . For both the standard DNN model and the SDNN model, the number of epoch equals \\(10,000\\) . The initial learning rate is set to \\(0.001\\) . \u6211\u4eec\u5bf9\u4e8e\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b (9) \u548c SDNN \u6a21\u578b (10) \u91c7\u7528\u76f8\u540c\u7684\u7f51\u7edc\u67b6\u6784, \u5373\u4e00\u5c42\u8f93\u5165\u5c42, \\(2\\) \u5c42\u9690\u85cf\u5c42, \\(1\\) \u5c42\u8f93\u51fa\u5c42, \u6bcf\u5c42\u9690\u85cf\u5c42\u6709 \\(5\\) \u4e2a\u795e\u7ecf\u5143. \u8bad\u7ec3\u96c6\u7531\u5728\u533a\u95f4 \\([-2,2]\\) \u4e0a\u8bbe\u7f6e\u6b65\u957f\u4e3a \\(0.01\\) \u7684\u7b49\u8ddd\u683c\u70b9\u7ec4\u6210. \u6d4b\u8bd5\u96c6\u7531\u5728\u533a\u95f4 \\([-5,5]\\) \u4e0a\u8bbe\u7f6e\u6b65\u957f\u4e3a \\(0.1\\) \u7684\u7b49\u8ddd\u683c\u70b9\u7ec4\u6210. \u5bf9\u4e8e\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc, \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([10^{-4}, 10^{-3}, 10^{-3}]\\) . \u5bf9\u4e8e\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u548c SDNN \u6a21\u578b, epochs \u7684\u6570\u91cf\u5747\u4e3a \\(10,000\\) . \u521d\u59cb\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a \\(0.001\\) . We present numerical results of this experiment in Table 3 , where we compare errors and sparsity of the functions learned from the two models. Clearly, the network learned from the standard DNN model is non-sparse: all entries of its weight matrices are nonzero. While the network learned from the SDNN model has a good sparsity property: There are only \\(1\\) non-zero entries in \\(W_3\\) and \\(2\\) non-zero entries in \\(W_2\\) in the network learned from the SDNN model. Note that the absolution value function is the linear composition of two ReLU functions, that is \\(|x| = \\text{ReLU}(x)+\\text{ReLU}(-x)\\) . The SDNN model is able to find a linear combination of the two functions to represent the function \\(f(x) := |x|\\) but the standard DNN model fails to do so. \u6211\u4eec\u5728\u8868\u683c 3 \u4e2d\u5c55\u793a\u4e86\u8fd9\u4e00\u5b9e\u9a8c\u7684\u6570\u503c\u7ed3\u679c, \u5176\u4e2d\u6211\u4eec\u5bf9\u6bd4\u4e86\u4ece\u4e24\u4e2a\u6a21\u578b\u5b66\u4e60\u5230\u7684\u51fd\u6570\u7684\u8bef\u5dee\u548c\u7a00\u758f\u5ea6. \u5f88\u660e\u663e, \u4ece\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\u5b66\u4e60\u5f97\u7f51\u7edc\u662f\u975e\u7a00\u758f\u7684: \u6743\u91cd\u77e9\u9635\u7684\u6240\u6709\u5143\u7d20\u90fd\u4e0d\u4e3a\u96f6. \u800c\u4ece SDNN \u6a21\u578b\u4e2d\u5b66\u4e60\u7684\u7f51\u7edc\u7531\u826f\u597d\u7684\u7a00\u758f\u6027\u8d28: \\(W_3\\) \u4e2d\u53ea\u6709\u4e00\u4e2a\u975e\u96f6\u5143\u7d20, \\(W_2\\) \u4e2d\u53ea\u6709\u4e24\u4e2a\u975e\u96f6\u5143\u7d20. \u6ce8\u610f\u7edd\u5bf9\u503c\u51fd\u6570\u662f\u4e24\u4e2a\u6574\u6d41\u7ebf\u6027\u5355\u5143\u7684\u7ebf\u6027\u7ec4\u5408, \u5373 \\(|x| = \\text{ReLU}(x)+\\text{ReLU}(-x)\\) . SDNN \u6a21\u578b\u80fd\u591f\u627e\u5230\u4e24\u4e2a\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u6765\u8868\u793a\u7edd\u5bf9\u503c\u51fd\u6570, \u800c\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5219\u4e0d\u884c. Model Relative \\(L_2\\) error Sparsity of weight matrices \\([W_1, W_2, W_3]\\) Standard DNN model \\(5.58\\times10^{-2}\\) \\([0\\%, 0\\%, 0\\%]\\) SDNN model \\(1.87\\times10^{-3}\\) \\([20\\%, 92\\%, 80\\%]\\) Table 3 : Approximation of the absolute value function by a SDNN with regularization parameters \\([10^{-4}, 10^{-3}, 10^{-3}]\\) . We plot the graphs of the reconstructed functions by the standard DNN model (9) and the SDNN model (10) in Figure 4 and Figure 5 , respectively. It can be seen from Figure 4 that the function reconstructed by the standard DNN model (9) has large errors in the interval \\([3, 5]\\) . Figure 5 shows that the function reconstructed by the SDNN model (10) almost coincides with the original function. This example indicates that the SDNN model (10) has better generalization ability than the standard DNN model (9) . \u6211\u4eec\u5206\u522b\u5728\u56fe 4 \u548c\u56fe 5 \u4e2d\u7ed8\u5236\u4e86\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u548c SDNN \u6a21\u578b\u7684\u91cd\u6784\u51fd\u6570. \u53ef\u4ee5\u4ece\u56fe 4 \u4e2d\u770b\u5230\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u91cd\u6784\u51fd\u6570\u5728\u533a\u95f4 \\([3,5]\\) \u4e0a\u6709\u8f83\u5927\u8bef\u5dee. \u56fe 5 \u5219\u5c55\u793a\u4e86 SDNN \u6a21\u578b\u548c\u539f\u59cb\u51fd\u6570\u57fa\u672c\u76f8\u7b26. \u8fd9\u4e00\u4f8b\u5b50\u8bf4\u660e\u4e86 SDNN \u6a21\u578b\u6bd4\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. Figure 4 (Left) : Reconstruction of function \\(f(x) := |x|\\) by the standard DNN model (9) . Figure 5 (Right) : Reconstruction of function \\(f(x) := |x|\\) by the SDNN model (10) . Reconstruction of A Black Hole In this example, we consider reconstruction of the image of a black hole by the SDNN model. Specifically, we compare numerical results and reconstructed image quality of the SDNN model with those of the standard DNN model. We choose a color image of the black hole shown in Figure 6 (Left), which is turned into a gray image shown in Figure 6 (Right). The image has the size \\(128 \\times 128\\) and can be represented as a two-dimensional discrete function. The value of the gray image at the point \\((x_1, x_2)\\) is defined as a \\(f_{image}(x_1, x_2), x_1, x_2= 1, 2,\\cdots, 128\\) . The function clearly has singularities. \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d, \u6211\u4eec\u8003\u8651\u901a\u8fc7 SDNN \u6a21\u578b \u91cd\u6784\u9ed1\u6d1e\u56fe\u50cf. \u5177\u4f53\u5730, \u6211\u4eec\u5c06\u6bd4\u8f83 SDNN \u6a21\u578b\u548c\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u6570\u503c\u7ed3\u679c\u548c\u91cd\u6784\u56fe\u50cf\u8d28\u91cf. \u6211\u4eec\u9009\u62e9\u56fe 6 \u5de6\u56fe\u6240\u793a\u7684\u9ed1\u6d1e\u7684\u5f69\u8272\u56fe\u7247, \u8f6c\u5316\u4e3a\u56fe 6 \u53f3\u56fe\u6240\u793a\u7684\u7070\u5ea6\u56fe\u7247. \u56fe\u7247\u5927\u5c0f\u4e3a \\(128\\times 128\\) \u80fd\u591f\u8868\u793a\u4e3a\u4e8c\u7ef4\u79bb\u6563\u51fd\u6570. \u7070\u5ea6\u56fe\u5728 \\((x_1,x_2)\\) \u7684\u503c\u5b9a\u4e49\u4e3a \\(f_{image}(x_1, x_2)\\) , \u8fd9\u4e2a\u51fd\u6570\u663e\u7136\u5177\u6709\u5947\u6027. Figure 6 : Left: color image of the black hole. Right: gray image of the black hole. The network architecture that we used for the construction is \\([2, 100, 100, 100, 100, 100, 100, 1]\\) . We randomly choose \\(5,000\\) points \\((x^i_1, x^i_2, f_{image}(x^i_1, x^i_2))\\) by uniform sampling, \\(i =1, 2,\\cdots, 5,000\\) , from the image of the black hole to train both the standard neural network and the sparse regularized network. The optimizer is chosen as the Adam algorithm with batch size \\(1,024\\) . The number of epoch is \\(40,000\\) . The patience parameter of early stopping is \\(200\\) . Prediction results by the standard DNN model and by the SDNN model are shown respectively on Figure 7 (Left) and (Right). \u6211\u4eec\u4f7f\u7528\u7684\u7f51\u7edc\u67b6\u6784\u4e3a \\([2, 100, 100, 100, 100, 100, 100, 1]\\) . \u6211\u4eec\u4ece\u9ed1\u6d1e\u56fe\u50cf\u4e2d\u5747\u5300\u91c7\u6837 \\(5,000\\) \u4e2a\u6837\u672c\u70b9 \\((x^i_1, x^i_2, f_{image}(x^i_1, x^i_2))\\) \u7528\u4e8e\u8bad\u7ec3\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc. \u9009\u62e9 Adam \u7b97\u6cd5\u4f5c\u4e3a\u4f18\u5316\u5668, \u6279\u91cf\u5927\u5c0f\u4e3a \\(1024\\) . epoch \u7684\u6570\u91cf\u4e3a \\(40,000\\) . \u65e9\u505c\u6cd5\u7684\u8010\u5fc3\u53c2\u6570\u8bbe\u7f6e\u4e3a \\(200\\) , \u5373\u5141\u8bb8 \\(200\\) \u4e2a epochs \u5185\u6a21\u578b\u6027\u80fd\u6ca1\u6709\u63d0\u5347. \u56fe 7 \u7684\u5de6\u56fe\u548c\u53f3\u56fe\u5206\u522b\u5c55\u793a\u4e86\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c SDNN \u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c. Figure 7 : Images of the black hole reconstructed: by the standard DNN model (Left) and by the SDNN model (Right). Error images of the two models are presented in Figure 8 , from which it can be seen that the sparse network has a smaller reconstruction error. The prediction error of the fully connected network is \\(9.66\\times10^{-3}\\) . For the sparse regularized neural network, the regularized parameters are set to be \\([10^{-9}, 10^{-9}, 10^{-9}, 10^{-9}, 10^{-8}, 10^{-8}, 10^{-8}]\\) . The prediction error of the sparse regularized network is \\(9.28\\times10^{-3}\\) . The sparsity of the weight matrices are \\([44.0\\%, 78.3\\%, 78.4\\%, 80.3\\%, 96.5\\%, 98.2\\%, 84.0\\%]\\) . It shows that the sparse regularized network uses fewer neurons and has smaller prediction error. This indicates that by using the proposed multi-parameter sparse regularization, the deep neural network has the ability of multi-scale and adaptive learning. \u4e24\u4e2a\u6a21\u578b\u7684\u8bef\u5dee\u56fe\u50cf\u5728\u56fe 8 \u4e2d\u5c55\u793a, \u80fd\u591f\u4ece\u4e2d\u770b\u5230\u7a00\u758f\u7f51\u7edc\u5177\u6709\u66f4\u5c0f\u7684\u91cd\u6784\u8bef\u5dee. \u5168\u8fde\u63a5\u7f51\u7edc\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(9.66\\times10^{-3}\\) . \u5bf9\u4e8e\u7a00\u758f\u6b63\u5219\u5316\u795e\u7ecf\u7f51\u7edc, \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([10^{-9}, 10^{-9}, 10^{-9}, 10^{-9}, 10^{-8}, 10^{-8}, 10^{-8}]\\) . \u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(9.28\\times10^{-3}\\) . \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([44.0\\%, 78.3\\%, 78.4\\%, 80.3\\%, 96.5\\%, 98.2\\%, 84.0\\%]\\) . \u8fd9\u5c55\u793a\u4e86\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u4f7f\u7528\u4e86\u66f4\u5c11\u7684\u795e\u7ecf\u5143\u4e14\u83b7\u5f97\u4e86\u66f4\u5c0f\u7684\u9884\u6d4b\u8bef\u5dee. \u8fd9\u8bf4\u660e\u4e86\u901a\u8fc7\u4f7f\u7528\u6211\u4eec\u63d0\u51fa\u7684\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316, \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c3a\u5ea6\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7684\u80fd\u529b. Figure 8 : Reconstruction errors of the black hole: by the standard DNN model (Left) and by the SDNN model (Right). Model Relative \\(L_2\\) error Sparsity of weight matrices Standard DNN model \\(9.66\\times10^{-3}\\) \\([0\\%, 0\\%, 0\\%, 0\\%, 0\\%, 0\\%, 0\\%]\\) SDNN model \\(9.28\\times10^{-3}\\) \\([44.0\\%, 78.3\\%, 78.4\\%, 80.3\\%, 96.5\\%, 98.2\\%, 84.0\\%]\\) Table 4 : Numerical results of the black hole reconstructed by the standard DNN model vs. the SDNN model. Numerical Solutions of Partial Differential Equations We study in this section numerical performance of the proposed SDNN model for solving partial differential equations. We consider two equations: the Burgers equation and the Schr\u00f6dinger equation. For both of these two equations, we choose the hyperbolic tangent (tanh) function defined by \u672c\u8282\u6211\u4eec\u7814\u7a76\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u6027\u80fd. \u6211\u4eec\u8003\u8651\u4e24\u4e2a\u65b9\u7a0b: Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b. \\[ \\tanh(x) := \\frac{e^x-e^{-x}}{e^x+ e^{-x}}, x \\in \\mathbb{R} \\] as the activation function to build networks for our approximate solutions due to its differentiability which is required by the differential equations. \u5bf9\u8fd9\u4e24\u4e2a\u65b9\u7a0b, \u6211\u4eec\u90fd\u4f7f\u7528\u53cc\u66f2\u6b63\u5207\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\u6765\u5efa\u7acb\u7f51\u7edc\u4ee5\u8fd1\u4f3c\u89e3\u51fd\u6570. \u8fd9\u662f\u56e0\u4e3a\u5b83\u7684\u53ef\u5fae\u5206\u6027\u6b63\u662f\u5fae\u5206\u65b9\u7a0b\u6240\u8981\u6c42\u7684. The Burgers Equation The Burgers equation has attracted much attention since it is often used as simplified model for turbulence and shock waves 31 . It is well-known that the solution of this equation presents a jump discontinuity (a shock wave), even though the initial function is smooth. Burgers \u65b9\u7a0b\u7531\u4e8e\u7ecf\u5e38\u4f5c\u4e3a\u6e4d\u6d41\u548c\u6fc0\u6ce2\u7684\u7b80\u5316\u6a21\u578b\u800c\u53d7\u5230\u5f88\u591a\u5173\u6ce8. \u4f17\u6240\u5468\u77e5\u5373\u4f7f\u521d\u59cb\u51fd\u6570\u662f\u5149\u6ed1\u7684, \u8fd9\u4e2a\u65b9\u7a0b\u7684\u89e3\u4e5f\u5b58\u5728\u8df3\u8dc3\u4e0d\u8fde\u7eed\u6027 (\u6fc0\u6ce2). In this example, we consider the following one dimensional Burgers equation \u5728\u8fd9\u4e00\u4f8b\u5b50\u4e2d, \u6211\u4eec\u8003\u8651\u5982\u4e0b\u4e00\u7ef4 Burgers \u65b9\u7a0b. \\[ \\begin{align} &u_t(t, x) + u(t, x)u_x(t, x) - \\frac{0.01}{\\pi} u_{xx}(t, x) = 0, &t \\in (0, 1], x \\in (-1, 1), \\tag{15}\\\\ &u(0, x) = - \\sin(\\pi x),\\tag{16}\\\\ &u(t,-1) = u(t, 1) = 0.\\tag{17} \\end{align} \\] The analytic solution of this equation, known in 2 , will be used as our exact solution for comparison. Indeed, the analytic solution has the form \u8fd9\u4e00\u65b9\u7a0b\u7684\u89e3\u6790\u89e3\u5c06\u4f5c\u4e3a\u6211\u4eec\u7684\u7cbe\u786e\u89e3\u4ee5\u8fdb\u884c\u5bf9\u6bd4. \u89e3\u6790\u89e3\u7684\u5f62\u5f0f\u5982\u4e0b \\[ u(t, x) := -\\frac{\\int_{-\\infty}^\\infty \\sin\\pi(x-\\eta)h(x-\\eta)\\exp(-\\eta^2/4vt)\\text{d}\\eta}{\\int_{-\\infty}^\\infty h(x-\\eta)\\exp(-\\eta^2/4vt)\\text{d}\\eta}t \\in [0, 1], x \\in [-1, 1], \\] where \\(\u03bd := \\dfrac{0.01}{\\pi}\\) and \\(h(y) := \\exp(-\\cos \\pi y/2\\pi \u03bd)\\) . A neural network solution of equation (15) - (17) was obtained recently from the standard DNN model in 35 . \u4e0a\u8ff0\u65b9\u7a0b\u7684\u795e\u7ecf\u7f51\u7edc\u89e3\u662f\u4ece PINN \u8bba\u6587\u7684\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u83b7\u5f97\u7684. We apply the setting (1) - (3) with \u6211\u4eec\u5c06\u504f\u5fae\u5206\u65b9\u7a0b\u4e00\u822c\u5f62\u5f0f\u4ee3\u5165\u53ef\u77e5 \\[ \\mathcal{F}(u(t, x)) := u_t(t, x) + u(t, x)u_x(t, x) - \\frac{0.01}{\\pi} u_{xx}(t, x), t \\in (0, 1], x \\in (-1, 1). \\] Let \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) denote the training data of \\(u\\) satisfying initial condition (16) , that is, \\(u^i_0= - \\sin(\\pi x^i_0)\\) . Let \\(\\{t^i_{b_1}\\}_{i=1}^{N_{b_1}}\\) and \\(\\{t^i_{b_2}\\}_{i=1}^{N_{b_2}}\\) be the collocation points related to boundary condition (17) for \\(x = -1\\) and \\(x = 1\\) respectively. We denote by \\(\\{t^i_f, x^i_f\\}_{i=1}^{N_f}\\) the collocation points for \\(\\mathcal{F}(u(t, x))\\) in \\([0, 1]\\times(-1, 1)\\) . The sparse deep neural network \\(\\mathcal{N}_\\Theta (t, x)\\) are learned by model (8) with \u4ee4 \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) \u8868\u793a \\(u\\) \u6ee1\u8db3\u521d\u59cb\u6761\u4ef6\u7684\u8bad\u7ec3\u6570\u636e, \u5373 \\(u^i_0= - \\sin(\\pi x^i_0)\\) . \u4ee4 \\(\\{t^i_{b_1}\\}_{i=1}^{N_{b_1}}\\) \u548c \\(\\{t^i_{b_2}\\}_{i=1}^{N_{b_2}}\\) \u5206\u522b\u8868\u793a\u4e0e\u8fb9\u754c\u6761\u4ef6 \\(x=-1\\) \u548c \\(x=1\\) \u76f8\u5173\u7684\u914d\u7f6e\u70b9. \u4ee4 \\(\\{t^i_f, x^i_f\\}_{i=1}^{N_f}\\) \u8868\u793a\u6ee1\u8db3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u914d\u7f6e\u70b9. \u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta (t, x)\\) \u901a\u8fc7\u6a21\u578b (8) \u53ca\u4ee5\u4e0b\u635f\u5931\u8fdb\u884c\u5b66\u4e60. \\[ \\begin{aligned} Loss_0 &=\\frac{1}{N_0}\\sum_{i=1}^{N_0}|\\mathcal{N}_\\Theta (0, x^i_0) - u^i_0|^2,\\\\ Loss_b &=\\frac{1}{N_b}\\sum_{i=1}^{N_b}|\\mathcal{N}_\\Theta (t^i_{b_1}, -1)| +\\frac{1}{N_{b_2}}\\sum_{i=1}^{N_{b_2}}|\\mathcal{N}_\\Theta (t^i_{b_2}, 1)|. \\end{aligned} \\] In this experiment, \\(100\\) data points are randomly selected from boundary and initial data points, among which \\(N_{b_1}= 25\\) points are located on the boundary \\(x = -1\\) , \\(N_{b_2}= 23\\) points on the boundary \\(x = 1\\) , and \\(N_0= 52\\) points on the initial line \\(t = 0\\) . The distribution of random collocation points is shown in the top of Figure 9 . The number of collocation points of the partial differential equation is \\(N_f= 10,000\\) by employing the Latin hypercube sampling method. The test set is composed of grid points \\([0, 1] \\times [-1, 1]\\) uniformly discretized with step size \\(1/100\\) on the \\(t\\) direction and step size \\(2/255\\) on the \\(x\\) direction. \u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d, \u4ece\u8fb9\u754c\u548c\u521d\u59cb\u6570\u636e\u70b9\u968f\u673a\u9009\u62e9 \\(100\\) \u4e2a\u6570\u636e\u70b9: \\(N_{b_1}= 25\\) \u4e2a\u5728\u8fb9\u754c \\(x=-1\\) \u4e0a, \\(N_{b_2}=23\\) \u4e2a\u5728\u8fb9\u754c \\(x=1\\) \u4e0a, \\(N_0=52\\) \u4e2a\u5728\u521d\u59cb\u7ebf \\(t=0\\) \u4e0a. \u968f\u673a\u914d\u7f6e\u70b9\u7684\u5206\u5e03\u5c55\u793a\u5728\u56fe 9 \u7684\u9876\u90e8. \u504f\u5fae\u5206\u65b9\u7a0b\u7684\u914d\u7f6e\u70b9\u6570\u91cf\u4e3a \\(N_f=10,000\\) \u901a\u8fc7 LHS \u91c7\u6837\u65b9\u6cd5\u83b7\u5f97. \u6d4b\u8bd5\u96c6\u5219\u7531\u5b9a\u4e49\u57df \\([0, 1] \\times [-1, 1]\\) \u4e0a\u65f6\u95f4 \\(t\\) \u65b9\u5411\u6b65\u957f\u4e3a \\(0.01\\) , \\(x\\) \u65b9\u5411\u4e0a\u6b65\u957f\u4e3a \\(2/225\\) \u7684\u5747\u5300\u7f51\u683c\u70b9\u7ec4\u6210. Figure 9 : Burgers equation: Top: The training data and predicted solution \\(u(t, x)\\) for sparse deep neural network with \\([2, 50, 50, 50, 1]\\) , regularization parameter \\(\\alpha = [10^{-6}, 10^{-6}, 10^{-6}, 10^{-4}]\\) , \\(\\beta = 20\\) . Bottom: Predicted solution \\(u(t, x)\\) at time \\(t = 0.3\\) , \\(t = 0.6\\) , and \\(t = 0.8\\) . We use two different network architectures \\([2, 50, 50, 50, 1]\\) and \\([2, 50, 50, 50,50, 50, 50, 50, 1]\\) for DNNs. We choose Adam as the optimizer for both neural networks. The number of epoch is \\(30,000\\) . The initial learning rate is set to \\(0.001\\) . Numerical results of these two networks presented respectively in Table 5 and Table 6 show that the proposed SDNN model outperforms the PINN model in both weight matrix sparsity and approximation accuracy. \u6211\u4eec\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784 \\([2, 50, 50, 50, 1]\\) \u548c \\([2, 50, 50, 50,50, 50, 50, 50, 1]\\) . \u6211\u4eec\u9009\u62e9 Adam \u4f5c\u4e3a\u4f18\u5316\u5668. epochs \u7684\u6570\u91cf\u4e3a \\(30,000\\) . \u521d\u59cb\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a \\(0.001\\) . \u8fd9\u4e24\u4e2a\u7f51\u7edc\u7684\u6570\u503c\u7ed3\u679c\u5206\u522b\u5c55\u793a\u5728\u8868\u683c 5 \u548c\u8868\u683c 6 \u91cc. \u8868\u683c\u8bf4\u660e\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u5728\u6743\u91cd\u77e9\u9635\u7a00\u758f\u5ea6\u548c\u8fd1\u4f3c\u8fdb\u5ea6\u4e0a\u90fd\u6bd4 PINN \u6a21\u578b\u4f18\u8d8a. Algorithms Parameters \\(\\alpha\\) & sparsity of weight matrices Relative L2error PINN No regularization \\([0.0\\%, 0.2\\%, 0.5\\%, 0.0\\%]\\) \\(2.45\\times10^{-2}\\) SDNN ( \\(\\beta=20\\) ) \\([10^{-6}, 10^{-6}, 10^{-6}, 10^{-4}]\\) \\([13.0\\%, 61.9\\%, 71.2\\%, 62.0\\%]\\) \\(1.68\\times10^{-3}\\) Table 5 : The Burgers equation: A neural network of \\(4\\) layers, with network architecture \\([2, 50,50, 50, 1]\\) . Algorithms Parameters \\(\\alpha\\) & sparsity of weight matrices Relative L2error PINN No regularization \\([0.0\\%, 0.8\\%, 0.6\\%, 0.6\\%, 0.8\\%, 0.6\\%, 0.4\\%, 0.0\\%]\\) \\(3.39\\times10^{-3}\\) SDNN ( \\(\\beta=10\\) ) \\([0, 0, 0, 0, 10^{-7}, 10^{-1}0, 10^{-6}, 10^{-5}]\\) \\([0.0\\%, 0.7\\%, 0.8\\%, 0.7\\%, 15.6\\%, 0.5\\%, 93.8\\%, 94.0\\%]\\) \\(1.45\\times10^{-4}\\) SDNN ( \\(\\beta=10\\) ) \\([10^{-6}, 10^{-6}, 10^{-6}, 10^{-6}, 10^{-6}, 10^{-6}, 10^{-5}, 10^{-5}]\\) \\([25.0\\%, 78.6\\%, 85.3\\%, 82.8\\%, 79.5\\%, 84.0\\%, 98.6\\%, 94.0\\%]\\) \\(4.83\\times10^{-4}\\) Table 6 : The Burgers equation: Neural networks of \\(8\\) layers with network architecture \\([2, 50, 50,50, 50, 50, 50, 50, 1]\\) . The Schr\u00f6dinger Equation The Schr\u00f6dinger equation is the most essential equation of non-relativistic quantum mechanics. It plays an important role in studying nonlinear optics, Bose-Einstein condensates, protein folding and bending. It is also a model equation for studying waves propagation and soliton 36 . In this subsection, we consider a one-dimensional Schr\u00f6dinger equation with periodic boundary conditions Schr\u00f6dinger \u65b9\u7a0b\u662f\u975e\u76f8\u5bf9\u8bba\u91cf\u5b50\u529b\u5b66\u7684\u6700\u57fa\u672c\u7684\u65b9\u7a0b. \u5b83\u5728\u7814\u7a76\u975e\u7ebf\u6027\u5149\u5b66, Bose-Einstein \u51dd\u805a, \u86cb\u767d\u8d28\u6298\u53e0\u548c\u5f2f\u66f2\u65b9\u9762\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528. \u5b83\u4e5f\u662f\u7814\u7a76\u6ce2\u4f20\u64ad\u548c\u5b64\u5b50\u7684\u4e00\u4e2a\u6a21\u578b\u65b9\u7a0b. \u5728\u8fd9\u4e00\u5c0f\u8282\u4e2d, \u6211\u4eec\u8003\u8651\u5e26\u6709\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684\u4e00\u7ef4 Schr\u00f6dinger \u65b9\u7a0b. \\[ \\begin{aligned} &iu_t(t, x) + 0.5u_{xx}(t, x) + |u(t, x)|^2u(t, x) = 0, t \\in (0, \\pi/2], x \\in (-5, 5), \\\\ &u(0, x) = 2 \\text{sech}(x),\\\\ &u(t, -5) = u(t, 5), \\\\ &u_x(t, -5) = u_x(t, 5).\\tag{18} \\end{aligned} \\] Note that the solution \\(u\\) of problem (18) is a complex-valued function. The goal of this study is to test the effectiveness of the proposed SDNN model in solving complex-valued nonlinear differential equations with periodic boundary conditions, with a comparison to the standard DNN model recently developed in 35 . \u6ce8\u610f\u5230\u8fd9\u4e00\u95ee\u9898\u7684\u89e3 \\(u\\) \u662f\u4e00\u4e2a\u590d\u503c\u51fd\u6570. \u8fd9\u4e00\u7814\u7a76\u7684\u76ee\u7684\u662f\u6d4b\u8bd5\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u5728\u6c42\u89e3\u5e26\u6709\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684\u590d\u503c\u975e\u7ebf\u6027\u5fae\u5206\u65b9\u7a0b\u5f97\u5230\u6709\u6548\u6027, \u5e76\u4e0e\u57fa\u4e8e PINN \u7684\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83. Problem (18) falls into the setting (1) - (3) with \u4e0a\u8ff0\u95ee\u9898\u4ee3\u5165\u4e00\u822c\u504f\u5fae\u5206\u65b9\u7a0b\u8bbe\u7f6e\u53ef\u77e5 \\[ \\mathcal{F}(u(t, x)) := iu_t(t, x) + 0.5u_{xx}(t, x) + |u(t, x)|^2u(t, x), t \\in (0, \\pi/2], x \\in (-5, 5). \\] Let \\(\\psi\\) and \\(\\phi\\) be respectively the real part and imaginary part of the solution \\(u\\) of problem (18) . We intend to approximate the solution \\(u(t, x)\\) by a neural network \\(\\mathcal{N}_\\Theta (t, x)\\) with two inputs \\((t, x)\\) and two outputs which approximate \\(\\psi(t, x)\\) and \\(\\phi(t, x)\\) , respectively. Let \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) denote the training data to enforce the initial condition at time \\(t = 0\\) , that is, \\(u^i_0= \\text{sech}(x^i_0)\\) , \\(\\{t^i_b\\}^{N_b}_{i=1}\\) the collocation points on the boundary \\(x = -5\\) and \\(x = 5\\) to enforce the periodic boundary conditions, and \\(\\{t^i_f, x^i_f\\}^{N_f}_{i=1}\\) the collocation points in \\((0, \\pi/2]\\times (-5, 5)\\) . These collocation points were generated by the Latin hypercube sampling method. We then learn the neural network \\(\\mathcal{N}_\\Theta (t, x)\\) by model (8) with \u4ee4 \\(\\psi\\) \u548c \\(\\phi\\) \u5206\u522b\u8868\u793a\u89e3 \\(u\\) \u7684\u5b9e\u90e8\u548c\u865a\u90e8. \u6211\u4eec\u8bd5\u56fe\u7528\u5177\u6709\u4e24\u4e2a\u8f93\u5165 \\((t, x)\\) \u548c\u4e24\u4e2a\u8f93\u51fa\u5206\u522b\u8fd1\u4f3c \\(\\psi(t, x)\\) \u548c \\(\\phi(t, x)\\) \u7684\u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta (t, x)\\) \u6765\u8fd1\u4f3c\u65b9\u7a0b\u7684\u89e3 \\(u(t, x)\\) . \u4ee4 \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) \u8868\u793a\u7528\u4e8e\u6ee1\u8db3 \\(t=0\\) \u4e0a\u521d\u503c\u6761\u4ef6\u7684\u8bad\u7ec3\u6570\u636e, \u5373 \\(u^i_0= \\text{sech}(x^i_0)\\) , \\(\\{t^i_b\\}^{N_b}_{i=1}\\) \u8868\u793a\u7528\u4e8e\u6ee1\u8db3 \\(x=-5\\) \u548c \\(x=5\\) \u4e0a\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684\u914d\u7f6e\u70b9. \\(\\{t^i_f, x^i_f\\}^{N_f}_{i=1}\\) \u8868\u793a\u5728 \\((0, \\pi/2]\\times (-5, 5)\\) \u7684\u914d\u7f6e\u70b9. \u8fd9\u4e9b\u914d\u7f6e\u70b9\u901a\u8fc7 LHS \u65b9\u6cd5\u751f\u6210. \u7136\u540e\u6211\u4eec\u901a\u8fc7\u5177\u6709\u4ee5\u4e0b\u635f\u5931\u7684\u6a21\u578b (8) \u6765\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta (t, x)\\) . \\[ \\begin{aligned} Loss_0&:= \\frac{1}{N_0}\\sum_{i=1}^{N_0} |\\mathcal{N}_\\Theta(0,x^i_0)-u^i_0|^2\\\\ Loss_b&:= \\frac{1}{N_b}\\sum_{i=1}^{N_b} \\bigg(|\\mathcal{N}_\\Theta(t^i_b, -5)- \\mathcal{N}_\\Theta(t^i_b, 5)|^2+\\Big|\\frac{\\partial \\mathcal{N}_\\Theta}{\\partial x}(t^i_b, -5)-\\frac{\\partial \\mathcal{N}_\\Theta}{\\partial x}(t^i_b, 5)\\Big|^2\\bigg) \\end{aligned} \\] A reference solution of problem (18) is solved by a Fourier spectral method using the Chebfun package 18 . Specifically, we obtain the reference solution by using \\(256\\) Fourier modes for space discretization and an explicit fourth-order Runge-Kutta method (RK4) with time-step \\(\\Delta t := (\\pi/2) \\times 10^{-6}\\) for time discretization. For more details of the discretization of Schr\u00f6dinger equation (18) , the readers are referred to 35 . For both the standard network and the sparse network, we used the network architecture \\([2, 50, 50, 50, 50, 50, 50, 2]\\) . Both the networks were trained by the Adam algorithm with \\(30,000\\) epochs. The initial learning rate is set to \\(0.001\\) . The training set is composed of \\(N_0:= 50\\) data points on \\(u(0, x)\\) , \\(N_b:= 50\\) sample points for enforcing the periodic boundaries, and \\(N_f:= 20,000\\) sample points inside the solution domain of equation (18) . The test set is composed of grid points \\((0, \\pi/2] \\times [-5, 5]\\) uniformly discretized with step size \\(\\pi/400\\) on the \\(t\\) direction and step size \\(10/256\\) on the \\(x\\) direction. \u95ee\u9898 (18) \u7684\u53c2\u7167\u89e3\u662f\u901a\u8fc7 Chebfun \u5305\u7684\u5085\u7acb\u53f6\u8c31\u65b9\u6cd5\u6c42\u89e3\u7684. \u5177\u4f53\u5730, \u6211\u4eec\u901a\u8fc7\u5728\u7a7a\u95f4\u79bb\u6563\u4e0a\u4f7f\u7528 \\(256\\) \u4e2a\u5085\u7acb\u53f6\u6a21\u548c\u65f6\u95f4\u79bb\u6563\u6b65\u957f\u4e3a \\(\\Delta t := (\\pi/2) \\times 10^{-6}\\) \u7684\u663e\u5f0f\u56db\u9636\u9f99\u683c\u5e93\u5854\u65b9\u6cd5. Schr\u00f6dinger \u65b9\u7a0b\u7684\u66f4\u591a\u79bb\u6563\u7ec6\u8282\u53ef\u4ee5\u53c2\u9605 PINN \u8bba\u6587. \u5bf9\u4e8e\u6807\u51c6\u7f51\u7edc\u548c\u7a00\u758f\u7f51\u7edc, \u6211\u4eec\u4f7f\u7528\u7f51\u7edc\u67b6\u6784\u4e3a \\([2, 50, 50, 50, 50, 50, 50, 2]\\) , \u90fd\u4f7f\u7528 Adam \u7b97\u6cd5\u8bad\u7ec3 \\(30,000\\) \u4e2a epochs. \u521d\u59cb\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a \\(0.001\\) . \u8bad\u7ec3\u96c6\u7531 \\(u(0,x)\\) \u4e0a\u7684 \\(N_0=50\\) \u4e2a\u6570\u636e\u70b9, \u7528\u4e8e\u6ee1\u8db3\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684 \\(N_b=50\\) \u6837\u672c\u70b9\u548c\u65b9\u7a0b\u5b9a\u4e49\u57df\u5185\u7684 \\(N_f=20,000\\) \u4e2a\u6837\u672c\u70b9\u7ec4\u6210. \u6d4b\u8bd5\u96c6\u5219\u7531\u5b9a\u4e49\u57df \\((0, \\pi/2] \\times [-5, 5]\\) \u6cbf \\(t\\) \u65b9\u5411\u4e0a\u5747\u5300\u79bb\u6563\u6b65\u957f\u4e3a \\(\\pi/400\\) \u548c\u6cbf \\(x\\) \u65b9\u5411\u4e0a\u5747\u5300\u79bb\u6563\u6b65\u957f\u4e3a \\(10/256\\) \u7684\u7f51\u683c\u70b9\u7ec4\u6210. Numerical results for this example are listed in Table 7 . As we can see, the sparse network has a smaller prediction error than the standard network. When regularization parameters \\(\\alpha = [0, 0, 0, 0, 5\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , the relative \\(L_2\\) error is smaller than the PINN method. When regularization parameters \\(\\alpha\\) are taken as \\([9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , the sparsity of weight matrices are \\([22.0\\%,50.5\\%, 51.9\\%, 50.6\\%, 50.0\\%, 64.5\\%, 66.0\\%]\\) . In other words, after removing more than half of the neural network connections, the sparse neural network still has a slightly higher prediction accuracy. The predicted solution of the SDNN is illustrated in Figure 10 . These numerical results clearly confirm that the proposed SDNN model outperforms the standard DNN model. \u8fd9\u4e00\u4f8b\u5b50\u7684\u6570\u503c\u7ed3\u679c\u5217\u4e3e\u5728\u8868\u683c 7 \u4e2d. \u6b63\u5982\u6211\u4eec\u6240\u770b\u5230\u7684, \u7a00\u758f\u7f51\u7edc\u76f8\u6bd4\u6807\u51c6\u7f51\u7edc\u5177\u6709\u66f4\u5c0f\u7684\u9884\u6d4b\u8bef\u5dee. \u5f53\u6b63\u5219\u5316\u53c2\u6570 \\(\\alpha = [0, 0, 0, 0, 5\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , \u76f8\u5bf9 \\(L_2\\) \u8bef\u5dee\u6bd4 PINN \u7684\u8981\u5c0f. \u5f53\u6b63\u5219\u5316\u53c2\u6570\u4e3a \\([9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([22.0\\%,50.5\\%, 51.9\\%, 50.6\\%, 50.0\\%, 64.5\\%, 66.0\\%]\\) . \u6362\u53e5\u8bdd\u8bf4, \u79fb\u9664\u4e86\u795e\u7ecf\u7f51\u7edc\u8d85\u8fc7\u4e00\u534a\u7684\u8fde\u63a5\u540e, \u7a00\u758f\u795e\u7ecf\u7f51\u7edc\u4ecd\u7136\u7531\u7a0d\u5fae\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6. SDNN \u7684\u9884\u6d4b\u89e3\u5982\u56fe 10 \u6240\u793a. \u8fd9\u4e9b\u6570\u503c\u7ed3\u679c\u6e05\u6670\u5730\u8bc1\u5b9e\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u6bd4\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u8d8a. Algorithms Parameters \\(\\alpha\\) & sparsity of weight matrices Relative \\(L_2\\) error PINN No regularization \\([0.0\\%, 0.3\\%, 0.4\\%, 0.6\\%, 0.4\\%, 0.68\\%, 0.0\\%]\\) \\(1.41\\times10^{-3}\\) SDNN ( \\(\\beta = 10\\) ) \\([0, 0, 0, 0, 5\\times10^{-7}, 10^{-6}, 10^{-5}]\\) \\([0.7\\%, 0.3\\%, 0.4\\%, 50.6\\%, 38.0\\%, 74.7\\%, 77.0\\%]\\) \\(8.15\\times10^{-4}\\) SDNN ( \\(\\beta = 10\\) ) \\([9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) \\([22.0\\%, 50.5\\%, 51.9\\%, 50.6\\%, 50.0\\%, 64.5\\%, 66.0\\%]\\) \\(1.38\\times10^{-3}\\) Table 7 : The Schr\u00f6dinger equation: The neural network of \\(7\\) layers with network architecture \\([2,50, 50, 50, 50, 50, 50, 2]\\) . Figure 10 : The Schr\u00f6dinger equation: Top: The training data and predicted solution \\(|u(t, x)|\\) by SDNN with network architecture \\([2, 50, 50, 50, 50, 50, 50, 2]\\) , regularization parameters \\(\\alpha := [9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , and \\(\\beta := 10\\) . Bottom: Predicted solutions at time \\(t := 0.55\\) , \\(t := 0.79\\) , and \\(t := 1.02\\) . Conclusion A sparse network requires less memory and computing time to operate it and thus it is desirable. We have developed a sparse deep neural network model by employing a sparse regularization with multiple parameters for solving nonlinear partial differential equations. Noticing that neural networks are layer-by-layer composite structures with an intrinsic multi-scale structure, we observe that the network weights of different layers have different weights of importance. Aiming at generating a sparse network structure while maintaining approximation accuracy, we proposed to impose different regularization parameters on different layers of the neural network. We first tested the proposed sparse regularization model in approximation of singular functions, and discovered that the proposed model can not only generate an adaptive approximation of functions having singularities but also have better generalization than the standard network. We then developed a sparse deep neural network model for solving nonlinear partial differential equations whose solutions may have certain singularities. Numerical examples show that the proposed model can remove redundant network connections leading to sparse networks and has better generalization ability. Theoretical investigation will be performed in a follow-up paper. \u7a00\u758f\u7f51\u7edc\u53ea\u9700\u8981\u66f4\u5c11\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u65f6\u95f4\u6765\u64cd\u4f5c\u5b83, \u56e0\u6b64\u5b83\u662f\u53ef\u53d6\u7684. \u6211\u4eec\u91c7\u7528\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316\u65b9\u6cd5\u5efa\u7acb\u4e86\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b. \u6ce8\u610f\u5230\u795e\u7ecf\u7f51\u7edc\u662f\u5177\u6709\u5185\u5728\u591a\u5c3a\u5ea6\u7ed3\u6784\u7684\u5c42\u5c42\u590d\u5408\u7ed3\u6784, \u6211\u4eec\u89c2\u5bdf\u5230\u4e0d\u540c\u5c42\u7684\u7f51\u7edc\u6743\u91cd\u6709\u4e0d\u540c\u7684\u91cd\u8981\u6027\u6743\u91cd. \u4e3a\u4e86\u5728\u4fdd\u6301\u903c\u8fd1\u7cbe\u5ea6\u7684\u540c\u65f6\u751f\u6210\u7a00\u758f\u7f51\u7edc\u7ed3\u6784, \u6211\u4eec\u63d0\u51fa\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u540c\u5c42\u4e0a\u52a0\u5165\u4e0d\u540c\u7684\u6b63\u5219\u5316\u53c2\u6570. \u9996\u5148\u5bf9\u7a00\u758f\u6b63\u5219\u5316\u6a21\u578b\u5728\u5947\u6027\u51fd\u6570\u903c\u8fd1\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u6d4b\u8bd5, \u53d1\u73b0\u8be5\u6a21\u578b\u4e0d\u4ec5\u80fd\u81ea\u9002\u5e94\u903c\u8fd1\u5177\u6709\u5947\u6027\u7684\u51fd\u6570, \u800c\u4e14\u6bd4\u6807\u51c6\u7f51\u7edc\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u7136\u540e, \u6211\u4eec\u5efa\u7acb\u4e86\u4e00\u4e2a\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u89e3\u51b3\u89e3\u6709\u4e00\u5b9a\u7684\u5947\u6027\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b. \u6570\u503c\u7b97\u4f8b\u8868\u660e, \u8be5\u6a21\u578b\u80fd\u591f\u53bb\u9664\u5197\u4f59\u7f51\u7edc\u8fde\u63a5\u5f97\u5230\u7a00\u758f\u7f51\u7edc, \u5177\u6709\u8f83\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u7406\u8bba\u7814\u7a76\u5c06\u5728\u540e\u7eed\u8bba\u6587\u4e2d\u8fdb\u884c. References \u672a\u88ab\u5b9e\u9645\u5f15\u7528\u7684\u6587\u732e . [3] Optimal Approximation with Sparsely Connected Deep Neural Networks, [2019] [SIAM] [15] Stochastic Subgradient Method Converges On Tame Functions. [2020]. [21] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. [2011]. The Gap between Theory and Practice in Function Approximation with Deep Neural Networks. [2021] [SIAM]. \u21a9 Spectral and Finite Difference Solutions of the Burgers Equation [1986]. \u21a9 Multiparameter Regularization for Volterra Kernel Identification Via Multiscale Collocation Methods. [2009] Y. Xu . \u21a9 Robust Uncertainty Principles: Exact Signal Reconstruction from Highly Incomplete Frequency Information [2006]. \u21a9 An Introduction to Compressive Sampling. [2008]. \u21a9 Multi-Parameter Tikhonov Regularization for Linear Ill-Posed Operator Equations [2008] Y. Xu . \u21a9 Multiscale Methods for Fredholm Integral Equations. [2015] Y. Xu . \u21a9 Deep Learning Networks for Stock Market Analysis and Prediction: Methodology, Data Representations, and Case Studies. [2017]. \u21a9 Approximation by Superpositions of A Sigmoidal Function. [1989]. \u21a9 \u21a9 Robust Training and Initialization of Deep Neural Networks: An Adaptive Basis Viewpoint. [2020]. \u21a9 \u21a9 Context-Dependent Pretrained Deep Neural Networks for Large-Vocabulary Speech Recognition. [2012]. \u21a9 (\u5c0f\u6ce2\u5341\u8bb2) Ten Lectures on Wavelets, [1992]. \u21a9 Nonlinear Approximation and (Deep) ReLU Networks. [2021]. \u21a9 (BERT) BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding . [2018] [arXiv:1810.04805v1] \u21a9 Neural Network Approximation. [2021]. \u21a9 Deeply Learning Deep Inelastic Scattering Kinematics. [2021] Y. Xu , [arxiv:2108.11638v1] \u21a9 Compressive Sensing. [2006]. \u21a9 Chebfun Guide. [2014]. \u21a9 Hierarchical Models in the Brain, [2008]. \u21a9 Deep Learning . [2016] [MIT Press]. \u21a9 (DeepBSDE) Solving High-Dimensional Partial Differential Equations Using Deep Learning . [2018] [PNAS]. \u21a9 ReLU Deep Neural Networks and Linear Finite Elements. [2020]. \u21a9 Latin Hypercube Sampling and the Propagation of Uncertainty in Analyses of Complex Systems. [2003]. \u21a9 The Future of Deep Learning Will Be Sparse. [2021]. \u21a9 \u21a9 Sparsity in Deep Learning: Pruning and Growth for Efficient Inference and Training in Neural Networks . [2021]. \u21a9 \u21a9 Deep Learned Finite Elements, [2020]. \u21a9 Adam: A Method for Stochastic Optimization . [2015] [ICLR]. \u21a9 Imagenet Classification with Deep Convolutional Neural Networks. [2012]. \u21a9 Artificial Neural Networks for Solving Ordinary and Partial Differential Equations. [1998]. \u21a9 Neural-Network Methods for Boundary Value Problems with Irregular Boundaries. [2000]. \u21a9 Nonlinear Stability of An Undercompressive Shock for Complex Burgers Equation. [1995] \u21a9 Multi-Parameter Regularization Methods for High-Resolution Image Reconstruction with Displacement Errors. [2007] Y. Xu . \u21a9 Using the Matrix Refinement Equation for the Construction of Wavelets on Invariant Sets. [1994] Y. Xu . \u21a9 (DHM) Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations . [2018]. \u21a9 (PINN) Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations . [2019] [JCP]. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 Novel Soliton Solutions of the Nonlinear Schr\u00f6dinger Equation Model. [2000]. \u21a9 A Representer Theorem for Deep Neural Networks. [2019]. \u21a9 Sparse Regularization with the \\(l_0\\) -norm . [2021] Y. Xu , arXiv:2111.08244. \u21a9 Generalized Mercer Kernels and Reproducing Kernel Banach Spaces. [2019] Y. Xu . \u21a9 Convergence of Deep ReLU Networks. [2021] Y. Xu , arXiv:2107.12530. \u21a9 \u21a9 Convergence of Deep Convolutional Neural Networks. [2021] Y. Xu , arXiv:2109.13542. \u21a9 \u21a9 Reproducing Kernel Banach Spaces for Machine Learning. [2009] Y. Xu . \u21a9 \u21a9","title":"Sparse Deep Neural Network for Nonlinear Partial Differential Equations"},{"location":"Scholars/PN-2207.13266/#sparse-deep-neural-network-for-nonlinear-partial-differential-equations","text":"\u4f5c\u8005: \u8bb8\u8dc3\u751f, Zeng Taishan \u94fe\u63a5: arXiv:2207.13266v1 \u65f6\u95f4: 2022-07-27 \u6807\u7b7e: Sparse Approximation, \u6df1\u5ea6\u5b66\u4e60, \u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b, Sparse Regularization, Adaptive Approximation \u76ee\u5f55 [Toc] author{ color: red; }","title":"Sparse Deep Neural Network for Nonlinear Partial Differential Equations"},{"location":"Scholars/PN-2207.13266/#abstarct","text":"More competent learning models are demanded for data processing due to increasingly greater amounts of data available in applications. Data that we encounter often have certain embedded sparsity structures. That is, if they are represented in an appropriate basis, their energies can concentrate on a small number of basis functions. This paper is devoted to a numerical study of adaptive approximation of solutions of nonlinear partial differential equations whose solutions may have singularities, by deep neural networks (DNNs) with a sparse regularization with multiple parameters. Noting that DNNs have an intrinsic multi-scale structure which is favorable for adaptive representation of functions, by employing a penalty with multiple parameters, we develop DNNs with a multi-scale sparse regularization ( SDNN ) for effectively representing functions having certain singularities. We then apply the proposed SDNN to numerical solutions of the Burgers equation and the Schr\u00f6dinger equation. Numerical examples confirm that solutions generated by the proposed SDNN are sparse and accurate. \u7531\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u7528\u7684\u6570\u636e\u8d8a\u6765\u8d8a\u591a, \u56e0\u6b64\u9700\u8981\u66f4\u6709\u80fd\u529b\u7684\u5b66\u4e60\u6a21\u578b\u6765\u8fdb\u884c\u6570\u636e\u5904\u7406. \u6211\u4eec\u9047\u5230\u7684\u6570\u636e\u901a\u5e38\u5177\u6709\u67d0\u79cd\u5d4c\u5165\u5f0f\u7a00\u758f\u7ed3\u6784. \u4e5f\u5c31\u662f\u8bf4, \u5982\u679c\u7528\u9002\u5f53\u7684\u57fa\u51fd\u6570\u8868\u793a\u5b83\u4eec, \u5b83\u4eec\u7684\u80fd\u91cf\u5c31\u53ef\u4ee5\u96c6\u4e2d\u5728\u5c11\u91cf\u7684\u57fa\u51fd\u6570\u4e0a. \u672c\u6587\u5229\u7528\u5177\u6709\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc, \u5bf9\u89e3\u5177\u6709\u5947\u5f02\u6027\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7684\u81ea\u9002\u5e94\u903c\u8fd1\u8fdb\u884c\u4e86\u6570\u503c\u7814\u7a76. \u6ce8\u610f\u5230\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u5185\u5728\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784, \u6709\u5229\u4e8e\u51fd\u6570\u7684\u81ea\u9002\u5e94\u8868\u793a, \u901a\u8fc7\u4f7f\u7528\u591a\u53c2\u6570\u60e9\u7f5a, \u6211\u4eec\u5efa\u7acb\u4e86\u5177\u6709\u591a\u5c3a\u5ea6\u7a00\u758f\u6b63\u5219\u5316\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc (SDNN) \u6765\u6709\u6548\u5730\u8868\u793a\u5177\u6709\u67d0\u4e9b\u5947\u5f02\u6027\u7684\u51fd\u6570. \u7136\u540e\u6211\u4eec\u5c06\u6240\u63d0\u51fa\u7684 SDNN \u5e94\u7528\u4e8e\u6c42\u89e3 Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b\u7684\u6570\u503c\u89e3. \u6570\u503c\u7b97\u4f8b\u8868\u660e, \u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u751f\u6210\u7684\u89e3\u662f\u7a00\u758f\u4e14\u51c6\u786e\u7684.","title":"Abstarct"},{"location":"Scholars/PN-2207.13266/#introduction","text":"The goal of this paper is to develop a sparse regularization deep neural network model for numerical solutions of nonlinear partial differential equations whose solutions may have singularities. We will mainly focus on designing a sparse regularization model by employing multiple parameters to balance sparsity of different layers and the overall accuracy. The proposed ideas are tested in this paper numerically to confirm our intuition and more in-depth theoretical studies will be followed in a future paper. \u672c\u6587\u7684\u76ee\u7684\u662f\u5efa\u7acb\u4e00\u4e2a\u7a00\u758f\u6b63\u5219\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b, \u7528\u4e8e\u6c42\u89e3\u90a3\u4e9b\u53ef\u80fd\u5177\u6709\u5947\u5f02\u6027\u7684\u89e3\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u89e3. \u6211\u4eec\u5c06\u7740\u91cd\u4e8e\u8bbe\u8ba1\u4e00\u4e2a\u7a00\u758f\u6b63\u5219\u5316\u6a21\u578b, \u91c7\u7528\u591a\u4e2a\u53c2\u6570\u6765\u5e73\u8861\u4e0d\u540c\u5c42\u7684\u7a00\u758f\u6027\u548c\u6574\u4f53\u7cbe\u5ea6. \u4e3a\u4e86\u9a8c\u8bc1\u6211\u4eec\u7684\u76f4\u89c9, \u672c\u6587\u5bf9\u6240\u63d0\u51fa\u7684\u89c2\u70b9\u8fdb\u884c\u4e86\u6570\u503c\u5b9e\u9a8c, \u5e76\u5c06\u5728\u4eca\u540e\u7684\u8bba\u6587\u4e2d\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u7406\u8bba\u7814\u7a76. Artificial intelligence especially deep neural networks (DNN) has received great attention in many research fields. From the approximation theory point of view, a neural network is built by functional composition to approximate a continuous function with arbitrary accuracy. Deep neural networks are proven to have better approximation by practice and theory due to their relatively large number of hidden layers. Deep neural network has achieved state-of-the-art performance in a wide range of applications, including speech recognition 11 , computer vision 28 , natural language processing 14 , and finance 8 . For an overview of deep learning the readers are referred to monograph 20 . Recently, there was great interest in applying deep neural networks to the field of scientific computing, such as discovering the differential equations from observed data 34 , solving the partial differential equation (PDE) 21 29 30 35 , and problem aroused in physics 16 . Mathematical understanding of deep neural networks received much attention in the applied mathematics community. A universal approximation theory of neural network for Borel measurable function on compact domain is established in 9 . Some recent research studies the expressivity of deep neural networks for different function spaces 15 , for example, Sobolev spaces, Barron functions, and H\u00f6lder spaces. There are close connections between deep neural network and traditional approximation methods, such as splines 13 37 , compressed sensing 1 , and finite elements 22 26 . Convergence of deep neural networks and deep convolutional neural networks are studied in 40 and 41 respectively. Some work aims at understanding the training process of DNN. For instance, in paper 10 , the training process of DNN is interpreted as learning adaptive basis from data. \u4eba\u5de5\u667a\u80fd, \u7279\u522b\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5df2\u7ecf\u5728\u8bb8\u591a\u9886\u57df\u5f97\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8. \u4ece\u903c\u8fd1\u7406\u8bba\u7684\u89d2\u5ea6\u6765\u770b, \u795e\u7ecf\u7f51\u7edc\u662f\u901a\u8fc7\u51fd\u6570\u7ec4\u5408\u6765\u903c\u8fd1\u4efb\u610f\u7cbe\u5ea6\u7684\u8fde\u7eed\u51fd\u6570. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7531\u4e8e\u5176\u76f8\u5bf9\u8f83\u5927\u7684\u9690\u5c42\u6570, \u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u88ab\u8bc1\u660e\u5177\u6709\u8f83\u597d\u7684\u903c\u8fd1\u6027\u80fd. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bed\u97f3\u8bc6\u522b, \u8ba1\u7b97\u673a\u89c6\u89c9, \u81ea\u7136\u8bed\u8a00\u5904\u7406 (BERT) \u548c\u91d1\u878d\u7b49\u5e7f\u6cdb\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd. \u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u8ff0, \u8bfb\u8005\u53ef\u4ee5\u53c2\u8003\u4e13\u8457 Deep Learning . \u6700\u8fd1, \u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u5f15\u8d77\u4e86\u6781\u5927\u7684\u5174\u8da3, \u4f8b\u5982\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u53d1\u73b0\u5fae\u5206\u65b9\u7a0b, \u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b, \u4ee5\u53ca\u7269\u7406\u5b66\u4e2d\u51fa\u73b0\u7684\u76f8\u5173\u95ee\u9898. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u7406\u89e3\u5728\u5e94\u7528\u6570\u5b66\u754c\u5907\u53d7\u5173\u6ce8. \u6587\u732e 9 \u4e2d\u5efa\u7acb\u4e86\u4e00\u4e2a\u7528\u4e8e\u7d27\u81f4\u57df\u4e0a Borel \u53ef\u6d4b\u51fd\u6570\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u901a\u7528\u903c\u8fd1\u7406\u8bba. \u6700\u8fd1\u7684\u4e00\u4e9b\u5de5\u4f5c\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5bf9\u4e0d\u540c\u51fd\u6570\u7a7a\u95f4\u7684\u8868\u8fbe\u80fd\u529b, \u4f8b\u5982 Sobolev \u7a7a\u95f4, Barron \u51fd\u6570\u548c H\u00f6lder \u7a7a\u95f4. \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e0e\u4f20\u7edf\u903c\u8fd1\u65b9\u6cd5\u6709\u7740\u5bc6\u5207\u7684\u8054\u7cfb, \u4f8b\u5982\u6837\u6761\u51fd\u6570, \u538b\u7f29\u611f\u77e5\u548c\u6709\u9650\u5143. \u6587\u732e 40 \u548c 41 \u4e2d\u5206\u522b\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6536\u655b\u6027. \u4e00\u4e9b\u5de5\u4f5c\u8bd5\u56fe\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b. \u4f8b\u5982, \u6587\u732e 10 \u4e2d\u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u88ab\u89e3\u91ca\u4e3a\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u81ea\u9002\u5e94\u57fa. Traditionally, deep neural networks are dense and over-parameterized. A dense network model requires more memory and other computational resources during training and inference of the model. Increasingly greater amounts of data and related model sizes demand the availability of more competent learning models. Compared to dense models, sparse deep neural networks require less memory, less computing time and have better interpretability. Hence, sparse deep neural network models are desirable. On the other hand, animal brains are found to have hierarchical and sparse structures 19 . The connectivity of an animal brain becomes sparser as the size of the brain grows larger. Therefore, it is not only necessary but also natural to design sparse networks. In fact, it was pointed out in 24 that the future of deep learning relies on sparsity. Further more, over-parameterized and dense models tend to lead to overfitting and weakening the ability to generalize over unseen examples. Sparse models can improve accuracy of approximation. Sparse regularization is a popular way to learn the sparse solutions 5 38 39 42 . The readers are referred to 25 for an overview of sparse deep learning. \u4e00\u822c\u6765\u8bf4, \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5bc6\u96c6\u4e14\u8fc7\u53c2\u6570\u5316. \u5728\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d, \u5bc6\u96c6\u7f51\u7edc\u6a21\u578b\u9700\u8981\u66f4\u591a\u7684\u5185\u5b58\u548c\u5176\u4ed6\u8ba1\u7b97\u8d44\u6e90. \u8d8a\u6765\u8d8a\u591a\u7684\u6570\u636e\u548c\u76f8\u5173\u6a21\u578b\u7684\u5927\u5c0f\u8981\u6c42\u63d0\u4f9b\u66f4\u6709\u80fd\u529b\u7684\u5b66\u4e60\u6a21\u578b. \u4e0e\u5bc6\u96c6\u6a21\u578b\u76f8\u6bd4, \u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u5185\u5b58\u66f4\u5c11, \u8ba1\u7b97\u65f6\u95f4\u66f4\u77ed, \u53ef\u89e3\u91ca\u6027\u66f4\u597d\u7b49\u4f18\u70b9. \u56e0\u6b64, \u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u662f\u53ef\u53d6\u7684. \u53e6\u4e00\u65b9\u9762, \u52a8\u7269\u7684\u5927\u8111\u88ab\u53d1\u73b0\u5177\u6709\u5c42\u6b21\u548c\u7a00\u758f\u7ed3\u6784. \u52a8\u7269\u5927\u8111\u7684\u8fde\u63a5\u6027\u968f\u7740\u5927\u8111\u5c3a\u5bf8\u7684\u589e\u5927\u800c\u53d8\u5f97\u7a00\u758f. \u56e0\u6b64\u8bbe\u8ba1\u7a00\u758f\u7f51\u7edc\u4e0d\u4ec5\u662f\u5fc5\u8981\u7684, \u800c\u4e14\u662f\u81ea\u7136\u7684. \u4e8b\u5b9e\u4e0a, \u5728\u6587\u732e 24 \u4e2d\u6307\u51fa, \u6df1\u5ea6\u5b66\u4e60\u7684\u672a\u6765\u4f9d\u8d56\u4e8e\u7a00\u758f\u6027. \u6b64\u5916, \u8fc7\u53c2\u6570\u5316\u548c\u5bc6\u96c6\u6a21\u578b\u5f80\u5f80\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u524a\u5f31\u5728\u672a\u77e5\u6837\u672c\u4e0a\u6cdb\u5316\u7684\u80fd\u529b. \u7a00\u758f\u6a21\u578b\u53ef\u4ee5\u63d0\u9ad8\u903c\u8fd1\u7cbe\u5ea6. \u7a00\u758f\u6b63\u5219\u5316\u662f\u5b66\u4e60\u7a00\u758f\u89e3\u7684\u4e00\u79cd\u6d41\u884c\u65b9\u6cd5. \u8bfb\u8005\u53ef\u53c2\u8003 25 \u4ee5\u4e86\u89e3\u7a00\u758f\u6df1\u5ea6\u5b66\u4e60. Although much progress has been made in theoretical research of deep learning, it remains a challenging issue to construct an effective neural network approximation for general function spaces using as few neuron connections or neurons as possible. Most of existing network structures are specific for a particular class of functions. In this paper, we aim to propose a multi-scale sparse regularized neural network to approximate the function effectively. A neural network with multiple hidden layers can be viewed as a multi-scale transformation from simple features to complex features. The layer-by-layer composite of functions can be seen as a generalization of wavelet transforms 7 12 33 . For neurons in different layers, corresponding to different transformation scales, the corresponding features have different levels of importance. Imposing different regularization parameters for different scales was proved to be an effective way to deal with multi-scale regularization problems 3 6 32 . Inspired by multi-scale analysis, we propose a sparse regularization network model by applying different sparse regularization penalties to the neuron connections in different layers. During the training process, the neural network adaptively learns matrix weights from given data. By sparse optimization, many weight connections are automatically zero. The remaining neural networks composed of non-zero weights form the sparse deep neural network that we desire. \u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u8bba\u7814\u7a76\u5df2\u7ecf\u53d6\u5f97\u4e86\u5f88\u5927\u7684\u8fdb\u5c55, \u4f46\u662f\u5982\u4f55\u5229\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u6216\u795e\u7ecf\u5143\u6765\u6784\u9020\u4e00\u4e2a\u6709\u6548\u7684\u7528\u4e8e\u4e00\u822c\u51fd\u6570\u7a7a\u95f4\u7684\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898. \u5927\u591a\u6570\u73b0\u6709\u7684\u7f51\u7edc\u7ed3\u6784\u90fd\u662f\u7279\u5b9a\u4e8e\u67d0\u4e00\u7c7b\u51fd\u6570\u7684. \u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u5c3a\u5ea6\u7a00\u758f\u6b63\u5219\u5316\u795e\u7ecf\u7f51\u7edc\u6765\u6709\u6548\u5730\u903c\u8fd1\u51fd\u6570. \u5177\u6709\u591a\u4e2a\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u770b\u4f5c\u662f\u7531\u7b80\u5355\u7279\u5f81\u5411\u590d\u6742\u7279\u5f81\u7684\u591a\u5c3a\u5ea6\u53d8\u6362. \u51fd\u6570\u7684\u9010\u5c42\u590d\u5408\u53ef\u4ee5\u770b\u4f5c\u662f\u5c0f\u6ce2\u53d8\u6362\u7684\u4e00\u79cd\u63a8\u5e7f. \u5bf9\u4e8e\u4e0d\u540c\u5c42\u7684\u795e\u7ecf\u5143, \u5bf9\u5e94\u4e8e\u4e0d\u540c\u7684\u53d8\u6362\u5c3a\u5ea6, \u76f8\u5e94\u7684\u7279\u5f81\u5177\u6709\u4e0d\u540c\u7ea7\u522b\u7684\u91cd\u8981\u6027. \u9488\u5bf9\u4e0d\u540c\u5c3a\u5ea6\u8bbe\u7f6e\u4e0d\u540c\u7684\u6b63\u5219\u5316\u53c2\u6570\u662f\u5904\u7406\u591a\u5c3a\u5ea6\u6b63\u5219\u5316\u95ee\u9898\u7684\u4e00\u79cd\u6709\u6548\u65b9\u6cd5. \u53d7\u591a\u5c3a\u5ea6\u5206\u6790\u7684\u542f\u53d1, \u6211\u4eec\u901a\u8fc7\u5bf9\u4e0d\u540c\u5c42\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u65bd\u52a0\u4e0d\u540c\u7684\u7a00\u758f\u6b63\u5219\u5316\u60e9\u7f5a, \u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u6a21\u578b. \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d, \u795e\u7ecf\u7f51\u7edc\u4ece\u7ed9\u5b9a\u7684\u6570\u636e\u4e2d\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u77e9\u9635\u6743\u91cd. \u901a\u8fc7\u7a00\u758f\u4f18\u5316, \u8bb8\u591a\u6743\u91cd\u8fde\u63a5\u81ea\u52a8\u4e3a\u96f6. \u5176\u4f59\u7531\u975e\u96f6\u6743\u91cd\u7ec4\u6210\u7684\u795e\u7ecf\u7f51\u7edc\u6784\u6210\u6211\u4eec\u6240\u9700\u8981\u7684\u7a00\u758f\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc. This paper is organized in five sections. In Section 2, we describe a multi-parameter regularization model for solving partial differential equations by using deep neural networks. We study in Section 3 the capacity of the proposed multi-parameter regularization in adaptive representing functions having certain singularities. In Section 4, we investigate numerical solutions of nonlinear partial differential equations by using the proposed SDNN model. Specifically, we consider two equations: the Burgers equation and the Schr\u00f6dinger equation since solutions of these two equations exhibit certain types of singularities. Finally, a conclusion is drawn in Section 5. \u672c\u6587\u5206\u4e3a\u4e94\u4e2a\u90e8\u5206. \u5728\u7b2c\u4e8c\u8282\u4e2d, \u6211\u4eec\u63cf\u8ff0\u4e86\u4e00\u4e2a\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u591a\u53c2\u6570\u6b63\u5219\u5316\u6a21\u578b. \u5728\u7b2c\u4e09\u8282\u4e2d, \u6211\u4eec\u7814\u7a76\u4e86\u6240\u63d0\u51fa\u7684\u591a\u53c2\u6570\u6b63\u5219\u5316\u6a21\u578b\u5728\u81ea\u9002\u5e94\u8868\u793a\u5177\u6709\u4e00\u5b9a\u5947\u6027\u7684\u51fd\u6570\u80fd\u529b. \u5728\u7b2c\u56db\u8282\u4e2d, \u6211\u4eec\u4f7f\u7528\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u89e3. \u5177\u4f53\u6765\u8bf4, \u6211\u4eec\u8003\u8651\u4e24\u4e2a\u65b9\u7a0b: Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b, \u56e0\u4e3a\u8fd9\u4e24\u4e2a\u65b9\u7a0b\u7684\u89e3\u663e\u793a\u51fa\u67d0\u79cd\u7c7b\u578b\u7684\u5947\u6027. \u5728\u7b2c\u4e94\u8282\u4e2d, \u5f97\u51fa\u6700\u540e\u7684\u7ed3\u8bba.","title":"Introduction"},{"location":"Scholars/PN-2207.13266/#a-sparse-dnn-model-for-solving-partial-differential-equations","text":"In this section, we propose a sparse DNN model for solving nonlinear partial differential equations (PDEs). \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u63d0\u51fa\u4e00\u4e2a\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7528\u4e8e\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b. We begin with describing the PDE and its boundary, initial conditions to be considered in this paper. Suppose that \\(\\Omega\\) is an open domain in \\(\\mathbb{R}^d\\) . By \\(\\Gamma\\) we denote the boundary of the domain \\(\\Omega\\) . Let \\(\\mathcal{F}\\) denote a nonlinear differential operator, \\(\\mathcal{I}\\) the initial condition operator, and \\(\\mathcal{B}\\) the boundary operator. We consider the following boundary/initial value problem of the nonlinear partial differential equation: \u9996\u5148\u4ece\u63cf\u8ff0\u672c\u6587\u8003\u8651\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u53ca\u5176\u521d\u8fb9\u503c\u6761\u4ef6\u5f00\u59cb. \u8bbe \\(\\Omega\\) \u662f \\(\\mathbb{R}^d\\) \u4e0a\u7684\u4e00\u4e2a\u5f00\u96c6. \u7528 \\(\\Gamma\\) \u8868\u793a\u5b9a\u4e49\u57df \\(\\Omega\\) \u7684\u8fb9\u754c. \u7528 \\(\\mathcal{F}\\) \u8868\u793a\u975e\u7ebf\u6027\u5fae\u5206\u7b97\u5b50, \\(\\mathcal{I}\\) \u8868\u793a\u521d\u59cb\u6761\u4ef6\u7b97\u5b50, \\(\\mathcal{B}\\) \u8868\u793a\u8fb9\u754c\u6761\u4ef6\u7b97\u5b50. \u6211\u4eec\u8003\u8651\u5982\u4e0b\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8fb9\u503c\u95ee\u9898: $$ \\begin{align} \\mathcal{F}(u(t,x)) &= 0, &x\\in\\Omega,\\ &t\\in [0,T],\\tag{1}\\ \\mathcal{I}(u(t,x)) &= 0, &x\\in\\Omega,\\ &t=0,\\tag{2}\\ \\mathcal{B}(u(t,x)) &= 0, &x\\in\\Gamma,\\ &t\\in [0,T],\\tag{3}\\ \\end{align} $$ where \\(T > 0\\) , the data \\(u\\) on \\(\\Gamma\\) and \\(t = 0\\) are given and \\(u\\) in \\(\\Omega\\) is the solution to be learned. The formulation (1) - (3) covers a broad range of problems including conservation laws, reaction-diffusion equations, and Navier-Stokes equations. \u5176\u4e2d \\(T>0\\) , \u5728 \\(\\Gamma\\) \u548c \\(t=0\\) \u5904\u7684\u6570\u636e \\(u\\) \u7ed9\u5b9a, \u5728 \\(\\Omega\\) \u4e0a\u7684 \\(u\\) \u662f\u9700\u8981\u5b66\u4e60\u7684\u89e3. \u516c\u5f0f 1-3 \u6db5\u76d6\u4e86\u5f88\u5927\u8303\u56f4\u7684\u95ee\u9898\u5982\u5b88\u6052\u5f8b, \u53cd\u5e94\u6269\u6563\u65b9\u7a0b, Navier-Stokes \u65b9\u7a0b\u7b49. For example, the one dimensional Burgers equation can be recognized as \u4f8b\u5982, \u4e00\u7ef4 Burgers \u65b9\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a \\[ \\mathcal{F}(u) := \\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} - \\frac{\\partial^2 u}{\\partial x^2}. \\] The goal of this paper is to develop a sparse DNN model for solving problem(1). We will conduct numerical study of the proposed model by applying it to two equations, the Burgers equation and the Schr\u00f6dinger equation, of practical importance. \u672c\u6587\u7684\u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6c42\u89e3\u95ee\u9898 (1) . \u6211\u4eec\u5c06\u901a\u8fc7\u628a\u6a21\u578b\u5e94\u7528\u5230\u4e24\u4e2a\u5177\u6709\u5b9e\u9645\u91cd\u8981\u6027\u7684\u65b9\u7a0b, Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b\u6765\u5bf9\u8fd9\u4e2a\u6a21\u578b\u8fdb\u884c\u6570\u503c\u7814\u7a76. Now, we present the sparse DNN model with multi-parameter regularization. We first recall the the feed forward neural network (FNN). A neural network can be viewed as a composition of functions. A FNN of depth \\(D\\) is defined to be a neural network with an input layer, \\(D - 1\\) hidden layers, and an output layer. A neural network with more than two hidden layers is usually called a deep neural network (DNN). Suppose that there are \\(d_i\\) neurons in the \\(i\\) -th hidden layer. Let \\(W_i\\in \\mathbb{R}^{d_i\\times d_{i-1}}\\) and \\(b_i\\in\\mathbb{R}^{d_i}\\) denote, respectively, the weight matrix and bias vector of the \\(i\\) -th layer. By \\(x_0:= x \\in \\mathbb{R}^{d_0}\\) we denote the input vector and by \\(x_{i-1}\\in \\mathbb{R}^{d_{i-1}}\\) we denote the output vector of the ( \\(i - 1\\) )-th layer. For the \\(i\\) -th hidden layer, we define the affine transform \\(L_i: \\mathbb{R}^{d_{i-1}}\\mapsto \\mathbb{R}^{d_i}\\) by \u73b0\u5728\u6211\u4eec\u4ecb\u7ecd\u5e26\u6709\u591a\u53d8\u91cf\u6b63\u5219\u5316\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b. \u6211\u4eec\u9996\u5148\u56de\u5fc6\u524d\u9988\u795e\u7ecf\u7f51\u7edc FNN. \u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u89c6\u4e3a\u51fd\u6570\u7684\u590d\u5408. \u4e00\u4e2a \\(D\\) \u5c42\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u662f\u6307\u5177\u6709\u4e00\u5c42\u8f93\u5165\u5c42, \\(D-1\\) \u5c42\u9690\u85cf\u5c42\u548c\u4e00\u5c42\u8f93\u51fa\u5c42\u7684\u795e\u7ecf\u7f51\u7edc. \u5177\u6709\u8d85\u8fc7\u4e24\u5c42\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u79f0\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc DNN. \u5047\u8bbe\u7b2c \\(i\\) \u5c42\u9690\u85cf\u5c42\u4e2d\u6709 \\(d_i\\) \u4e2a\u795e\u7ecf\u7f51\u7edc. \u7528 \\(W_i,b_i\\) \u5206\u522b\u8868\u793a\u7b2c \\(i\\) \u5c42\u7684\u6743\u91cd\u77e9\u9635\u548c\u504f\u5dee\u5411\u91cf. \\(x_0\\) \u8868\u793a\u8f93\u5165\u5411\u91cf, \\(x_{i-1}\\) \u8868\u793a\u7b2c \\(i-1\\) \u5c42\u7684\u8f93\u51fa\u5411\u91cf. \u5bf9\u4e8e\u7b2c \\(i\\) \u5c42\u9690\u85cf\u5c42, \u6211\u4eec\u5b9a\u4e49\u4eff\u5c04\u53d8\u6362 \\(L_i\\) \u5982\u4e0b: \\[ L_i(x_{i-1}) := W_i x_{i-1}+ b_i, i = 1,2,\\cdots,D. \\] For an activation function \\(\\sigma_i\\) , the output vector of the \\(i\\) -th hidden layer is defined as \u5bf9\u4e8e\u6fc0\u6d3b\u51fd\u6570 \\(\\sigma_i\\) , \u7b2c \\(i\\) \u5c42\u9690\u85cf\u5c42\u7684\u8f93\u51fa\u5411\u91cf\u5b9a\u4e49\u4e3a \\[ x_i:= \\sigma_i(L_i(x_{i-1})). \\] Given nonlinear activation functions \\(\\sigma_i, i = 1, 2,\\cdots, D-1\\) , the feed forward neural network \\(N_\\Theta(x)\\) of depth \\(D\\) is defined as \u7ed9\u5b9a \\(D-1\\) \u4e2a\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570 \\(\\sigma_i\\) , \u6df1\u5ea6\u4e3a \\(D\\) \u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc \\(N_\\Theta(x)\\) \u5b9a\u4e49\u4e3a \\[ N_\\Theta(x) := L_D\\circ \\sigma_{D-1} \\circ L_{D-1}\\circ \\cdots\\circ \\sigma_1\\circ L_1(x),\\tag{4} \\] where \\(\\circ\\) denotes the composition operator and \\(\\Theta :=\\{W_i, b_i\\}^D_{i=1}\\) is the set of trainable parameters in the network. \u5176\u4e2d \\(\\circ\\) \u8868\u793a\u590d\u5408\u7b97\u5b50, \\(\\Theta\\) \u662f\u7f51\u7edc\u53ef\u8bad\u7ec3\u53c2\u6570\u96c6\u5408. We first describe the physics-informed neural network ( PINN ) model introduced in 35 for solving the partial differential equation (1) . We denote by \\(Loss_{PDE}\\) the loss of training data on the partial differential equation (1) . We choose \\(N_f\\) collocation points \\((t^i_f, x^i_f)\\) by randomly sampling in domain \\(\\Omega\\) using a sampling method such as Latin hypercube sampling 23 . We then evaluate \\(\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))\\) for \\(i = 1, 2,\\cdots N_f\\) and define \u6211\u4eec\u9996\u5148\u4ecb\u7ecd\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b (1) \u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc PINN. \u6211\u4eec\u4f7f\u7528\u67d0\u79cd\u91c7\u6837\u65b9\u6cd5\u5982\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837 (LHS) \u4ece\u5b9a\u4e49\u57df \\(\\Omega\\) \u4e2d\u968f\u673a\u91c7\u6837 \\(N_f\\) \u4e2a\u914d\u7f6e\u70b9, \u7136\u540e\u5728\u8fd9\u4e9b\u70b9\u4e0a\u8ba1\u7b97 \\(\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))\\) \u7684\u503c\u5e76\u5b9a\u4e49 \\[ Loss_{PDE}:= \\frac{1}{N_f} \\sum_{i=1}^{N_f} |\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))|^2, \\] where \\(\\mathcal{F}\\) is the operator for the partial differential equation (1) . \u5176\u4e2d \\(\\mathcal{F}\\) \u662f\u504f\u5fae\u5206\u65b9\u7a0b (1) \u7684\u7b97\u5b50. We next describe the loss function for the boundary/initial condition. We randomly sample \\(N_0\\) points \\(x^i_0\\) for the initial condition (2) , \\(N_b\\) points \\(\\{t^i_b, x^i_b\\}\\) for the boundary condition (3) . The loss function \\(Loss_0\\) related to the initial value condition is given by \u7136\u540e\u6211\u4eec\u4ecb\u7ecd\u8fb9\u754c\u6761\u4ef6/\u521d\u59cb\u6761\u4ef6\u7684\u635f\u5931\u51fd\u6570. \u6211\u4eec\u4e3a\u521d\u59cb\u6761\u4ef6\u968f\u673a\u91c7\u6837 \\(N_0\\) \u4e2a\u70b9, \u4e3a\u8fb9\u754c\u6761\u4ef6\u968f\u673a\u91c7\u6837 \\(N_b\\) \u4e2a\u70b9. \u7136\u540e\u4e0e\u521d\u503c\u6761\u4ef6\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570 \\(Loss_0\\) \u5b9a\u4e49\u5982\u4e0b \\[ Loss_0 := \\frac{1}{N_0} \\sum_{i=1}^{N_0} |\\mathcal{I}(\\mathcal{N}_\\Theta(0, x^i_0))|. \\] The loss function \\(Loss_b\\) pertaining to the boundary value is given as \u4e0e\u8fb9\u503c\u6761\u4ef6\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570 \\(Loss_b\\) \u5b9a\u4e49\u5982\u4e0b \\[ Loss_b := \\frac{1}{N_b} \\sum_{i=1}^{N_b}|\\mathcal{B}(\\mathcal{N}_\\Theta(t^i_b, x^i_b))|, x^i_b\\in \\Gamma. \\] Adding the three loss functions \\(Loss_{PDE}\\) , \\(Loss_0\\) , and \\(Loss_b\\) together gives rise to the PINN model \u5c06\u4e09\u4e2a\u635f\u5931\u51fd\u6570 \\(Loss_{PDE}\\) , \\(Loss_0\\) , \\(Loss_b\\) \u76f8\u52a0\u5c31\u5f97\u5230\u4e86 PINN \u6a21\u578b \\[ \\min_\\Theta\\bigg\\{\\frac{1}{N_f} \\sum_{i=1}^{N_f} |\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))|^2 + \\frac{1}{N_0} \\sum_{i=1}^{N_0} |\\mathcal{I}(\\mathcal{N}_\\Theta(0, x^i_0))| + \\frac{1}{N_b} \\sum_{i=1}^{N_b}|\\mathcal{B}(\\mathcal{N}_\\Theta(t^i_b, x^i_b))|\\bigg\\}\\tag{5} \\] where \\(\\Theta:=\\{W_i, b_i\\}^D_{i=1}\\) . \u5176\u4e2d \\(\\Theta:=\\{W_i, b_i\\}^D_{i=1}\\) . The neural network learned from (5) is often dense and may be over-parameterized. Moreover, training data are often contaminated with noise. When noise presents, over-parameterized models may overfit training data samples and result in bad generalization to the unseen samples. The problem of overfitting is often overcome by adding a regularization term: \u4ece\u4e0a\u8ff0\u635f\u5931\u51fd\u6570\u5b66\u4e60\u5230\u7684\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u662f\u5bc6\u96c6\u7684\u4e14\u53ef\u80fd\u8fc7\u53c2\u6570\u5316. \u6b64\u5916, \u8bad\u7ec3\u6570\u636e\u7ecf\u5e38\u88ab\u566a\u58f0\u6c61\u67d3. \u5f53\u566a\u58f0\u51fa\u73b0, \u8fc7\u53c2\u6570\u5316\u7684\u6a21\u578b\u53ef\u80fd\u5bf9\u8bad\u7ec3\u6570\u636e\u8fc7\u62df\u5408\u4ece\u800c\u5728\u672a\u77e5\u6837\u672c\u4e0a\u6cdb\u5316\u5f97\u5f88\u5dee. \u8fc7\u62df\u5408\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2a\u6b63\u5219\u5316\u9879\u6765\u514b\u670d. \\[ Loss := Loss_{PDE}+ \\beta (Loss_0 + Loss_b) + \\text{Regularization}. \\] The \\(l_1\\) - and \\(l_2\\) -norms are popular choices for regularization. Design of the regularization often makes use of prior information of the solution to be learned. It is known 4 17 42 that the \\(l_1\\) -norm can promote sparsity. Hence, the \\(l_1\\) -norm regularization not only has many advantages over the \\(l_2\\) -norm regularization, but also leads to sparse models which can be more easily interpreted. Therefore, we choose to use the \\(l_1\\) -norm as the regularizer in this study. Furthermore, we observe that DNNs have an intrinsic multiscale structure whose different layers represent different scales of information, which will be validated later by numerical studies. \\(l_1\\) \u8303\u6570\u548c \\(l_2\\) \u8303\u6570\u662f\u6b63\u5219\u5316\u7684\u5e38\u7528\u9009\u62e9. \u6b63\u5219\u5316\u7684\u8bbe\u8ba1\u901a\u5e38\u4f7f\u7528\u9700\u8981\u5b66\u4e60\u7684\u89e3\u7684\u5148\u9a8c\u4fe1\u606f. \u4ece\u5148\u524d\u7684\u5de5\u4f5c\u4e2d\u76f4\u5230 \\(l_1\\) \u8303\u6570\u53ef\u4ee5\u4fc3\u8fdb\u7a00\u758f\u6027. \u56e0\u6b64 \\(l_1\\) \u8303\u6570\u6b63\u5219\u5316\u4e0d\u4ec5\u6bd4 \\(l_2\\) \u8303\u6570\u6b63\u5219\u5316\u6709\u8bf8\u591a\u4f18\u70b9, \u8fd8\u80fd\u591f\u5bfc\u51fa\u66f4\u6613\u4e8e\u89e3\u91ca\u7684\u7a00\u758f\u6a21\u578b. \u56e0\u6b64\u6211\u4eec\u5728\u672c\u9879\u5de5\u4f5c\u4e2d\u9009\u62e9 \\(l_1\\) \u8303\u6570\u4f5c\u4e3a\u6b63\u5219\u5316\u9879. \u6b64\u5916, \u6211\u4eec\u89c2\u5bdf\u5230\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6709\u4e00\u4e2a\u5185\u5728\u591a\u5c3a\u5ea6\u7ed3\u6784, \u4e0d\u540c\u5c42\u8868\u793a\u4fe1\u606f\u7684\u4e0d\u540c\u5c3a\u5ea6, \u8fd9\u5c06\u5728\u4e4b\u540e\u7684\u6570\u503c\u7b97\u4f8b\u4e2d\u5f97\u5230\u9a8c\u8bc1. In fact, we will demonstrate in the next section that a smooth function or smooth parts of a function can be represented by a DNN with sparse weight matrices. This is because a smooth part of a function contains redundant information, which can be described very well by a few parameters, and only non-smooth parts of a function require more parameters to describe them. In other words, by properly choosing regularization, DNNs can lead to adaptive sparse representations of functions having certain singularities. With this understanding, we construct an adaptive representation of a function, especially for a function having certain singularity by adopting a sparse regularization model. Our idea for the adaptive representation is to impose different sparsity penalties for different layers. Specifically, we propose a multiscale-like sparse regularization using the \\(l_1\\) -norm of the weight matrix for each layer with a different parameter for a different layer. The regularization with multiple parameters allows us to represent a function in a multiscale-like neural network which is determined by sparse weight matrices having different sparsity at different layers. Such a regularization added to the loss function will enable us to robustly extract critical information of the solution of the PDE. \u5b9e\u9645\u4e0a, \u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u8282\u8bf4\u660e\u7684\u662f\u4e00\u4e2a\u5149\u6ed1\u51fd\u6570\u6216\u51fd\u6570\u7684\u5149\u6ed1\u90e8\u5206\u53ef\u4ee5\u7531\u5177\u6709\u7a00\u758f\u6743\u91cd\u77e9\u9635\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6765\u8868\u793a. \u8fd9\u662f\u56e0\u4e3a\u51fd\u6570\u7684\u5149\u6ed1\u90e8\u5206\u5305\u542b\u4e86\u5197\u4f59\u4fe1\u606f, \u80fd\u591f\u88ab\u5c11\u6570\u53c2\u6570\u63cf\u8ff0\u5f97\u5f88\u597d, \u5e76\u4e14\u53ea\u6709\u51fd\u6570\u5f97\u975e\u5149\u6ed1\u90e8\u5206\u9700\u8981\u66f4\u591a\u7684\u53c2\u6570\u53bb\u63cf\u8ff0\u5b83\u4eec. \u6362\u53e5\u8bdd\u8bf4, \u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u6b63\u5219\u5316, \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u5f97\u5230\u5e26\u6709\u5947\u6027\u7684\u51fd\u6570\u7684\u81ea\u9002\u5e94\u7a00\u758f\u8868\u793a. \u6839\u636e\u8fd9\u4e00\u8ba4\u77e5, \u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u7a00\u758f\u6b63\u5219\u5316\u6a21\u578b\u6765\u6784\u9020\u51fd\u6570, \u7279\u522b\u662f\u5e26\u6709\u67d0\u4e9b\u5947\u6027\u7684\u51fd\u6570\u7684\u81ea\u9002\u5e94\u8868\u793a. \u5173\u4e8e\u81ea\u9002\u5e94\u8868\u793a\u7684\u601d\u8def\u662f\u7ed9\u4e0d\u540c\u7684\u5c42\u4e16\u5bb6\u4e0d\u540c\u7684\u7a00\u758f\u5ea6\u60e9\u7f5a. \u5177\u4f53\u6765\u8bf4, \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7c7b\u591a\u5c3a\u5ea6\u7a00\u758f\u6b63\u5219\u5316, \u5bf9\u6bcf\u4e00\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684 \\(l_1\\) \u8303\u6570\u8d4b\u4e88\u4e0d\u540c\u7684\u53c2\u6570 \u591a\u53c2\u6570\u6b63\u5219\u5316\u4f7f\u5f97\u6211\u4eec\u80fd\u591f\u5728\u7c7b\u591a\u5c3a\u5ea6\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\u8868\u793a\u4e00\u4e2a\u51fd\u6570, \u8be5\u7f51\u7edc\u7531\u4e0d\u540c\u5c42\u4e0a\u5177\u6709\u4e0d\u540c\u7a00\u758f\u5ea6\u7684\u7a00\u758f\u6743\u91cd\u77e9\u9635\u51b3\u5b9a. \u5728\u635f\u5931\u51fd\u6570\u4e2d\u52a0\u5165\u8fd9\u79cd\u6b63\u5219\u5316, \u53ef\u4ee5\u6709\u6548\u5730\u63d0\u53d6\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7684\u5173\u952e\u4fe1\u606f. We now describe the proposed regularization. For layer \\(i\\) , we denote by \\(W^{k,j}_i\\) the \\((k, j)\\) -th entry of matrix \\(W_i\\) , the entry in the \\(k\\) -th row and the \\(j\\) -th column. For this reason, we adopt the \\(l_1\\) -norm of matrix \\(W_i\\) defined by following formula as our sparse regularization. \u6211\u4eec\u73b0\u5728\u63cf\u8ff0\u6240\u63d0\u51fa\u7684\u6b63\u5219\u5316. \u5bf9\u4e8e\u5c42 \\(i\\) , \u6211\u4eec\u7528 \\(W^{k,j}_i\\) \u8868\u793a\u77e9\u9635 \\(W_i\\) \u7684\u7b2c \\(k\\) \u884c\u7b2c \\(j\\) \u5217\u9879. \u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u77e9\u9635 \\(W_i\\) \u7684 \\(l_1\\) \u8303\u6570\u4f5c\u4e3a\u6211\u4eec\u7684\u7a00\u758f\u6b63\u5219\u5316. \\[ \\|W_i\\|_1:=\\sum_{k=1}^{d_i}\\sum_{j=1}^{d_{i-1}}|W^{k,j}_i| \\] Considering that different layers of the neural network play different roles in approximation of a function, we introduce here a multi-parameter regularization model \u8003\u8651\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u540c\u5c42\u5728\u903c\u8fd1\u4e00\u4e2a\u51fd\u6570\u65f6\u626e\u6f14\u4e0d\u540c\u7684\u89d2\u8272, \u6211\u4eec\u5f15\u5165\u5982\u4e0b\u591a\u53c2\u6570\u6b63\u5219\u5316\u6a21\u578b \\[ \\text{Regularization} :=\\sum_{i=1}^D \\alpha_i\\|W_i\\|_1 \\tag{6} \\] where \\(\\alpha_i\\) are nonnegative regularization parameters. \u5176\u4e2d \\(\\alpha_i\\) \u662f\u975e\u8d1f\u7684\u6b63\u5219\u5316\u53c2\u6570. The use of different parameters for weight matrices of different layers in the regularization term (6) allows us to penalize the weight matrices at different layers of the neural network differently in order to extract the multiscale representation of the solution to be learned. That is, for a fixed \\(i\\) , parameter \\(\\alpha_i\\) determines the sparsity of weight matrix \\(W_i\\) . The larger the parameter \\(\\alpha_i\\) , the more sparse the weight matrix \\(W_i\\) is. The regularized loss function takes the form \u5728\u6b63\u5219\u5316\u9879 (6) \u4e2d\u5bf9\u4e8e\u4e0d\u540c\u5c42\u7684\u6743\u91cd\u77e9\u9635\u4f7f\u7528\u4e0d\u540c\u53c2\u6570\u4f7f\u5f97\u6211\u4eec\u5bf9\u7f51\u7edc\u4e0d\u540c\u5c42\u7684\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u60e9\u7f5a\u4ee5\u63d0\u53d6\u6240\u9700\u5b66\u4e60\u7684\u89e3\u7684\u591a\u5c3a\u5ea6\u8868\u793a. \u5373\u5bf9\u4e8e\u4e00\u4e2a\u56fa\u5b9a\u7684 \\(i\\) , \u53c2\u6570 \\(\\alpha_i\\) \u51b3\u5b9a\u4e86\u6743\u91cd\u77e9\u9635 \\(W_i\\) \u7684\u7a00\u758f\u6027. \\(\\alpha_i\\) \u8d8a\u5927, \u6743\u91cd\u77e9\u9635 \\(W_i\\) \u8d8a\u7a00\u758f. \u6b63\u5219\u5316\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u5982\u4e0b: \\[ Loss := Loss_{PDE}+ \\beta(Loss_0+ Loss_b) +\\sum_{i=1}^D \\alpha_i\\|W_i\\|_1. \\tag{7} \\] The parameters \\(\\Theta:= \\{W_i, b_i\\}^D_{i=1}\\) of the neural network \\(\\mathcal{N}_\\Theta(t,x)\\) are learned by minimizing the loss function \u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta(t,x)\\) \u7684\u53c2\u6570 \\(\\Theta\\) \u901a\u8fc7\u6700\u5c0f\u5316\u5982\u4e0b\u635f\u5931\u51fd\u6570\u8fdb\u884c\u5b66\u4e60. \\[ \\min_\\Theta \\bigg\\{\\frac{1}{N_f} \\sum_{i=1}^{N_f} |\\mathcal{F}(\\mathcal{N}_\\Theta(t^i_f, x^i_f))|^2 + \\beta(Loss_0+Loss_b) + \\sum_{i=1}^D \\alpha_i\\|W_i\\|_1\\bigg\\}.\\tag{8} \\] Truncating the weights of the layers close to the input layer has an impact on all subsequent layers. In practice, we usually set smaller regularization parameters in layers close to the input and larger regularization parameters in layers close to the output. The resulting neural network will exhibit denser weight matrices near the input layer and sparser weight matrices near the output layer. This network structure reflects the multi-scale nature of neural networks and is automatically learned by sparse regularization. \u622a\u65ad\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u9690\u85cf\u5c42\u7684\u6743\u91cd\u4f1a\u5bf9\u540e\u7eed\u5c42\u4ea7\u751f\u5f71\u54cd. \u5b9e\u8df5\u4e2d\u6211\u4eec\u901a\u5e38\u5bf9\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u9690\u85cf\u5c42\u8bbe\u7f6e\u66f4\u5c0f\u7684\u6b63\u5219\u5316\u53c2\u6570, \u5bf9\u9760\u8fd1\u8f93\u51fa\u5c42\u7684\u9690\u85cf\u5c42\u8bbe\u7f6e\u66f4\u5927\u7684\u6b63\u5219\u5316\u53c2\u6570. \u5f97\u5230\u7684\u795e\u7ecf\u7f51\u7edc\u4f1a\u8868\u73b0\u51fa\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u6743\u91cd\u77e9\u9635\u66f4\u5bc6\u96c6, \u9760\u8fd1\u8f93\u51fa\u5c42\u7684\u6743\u91cd\u77e9\u9635\u66f4\u7a00\u758f. \u8fd9\u6837\u7684\u7f51\u7edc\u7ed3\u6784\u53cd\u6620\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u5c3a\u5ea6\u672c\u8d28\u4e14\u81ea\u52a8\u5730\u7531\u7a00\u758f\u6b63\u5219\u5316\u5b66\u4e60\u5230. Appropriate choices of the regularization parameters are key to achieve good prediction results. We need to balance sparsity and prediction accuracy. Since there are multiple regularization parameters, the regularization parameters are chosen by grid search layer by layer in this paper. In practice, we first choose the regularization parameters close to the output layer, and then gradually choose the regularization coefficients close to the input layer. \u6b63\u5219\u5316\u53c2\u6570\u7684\u9002\u5f53\u9009\u62e9\u662f\u83b7\u5f97\u826f\u597d\u9884\u6d4b\u7ed3\u679c\u7684\u5173\u952e. \u6211\u4eec\u9700\u8981\u5e73\u8861\u7a00\u758f\u6027\u548c\u9884\u6d4b\u7cbe\u5ea6. \u56e0\u4e3a\u6709\u591a\u4e2a\u6b63\u5219\u5316\u53c2\u6570, \u6240\u4ee5\u672c\u6587\u7684\u6b63\u5219\u5316\u53c2\u6570\u901a\u8fc7\u9010\u5c42\u7f51\u683c\u641c\u7d22\u5f97\u5230. \u5b9e\u8df5\u4e2d\u6211\u4eec\u9996\u5148\u9009\u62e9\u9760\u8fd1\u8f93\u51fa\u5c42\u7684\u6b63\u5219\u5316\u53c2\u6570, \u7136\u540e\u9010\u6e10\u9009\u62e9\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u6b63\u5219\u5316\u7cfb\u6570. We refer equation (8) as to the sparse DNN ( SDNN ) model for the partial differential equation. Upon solving the minimization problem (8) , we obtain an approximate solution \\(u(t,x) := \\mathcal{N}_\\Theta(t, x)\\) with sparse weight matrices. When the regularization parameters \\(\\alpha_i\\) are all set to \\(0\\) , the SDNN model (8) reduces to the PINN model introduced in 35 . We will compare numerical performance of the proposed SDNN model with that of PINN model, for both the Burgers equation and the Schr\u00f6dinger equation. \u6211\u4eec\u5f15\u7528\u65b9\u7a0b (8) \u4f5c\u4e3a\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc ( SDNN ) \u6a21\u578b. \u57fa\u4e8e\u6c42\u89e3\u6700\u5c0f\u5316\u95ee\u9898 (8) , \u6211\u4eec\u83b7\u5f97\u4e86\u4e00\u4e2a\u5e26\u6709i\u5b66\u672f\u6743\u91cd\u77e9\u9635\u7684\u8fd1\u4f3c\u89e3 \\(u(t,x) := \\mathcal{N}_\\Theta(t, x)\\) . \u5f53\u6b63\u5219\u5316\u53c2\u6570 \\(\\alpha_i\\) \u5168\u90e8\u8bbe\u7f6e\u4e3a \\(0\\) , \u90a3\u4e48 SDNN \u6a21\u578b\u5c06\u9000\u5316\u4e3a PINN \u6a21\u578b. \u6211\u4eec\u5c06\u5728 Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b\u4e0a\u6bd4\u8f83\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u548c PINN \u7684\u6570\u503c\u8868\u73b0.","title":"A Sparse DNN Model for Solving Partial Differential Equations"},{"location":"Scholars/PN-2207.13266/#function-adaptive-approximation-by-the-sdnn-model","text":"We explore in this section the capacity of the proposed multi-parameter regularization in adaptive representing functions that have certain singularities. We will first reveal that a DNN indeed has an intrinsic multiscale-like structure which is desirable for representing non-smooth functions. We demonstrate in our numerical studies that the proposed SDNN model can reconstruct neural networks which approximate functions in the same accuracy order with nearly the same order of network complexity, regardless the smoothness of the functions. We include in this section a numerical study of reconstruction of black holes by the proposed SDNN model. In this section, we use the rectified linear unit (ReLU) function as an activation function. \u672c\u8282\u6211\u4eec\u63a2\u7a76\u6240\u63d0\u51fa\u7684\u591a\u53c2\u6570\u6b63\u5219\u5316\u5728\u81ea\u9002\u5e94\u8868\u793a\u5e26\u6709\u67d0\u4e9b\u5947\u6027\u7684\u51fd\u6570\u7684\u80fd\u529b. \u6211\u4eec\u9996\u5148\u63ed\u793a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u786e\u5b9e\u5177\u6709\u5185\u5728\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784, \u8fd9\u79cd\u7ed3\u6784\u5bf9\u4e8e\u8868\u793a\u975e\u5149\u6ed1\u51fd\u6570\u662f\u53ef\u53d6\u7684. \u6570\u503c\u7814\u7a76\u8868\u660e, \u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u65e0\u8bba\u51fd\u6570\u7684\u5149\u6ed1\u5ea6\u5982\u4f55, \u90fd\u80fd\u4ee5\u8fd1\u4f3c\u76f8\u540c\u7684\u7f51\u7edc\u590d\u6742\u5ea6\u9636\u6570\u91cd\u6784\u51fa\u7cbe\u5ea6\u76f8\u540c\u7684\u51fd\u6570. \u5728\u8fd9\u4e00\u8282\u4e2d\u8fd8\u5305\u62ec\u4e00\u4e2a\u4f7f\u7528\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u91cd\u5efa\u9ed1\u6d1e\u7684\u6570\u503c\u7814\u7a76. \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u4f7f\u7528\u6574\u6d41\u7ebf\u6027\u5355\u4f4d\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570. \\[ \\text{ReLU}(x) := \\max\\{0, x\\}, x \\in \\mathbb{R} \\] We first describe the data fitting problem. Given training points \\((x_i, y_i), i =1, 2, \\cdots, N\\) , a non-regularized neural network is determined by minimizing the regression error, that is, \u6211\u4eec\u9996\u5148\u63cf\u8ff0\u6570\u636e\u62df\u5408\u95ee\u9898. \u7ed9\u5b9a\u8bad\u7ec3\u6837\u672c\u70b9 \\((x_i, y_i), i =1, 2, \\cdots, N\\) , \u975e\u6b63\u5219\u5316\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u6700\u5c0f\u5316\u5982\u4e0b\u56de\u5f52\u635f\u5931\u786e\u5b9a \\[ \\min_\\Theta\\frac{1}{N} \\sum_{i=1}^N |\\mathcal{N}_\\Theta(x_i) - y_i|^2.\\tag{9} \\] The multi-parameter sparse regularization DNN model for the data fitting problem reads \u7528\u4e8e\u6570\u636e\u62df\u5408\u95ee\u9898\u7684\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5219\u6700\u5c0f\u5316\u5982\u4e0b\u635f\u5931 \\[ \\min_\\Theta\\bigg\\{\\frac{1}{N}\\sum_{i=1}^N|\\mathcal{N}_\\Theta(x_i) - y_i|^2+\\sum_{i=1}^D \\alpha_i \\|W_i\\|_1\\bigg\\},\\tag{10} \\] where \\(\\alpha_i\\) are nonnegative regularization parameters and \\(W_i\\) are weight matrices. \u5176\u4e2d \\(\\alpha_i\\) \u662f\u975e\u8d1f\u6b63\u5219\u5316\u53c2\u6570, \\(W_i\\) \u662f\u6743\u91cd\u77e9\u9635. In examples to be presented in this section and the section that follows, the network structure is described by the number of neurons in each layer. Specifically, we use the notation \\([d_0, d_1,\\cdots,d_D]\\) to describe networks that have one input layer, \\(D - 1\\) hidden layers and one output layer, with \\(d_0, d_1,\\cdots, d_D\\) number of neurons, respectively. The regularization parameters, which will be presented as a vector \\(\\alpha:= [\\alpha_1, \\alpha_2,\\cdots, \\alpha_D]\\) , are chosen so that best results are obtained. We will use the relative \\(L_2\\) error to measure approximation accuracy. Suppose that \\(y_i\\) is the exact value of function \\(f\\) to be approximated at \\(x_i\\) , that is, \\(y_i= f(x_i)\\) , and suppose that \\(\\hat{y}_i:= \\mathcal{N}_\\Theta (x_i)\\) is the output of the neural network approximation of \\(f\\) . We let \\(y := [y_1, y_2,\\cdots, y_N]\\) and \\(\\hat{y} := [\\hat{y}_1, \\hat{y}_2,\\cdots, \\hat{y}_N]\\) , and define the error by \\(\\dfrac{\\|y-\\hat{y}\\|_2}{\\|y\\|_2}\\) . Sparsity of the weight matrices is measured by the percentage of zero entries in the weight matrices \\(W_i\\) . In our computation, we set a weight matrix entry \u5728\u672c\u8282\u548c\u4e4b\u540e\u7ae0\u8282\u5c55\u793a\u7684\u4f8b\u5b50\u4e2d, \u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u901a\u8fc7\u6bcf\u5c42\u795e\u7ecf\u5143\u7684\u6570\u91cf\u8fdb\u884c\u63cf\u8ff0. \u5177\u4f53\u7684, \u6211\u4eec\u4f7f\u7528 \\([d_0, d_1,\\cdots,d_D]\\) \u6765\u63cf\u8ff0\u5177\u6709\u4e00\u5c42\u8f93\u5165\u5c42, \\(D-1\\) \u5c42\u9690\u85cf\u5c42\u548c\u4e00\u5c42\u8f93\u51fa\u5c42, \u5bf9\u5e94\u795e\u7ecf\u5143\u6570\u91cf\u4e3a \\(d_0, d_1,\\cdots, d_D\\) \u7684\u795e\u7ecf\u7f51\u7edc. \u6b63\u5219\u5316\u53c2\u6570\u5c06\u8868\u793a\u4e3a\u4e00\u4e2a\u5411\u91cf \\(\\alpha:= [\\alpha_1, \\alpha_2,\\cdots, \\alpha_D]\\) , \u5c06\u9009\u62e9\u51fa\u80fd\u83b7\u5f97\u6700\u4f73\u7ed3\u679c\u7684\u53c2\u6570. \u6211\u4eec\u5c06\u4f7f\u7528\u76f8\u5bf9 \\(L_2\\) \u8bef\u5dee\u6765\u5ea6\u91cf\u903c\u8fd1\u7cbe\u5ea6. \u5047\u8bbe \\(y_i\\) \u662f\u88ab\u903c\u8fd1\u51fd\u6570 \\(f\\) \u5728 \\(x_i\\) \u7684\u7cbe\u786e\u503c, \u5373 \\(y_i=f(x_i)\\) , \u8bbe \\(\\hat{y}_i:= \\mathcal{N}_\\Theta (x_i)\\) \u662f\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c \\(f\\) \u7684\u8f93\u51fa. \u6211\u4eec\u8ba1\u7b97 \\(N\\) \u4e2a\u70b9\u4e0a\u7684 \\(y := [y_1, y_2,\\cdots, y_N]\\) \u4ee5\u53ca \\(\\hat{y} := [\\hat{y}_1, \\hat{y}_2,\\cdots, \\hat{y}_N]\\) , \u4ece\u800c\u5b9a\u4e49\u8bef\u5dee\u4e3a \\(\\dfrac{\\|y-\\hat{y}\\|_2}{\\|y\\|_2}\\) . \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u5219\u901a\u8fc7\u6743\u91cd\u77e9\u9635 \\(W_i\\) \u91cc\u96f6\u5143\u7d20\u7684\u767e\u5206\u6bd4\u8fdb\u884c\u5ea6\u91cf. \u5728\u6211\u4eec\u7684\u8ba1\u7b97\u4e2d, \u6211\u4eec\u8bbe\u7f6e\u4e00\u4e2a\u6743\u91cd\u77e9\u9635\u5143\u7d20\u4e3a \\[ W^{k,j}_i= 0,\\quad \\text{if}\\ |W^{k,j}_i| < \\epsilon, \\] where \\(\\epsilon\\) is small positive number. In our numerical examples, we set \\(\\epsilon := 0.001\\) by default. For all numerical examples, the non-smooth, non-convex optimization problem (10) is solved by the Adam algorithm, which is an improved version of the stochastic gradient descent algorithm proposed in 27 for training deep learning models. \u5176\u4e2d \\(\\epsilon\\) \u662f\u4e00\u4e2a\u8f83\u5c0f\u7684\u6574\u6570. \u5728\u6211\u4eec\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u9ed8\u8ba4\u8bbe\u7f6e \\(\\epsilon=0.001\\) . \u5bf9\u4e8e\u6240\u6709\u7684\u6570\u503c\u4f8b\u5b50, \u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u95ee\u9898 (10) \u901a\u8fc7\u7528\u4e8e\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u6539\u8fdb\u7248 Adam \u7b97\u6cd5\u8fdb\u884c\u6c42\u89e3.","title":"Function Adaptive Approximation by the SDNN Model"},{"location":"Scholars/PN-2207.13266/#intrinsic-adaptivity-of-the-sdnn-model","text":"We first investigate whether the SDNN model (10) can generate a network that has an intrinsic adaptive representation of a function. That is, a function generated by the model has a multiscale-like structure so that the reconstructed neural networks approximate functions in the same accuracy order with nearly the same order of network complexity, regardless the smoothness of the functions. In particular, when a function is singular a sparse network with higher layers is generated to capture the higher resolution information of the function. The complexity of the network is nearly proportional to the reciprocal of the approximation error regardless whether the function is smooth or not. In this experiment, we consider two examples: (1) one-dimensional functions and (2) two-dimensional functions. \u6211\u4eec\u9996\u5148\u7814\u7a76 SDNN \u6a21\u578b (10) \u662f\u5426\u80fd\u591f\u751f\u6210\u5177\u6709\u51fd\u6570\u5185\u5728\u81ea\u9002\u5e94\u8868\u793a\u7684\u7f51\u7edc. \u7531\u8be5\u6a21\u578b\u751f\u6210\u7684\u51fd\u6570\u5177\u6709\u591a\u5c3a\u5ea6\u7ed3\u6784, \u4f7f\u5f97\u91cd\u6784\u540e\u7684\u795e\u7ecf\u7f51\u7edc\u65e0\u8bba\u51fd\u6570\u7684\u5149\u6ed1\u5ea6\u5982\u4f55, \u90fd\u80fd\u4ee5\u76f8\u540c\u7684\u7cbe\u5ea6\u9636\u903c\u8fd1\u51fd\u6570, \u800c\u7f51\u7edc\u7684\u590d\u6742\u5ea6\u9636\u51e0\u4e4e\u76f8\u540c. \u7279\u522b\u5730, \u5f53\u4e00\u4e2a\u51fd\u6570\u662f\u5947\u5f02\u7684, \u4f1a\u4ea7\u751f\u4e00\u4e2a\u5177\u6709\u66f4\u591a\u5c42\u7684\u7a00\u758f\u7f51\u7edc\u6765\u6355\u83b7\u8be5\u51fd\u6570\u7684\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u4fe1\u606f. \u4e0d\u7ba1\u51fd\u6570\u662f\u5426\u5149\u6ed1, \u7f51\u7edc\u590d\u6742\u5ea6\u51e0\u4e4e\u4e0e\u903c\u8fd1\u8bef\u5dee\u7684\u5012\u6570\u6210\u6b63\u6bd4. \u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8003\u8651\u4e24\u4e2a\u4f8b\u5b50: (1) \u4e00\u7ef4\u51fd\u6570 (2) \u4e8c\u7ef4\u51fd\u6570. In our first example, we consider approximation of the quadratic function \u5728\u7b2c\u4e00\u4e2a\u4f8b\u5b50\u4e2d, \u6211\u4eec\u4f7f\u7528 SDNN \u5bf9\u4e8c\u6b21\u51fd\u6570\u548c\u4e8c\u6b21\u5206\u6bb5\u51fd\u6570\u8fdb\u884c\u8fd1\u4f3c. \\[ f(x) := x^2, \\tag{11} \\] and the piecewise quadratic function by SDNN . \\[ f(x) = \\begin{cases} x^2 + 1, &x \\geq 0,\\\\ x^2, &x < 0, \\end{cases}\\tag{12} \\] Note that the function defined by (11) is smooth and the function by (12) has a jump discontinuity at the point \\(0\\) . We applied the sparse regularized network having the architecture \\([1, 10, 10, 10, 10, 1]\\) to learn these functions. We divide the interval \\([-2, 2]\\) by the nodes \\(x_j:= -2 + jh\\) , for \\(j := 0, 1,\\cdots, 200\\) , with \\(h := 1/50\\) , and sample the functions \\(f\\) at \\(x_j\\) . The test set is \\(\\{(x_k, f(x_k))\\}\\) , where \\(x_k:= -2 + kh, h := 1/30, k = 0, 1,\\cdots, 120\\) . The network is trained by the Adam algorithm with epochs \\(20,000\\) and initial learning rate \\(0.001\\) . For function (11) , regularization parameters are set to be \\([0, 10^{-4}, 10^{-4}, 10^{-3},10^{-3}]\\) . We obtain the prediction error \\(5.94\\times10^{-3}\\) for the test set. Sparsity of the resulting weight matrices is \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) and the number of nonzero weight matrix entries is \\(31\\) . Left of Figure 1 shows the reconstructed SDNN for the function defined by (11) . \u6ce8\u610f\u7531 (11) \u5b9a\u4e49\u7684\u51fd\u6570\u662f\u5149\u6ed1\u7684, (12) \u5b9a\u4e49\u7684\u51fd\u6570\u5728\u70b9 \\(0\\) \u5904\u662f\u8df3\u8dc3\u95f4\u65ad\u7684. \u6211\u4eec\u4f7f\u7528\u7f51\u7edc\u67b6\u6784\u4e3a \\([1, 10, 10, 10, 10, 1]\\) \u7684\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u6765\u5b66\u4e60\u8fd9\u4e9b\u51fd\u6570. \u6211\u4eec\u5c06\u533a\u95f4 \\([-2,2]\\) \u8fdb\u884c\u4e24\u767e\u7b49\u5206, \u5e76\u5728\u8fd9\u4e9b\u70b9\u4e0a\u91c7\u6837 \\(f\\) . \u6d4b\u8bd5\u96c6\u5219\u662f\u5c06\u533a\u95f4\u4e00\u767e\u4e8c\u5341\u7b49\u5206. \u7f51\u7edc\u901a\u8fc7 Adam \u7b97\u6cd5\u8bad\u7ec3 \\(20,000\\) \u4e2a epochs, \u521d\u59cb\u5b66\u4e60\u7387\u4e3a \\(0.001\\) . \u5bf9\u4e8e\u51fd\u6570 (11) , \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([0, 10^{-4}, 10^{-4}, 10^{-3},10^{-3}]\\) . \u6211\u4eec\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u4e86 \\(5.94\\times10^{-3}\\) \u7684\u9884\u6d4b\u8bef\u5dee. \u5f97\u5230\u7684\u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) , \u6743\u91cd\u77e9\u9635\u5143\u7d20\u975e\u96f6\u6570\u91cf\u4e3a \\(31\\) . \u56fe 1 \u7684\u5de6\u56fe\u5c55\u793a\u4e86\u903c\u8fd1\u51fd\u6570 (11) \u7684 SDNN \u7684\u91cd\u6784\u7ed3\u679c. For function (12) the regularization parameters are chosen as \\([10^{-5}, 10^{-4}, 10^{-4},10^{-4}, 10^{-3}]\\) . We obtain the prediction error \\(5.42\\times10^{-3}\\) for the test set. Sparsity of the resulting weight matrices is \\([50\\%, 93.0\\%, 88.0\\%, 93.0\\%, 90.0\\%]\\) and the number of nonzero weight matrix entries is 32. The reconstructed function is shown in Right of Figure 1 . \u5bf9\u4e8e\u51fd\u6570 (12) , \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([10^{-5}, 10^{-4}, 10^{-4},10^{-4}, 10^{-3}]\\) . \u6211\u4eec\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u4e86 \\(5.42\\times10^{-3}\\) \u7684\u9884\u6d4b\u8bef\u5dee. \u5f97\u5230\u7684\u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) , \u6743\u91cd\u77e9\u9635\u5143\u7d20\u975e\u96f6\u6570\u91cf\u4e3a \\(32\\) . \u56fe 1 \u7684\u53f3\u56fe\u5c55\u793a\u4e86\u903c\u8fd1\u51fd\u6570 (12) \u7684 SDNN \u7684\u91cd\u6784\u7ed3\u679c. Figure 1 : Numerical results of SDNN : for function (11) (Left); for function (12) (Right) Numerical results for both functions (11) and (12) are summarized in Table 1 . These results demonstrate that even though the function (12) has a jump discontinuity at the point \\(0\\) , the proposed SDNN model can generate a network with nearly the same number of nonzero weight matrix entries and with the same accuracy as those for the smooth function (11) . This shows that the proposed SDNN model has a good adaptive approximation property. \u8868\u683c 1 \u603b\u7ed3\u4e86 (11) \u548c (12) \u7684\u6570\u503c\u7ed3\u679c. \u8fd9\u4e9b\u7ed3\u679c\u8bf4\u660e\u4e86\u5c3d\u7ba1\u51fd\u6570 (12) \u5728 \\(0\\) \u5904\u8df3\u8dc3\u95f4\u65ad, \u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u80fd\u591f\u751f\u6210\u548c\u903c\u8fd1\u5149\u6ed1\u51fd\u6570 (11) \u65f6\u975e\u96f6\u6743\u91cd\u77e9\u9635\u5143\u7d20\u6570\u91cf\u51e0\u4e4e\u76f8\u540c\u4e14\u7cbe\u5ea6\u76f8\u540c\u7684\u7f51\u7edc. \u8fd9\u8bf4\u660e\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u6709\u826f\u597d\u7684\u81ea\u9002\u5e94\u903c\u8fd1\u6027\u8d28. Results for function (11) (12) Regularization parameters \\([0, 10^{-4}, 10^{-4}, 10^{-3}, 10^{-3}]\\) \\([10^{-5}, 10^{-4}, 10^{-4}, 10^{-4}, 10^{-3}]\\) Relative \\(L_2\\) error \\(5.94\\times10^{-3}\\) \\(5.42\\times10^{-3}\\) Sparsity of weight matrices \\([0.0\\%, 87.0\\%, 95.0\\%, 98.0\\%, 90.0\\%]\\) \\([50\\%, 93.0\\%, 88.0\\%, 93.0\\%, 90.0\\%]\\) No. of nonzero entries 31 32 Table 1 : Numerical result for quadratic function (11) and piecewise quadratic function (12) with network structure \\([1, 10, 10, 10, 10, 1]\\) . In our second example, we consider approximation of two-dimensional functions, once again one smooth function and one discontinuous function. We study smooth function \u5728\u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8003\u8651\u4e8c\u7ef4\u51fd\u6570, \u540c\u6837\u662f\u4e00\u4e2a\u5149\u6ed1\u51fd\u6570, \u4e00\u4e2a\u662f\u4e0d\u8fde\u7eed\u51fd\u6570. \u5149\u6ed1\u51fd\u6570\u7684\u56fe\u50cf\u5728\u56fe 2 \u5de6\u56fe\u5c55\u793a, \u5206\u6bb5\u51fd\u6570\u7684\u56fe\u50cf\u5728\u56fe 3 \u5de6\u56fe\u5c55\u793a. \\[ g(x, y) := e^{2x+y^2},\\tag{13} \\] whose image is illustrated in Figure 2 (Left), and piecewise function \\[ g_d(x, y) = \\begin{cases} e^{2x+y^2} + 1, &x \\geq 0,\\\\ e^{2x+y^2}, &x < 0,\\\\ \\end{cases}\\tag{14} \\] whose image is illustrated in Figure 3 (Left). Note that function (13) is smooth and function (14) has a jump discontinuity along \\(x = 0\\) . \u6ce8\u610f\u51fd\u6570 (13) \u662f\u5149\u6ed1\u7684, \u51fd\u6570 (14) \u6cbf\u7740 \\(x=0\\) \u6709\u8df3\u8dc3\u95f4\u65ad. For these two functions, the training data set is composed of grid points \\([-1, 1]\\times[-1, 1]\\) uniformly discretized with step size \\(1/200\\) on \\(x\\) and \\(y\\) direction, and the test set is composed of grid points \\([-1, 1]\\times[-1, 1]\\) uniformly discretized with step size \\(1/300\\) on the \\(x\\) and \\(y\\) directions. The network has \\(2\\) inputs, \\(4\\) hidden layers, and \\(1\\) output, with the architecture \\([2, 20, 20, 20, 20, 1]\\) . For each hidden layer, there are \\(20\\) neurons. The initial learning rate for Adam is set to \\(0.001\\) . The batch size is equal to \\(1024\\) . \u5bf9\u4e8e\u8fd9\u4e24\u4e2a\u51fd\u6570, \u8bad\u7ec3\u6570\u636e\u7531\u5bf9\u5b9a\u4e49\u57df \\([-1, 1]\\times[-1, 1]\\) \u5728 \\(x\\) \\(y\\) \u4e24\u4e2a\u65b9\u5411\u6b65\u957f\u4e3a \\(1/200\\) \u5f97\u5230\u7684\u7f51\u683c\u70b9\u7ec4\u6210, \u6d4b\u8bd5\u96c6\u5219\u8fdb\u884c\u4e09\u767e\u7b49\u5206. \u7f51\u7edc\u6709\u4e24\u4e2a\u8f93\u5165, \u56db\u5c42\u9690\u85cf\u5c42\u548c\u4e00\u4e2a\u8f93\u51fa, \u7f51\u7edc\u7ed3\u6784\u4e3a \\([2, 20, 20, 20, 20, 1]\\) . \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u9690\u85cf\u5c42, \u90fd\u6709\u4e8c\u5341\u4e2a\u795e\u7ecf\u5143. Adam \u521d\u59cb\u5b66\u4e60\u7387\u4e3a 0.001. \u6279\u91cf\u5927\u5c0f\u53d6 1024. For function (13) we set the sparse regularization parameters as \\([0, 10^{-6}, 10^{-4},10^{-4}, 10^{-4}]\\) . After \\(10,000\\) epochs training, the sparsity of weight matrices is \\([0.0\\%, 68.5\\%, 95.75\\%, 97.75\\%, 80.0\\%]\\) and the number of nonzero weight matrix entries is \\(178\\) . The prediction error for the test set is \\(4.38\\times10^{-3}\\) . For function (14) , the regularization parameters are set to be \\([10^{-4}, 10^{-5}, 10^{-5}, 10^{-4}, 10^{-4}]\\) . The sparsity of weight matrices after regularization are \\([60.0\\%, 71.75\\%, 81.75\\%, 97.5\\%, 90.0\\%]\\) and the number of nonzero weight matrix entries is \\(206\\) . The prediction error for sparse regularized deep neural network is \\(4.27\\times10^{-3}\\) , which is even slightly better than that for function (13) . The images of the reconstructed functions are shown respectively in Figures 2 , Figure 3 (Right). Numerical results for this example are reported in Table 2 . \u5bf9\u4e8e\u51fd\u6570 (13) , \u6211\u4eec\u8bbe\u7f6e\u7a00\u758f\u6b63\u5219\u5316\u53c2\u6570\u4e3a \\([0, 10^{-6}, 10^{-4},10^{-4}, 10^{-4}]\\) . \u5728 \\(10,000\\) \u4e2a epochs \u8bad\u7ec3\u540e, \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([0.0\\%, 68.5\\%, 95.75\\%, 97.75\\%, 80.0\\%]\\) \u4e14\u975e\u96f6\u6743\u91cd\u77e9\u9635\u5143\u7d20\u6570\u91cf\u4e3a \\(178\\) . \u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(4.38\\times10^{-3}\\) . \u5bf9\u4e8e\u51fd\u6570 (14) , \u6211\u4eec\u8bbe\u7f6e\u7a00\u758f\u6b63\u5219\u5316\u53c2\u6570\u4e3a \\([10^{-4}, 10^{-5}, 10^{-5}, 10^{-4}, 10^{-4}]\\) . \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([60.0\\%, 71.75\\%, 81.75\\%, 97.5\\%, 90.0\\%]\\) \u4e14\u975e\u96f6\u6743\u91cd\u77e9\u9635\u5143\u7d20\u6570\u91cf\u4e3a \\(206\\) . \u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(4.27\\times10^{-3}\\) , \u751a\u81f3\u6bd4\u51fd\u6570 (13) \u7684\u7ed3\u679c\u8fd8\u7a0d\u5fae\u597d\u4e00\u70b9. \u91cd\u6784\u7684\u51fd\u6570\u56fe\u50cf\u5206\u522b\u5728\u56fe 2 \u53f3\u56fe\u548c\u56fe 3 \u53f3\u56fe\u5c55\u793a. \u8868\u683c 2 \u62a5\u544a\u4e86\u8fd9\u4e2a\u4f8b\u5b50\u7684\u6570\u503c\u7ed3\u679c. Figure 2 : Left: image of function \\(e^{2x+y^2}\\) . Right: predicted by fully connected neural network. Figure 3 : image of piecewise discontinuous function (14) . Right: predicted by sparse regularized neural network. Results for function (13) (14) Regularization parameters \\([0, 10^{-6}, 10^{-4}, 10^{-4}, 10^{-4}]\\) \\([10^{-4}, 10^{-5}, 10^{-5}, 10^{-4}, 10^{-4}]\\) Relative \\(L_2\\) error \\(4.38\\times10^{-3}\\) \\(4.27\\times10^{-3}\\) Sparsity of weight matrices \\([0.0\\%, 68.5\\%, 95.75\\%, 97.75\\%, 80.0\\%]\\) \\([60.0\\%, 71.75\\%, 81.75\\%, 97.5\\%, 90.0\\%]\\) No. of nonzero entries 178 206 Table 2 : Numerical result for two dimensional function (13) and (14) with network structure \\([2,20, 20, 20, 20, 1]\\) . The numerical results presented in this subsection indicate that indeed the proposed SDNN model has an excellent adaptivity property in the sense that it generates networks with nearly the same number of nonzero weight matrix entries and the same order of approximation accuracy for functions regardless their smoothness. \u8fd9\u4e00\u5c0f\u8282\u5c55\u793a\u7684\u6570\u503c\u7ed3\u679c\u6307\u51fa\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u786e\u5b9e\u6709\u4f18\u79c0\u7684\u81ea\u9002\u5e94\u6027\u8d28, \u5373\u4e0d\u7ba1\u51fd\u6570\u5149\u6ed1\u6027\u5982\u4f55, \u6a21\u578b\u751f\u6210\u7684\u7f51\u7edc\u5177\u6709\u51e0\u4e4e\u76f8\u540c\u7684\u6743\u91cd\u533a\u95f4\u975e\u96f6\u8881\u672f\u6570\u91cf\u548c\u76f8\u540c\u8fd1\u4f3c\u7cbe\u5ea6\u7684\u9636\u6570.","title":"Intrinsic Adaptivity of the SDNN Model"},{"location":"Scholars/PN-2207.13266/#an-example-of-adaptive-function-approximation-by-the-sdnn-model","text":"The second experiment is designed to test the sparsity of the network learned from the SDNN model (10) and the model\u2019s generalization ability. Specifically, in this example, we demonstrate that the sparse model (10) leads to a sparse DNN with higher accuracy in comparison to the standard DNN model (9) . We consider the absolute value function \u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u65e8\u5728\u6d4b\u8bd5\u4ece SDNN \u6a21\u578b\u5b66\u4e60\u5230\u7684\u7f51\u7edc\u7684\u7a00\u758f\u6027\u548c\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b. \u5177\u4f53\u5730, \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\u6211\u4eec\u8bc1\u660e\u4e86\u7a00\u758f\u6a21\u578b\u80fd\u591f\u5bfc\u51fa\u76f8\u6bd4\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u9ad8\u7cbe\u5ea6\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc. \u6211\u4eec\u8003\u8651\u7edd\u5bf9\u503c\u51fd\u6570 \\[ y = f(x) := |x|, \\text{for} x \\in \\mathbb{R}. \\] Note that function \\(f\\) is not differentiable at \\(x = 0\\) . \u6ce8\u610f\u51fd\u6570 \\(f\\) \u5728 \\(x=0\\) \u5904\u4e0d\u53ef\u5fae. We adopt the same network architecture, that is, \\(1\\) input layer, \\(2\\) hidden layers, \\(1\\) output layer and each hidden layer containing \\(5\\) neurons, for both the standard DNN model (9) and the SDNN model (10) . The training set is composed of equal-distance grid points laying in \\([-2, 2]\\) with step size \\(0.01\\) . The test set is composed of equal-distance grid points in \\([-5, 5]\\) with step size \\(0.1\\) . For the sparse regularized network, the regularization parameters are set as \\([10^{-4}, 10^{-3}, 10^{-3}]\\) . For both the standard DNN model and the SDNN model, the number of epoch equals \\(10,000\\) . The initial learning rate is set to \\(0.001\\) . \u6211\u4eec\u5bf9\u4e8e\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b (9) \u548c SDNN \u6a21\u578b (10) \u91c7\u7528\u76f8\u540c\u7684\u7f51\u7edc\u67b6\u6784, \u5373\u4e00\u5c42\u8f93\u5165\u5c42, \\(2\\) \u5c42\u9690\u85cf\u5c42, \\(1\\) \u5c42\u8f93\u51fa\u5c42, \u6bcf\u5c42\u9690\u85cf\u5c42\u6709 \\(5\\) \u4e2a\u795e\u7ecf\u5143. \u8bad\u7ec3\u96c6\u7531\u5728\u533a\u95f4 \\([-2,2]\\) \u4e0a\u8bbe\u7f6e\u6b65\u957f\u4e3a \\(0.01\\) \u7684\u7b49\u8ddd\u683c\u70b9\u7ec4\u6210. \u6d4b\u8bd5\u96c6\u7531\u5728\u533a\u95f4 \\([-5,5]\\) \u4e0a\u8bbe\u7f6e\u6b65\u957f\u4e3a \\(0.1\\) \u7684\u7b49\u8ddd\u683c\u70b9\u7ec4\u6210. \u5bf9\u4e8e\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc, \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([10^{-4}, 10^{-3}, 10^{-3}]\\) . \u5bf9\u4e8e\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u548c SDNN \u6a21\u578b, epochs \u7684\u6570\u91cf\u5747\u4e3a \\(10,000\\) . \u521d\u59cb\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a \\(0.001\\) . We present numerical results of this experiment in Table 3 , where we compare errors and sparsity of the functions learned from the two models. Clearly, the network learned from the standard DNN model is non-sparse: all entries of its weight matrices are nonzero. While the network learned from the SDNN model has a good sparsity property: There are only \\(1\\) non-zero entries in \\(W_3\\) and \\(2\\) non-zero entries in \\(W_2\\) in the network learned from the SDNN model. Note that the absolution value function is the linear composition of two ReLU functions, that is \\(|x| = \\text{ReLU}(x)+\\text{ReLU}(-x)\\) . The SDNN model is able to find a linear combination of the two functions to represent the function \\(f(x) := |x|\\) but the standard DNN model fails to do so. \u6211\u4eec\u5728\u8868\u683c 3 \u4e2d\u5c55\u793a\u4e86\u8fd9\u4e00\u5b9e\u9a8c\u7684\u6570\u503c\u7ed3\u679c, \u5176\u4e2d\u6211\u4eec\u5bf9\u6bd4\u4e86\u4ece\u4e24\u4e2a\u6a21\u578b\u5b66\u4e60\u5230\u7684\u51fd\u6570\u7684\u8bef\u5dee\u548c\u7a00\u758f\u5ea6. \u5f88\u660e\u663e, \u4ece\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\u5b66\u4e60\u5f97\u7f51\u7edc\u662f\u975e\u7a00\u758f\u7684: \u6743\u91cd\u77e9\u9635\u7684\u6240\u6709\u5143\u7d20\u90fd\u4e0d\u4e3a\u96f6. \u800c\u4ece SDNN \u6a21\u578b\u4e2d\u5b66\u4e60\u7684\u7f51\u7edc\u7531\u826f\u597d\u7684\u7a00\u758f\u6027\u8d28: \\(W_3\\) \u4e2d\u53ea\u6709\u4e00\u4e2a\u975e\u96f6\u5143\u7d20, \\(W_2\\) \u4e2d\u53ea\u6709\u4e24\u4e2a\u975e\u96f6\u5143\u7d20. \u6ce8\u610f\u7edd\u5bf9\u503c\u51fd\u6570\u662f\u4e24\u4e2a\u6574\u6d41\u7ebf\u6027\u5355\u5143\u7684\u7ebf\u6027\u7ec4\u5408, \u5373 \\(|x| = \\text{ReLU}(x)+\\text{ReLU}(-x)\\) . SDNN \u6a21\u578b\u80fd\u591f\u627e\u5230\u4e24\u4e2a\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u6765\u8868\u793a\u7edd\u5bf9\u503c\u51fd\u6570, \u800c\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5219\u4e0d\u884c. Model Relative \\(L_2\\) error Sparsity of weight matrices \\([W_1, W_2, W_3]\\) Standard DNN model \\(5.58\\times10^{-2}\\) \\([0\\%, 0\\%, 0\\%]\\) SDNN model \\(1.87\\times10^{-3}\\) \\([20\\%, 92\\%, 80\\%]\\) Table 3 : Approximation of the absolute value function by a SDNN with regularization parameters \\([10^{-4}, 10^{-3}, 10^{-3}]\\) . We plot the graphs of the reconstructed functions by the standard DNN model (9) and the SDNN model (10) in Figure 4 and Figure 5 , respectively. It can be seen from Figure 4 that the function reconstructed by the standard DNN model (9) has large errors in the interval \\([3, 5]\\) . Figure 5 shows that the function reconstructed by the SDNN model (10) almost coincides with the original function. This example indicates that the SDNN model (10) has better generalization ability than the standard DNN model (9) . \u6211\u4eec\u5206\u522b\u5728\u56fe 4 \u548c\u56fe 5 \u4e2d\u7ed8\u5236\u4e86\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u548c SDNN \u6a21\u578b\u7684\u91cd\u6784\u51fd\u6570. \u53ef\u4ee5\u4ece\u56fe 4 \u4e2d\u770b\u5230\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u91cd\u6784\u51fd\u6570\u5728\u533a\u95f4 \\([3,5]\\) \u4e0a\u6709\u8f83\u5927\u8bef\u5dee. \u56fe 5 \u5219\u5c55\u793a\u4e86 SDNN \u6a21\u578b\u548c\u539f\u59cb\u51fd\u6570\u57fa\u672c\u76f8\u7b26. \u8fd9\u4e00\u4f8b\u5b50\u8bf4\u660e\u4e86 SDNN \u6a21\u578b\u6bd4\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. Figure 4 (Left) : Reconstruction of function \\(f(x) := |x|\\) by the standard DNN model (9) . Figure 5 (Right) : Reconstruction of function \\(f(x) := |x|\\) by the SDNN model (10) .","title":"An Example of Adaptive Function Approximation by the SDNN Model"},{"location":"Scholars/PN-2207.13266/#reconstruction-of-a-black-hole","text":"In this example, we consider reconstruction of the image of a black hole by the SDNN model. Specifically, we compare numerical results and reconstructed image quality of the SDNN model with those of the standard DNN model. We choose a color image of the black hole shown in Figure 6 (Left), which is turned into a gray image shown in Figure 6 (Right). The image has the size \\(128 \\times 128\\) and can be represented as a two-dimensional discrete function. The value of the gray image at the point \\((x_1, x_2)\\) is defined as a \\(f_{image}(x_1, x_2), x_1, x_2= 1, 2,\\cdots, 128\\) . The function clearly has singularities. \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d, \u6211\u4eec\u8003\u8651\u901a\u8fc7 SDNN \u6a21\u578b \u91cd\u6784\u9ed1\u6d1e\u56fe\u50cf. \u5177\u4f53\u5730, \u6211\u4eec\u5c06\u6bd4\u8f83 SDNN \u6a21\u578b\u548c\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u6570\u503c\u7ed3\u679c\u548c\u91cd\u6784\u56fe\u50cf\u8d28\u91cf. \u6211\u4eec\u9009\u62e9\u56fe 6 \u5de6\u56fe\u6240\u793a\u7684\u9ed1\u6d1e\u7684\u5f69\u8272\u56fe\u7247, \u8f6c\u5316\u4e3a\u56fe 6 \u53f3\u56fe\u6240\u793a\u7684\u7070\u5ea6\u56fe\u7247. \u56fe\u7247\u5927\u5c0f\u4e3a \\(128\\times 128\\) \u80fd\u591f\u8868\u793a\u4e3a\u4e8c\u7ef4\u79bb\u6563\u51fd\u6570. \u7070\u5ea6\u56fe\u5728 \\((x_1,x_2)\\) \u7684\u503c\u5b9a\u4e49\u4e3a \\(f_{image}(x_1, x_2)\\) , \u8fd9\u4e2a\u51fd\u6570\u663e\u7136\u5177\u6709\u5947\u6027. Figure 6 : Left: color image of the black hole. Right: gray image of the black hole. The network architecture that we used for the construction is \\([2, 100, 100, 100, 100, 100, 100, 1]\\) . We randomly choose \\(5,000\\) points \\((x^i_1, x^i_2, f_{image}(x^i_1, x^i_2))\\) by uniform sampling, \\(i =1, 2,\\cdots, 5,000\\) , from the image of the black hole to train both the standard neural network and the sparse regularized network. The optimizer is chosen as the Adam algorithm with batch size \\(1,024\\) . The number of epoch is \\(40,000\\) . The patience parameter of early stopping is \\(200\\) . Prediction results by the standard DNN model and by the SDNN model are shown respectively on Figure 7 (Left) and (Right). \u6211\u4eec\u4f7f\u7528\u7684\u7f51\u7edc\u67b6\u6784\u4e3a \\([2, 100, 100, 100, 100, 100, 100, 1]\\) . \u6211\u4eec\u4ece\u9ed1\u6d1e\u56fe\u50cf\u4e2d\u5747\u5300\u91c7\u6837 \\(5,000\\) \u4e2a\u6837\u672c\u70b9 \\((x^i_1, x^i_2, f_{image}(x^i_1, x^i_2))\\) \u7528\u4e8e\u8bad\u7ec3\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc. \u9009\u62e9 Adam \u7b97\u6cd5\u4f5c\u4e3a\u4f18\u5316\u5668, \u6279\u91cf\u5927\u5c0f\u4e3a \\(1024\\) . epoch \u7684\u6570\u91cf\u4e3a \\(40,000\\) . \u65e9\u505c\u6cd5\u7684\u8010\u5fc3\u53c2\u6570\u8bbe\u7f6e\u4e3a \\(200\\) , \u5373\u5141\u8bb8 \\(200\\) \u4e2a epochs \u5185\u6a21\u578b\u6027\u80fd\u6ca1\u6709\u63d0\u5347. \u56fe 7 \u7684\u5de6\u56fe\u548c\u53f3\u56fe\u5206\u522b\u5c55\u793a\u4e86\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c SDNN \u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c. Figure 7 : Images of the black hole reconstructed: by the standard DNN model (Left) and by the SDNN model (Right). Error images of the two models are presented in Figure 8 , from which it can be seen that the sparse network has a smaller reconstruction error. The prediction error of the fully connected network is \\(9.66\\times10^{-3}\\) . For the sparse regularized neural network, the regularized parameters are set to be \\([10^{-9}, 10^{-9}, 10^{-9}, 10^{-9}, 10^{-8}, 10^{-8}, 10^{-8}]\\) . The prediction error of the sparse regularized network is \\(9.28\\times10^{-3}\\) . The sparsity of the weight matrices are \\([44.0\\%, 78.3\\%, 78.4\\%, 80.3\\%, 96.5\\%, 98.2\\%, 84.0\\%]\\) . It shows that the sparse regularized network uses fewer neurons and has smaller prediction error. This indicates that by using the proposed multi-parameter sparse regularization, the deep neural network has the ability of multi-scale and adaptive learning. \u4e24\u4e2a\u6a21\u578b\u7684\u8bef\u5dee\u56fe\u50cf\u5728\u56fe 8 \u4e2d\u5c55\u793a, \u80fd\u591f\u4ece\u4e2d\u770b\u5230\u7a00\u758f\u7f51\u7edc\u5177\u6709\u66f4\u5c0f\u7684\u91cd\u6784\u8bef\u5dee. \u5168\u8fde\u63a5\u7f51\u7edc\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(9.66\\times10^{-3}\\) . \u5bf9\u4e8e\u7a00\u758f\u6b63\u5219\u5316\u795e\u7ecf\u7f51\u7edc, \u6b63\u5219\u5316\u53c2\u6570\u8bbe\u7f6e\u4e3a \\([10^{-9}, 10^{-9}, 10^{-9}, 10^{-9}, 10^{-8}, 10^{-8}, 10^{-8}]\\) . \u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u7684\u9884\u6d4b\u8bef\u5dee\u4e3a \\(9.28\\times10^{-3}\\) . \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([44.0\\%, 78.3\\%, 78.4\\%, 80.3\\%, 96.5\\%, 98.2\\%, 84.0\\%]\\) . \u8fd9\u5c55\u793a\u4e86\u7a00\u758f\u6b63\u5219\u5316\u7f51\u7edc\u4f7f\u7528\u4e86\u66f4\u5c11\u7684\u795e\u7ecf\u5143\u4e14\u83b7\u5f97\u4e86\u66f4\u5c0f\u7684\u9884\u6d4b\u8bef\u5dee. \u8fd9\u8bf4\u660e\u4e86\u901a\u8fc7\u4f7f\u7528\u6211\u4eec\u63d0\u51fa\u7684\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316, \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c3a\u5ea6\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7684\u80fd\u529b. Figure 8 : Reconstruction errors of the black hole: by the standard DNN model (Left) and by the SDNN model (Right). Model Relative \\(L_2\\) error Sparsity of weight matrices Standard DNN model \\(9.66\\times10^{-3}\\) \\([0\\%, 0\\%, 0\\%, 0\\%, 0\\%, 0\\%, 0\\%]\\) SDNN model \\(9.28\\times10^{-3}\\) \\([44.0\\%, 78.3\\%, 78.4\\%, 80.3\\%, 96.5\\%, 98.2\\%, 84.0\\%]\\) Table 4 : Numerical results of the black hole reconstructed by the standard DNN model vs. the SDNN model.","title":"Reconstruction of A Black Hole"},{"location":"Scholars/PN-2207.13266/#numerical-solutions-of-partial-differential-equations","text":"We study in this section numerical performance of the proposed SDNN model for solving partial differential equations. We consider two equations: the Burgers equation and the Schr\u00f6dinger equation. For both of these two equations, we choose the hyperbolic tangent (tanh) function defined by \u672c\u8282\u6211\u4eec\u7814\u7a76\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6570\u503c\u6027\u80fd. \u6211\u4eec\u8003\u8651\u4e24\u4e2a\u65b9\u7a0b: Burgers \u65b9\u7a0b\u548c Schr\u00f6dinger \u65b9\u7a0b. \\[ \\tanh(x) := \\frac{e^x-e^{-x}}{e^x+ e^{-x}}, x \\in \\mathbb{R} \\] as the activation function to build networks for our approximate solutions due to its differentiability which is required by the differential equations. \u5bf9\u8fd9\u4e24\u4e2a\u65b9\u7a0b, \u6211\u4eec\u90fd\u4f7f\u7528\u53cc\u66f2\u6b63\u5207\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\u6765\u5efa\u7acb\u7f51\u7edc\u4ee5\u8fd1\u4f3c\u89e3\u51fd\u6570. \u8fd9\u662f\u56e0\u4e3a\u5b83\u7684\u53ef\u5fae\u5206\u6027\u6b63\u662f\u5fae\u5206\u65b9\u7a0b\u6240\u8981\u6c42\u7684.","title":"Numerical Solutions of Partial Differential Equations"},{"location":"Scholars/PN-2207.13266/#the-burgers-equation","text":"The Burgers equation has attracted much attention since it is often used as simplified model for turbulence and shock waves 31 . It is well-known that the solution of this equation presents a jump discontinuity (a shock wave), even though the initial function is smooth. Burgers \u65b9\u7a0b\u7531\u4e8e\u7ecf\u5e38\u4f5c\u4e3a\u6e4d\u6d41\u548c\u6fc0\u6ce2\u7684\u7b80\u5316\u6a21\u578b\u800c\u53d7\u5230\u5f88\u591a\u5173\u6ce8. \u4f17\u6240\u5468\u77e5\u5373\u4f7f\u521d\u59cb\u51fd\u6570\u662f\u5149\u6ed1\u7684, \u8fd9\u4e2a\u65b9\u7a0b\u7684\u89e3\u4e5f\u5b58\u5728\u8df3\u8dc3\u4e0d\u8fde\u7eed\u6027 (\u6fc0\u6ce2). In this example, we consider the following one dimensional Burgers equation \u5728\u8fd9\u4e00\u4f8b\u5b50\u4e2d, \u6211\u4eec\u8003\u8651\u5982\u4e0b\u4e00\u7ef4 Burgers \u65b9\u7a0b. \\[ \\begin{align} &u_t(t, x) + u(t, x)u_x(t, x) - \\frac{0.01}{\\pi} u_{xx}(t, x) = 0, &t \\in (0, 1], x \\in (-1, 1), \\tag{15}\\\\ &u(0, x) = - \\sin(\\pi x),\\tag{16}\\\\ &u(t,-1) = u(t, 1) = 0.\\tag{17} \\end{align} \\] The analytic solution of this equation, known in 2 , will be used as our exact solution for comparison. Indeed, the analytic solution has the form \u8fd9\u4e00\u65b9\u7a0b\u7684\u89e3\u6790\u89e3\u5c06\u4f5c\u4e3a\u6211\u4eec\u7684\u7cbe\u786e\u89e3\u4ee5\u8fdb\u884c\u5bf9\u6bd4. \u89e3\u6790\u89e3\u7684\u5f62\u5f0f\u5982\u4e0b \\[ u(t, x) := -\\frac{\\int_{-\\infty}^\\infty \\sin\\pi(x-\\eta)h(x-\\eta)\\exp(-\\eta^2/4vt)\\text{d}\\eta}{\\int_{-\\infty}^\\infty h(x-\\eta)\\exp(-\\eta^2/4vt)\\text{d}\\eta}t \\in [0, 1], x \\in [-1, 1], \\] where \\(\u03bd := \\dfrac{0.01}{\\pi}\\) and \\(h(y) := \\exp(-\\cos \\pi y/2\\pi \u03bd)\\) . A neural network solution of equation (15) - (17) was obtained recently from the standard DNN model in 35 . \u4e0a\u8ff0\u65b9\u7a0b\u7684\u795e\u7ecf\u7f51\u7edc\u89e3\u662f\u4ece PINN \u8bba\u6587\u7684\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u83b7\u5f97\u7684. We apply the setting (1) - (3) with \u6211\u4eec\u5c06\u504f\u5fae\u5206\u65b9\u7a0b\u4e00\u822c\u5f62\u5f0f\u4ee3\u5165\u53ef\u77e5 \\[ \\mathcal{F}(u(t, x)) := u_t(t, x) + u(t, x)u_x(t, x) - \\frac{0.01}{\\pi} u_{xx}(t, x), t \\in (0, 1], x \\in (-1, 1). \\] Let \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) denote the training data of \\(u\\) satisfying initial condition (16) , that is, \\(u^i_0= - \\sin(\\pi x^i_0)\\) . Let \\(\\{t^i_{b_1}\\}_{i=1}^{N_{b_1}}\\) and \\(\\{t^i_{b_2}\\}_{i=1}^{N_{b_2}}\\) be the collocation points related to boundary condition (17) for \\(x = -1\\) and \\(x = 1\\) respectively. We denote by \\(\\{t^i_f, x^i_f\\}_{i=1}^{N_f}\\) the collocation points for \\(\\mathcal{F}(u(t, x))\\) in \\([0, 1]\\times(-1, 1)\\) . The sparse deep neural network \\(\\mathcal{N}_\\Theta (t, x)\\) are learned by model (8) with \u4ee4 \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) \u8868\u793a \\(u\\) \u6ee1\u8db3\u521d\u59cb\u6761\u4ef6\u7684\u8bad\u7ec3\u6570\u636e, \u5373 \\(u^i_0= - \\sin(\\pi x^i_0)\\) . \u4ee4 \\(\\{t^i_{b_1}\\}_{i=1}^{N_{b_1}}\\) \u548c \\(\\{t^i_{b_2}\\}_{i=1}^{N_{b_2}}\\) \u5206\u522b\u8868\u793a\u4e0e\u8fb9\u754c\u6761\u4ef6 \\(x=-1\\) \u548c \\(x=1\\) \u76f8\u5173\u7684\u914d\u7f6e\u70b9. \u4ee4 \\(\\{t^i_f, x^i_f\\}_{i=1}^{N_f}\\) \u8868\u793a\u6ee1\u8db3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u914d\u7f6e\u70b9. \u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta (t, x)\\) \u901a\u8fc7\u6a21\u578b (8) \u53ca\u4ee5\u4e0b\u635f\u5931\u8fdb\u884c\u5b66\u4e60. \\[ \\begin{aligned} Loss_0 &=\\frac{1}{N_0}\\sum_{i=1}^{N_0}|\\mathcal{N}_\\Theta (0, x^i_0) - u^i_0|^2,\\\\ Loss_b &=\\frac{1}{N_b}\\sum_{i=1}^{N_b}|\\mathcal{N}_\\Theta (t^i_{b_1}, -1)| +\\frac{1}{N_{b_2}}\\sum_{i=1}^{N_{b_2}}|\\mathcal{N}_\\Theta (t^i_{b_2}, 1)|. \\end{aligned} \\] In this experiment, \\(100\\) data points are randomly selected from boundary and initial data points, among which \\(N_{b_1}= 25\\) points are located on the boundary \\(x = -1\\) , \\(N_{b_2}= 23\\) points on the boundary \\(x = 1\\) , and \\(N_0= 52\\) points on the initial line \\(t = 0\\) . The distribution of random collocation points is shown in the top of Figure 9 . The number of collocation points of the partial differential equation is \\(N_f= 10,000\\) by employing the Latin hypercube sampling method. The test set is composed of grid points \\([0, 1] \\times [-1, 1]\\) uniformly discretized with step size \\(1/100\\) on the \\(t\\) direction and step size \\(2/255\\) on the \\(x\\) direction. \u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d, \u4ece\u8fb9\u754c\u548c\u521d\u59cb\u6570\u636e\u70b9\u968f\u673a\u9009\u62e9 \\(100\\) \u4e2a\u6570\u636e\u70b9: \\(N_{b_1}= 25\\) \u4e2a\u5728\u8fb9\u754c \\(x=-1\\) \u4e0a, \\(N_{b_2}=23\\) \u4e2a\u5728\u8fb9\u754c \\(x=1\\) \u4e0a, \\(N_0=52\\) \u4e2a\u5728\u521d\u59cb\u7ebf \\(t=0\\) \u4e0a. \u968f\u673a\u914d\u7f6e\u70b9\u7684\u5206\u5e03\u5c55\u793a\u5728\u56fe 9 \u7684\u9876\u90e8. \u504f\u5fae\u5206\u65b9\u7a0b\u7684\u914d\u7f6e\u70b9\u6570\u91cf\u4e3a \\(N_f=10,000\\) \u901a\u8fc7 LHS \u91c7\u6837\u65b9\u6cd5\u83b7\u5f97. \u6d4b\u8bd5\u96c6\u5219\u7531\u5b9a\u4e49\u57df \\([0, 1] \\times [-1, 1]\\) \u4e0a\u65f6\u95f4 \\(t\\) \u65b9\u5411\u6b65\u957f\u4e3a \\(0.01\\) , \\(x\\) \u65b9\u5411\u4e0a\u6b65\u957f\u4e3a \\(2/225\\) \u7684\u5747\u5300\u7f51\u683c\u70b9\u7ec4\u6210. Figure 9 : Burgers equation: Top: The training data and predicted solution \\(u(t, x)\\) for sparse deep neural network with \\([2, 50, 50, 50, 1]\\) , regularization parameter \\(\\alpha = [10^{-6}, 10^{-6}, 10^{-6}, 10^{-4}]\\) , \\(\\beta = 20\\) . Bottom: Predicted solution \\(u(t, x)\\) at time \\(t = 0.3\\) , \\(t = 0.6\\) , and \\(t = 0.8\\) . We use two different network architectures \\([2, 50, 50, 50, 1]\\) and \\([2, 50, 50, 50,50, 50, 50, 50, 1]\\) for DNNs. We choose Adam as the optimizer for both neural networks. The number of epoch is \\(30,000\\) . The initial learning rate is set to \\(0.001\\) . Numerical results of these two networks presented respectively in Table 5 and Table 6 show that the proposed SDNN model outperforms the PINN model in both weight matrix sparsity and approximation accuracy. \u6211\u4eec\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784 \\([2, 50, 50, 50, 1]\\) \u548c \\([2, 50, 50, 50,50, 50, 50, 50, 1]\\) . \u6211\u4eec\u9009\u62e9 Adam \u4f5c\u4e3a\u4f18\u5316\u5668. epochs \u7684\u6570\u91cf\u4e3a \\(30,000\\) . \u521d\u59cb\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a \\(0.001\\) . \u8fd9\u4e24\u4e2a\u7f51\u7edc\u7684\u6570\u503c\u7ed3\u679c\u5206\u522b\u5c55\u793a\u5728\u8868\u683c 5 \u548c\u8868\u683c 6 \u91cc. \u8868\u683c\u8bf4\u660e\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u5728\u6743\u91cd\u77e9\u9635\u7a00\u758f\u5ea6\u548c\u8fd1\u4f3c\u8fdb\u5ea6\u4e0a\u90fd\u6bd4 PINN \u6a21\u578b\u4f18\u8d8a. Algorithms Parameters \\(\\alpha\\) & sparsity of weight matrices Relative L2error PINN No regularization \\([0.0\\%, 0.2\\%, 0.5\\%, 0.0\\%]\\) \\(2.45\\times10^{-2}\\) SDNN ( \\(\\beta=20\\) ) \\([10^{-6}, 10^{-6}, 10^{-6}, 10^{-4}]\\) \\([13.0\\%, 61.9\\%, 71.2\\%, 62.0\\%]\\) \\(1.68\\times10^{-3}\\) Table 5 : The Burgers equation: A neural network of \\(4\\) layers, with network architecture \\([2, 50,50, 50, 1]\\) . Algorithms Parameters \\(\\alpha\\) & sparsity of weight matrices Relative L2error PINN No regularization \\([0.0\\%, 0.8\\%, 0.6\\%, 0.6\\%, 0.8\\%, 0.6\\%, 0.4\\%, 0.0\\%]\\) \\(3.39\\times10^{-3}\\) SDNN ( \\(\\beta=10\\) ) \\([0, 0, 0, 0, 10^{-7}, 10^{-1}0, 10^{-6}, 10^{-5}]\\) \\([0.0\\%, 0.7\\%, 0.8\\%, 0.7\\%, 15.6\\%, 0.5\\%, 93.8\\%, 94.0\\%]\\) \\(1.45\\times10^{-4}\\) SDNN ( \\(\\beta=10\\) ) \\([10^{-6}, 10^{-6}, 10^{-6}, 10^{-6}, 10^{-6}, 10^{-6}, 10^{-5}, 10^{-5}]\\) \\([25.0\\%, 78.6\\%, 85.3\\%, 82.8\\%, 79.5\\%, 84.0\\%, 98.6\\%, 94.0\\%]\\) \\(4.83\\times10^{-4}\\) Table 6 : The Burgers equation: Neural networks of \\(8\\) layers with network architecture \\([2, 50, 50,50, 50, 50, 50, 50, 1]\\) .","title":"The Burgers Equation"},{"location":"Scholars/PN-2207.13266/#the-schrodinger-equation","text":"The Schr\u00f6dinger equation is the most essential equation of non-relativistic quantum mechanics. It plays an important role in studying nonlinear optics, Bose-Einstein condensates, protein folding and bending. It is also a model equation for studying waves propagation and soliton 36 . In this subsection, we consider a one-dimensional Schr\u00f6dinger equation with periodic boundary conditions Schr\u00f6dinger \u65b9\u7a0b\u662f\u975e\u76f8\u5bf9\u8bba\u91cf\u5b50\u529b\u5b66\u7684\u6700\u57fa\u672c\u7684\u65b9\u7a0b. \u5b83\u5728\u7814\u7a76\u975e\u7ebf\u6027\u5149\u5b66, Bose-Einstein \u51dd\u805a, \u86cb\u767d\u8d28\u6298\u53e0\u548c\u5f2f\u66f2\u65b9\u9762\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528. \u5b83\u4e5f\u662f\u7814\u7a76\u6ce2\u4f20\u64ad\u548c\u5b64\u5b50\u7684\u4e00\u4e2a\u6a21\u578b\u65b9\u7a0b. \u5728\u8fd9\u4e00\u5c0f\u8282\u4e2d, \u6211\u4eec\u8003\u8651\u5e26\u6709\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684\u4e00\u7ef4 Schr\u00f6dinger \u65b9\u7a0b. \\[ \\begin{aligned} &iu_t(t, x) + 0.5u_{xx}(t, x) + |u(t, x)|^2u(t, x) = 0, t \\in (0, \\pi/2], x \\in (-5, 5), \\\\ &u(0, x) = 2 \\text{sech}(x),\\\\ &u(t, -5) = u(t, 5), \\\\ &u_x(t, -5) = u_x(t, 5).\\tag{18} \\end{aligned} \\] Note that the solution \\(u\\) of problem (18) is a complex-valued function. The goal of this study is to test the effectiveness of the proposed SDNN model in solving complex-valued nonlinear differential equations with periodic boundary conditions, with a comparison to the standard DNN model recently developed in 35 . \u6ce8\u610f\u5230\u8fd9\u4e00\u95ee\u9898\u7684\u89e3 \\(u\\) \u662f\u4e00\u4e2a\u590d\u503c\u51fd\u6570. \u8fd9\u4e00\u7814\u7a76\u7684\u76ee\u7684\u662f\u6d4b\u8bd5\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u5728\u6c42\u89e3\u5e26\u6709\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684\u590d\u503c\u975e\u7ebf\u6027\u5fae\u5206\u65b9\u7a0b\u5f97\u5230\u6709\u6548\u6027, \u5e76\u4e0e\u57fa\u4e8e PINN \u7684\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83. Problem (18) falls into the setting (1) - (3) with \u4e0a\u8ff0\u95ee\u9898\u4ee3\u5165\u4e00\u822c\u504f\u5fae\u5206\u65b9\u7a0b\u8bbe\u7f6e\u53ef\u77e5 \\[ \\mathcal{F}(u(t, x)) := iu_t(t, x) + 0.5u_{xx}(t, x) + |u(t, x)|^2u(t, x), t \\in (0, \\pi/2], x \\in (-5, 5). \\] Let \\(\\psi\\) and \\(\\phi\\) be respectively the real part and imaginary part of the solution \\(u\\) of problem (18) . We intend to approximate the solution \\(u(t, x)\\) by a neural network \\(\\mathcal{N}_\\Theta (t, x)\\) with two inputs \\((t, x)\\) and two outputs which approximate \\(\\psi(t, x)\\) and \\(\\phi(t, x)\\) , respectively. Let \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) denote the training data to enforce the initial condition at time \\(t = 0\\) , that is, \\(u^i_0= \\text{sech}(x^i_0)\\) , \\(\\{t^i_b\\}^{N_b}_{i=1}\\) the collocation points on the boundary \\(x = -5\\) and \\(x = 5\\) to enforce the periodic boundary conditions, and \\(\\{t^i_f, x^i_f\\}^{N_f}_{i=1}\\) the collocation points in \\((0, \\pi/2]\\times (-5, 5)\\) . These collocation points were generated by the Latin hypercube sampling method. We then learn the neural network \\(\\mathcal{N}_\\Theta (t, x)\\) by model (8) with \u4ee4 \\(\\psi\\) \u548c \\(\\phi\\) \u5206\u522b\u8868\u793a\u89e3 \\(u\\) \u7684\u5b9e\u90e8\u548c\u865a\u90e8. \u6211\u4eec\u8bd5\u56fe\u7528\u5177\u6709\u4e24\u4e2a\u8f93\u5165 \\((t, x)\\) \u548c\u4e24\u4e2a\u8f93\u51fa\u5206\u522b\u8fd1\u4f3c \\(\\psi(t, x)\\) \u548c \\(\\phi(t, x)\\) \u7684\u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta (t, x)\\) \u6765\u8fd1\u4f3c\u65b9\u7a0b\u7684\u89e3 \\(u(t, x)\\) . \u4ee4 \\(\\{x^i_0, u^i_0\\}^{N_0}_{i=1}\\) \u8868\u793a\u7528\u4e8e\u6ee1\u8db3 \\(t=0\\) \u4e0a\u521d\u503c\u6761\u4ef6\u7684\u8bad\u7ec3\u6570\u636e, \u5373 \\(u^i_0= \\text{sech}(x^i_0)\\) , \\(\\{t^i_b\\}^{N_b}_{i=1}\\) \u8868\u793a\u7528\u4e8e\u6ee1\u8db3 \\(x=-5\\) \u548c \\(x=5\\) \u4e0a\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684\u914d\u7f6e\u70b9. \\(\\{t^i_f, x^i_f\\}^{N_f}_{i=1}\\) \u8868\u793a\u5728 \\((0, \\pi/2]\\times (-5, 5)\\) \u7684\u914d\u7f6e\u70b9. \u8fd9\u4e9b\u914d\u7f6e\u70b9\u901a\u8fc7 LHS \u65b9\u6cd5\u751f\u6210. \u7136\u540e\u6211\u4eec\u901a\u8fc7\u5177\u6709\u4ee5\u4e0b\u635f\u5931\u7684\u6a21\u578b (8) \u6765\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc \\(\\mathcal{N}_\\Theta (t, x)\\) . \\[ \\begin{aligned} Loss_0&:= \\frac{1}{N_0}\\sum_{i=1}^{N_0} |\\mathcal{N}_\\Theta(0,x^i_0)-u^i_0|^2\\\\ Loss_b&:= \\frac{1}{N_b}\\sum_{i=1}^{N_b} \\bigg(|\\mathcal{N}_\\Theta(t^i_b, -5)- \\mathcal{N}_\\Theta(t^i_b, 5)|^2+\\Big|\\frac{\\partial \\mathcal{N}_\\Theta}{\\partial x}(t^i_b, -5)-\\frac{\\partial \\mathcal{N}_\\Theta}{\\partial x}(t^i_b, 5)\\Big|^2\\bigg) \\end{aligned} \\] A reference solution of problem (18) is solved by a Fourier spectral method using the Chebfun package 18 . Specifically, we obtain the reference solution by using \\(256\\) Fourier modes for space discretization and an explicit fourth-order Runge-Kutta method (RK4) with time-step \\(\\Delta t := (\\pi/2) \\times 10^{-6}\\) for time discretization. For more details of the discretization of Schr\u00f6dinger equation (18) , the readers are referred to 35 . For both the standard network and the sparse network, we used the network architecture \\([2, 50, 50, 50, 50, 50, 50, 2]\\) . Both the networks were trained by the Adam algorithm with \\(30,000\\) epochs. The initial learning rate is set to \\(0.001\\) . The training set is composed of \\(N_0:= 50\\) data points on \\(u(0, x)\\) , \\(N_b:= 50\\) sample points for enforcing the periodic boundaries, and \\(N_f:= 20,000\\) sample points inside the solution domain of equation (18) . The test set is composed of grid points \\((0, \\pi/2] \\times [-5, 5]\\) uniformly discretized with step size \\(\\pi/400\\) on the \\(t\\) direction and step size \\(10/256\\) on the \\(x\\) direction. \u95ee\u9898 (18) \u7684\u53c2\u7167\u89e3\u662f\u901a\u8fc7 Chebfun \u5305\u7684\u5085\u7acb\u53f6\u8c31\u65b9\u6cd5\u6c42\u89e3\u7684. \u5177\u4f53\u5730, \u6211\u4eec\u901a\u8fc7\u5728\u7a7a\u95f4\u79bb\u6563\u4e0a\u4f7f\u7528 \\(256\\) \u4e2a\u5085\u7acb\u53f6\u6a21\u548c\u65f6\u95f4\u79bb\u6563\u6b65\u957f\u4e3a \\(\\Delta t := (\\pi/2) \\times 10^{-6}\\) \u7684\u663e\u5f0f\u56db\u9636\u9f99\u683c\u5e93\u5854\u65b9\u6cd5. Schr\u00f6dinger \u65b9\u7a0b\u7684\u66f4\u591a\u79bb\u6563\u7ec6\u8282\u53ef\u4ee5\u53c2\u9605 PINN \u8bba\u6587. \u5bf9\u4e8e\u6807\u51c6\u7f51\u7edc\u548c\u7a00\u758f\u7f51\u7edc, \u6211\u4eec\u4f7f\u7528\u7f51\u7edc\u67b6\u6784\u4e3a \\([2, 50, 50, 50, 50, 50, 50, 2]\\) , \u90fd\u4f7f\u7528 Adam \u7b97\u6cd5\u8bad\u7ec3 \\(30,000\\) \u4e2a epochs. \u521d\u59cb\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a \\(0.001\\) . \u8bad\u7ec3\u96c6\u7531 \\(u(0,x)\\) \u4e0a\u7684 \\(N_0=50\\) \u4e2a\u6570\u636e\u70b9, \u7528\u4e8e\u6ee1\u8db3\u5468\u671f\u8fb9\u503c\u6761\u4ef6\u7684 \\(N_b=50\\) \u6837\u672c\u70b9\u548c\u65b9\u7a0b\u5b9a\u4e49\u57df\u5185\u7684 \\(N_f=20,000\\) \u4e2a\u6837\u672c\u70b9\u7ec4\u6210. \u6d4b\u8bd5\u96c6\u5219\u7531\u5b9a\u4e49\u57df \\((0, \\pi/2] \\times [-5, 5]\\) \u6cbf \\(t\\) \u65b9\u5411\u4e0a\u5747\u5300\u79bb\u6563\u6b65\u957f\u4e3a \\(\\pi/400\\) \u548c\u6cbf \\(x\\) \u65b9\u5411\u4e0a\u5747\u5300\u79bb\u6563\u6b65\u957f\u4e3a \\(10/256\\) \u7684\u7f51\u683c\u70b9\u7ec4\u6210. Numerical results for this example are listed in Table 7 . As we can see, the sparse network has a smaller prediction error than the standard network. When regularization parameters \\(\\alpha = [0, 0, 0, 0, 5\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , the relative \\(L_2\\) error is smaller than the PINN method. When regularization parameters \\(\\alpha\\) are taken as \\([9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , the sparsity of weight matrices are \\([22.0\\%,50.5\\%, 51.9\\%, 50.6\\%, 50.0\\%, 64.5\\%, 66.0\\%]\\) . In other words, after removing more than half of the neural network connections, the sparse neural network still has a slightly higher prediction accuracy. The predicted solution of the SDNN is illustrated in Figure 10 . These numerical results clearly confirm that the proposed SDNN model outperforms the standard DNN model. \u8fd9\u4e00\u4f8b\u5b50\u7684\u6570\u503c\u7ed3\u679c\u5217\u4e3e\u5728\u8868\u683c 7 \u4e2d. \u6b63\u5982\u6211\u4eec\u6240\u770b\u5230\u7684, \u7a00\u758f\u7f51\u7edc\u76f8\u6bd4\u6807\u51c6\u7f51\u7edc\u5177\u6709\u66f4\u5c0f\u7684\u9884\u6d4b\u8bef\u5dee. \u5f53\u6b63\u5219\u5316\u53c2\u6570 \\(\\alpha = [0, 0, 0, 0, 5\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , \u76f8\u5bf9 \\(L_2\\) \u8bef\u5dee\u6bd4 PINN \u7684\u8981\u5c0f. \u5f53\u6b63\u5219\u5316\u53c2\u6570\u4e3a \\([9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , \u6743\u91cd\u77e9\u9635\u7684\u7a00\u758f\u6027\u4e3a \\([22.0\\%,50.5\\%, 51.9\\%, 50.6\\%, 50.0\\%, 64.5\\%, 66.0\\%]\\) . \u6362\u53e5\u8bdd\u8bf4, \u79fb\u9664\u4e86\u795e\u7ecf\u7f51\u7edc\u8d85\u8fc7\u4e00\u534a\u7684\u8fde\u63a5\u540e, \u7a00\u758f\u795e\u7ecf\u7f51\u7edc\u4ecd\u7136\u7531\u7a0d\u5fae\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6. SDNN \u7684\u9884\u6d4b\u89e3\u5982\u56fe 10 \u6240\u793a. \u8fd9\u4e9b\u6570\u503c\u7ed3\u679c\u6e05\u6670\u5730\u8bc1\u5b9e\u4e86\u6211\u4eec\u6240\u63d0\u51fa\u7684 SDNN \u6a21\u578b\u6bd4\u6807\u51c6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u8d8a. Algorithms Parameters \\(\\alpha\\) & sparsity of weight matrices Relative \\(L_2\\) error PINN No regularization \\([0.0\\%, 0.3\\%, 0.4\\%, 0.6\\%, 0.4\\%, 0.68\\%, 0.0\\%]\\) \\(1.41\\times10^{-3}\\) SDNN ( \\(\\beta = 10\\) ) \\([0, 0, 0, 0, 5\\times10^{-7}, 10^{-6}, 10^{-5}]\\) \\([0.7\\%, 0.3\\%, 0.4\\%, 50.6\\%, 38.0\\%, 74.7\\%, 77.0\\%]\\) \\(8.15\\times10^{-4}\\) SDNN ( \\(\\beta = 10\\) ) \\([9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) \\([22.0\\%, 50.5\\%, 51.9\\%, 50.6\\%, 50.0\\%, 64.5\\%, 66.0\\%]\\) \\(1.38\\times10^{-3}\\) Table 7 : The Schr\u00f6dinger equation: The neural network of \\(7\\) layers with network architecture \\([2,50, 50, 50, 50, 50, 50, 2]\\) . Figure 10 : The Schr\u00f6dinger equation: Top: The training data and predicted solution \\(|u(t, x)|\\) by SDNN with network architecture \\([2, 50, 50, 50, 50, 50, 50, 2]\\) , regularization parameters \\(\\alpha := [9\\times10^{-7}, 5\\times10^{-7}, 6\\times10^{-7}, 7\\times10^{-7}, 8\\times10^{-7}, 10^{-6}, 10^{-5}]\\) , and \\(\\beta := 10\\) . Bottom: Predicted solutions at time \\(t := 0.55\\) , \\(t := 0.79\\) , and \\(t := 1.02\\) .","title":"The Schr\u00f6dinger Equation"},{"location":"Scholars/PN-2207.13266/#conclusion","text":"A sparse network requires less memory and computing time to operate it and thus it is desirable. We have developed a sparse deep neural network model by employing a sparse regularization with multiple parameters for solving nonlinear partial differential equations. Noticing that neural networks are layer-by-layer composite structures with an intrinsic multi-scale structure, we observe that the network weights of different layers have different weights of importance. Aiming at generating a sparse network structure while maintaining approximation accuracy, we proposed to impose different regularization parameters on different layers of the neural network. We first tested the proposed sparse regularization model in approximation of singular functions, and discovered that the proposed model can not only generate an adaptive approximation of functions having singularities but also have better generalization than the standard network. We then developed a sparse deep neural network model for solving nonlinear partial differential equations whose solutions may have certain singularities. Numerical examples show that the proposed model can remove redundant network connections leading to sparse networks and has better generalization ability. Theoretical investigation will be performed in a follow-up paper. \u7a00\u758f\u7f51\u7edc\u53ea\u9700\u8981\u66f4\u5c11\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u65f6\u95f4\u6765\u64cd\u4f5c\u5b83, \u56e0\u6b64\u5b83\u662f\u53ef\u53d6\u7684. \u6211\u4eec\u91c7\u7528\u591a\u53c2\u6570\u7a00\u758f\u6b63\u5219\u5316\u65b9\u6cd5\u5efa\u7acb\u4e86\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b. \u6ce8\u610f\u5230\u795e\u7ecf\u7f51\u7edc\u662f\u5177\u6709\u5185\u5728\u591a\u5c3a\u5ea6\u7ed3\u6784\u7684\u5c42\u5c42\u590d\u5408\u7ed3\u6784, \u6211\u4eec\u89c2\u5bdf\u5230\u4e0d\u540c\u5c42\u7684\u7f51\u7edc\u6743\u91cd\u6709\u4e0d\u540c\u7684\u91cd\u8981\u6027\u6743\u91cd. \u4e3a\u4e86\u5728\u4fdd\u6301\u903c\u8fd1\u7cbe\u5ea6\u7684\u540c\u65f6\u751f\u6210\u7a00\u758f\u7f51\u7edc\u7ed3\u6784, \u6211\u4eec\u63d0\u51fa\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u540c\u5c42\u4e0a\u52a0\u5165\u4e0d\u540c\u7684\u6b63\u5219\u5316\u53c2\u6570. \u9996\u5148\u5bf9\u7a00\u758f\u6b63\u5219\u5316\u6a21\u578b\u5728\u5947\u6027\u51fd\u6570\u903c\u8fd1\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u6d4b\u8bd5, \u53d1\u73b0\u8be5\u6a21\u578b\u4e0d\u4ec5\u80fd\u81ea\u9002\u5e94\u903c\u8fd1\u5177\u6709\u5947\u6027\u7684\u51fd\u6570, \u800c\u4e14\u6bd4\u6807\u51c6\u7f51\u7edc\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u7136\u540e, \u6211\u4eec\u5efa\u7acb\u4e86\u4e00\u4e2a\u7a00\u758f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u89e3\u51b3\u89e3\u6709\u4e00\u5b9a\u7684\u5947\u6027\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b. \u6570\u503c\u7b97\u4f8b\u8868\u660e, \u8be5\u6a21\u578b\u80fd\u591f\u53bb\u9664\u5197\u4f59\u7f51\u7edc\u8fde\u63a5\u5f97\u5230\u7a00\u758f\u7f51\u7edc, \u5177\u6709\u8f83\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u7406\u8bba\u7814\u7a76\u5c06\u5728\u540e\u7eed\u8bba\u6587\u4e2d\u8fdb\u884c.","title":"Conclusion"},{"location":"Scholars/PN-2207.13266/#references","text":"\u672a\u88ab\u5b9e\u9645\u5f15\u7528\u7684\u6587\u732e . [3] Optimal Approximation with Sparsely Connected Deep Neural Networks, [2019] [SIAM] [15] Stochastic Subgradient Method Converges On Tame Functions. [2020]. [21] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. [2011]. The Gap between Theory and Practice in Function Approximation with Deep Neural Networks. [2021] [SIAM]. \u21a9 Spectral and Finite Difference Solutions of the Burgers Equation [1986]. \u21a9 Multiparameter Regularization for Volterra Kernel Identification Via Multiscale Collocation Methods. [2009] Y. Xu . \u21a9 Robust Uncertainty Principles: Exact Signal Reconstruction from Highly Incomplete Frequency Information [2006]. \u21a9 An Introduction to Compressive Sampling. [2008]. \u21a9 Multi-Parameter Tikhonov Regularization for Linear Ill-Posed Operator Equations [2008] Y. Xu . \u21a9 Multiscale Methods for Fredholm Integral Equations. [2015] Y. Xu . \u21a9 Deep Learning Networks for Stock Market Analysis and Prediction: Methodology, Data Representations, and Case Studies. [2017]. \u21a9 Approximation by Superpositions of A Sigmoidal Function. [1989]. \u21a9 \u21a9 Robust Training and Initialization of Deep Neural Networks: An Adaptive Basis Viewpoint. [2020]. \u21a9 \u21a9 Context-Dependent Pretrained Deep Neural Networks for Large-Vocabulary Speech Recognition. [2012]. \u21a9 (\u5c0f\u6ce2\u5341\u8bb2) Ten Lectures on Wavelets, [1992]. \u21a9 Nonlinear Approximation and (Deep) ReLU Networks. [2021]. \u21a9 (BERT) BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding . [2018] [arXiv:1810.04805v1] \u21a9 Neural Network Approximation. [2021]. \u21a9 Deeply Learning Deep Inelastic Scattering Kinematics. [2021] Y. Xu , [arxiv:2108.11638v1] \u21a9 Compressive Sensing. [2006]. \u21a9 Chebfun Guide. [2014]. \u21a9 Hierarchical Models in the Brain, [2008]. \u21a9 Deep Learning . [2016] [MIT Press]. \u21a9 (DeepBSDE) Solving High-Dimensional Partial Differential Equations Using Deep Learning . [2018] [PNAS]. \u21a9 ReLU Deep Neural Networks and Linear Finite Elements. [2020]. \u21a9 Latin Hypercube Sampling and the Propagation of Uncertainty in Analyses of Complex Systems. [2003]. \u21a9 The Future of Deep Learning Will Be Sparse. [2021]. \u21a9 \u21a9 Sparsity in Deep Learning: Pruning and Growth for Efficient Inference and Training in Neural Networks . [2021]. \u21a9 \u21a9 Deep Learned Finite Elements, [2020]. \u21a9 Adam: A Method for Stochastic Optimization . [2015] [ICLR]. \u21a9 Imagenet Classification with Deep Convolutional Neural Networks. [2012]. \u21a9 Artificial Neural Networks for Solving Ordinary and Partial Differential Equations. [1998]. \u21a9 Neural-Network Methods for Boundary Value Problems with Irregular Boundaries. [2000]. \u21a9 Nonlinear Stability of An Undercompressive Shock for Complex Burgers Equation. [1995] \u21a9 Multi-Parameter Regularization Methods for High-Resolution Image Reconstruction with Displacement Errors. [2007] Y. Xu . \u21a9 Using the Matrix Refinement Equation for the Construction of Wavelets on Invariant Sets. [1994] Y. Xu . \u21a9 (DHM) Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations . [2018]. \u21a9 (PINN) Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations . [2019] [JCP]. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 Novel Soliton Solutions of the Nonlinear Schr\u00f6dinger Equation Model. [2000]. \u21a9 A Representer Theorem for Deep Neural Networks. [2019]. \u21a9 Sparse Regularization with the \\(l_0\\) -norm . [2021] Y. Xu , arXiv:2111.08244. \u21a9 Generalized Mercer Kernels and Reproducing Kernel Banach Spaces. [2019] Y. Xu . \u21a9 Convergence of Deep ReLU Networks. [2021] Y. Xu , arXiv:2107.12530. \u21a9 \u21a9 Convergence of Deep Convolutional Neural Networks. [2021] Y. Xu , arXiv:2109.13542. \u21a9 \u21a9 Reproducing Kernel Banach Spaces for Machine Learning. [2009] Y. Xu . \u21a9 \u21a9","title":"References"},{"location":"Songs/%E6%B5%AA%E6%BC%AB%E4%B9%8B%E7%BA%A6/","text":"\u30ed\u30de\u30f3\u30b9\u306e\u7d04\u675f/\u6d6a\u6f2b\u4e4b\u7ea6 \u4f5c\u8bcd\uff1a\u5e7e\u7530\u308a\u3089 \u4f5c\u66f2\uff1a\u5e7e\u7530\u308a\u3089 \u6f14\u5531\uff1a\u5e7e\u7530\u308a\u3089 \u3053\u308c\u304b\u3089\u4e8c\u4eba(\u3075\u305f\u308a)\u904e(\u3059)\u3054\u3057\u3066\u3044\u304f\u305f\u3081\u306b \u4e3a\u4e86\u4eca\u540e\u4e24\u4e2a\u4eba\u7684\u751f\u6d3b \u7d04\u675f(\u3084\u304f\u305d\u304f)\u3057\u3066\u307b\u3057\u3044\u3053\u3068\u304c\u3042\u308b\u306e \u60f3\u8981\u548c\u4f60\u6709\u4e2a\u7ea6\u5b9a \u58f0(\u3053\u3048)\u304c\u67af(\u304b)\u308c\u3066\u540d\u524d(\u306a\u307e\u3048)\u304c\u547c(\u3088)\u3079\u306a\u304f\u306a\u308b \u76f4\u5230\u58f0\u97f3\u6c99\u54d1\u5730\u65e0\u6cd5\u547c\u5524\u5f7c\u6b64\u59d3\u540d \u305d\u306e\u65e5(\u3072)\u307e\u3067\u5fd8(\u308f\u3059)\u308c\u306a\u3044\u3067 \u90a3\u5929\u4e4b\u524d\u90fd\u4e0d\u8981\u5fd8\u8bb0 \u5149(\u3072\u304b\u308a)\u3092\u63a2(\u3055\u304c)\u3059\u3088\u3046\u306a\u7720(\u306d\u3080)\u308c\u306a\u3044\u591c(\u3088\u308b)\u306f \u4eff\u4f5b\u5728\u5bfb\u627e\u5149\u660e\u822c\u65e0\u6cd5\u5165\u7720\u7684\u591c\u665a \u671d(\u3042\u3055)\u307e\u3067\u624b(\u3066)\u3092\u63e1(\u306b\u304e)\u3063\u3066\u3044\u3066\u307b\u3057\u3044 \u5e0c\u671b\u4f60\u80fd\u4e00\u76f4\u63e1\u7740\u6211\u7684\u624b\u76f4\u5230\u6e05\u6668 \u6ca2\u5c71(\u305f\u304f\u3055\u3093)\u306e\u611b(\u3042\u3044)\u3067\u6ea2(\u3042\u3075)\u308c\u305f\u306a\u3089 \u5982\u679c\u7231\u591a\u5230\u6ee1\u6ea2\u800c\u51fa \u660e(\u3042)\u3051\u306a\u3044\u591c(\u3088\u308b)\u306e\u5922(\u3086\u3081)\u3092\u898b(\u307f)\u305b\u3066\u307b\u3057\u3044 \u5e0c\u671b\u4f60\u80fd\u8ba9\u6211\u505a\u4e00\u4e2a\u6c38\u4e0d\u7834\u6653\u7684\u7f8e\u68a6 \u5929\u79e4(\u3066\u3093\u3073\u3093)\u306f\u3044\u3064\u3082\u50be(\u304b\u305f\u3080)\u304f\u3051\u3069 \u5929\u5e73\u5c3d\u7ba1\u603b\u662f\u503e\u5411\u4e00\u7aef \u4eca\u591c(\u3053\u3093\u3084)\u3060\u3051\u306f\u540c(\u304a\u306a)\u3058\u3067\u3044\u305f\u3044 \u54ea\u6015\u53ea\u5728\u4eca\u665a\u4e5f\u60f3\u8ba9\u5b83\u8b8a\u5f97\u4e00\u6837 \u4e8c\u4eba(\u3075\u305f\u308a)\u3067\u9032(\u3059\u3059)\u307f\u59cb(\u306f\u3058)\u3081\u305f\u3053\u306e\u5217\u8eca(\u308c\u3063\u3057\u3083)\u306e \u4e24\u4e2a\u4eba\u4e00\u8d77\u5f00\u59cb\u4e58\u5750\u7684\u8fd9\u8d9f\u5217\u8f66 \u5207\u7b26(\u304d\u3063\u3077)\u306f\u6700\u5f8c(\u3055\u3044\u3054)\u307e\u3067\u5931(\u306a)\u304f\u3055\u306a\u3044\u3067\u306d \u76f4\u5230\u6700\u540e\u90fd\u8bf7\u4e0d\u8981\u5c06\u8f66\u7968\u5f04\u4e22\u54e6 \u3082\u3057\u3082\u884c(\u3086)\u304d\u5148(\u3055\u304d)\u3092\u898b(\u307f)\u5931(\u3046\u3057\u306a)\u3063\u305f\u306a\u3089 \u5982\u679c\u8ff7\u5931\u4e86\u76ee\u7684\u5730\u7684\u8bdd \u305d\u306e\u5834\u6240(\u3070\u3057\u3087)\u3067\u307e\u305f\u59cb(\u306f\u3058)\u3081\u3088\u3046 \u5c31\u5728\u90a3\u4e2a\u5730\u65b9\u91cd\u65b0\u5f00\u59cb\u5427 \u982c(\u307b\u307b)\u3092\u6fe1(\u306c)\u3089\u3059\u3088\u3046\u306a\u7720(\u306d\u3080)\u308c\u306a\u3044\u591c(\u3088\u308b)\u306f \u5728\u6cea\u6e7f\u8138\u988a\u7684\u4e0d\u7720\u4e4b\u591c \u5fc3\u5730(\u3053\u3053\u3061)\u3044\u3044\u5de6\u80a9(\u3072\u3060\u308a\u304b\u305f)\u3092\u8cb8(\u304b)\u3057\u3066\u307b\u3057\u3044 \u8bf7\u501f\u7ed9\u6211\u4f60\u90a3\u8212\u9002\u7684\u5de6\u80a9 \u6ca2\u5c71(\u305f\u304f\u3055\u3093)\u306e\u611b(\u3042\u3044)\u3092\u77e5(\u3057)\u308c\u305f\u306e\u306a\u3089 \u5982\u679c\u77e5\u9053\u4e86\u6211\u6eff\u5fc3\u7684\u7231\u610f \u53e3\u7d05(\u304f\u3061\u3079\u306b)\u3092\u6eb6(\u3068)\u304b\u3059\u3088\u3046\u306a\u30ad\u30b9(\u304d\u3059)\u3092\u3057\u3066 \u5c31\u7ed9\u6211\u6765\u4e2a\u80fd\u5c06\u53e3\u7ea2\u90fd\u878d\u5316\u7684\u543b\u5427 \u305d\u306e\u3042\u3068\u306f\u9f3b\u5148(\u306f\u306a\u3055\u304d)\u3067\u304f\u3059\u3063\u3068\u7b11(\u308f\u3089)\u3063\u3066 \u7136\u540e\u8138\u4e0a\u5e26\u7740\u7b11\u610f \u7d42(\u304a)\u308f\u308a\u306f\u306a\u3044\u3068\u8a00(\u3044)\u3063\u3066\u62b1(\u3060)\u304d\u3057\u3081\u3066 \u8bf4\u8fd8\u6ca1\u7ed3\u675f\u518d\u7d27\u62b1\u4f4f\u6211 \u541b(\u304d\u307f)\u306e\u77ed\u6240(\u305f\u3093\u3057\u3087)\u3084\u79c1(\u308f\u305f\u3057)\u306e\u9577\u6240(\u3061\u3087\u3046\u3057\u3087)\u304c\u5909(\u304b)\u308f\u3063\u3066\u3057\u307e\u3063\u3066\u3082 \u5373\u4f7f\u4f60\u7684\u7f3a\u70b9\u548c\u6211\u7684\u4f18\u70b9\u90fd\u6539\u53d8\u4e86 \u4ee3(\u304b)\u308f\u308a\u306f\u5c45(\u3044)\u306a\u3044\u3088 \u304d\u3063\u3068 \u4e5f\u6ca1\u6709\u80fd\u591f\u4ee3\u66ff\u7684\u5b58\u5728 \u601d(\u304a\u3082)\u3044\u51fa(\u3067)\u304c\u793a(\u3057\u3081)\u3059\u3088 \u307e\u305f\u624b(\u3066)\u3092\u53d6(\u3068)\u308d\u3046 \u50cf\u8bb0\u5fc6\u4e2d\u4e00\u6837\u518d\u6b21\u7275\u7740\u624b\u5427 \u661f\u5c51(\u307b\u3057\u304f\u305a)\u306e\u3088\u3046\u306a\u3053\u306e\u4e16\u754c(\u305b\u304b\u3044)\u3067 \u5728\u8fd9\u5982\u661f\u5c18\u822c\u7684\u4e16\u754c\u91cc \u7167(\u3066)\u3089\u3055\u308c\u305f\u5149(\u3072\u304b\u308a)\u306e\u5148(\u3055\u304d)\u306b\u3044\u305f\u3093\u3060 \u5728\u88ab\u7167\u8000\u7684\u5149\u8292\u4e4b\u524d \u541b(\u304d\u307f)\u306e\u307e\u307e\u305d\u306e\u307e\u307e\u304c\u7f8e(\u3046\u3064\u304f)\u3057\u3044\u304b\u3089 \u4f60\u662f\u5982\u6b64\u7684\u7f8e\u4e3d \u305d\u308c\u3067\u3044\u3044 \u305d\u308c\u3060\u3051\u3067\u3044\u3044 \u8fd9\u6837\u5c31\u597d~\u8fd9\u6837\u5c31\u8db3\u5920\u4e86 \u6ca2\u5c71(\u305f\u304f\u3055\u3093)\u306e\u611b(\u3042\u3044)\u3067\u6ea2(\u3042\u3075)\u308c\u305f\u306a\u3089 \u5982\u679c\u7231\u591a\u5230\u6ee1\u6ea2\u800c\u51fa \u660e(\u3042)\u3051\u306a\u3044\u591c(\u3088\u308b)\u306e\u5922(\u3086\u3081)\u3092\u898b(\u307f)\u305b\u3066\u307b\u3057\u3044 \u5e0c\u671b\u4f60\u80fd\u8ba9\u6211\u505a\u4e00\u4e2a\u6c38\u4e0d\u7834\u6653\u7684\u7f8e\u68a6 \u5929\u79e4(\u3066\u3093\u3073\u3093)\u306f\u304d\u3063\u3068\u307e\u305f\u50be(\u304b\u305f\u3080)\u304f\u3051\u3069 \u5c3d\u7ba1\u5929\u5e73\u8fd8\u4f1a\u518d\u5ea6\u503e\u659c \u305a\u3063\u3068\u305a\u3063\u3068\u541b(\u304d\u307f)\u3068\u4e00\u7dd2(\u3044\u3063\u3057\u3087)\u306b\u3044\u305f\u3044~ \u3044\u305f\u3044~ \u8fd8\u662f\u60f3\u8981\u6c38\u8fdc~\u6c38\u8fdc\u548c\u4f60\u5728\u4e00\u8d77","title":"\u30ed\u30de\u30f3\u30b9\u306e\u7d04\u675f/\u6d6a\u6f2b\u4e4b\u7ea6"},{"location":"Songs/%E6%B5%AA%E6%BC%AB%E4%B9%8B%E7%BA%A6/#_1","text":"\u4f5c\u8bcd\uff1a\u5e7e\u7530\u308a\u3089 \u4f5c\u66f2\uff1a\u5e7e\u7530\u308a\u3089 \u6f14\u5531\uff1a\u5e7e\u7530\u308a\u3089 \u3053\u308c\u304b\u3089\u4e8c\u4eba(\u3075\u305f\u308a)\u904e(\u3059)\u3054\u3057\u3066\u3044\u304f\u305f\u3081\u306b \u4e3a\u4e86\u4eca\u540e\u4e24\u4e2a\u4eba\u7684\u751f\u6d3b \u7d04\u675f(\u3084\u304f\u305d\u304f)\u3057\u3066\u307b\u3057\u3044\u3053\u3068\u304c\u3042\u308b\u306e \u60f3\u8981\u548c\u4f60\u6709\u4e2a\u7ea6\u5b9a \u58f0(\u3053\u3048)\u304c\u67af(\u304b)\u308c\u3066\u540d\u524d(\u306a\u307e\u3048)\u304c\u547c(\u3088)\u3079\u306a\u304f\u306a\u308b \u76f4\u5230\u58f0\u97f3\u6c99\u54d1\u5730\u65e0\u6cd5\u547c\u5524\u5f7c\u6b64\u59d3\u540d \u305d\u306e\u65e5(\u3072)\u307e\u3067\u5fd8(\u308f\u3059)\u308c\u306a\u3044\u3067 \u90a3\u5929\u4e4b\u524d\u90fd\u4e0d\u8981\u5fd8\u8bb0 \u5149(\u3072\u304b\u308a)\u3092\u63a2(\u3055\u304c)\u3059\u3088\u3046\u306a\u7720(\u306d\u3080)\u308c\u306a\u3044\u591c(\u3088\u308b)\u306f \u4eff\u4f5b\u5728\u5bfb\u627e\u5149\u660e\u822c\u65e0\u6cd5\u5165\u7720\u7684\u591c\u665a \u671d(\u3042\u3055)\u307e\u3067\u624b(\u3066)\u3092\u63e1(\u306b\u304e)\u3063\u3066\u3044\u3066\u307b\u3057\u3044 \u5e0c\u671b\u4f60\u80fd\u4e00\u76f4\u63e1\u7740\u6211\u7684\u624b\u76f4\u5230\u6e05\u6668 \u6ca2\u5c71(\u305f\u304f\u3055\u3093)\u306e\u611b(\u3042\u3044)\u3067\u6ea2(\u3042\u3075)\u308c\u305f\u306a\u3089 \u5982\u679c\u7231\u591a\u5230\u6ee1\u6ea2\u800c\u51fa \u660e(\u3042)\u3051\u306a\u3044\u591c(\u3088\u308b)\u306e\u5922(\u3086\u3081)\u3092\u898b(\u307f)\u305b\u3066\u307b\u3057\u3044 \u5e0c\u671b\u4f60\u80fd\u8ba9\u6211\u505a\u4e00\u4e2a\u6c38\u4e0d\u7834\u6653\u7684\u7f8e\u68a6 \u5929\u79e4(\u3066\u3093\u3073\u3093)\u306f\u3044\u3064\u3082\u50be(\u304b\u305f\u3080)\u304f\u3051\u3069 \u5929\u5e73\u5c3d\u7ba1\u603b\u662f\u503e\u5411\u4e00\u7aef \u4eca\u591c(\u3053\u3093\u3084)\u3060\u3051\u306f\u540c(\u304a\u306a)\u3058\u3067\u3044\u305f\u3044 \u54ea\u6015\u53ea\u5728\u4eca\u665a\u4e5f\u60f3\u8ba9\u5b83\u8b8a\u5f97\u4e00\u6837 \u4e8c\u4eba(\u3075\u305f\u308a)\u3067\u9032(\u3059\u3059)\u307f\u59cb(\u306f\u3058)\u3081\u305f\u3053\u306e\u5217\u8eca(\u308c\u3063\u3057\u3083)\u306e \u4e24\u4e2a\u4eba\u4e00\u8d77\u5f00\u59cb\u4e58\u5750\u7684\u8fd9\u8d9f\u5217\u8f66 \u5207\u7b26(\u304d\u3063\u3077)\u306f\u6700\u5f8c(\u3055\u3044\u3054)\u307e\u3067\u5931(\u306a)\u304f\u3055\u306a\u3044\u3067\u306d \u76f4\u5230\u6700\u540e\u90fd\u8bf7\u4e0d\u8981\u5c06\u8f66\u7968\u5f04\u4e22\u54e6 \u3082\u3057\u3082\u884c(\u3086)\u304d\u5148(\u3055\u304d)\u3092\u898b(\u307f)\u5931(\u3046\u3057\u306a)\u3063\u305f\u306a\u3089 \u5982\u679c\u8ff7\u5931\u4e86\u76ee\u7684\u5730\u7684\u8bdd \u305d\u306e\u5834\u6240(\u3070\u3057\u3087)\u3067\u307e\u305f\u59cb(\u306f\u3058)\u3081\u3088\u3046 \u5c31\u5728\u90a3\u4e2a\u5730\u65b9\u91cd\u65b0\u5f00\u59cb\u5427 \u982c(\u307b\u307b)\u3092\u6fe1(\u306c)\u3089\u3059\u3088\u3046\u306a\u7720(\u306d\u3080)\u308c\u306a\u3044\u591c(\u3088\u308b)\u306f \u5728\u6cea\u6e7f\u8138\u988a\u7684\u4e0d\u7720\u4e4b\u591c \u5fc3\u5730(\u3053\u3053\u3061)\u3044\u3044\u5de6\u80a9(\u3072\u3060\u308a\u304b\u305f)\u3092\u8cb8(\u304b)\u3057\u3066\u307b\u3057\u3044 \u8bf7\u501f\u7ed9\u6211\u4f60\u90a3\u8212\u9002\u7684\u5de6\u80a9 \u6ca2\u5c71(\u305f\u304f\u3055\u3093)\u306e\u611b(\u3042\u3044)\u3092\u77e5(\u3057)\u308c\u305f\u306e\u306a\u3089 \u5982\u679c\u77e5\u9053\u4e86\u6211\u6eff\u5fc3\u7684\u7231\u610f \u53e3\u7d05(\u304f\u3061\u3079\u306b)\u3092\u6eb6(\u3068)\u304b\u3059\u3088\u3046\u306a\u30ad\u30b9(\u304d\u3059)\u3092\u3057\u3066 \u5c31\u7ed9\u6211\u6765\u4e2a\u80fd\u5c06\u53e3\u7ea2\u90fd\u878d\u5316\u7684\u543b\u5427 \u305d\u306e\u3042\u3068\u306f\u9f3b\u5148(\u306f\u306a\u3055\u304d)\u3067\u304f\u3059\u3063\u3068\u7b11(\u308f\u3089)\u3063\u3066 \u7136\u540e\u8138\u4e0a\u5e26\u7740\u7b11\u610f \u7d42(\u304a)\u308f\u308a\u306f\u306a\u3044\u3068\u8a00(\u3044)\u3063\u3066\u62b1(\u3060)\u304d\u3057\u3081\u3066 \u8bf4\u8fd8\u6ca1\u7ed3\u675f\u518d\u7d27\u62b1\u4f4f\u6211 \u541b(\u304d\u307f)\u306e\u77ed\u6240(\u305f\u3093\u3057\u3087)\u3084\u79c1(\u308f\u305f\u3057)\u306e\u9577\u6240(\u3061\u3087\u3046\u3057\u3087)\u304c\u5909(\u304b)\u308f\u3063\u3066\u3057\u307e\u3063\u3066\u3082 \u5373\u4f7f\u4f60\u7684\u7f3a\u70b9\u548c\u6211\u7684\u4f18\u70b9\u90fd\u6539\u53d8\u4e86 \u4ee3(\u304b)\u308f\u308a\u306f\u5c45(\u3044)\u306a\u3044\u3088 \u304d\u3063\u3068 \u4e5f\u6ca1\u6709\u80fd\u591f\u4ee3\u66ff\u7684\u5b58\u5728 \u601d(\u304a\u3082)\u3044\u51fa(\u3067)\u304c\u793a(\u3057\u3081)\u3059\u3088 \u307e\u305f\u624b(\u3066)\u3092\u53d6(\u3068)\u308d\u3046 \u50cf\u8bb0\u5fc6\u4e2d\u4e00\u6837\u518d\u6b21\u7275\u7740\u624b\u5427 \u661f\u5c51(\u307b\u3057\u304f\u305a)\u306e\u3088\u3046\u306a\u3053\u306e\u4e16\u754c(\u305b\u304b\u3044)\u3067 \u5728\u8fd9\u5982\u661f\u5c18\u822c\u7684\u4e16\u754c\u91cc \u7167(\u3066)\u3089\u3055\u308c\u305f\u5149(\u3072\u304b\u308a)\u306e\u5148(\u3055\u304d)\u306b\u3044\u305f\u3093\u3060 \u5728\u88ab\u7167\u8000\u7684\u5149\u8292\u4e4b\u524d \u541b(\u304d\u307f)\u306e\u307e\u307e\u305d\u306e\u307e\u307e\u304c\u7f8e(\u3046\u3064\u304f)\u3057\u3044\u304b\u3089 \u4f60\u662f\u5982\u6b64\u7684\u7f8e\u4e3d \u305d\u308c\u3067\u3044\u3044 \u305d\u308c\u3060\u3051\u3067\u3044\u3044 \u8fd9\u6837\u5c31\u597d~\u8fd9\u6837\u5c31\u8db3\u5920\u4e86 \u6ca2\u5c71(\u305f\u304f\u3055\u3093)\u306e\u611b(\u3042\u3044)\u3067\u6ea2(\u3042\u3075)\u308c\u305f\u306a\u3089 \u5982\u679c\u7231\u591a\u5230\u6ee1\u6ea2\u800c\u51fa \u660e(\u3042)\u3051\u306a\u3044\u591c(\u3088\u308b)\u306e\u5922(\u3086\u3081)\u3092\u898b(\u307f)\u305b\u3066\u307b\u3057\u3044 \u5e0c\u671b\u4f60\u80fd\u8ba9\u6211\u505a\u4e00\u4e2a\u6c38\u4e0d\u7834\u6653\u7684\u7f8e\u68a6 \u5929\u79e4(\u3066\u3093\u3073\u3093)\u306f\u304d\u3063\u3068\u307e\u305f\u50be(\u304b\u305f\u3080)\u304f\u3051\u3069 \u5c3d\u7ba1\u5929\u5e73\u8fd8\u4f1a\u518d\u5ea6\u503e\u659c \u305a\u3063\u3068\u305a\u3063\u3068\u541b(\u304d\u307f)\u3068\u4e00\u7dd2(\u3044\u3063\u3057\u3087)\u306b\u3044\u305f\u3044~ \u3044\u305f\u3044~ \u8fd8\u662f\u60f3\u8981\u6c38\u8fdc~\u6c38\u8fdc\u548c\u4f60\u5728\u4e00\u8d77","title":"\u30ed\u30de\u30f3\u30b9\u306e\u7d04\u675f/\u6d6a\u6f2b\u4e4b\u7ea6"},{"location":"Wisdom/Millennium%20Prize%20Problems%20%C2%B7%20%E5%8D%83%E7%A6%A7%E5%B9%B4%E5%A4%A7%E5%A5%96%E9%9A%BE%E9%A2%98/Non-deterministic%20Polynomial%20Complete/","text":"Non-Deterministic Polynomial Complete NP \u5b8c\u5168\u95ee\u9898/\u591a\u9879\u5f0f\u590d\u6742\u7a0b\u5ea6\u7684\u975e\u786e\u5b9a\u6027\u95ee\u9898. NP=P? \u76f8\u5173\u5b9a\u4e49 \u5224\u5b9a\u95ee\u9898 \u5224\u65ad\u662f\u5426\u6709\u4e00\u79cd\u80fd\u591f\u89e3\u51b3\u67d0\u4e00\u7c7b\u95ee\u9898\u7684\u80fd\u884c\u7b97\u6cd5\u7684\u7814\u7a76\u8bfe\u9898. P \u7c7b\u95ee\u9898 \u6240\u6709\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6c42\u89e3\u7684\u5224\u5b9a\u95ee\u9898\u6784\u6210 P \u7c7b\u95ee\u9898. NP \u7c7b\u95ee\u9898 \u6240\u6709\u7684\u975e\u786e\u5b9a\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u7684\u5224\u5b9a\u95ee\u9898\u6784\u6210 NP \u7c7b\u95ee\u9898. \u975e\u786e\u5b9a\u6027\u7b97\u6cd5 \u975e\u786e\u5b9a\u6027\u7b97\u6cd5\u5c06\u95ee\u9898\u5206\u89e3\u6210\u731c\u6d4b\u548c\u9a8c\u8bc1\u4e24\u4e2a\u9636\u6bb5. \u7b97\u6cd5\u7684\u731c\u6d4b\u9636\u6bb5\u65f6\u975e\u786e\u5b9a\u6027\u7684, \u7b97\u6cd5\u7684\u9a8c\u8bc1\u9636\u6bb5\u662f\u786e\u5b9a\u6027\u7684, \u5373\u9a8c\u8bc1\u731c\u6d4b\u9636\u6bb5\u7ed9\u51fa\u89e3\u7684\u6b63\u786e\u6027. \u8bbe\u7b97\u6cd5 A \u662f\u89e3\u4e00\u4e2a\u5224\u5b9a\u95ee\u9898 Q \u7684\u975e\u786e\u5b9a\u6027\u7b97\u6cd5, \u5982\u679c A \u7684\u9a8c\u8bc1\u9636\u6bb5\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210, \u5219\u79f0 A \u662f\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u975e\u786e\u5b9a\u6027\u7b97\u6cd5. \u6709\u4e9b\u8ba1\u7b97\u95ee\u9898\u662f\u786e\u5b9a\u6027\u7684 (\u5982: \u52a0\u51cf\u4e58\u9664), \u53ea\u9700\u6309\u7167\u516c\u5f0f\u63a8\u5bfc\u5373\u53ef\u5f97\u5230\u7ed3\u679c. \u6709\u4e9b\u8ba1\u7b97\u95ee\u9898\u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u51fa\u6765 (\u5982: \u627e\u5927\u8d28\u6570), \u53ea\u80fd\u901a\u8fc7\u95f4\u63a5\u7684\u731c\u7b97\u5f97\u5230\u7ed3\u679c, \u5373\u975e\u786e\u5b9a\u6027\u95ee\u9898. \u975e\u786e\u5b9a\u6027\u95ee\u9898\u901a\u5e38\u6709\u4e2a\u7b97\u6cd5, \u65e0\u6cd5\u76f4\u63a5\u7ed9\u51fa\u7b54\u6848, \u4f46\u662f\u80fd\u591f\u5224\u65ad\u67d0\u4e2a\u53ef\u80fd\u7684\u7ed3\u679c\u662f\u6b63\u786e\u6216\u9519\u8bef. \u5982\u679c\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u51fa\u6765\u5c31\u79f0\u4e3a\u591a\u9879\u5f0f\u975e\u786e\u5b9a\u6027\u95ee\u9898. NPC \u95ee\u9898 NP \u4e2d\u7684\u67d0\u4e9b\u95ee\u9898\u7684\u590d\u6742\u6027\u4e0e\u6574\u4e2a\u7c7b\u7684\u590d\u6742\u6027\u76f8\u5173\u8054. \u8fd9\u4e9b\u95ee\u9898\u4e2d\u4efb\u4f55\u4e00\u4e2a\u5982\u679c\u5b58\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u7684\u7b97\u6cd5, \u90a3\u4e48\u6240\u6709 NP \u95ee\u9898\u90fd\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u7684. \u8fd9\u4e9b\u95ee\u9898\u79f0\u4e3a NP-\u5b8c\u5168\u95ee\u9898 (NPC \u95ee\u9898). \u6240\u6709\u7684\u5b8c\u5168\u591a\u9879\u5f0f\u975e\u786e\u5b9a\u6027\u95ee\u9898, \u90fd\u53ef\u4ee5\u8f6c\u6362\u4e3a\u4e00\u7c7b\u53eb\u6ee1\u8db3\u6027\u95ee\u9898\u7684\u903b\u8f91\u8fd0\u7b97\u95ee\u9898. \u65e2\u7136\u8fd9\u7c7b\u95ee\u9898\u7684\u6240\u6709\u53ef\u80fd\u7b54\u6848, \u90fd\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97, \u90a3\u4e48\u8fd9\u7c7b\u95ee\u9898\u662f\u5426\u5b58\u5728\u786e\u5b9a\u6027\u7b97\u6cd5, \u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u76f4\u63a5\u7b97\u51fa\u6216\u641c\u7d22\u51fa\u6b63\u786e\u7b54\u6848\u5462? 1971 \u65af\u8482\u6587\u00b7\u8003\u514b \u7f8e\u56fd\u9ebb\u5dde\u7684\u514b\u96f7\uff08Clay\uff09\u6570\u5b66\u7814\u7a76\u6240\u4e8e2000\u5e745\u670824\u65e5\u5728\u5df4\u9ece\u6cd5\u5170\u897f\u5b66\u9662\u5ba3\u5e03\u4e86\u4e00\u4ef6\u88ab\u5a92\u4f53\u7092\u5f97\u706b\u70ed\u7684\u5927\u4e8b\uff1a\u5bf9\u4e03\u4e2a\u201c\u5343\u50d6\u5e74\u6570\u5b66\u96be\u9898\u201d\u7684\u6bcf\u4e00\u4e2a\u60ac\u8d4f\u4e00\u767e\u4e07\u7f8e\u5143\u3002 \u89e3\u51b3\u8fd9\u4e2a\u731c\u60f3\uff0c\u65e0\u975e\u4e24\u79cd\u53ef\u80fd\uff0c\u4e00\u79cd\u662f\u627e\u5230\u4e00\u4e2a\u8fd9\u6837\u7684\u7b97\u6cd5\uff0c\u53ea\u8981\u9488\u5bf9\u67d0\u4e2a\u7279\u5b9aNP\u5b8c\u5168\u95ee\u9898\u627e\u5230\u4e00\u4e2a\u7b97\u6cd5\uff0c\u6240\u6709\u8fd9\u7c7b\u95ee\u9898\u90fd\u53ef\u4ee5\u8fce\u5203\u800c\u89e3\u4e86\uff0c\u56e0\u4e3a\u4ed6\u4eec\u53ef\u4ee5\u8f6c\u5316\u4e3a\u540c\u4e00\u4e2a\u95ee\u9898\u3002\u53e6\u5916\u7684\u4e00\u79cd\u53ef\u80fd\uff0c\u5c31\u662f\u8fd9\u6837\u7684\u7b97\u6cd5\u662f\u4e0d\u5b58\u5728\u7684\u3002\u90a3\u4e48\u5c31\u8981\u4ece\u6570\u5b66\u7406\u8bba\u4e0a\u8bc1\u660e\u5b83\u4e3a\u4ec0\u4e48\u4e0d\u5b58\u5728\u3002","title":"Non-Deterministic Polynomial Complete"},{"location":"Wisdom/Millennium%20Prize%20Problems%20%C2%B7%20%E5%8D%83%E7%A6%A7%E5%B9%B4%E5%A4%A7%E5%A5%96%E9%9A%BE%E9%A2%98/Non-deterministic%20Polynomial%20Complete/#non-deterministic-polynomial-complete","text":"NP \u5b8c\u5168\u95ee\u9898/\u591a\u9879\u5f0f\u590d\u6742\u7a0b\u5ea6\u7684\u975e\u786e\u5b9a\u6027\u95ee\u9898. NP=P?","title":"Non-Deterministic Polynomial Complete"},{"location":"Wisdom/Millennium%20Prize%20Problems%20%C2%B7%20%E5%8D%83%E7%A6%A7%E5%B9%B4%E5%A4%A7%E5%A5%96%E9%9A%BE%E9%A2%98/Non-deterministic%20Polynomial%20Complete/#_1","text":"\u5224\u5b9a\u95ee\u9898 \u5224\u65ad\u662f\u5426\u6709\u4e00\u79cd\u80fd\u591f\u89e3\u51b3\u67d0\u4e00\u7c7b\u95ee\u9898\u7684\u80fd\u884c\u7b97\u6cd5\u7684\u7814\u7a76\u8bfe\u9898. P \u7c7b\u95ee\u9898 \u6240\u6709\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6c42\u89e3\u7684\u5224\u5b9a\u95ee\u9898\u6784\u6210 P \u7c7b\u95ee\u9898. NP \u7c7b\u95ee\u9898 \u6240\u6709\u7684\u975e\u786e\u5b9a\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u7684\u5224\u5b9a\u95ee\u9898\u6784\u6210 NP \u7c7b\u95ee\u9898. \u975e\u786e\u5b9a\u6027\u7b97\u6cd5 \u975e\u786e\u5b9a\u6027\u7b97\u6cd5\u5c06\u95ee\u9898\u5206\u89e3\u6210\u731c\u6d4b\u548c\u9a8c\u8bc1\u4e24\u4e2a\u9636\u6bb5. \u7b97\u6cd5\u7684\u731c\u6d4b\u9636\u6bb5\u65f6\u975e\u786e\u5b9a\u6027\u7684, \u7b97\u6cd5\u7684\u9a8c\u8bc1\u9636\u6bb5\u662f\u786e\u5b9a\u6027\u7684, \u5373\u9a8c\u8bc1\u731c\u6d4b\u9636\u6bb5\u7ed9\u51fa\u89e3\u7684\u6b63\u786e\u6027. \u8bbe\u7b97\u6cd5 A \u662f\u89e3\u4e00\u4e2a\u5224\u5b9a\u95ee\u9898 Q \u7684\u975e\u786e\u5b9a\u6027\u7b97\u6cd5, \u5982\u679c A \u7684\u9a8c\u8bc1\u9636\u6bb5\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210, \u5219\u79f0 A \u662f\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u975e\u786e\u5b9a\u6027\u7b97\u6cd5. \u6709\u4e9b\u8ba1\u7b97\u95ee\u9898\u662f\u786e\u5b9a\u6027\u7684 (\u5982: \u52a0\u51cf\u4e58\u9664), \u53ea\u9700\u6309\u7167\u516c\u5f0f\u63a8\u5bfc\u5373\u53ef\u5f97\u5230\u7ed3\u679c. \u6709\u4e9b\u8ba1\u7b97\u95ee\u9898\u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u51fa\u6765 (\u5982: \u627e\u5927\u8d28\u6570), \u53ea\u80fd\u901a\u8fc7\u95f4\u63a5\u7684\u731c\u7b97\u5f97\u5230\u7ed3\u679c, \u5373\u975e\u786e\u5b9a\u6027\u95ee\u9898. \u975e\u786e\u5b9a\u6027\u95ee\u9898\u901a\u5e38\u6709\u4e2a\u7b97\u6cd5, \u65e0\u6cd5\u76f4\u63a5\u7ed9\u51fa\u7b54\u6848, \u4f46\u662f\u80fd\u591f\u5224\u65ad\u67d0\u4e2a\u53ef\u80fd\u7684\u7ed3\u679c\u662f\u6b63\u786e\u6216\u9519\u8bef. \u5982\u679c\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u51fa\u6765\u5c31\u79f0\u4e3a\u591a\u9879\u5f0f\u975e\u786e\u5b9a\u6027\u95ee\u9898. NPC \u95ee\u9898 NP \u4e2d\u7684\u67d0\u4e9b\u95ee\u9898\u7684\u590d\u6742\u6027\u4e0e\u6574\u4e2a\u7c7b\u7684\u590d\u6742\u6027\u76f8\u5173\u8054. \u8fd9\u4e9b\u95ee\u9898\u4e2d\u4efb\u4f55\u4e00\u4e2a\u5982\u679c\u5b58\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u7684\u7b97\u6cd5, \u90a3\u4e48\u6240\u6709 NP \u95ee\u9898\u90fd\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u7684. \u8fd9\u4e9b\u95ee\u9898\u79f0\u4e3a NP-\u5b8c\u5168\u95ee\u9898 (NPC \u95ee\u9898). \u6240\u6709\u7684\u5b8c\u5168\u591a\u9879\u5f0f\u975e\u786e\u5b9a\u6027\u95ee\u9898, \u90fd\u53ef\u4ee5\u8f6c\u6362\u4e3a\u4e00\u7c7b\u53eb\u6ee1\u8db3\u6027\u95ee\u9898\u7684\u903b\u8f91\u8fd0\u7b97\u95ee\u9898. \u65e2\u7136\u8fd9\u7c7b\u95ee\u9898\u7684\u6240\u6709\u53ef\u80fd\u7b54\u6848, \u90fd\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97, \u90a3\u4e48\u8fd9\u7c7b\u95ee\u9898\u662f\u5426\u5b58\u5728\u786e\u5b9a\u6027\u7b97\u6cd5, \u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u76f4\u63a5\u7b97\u51fa\u6216\u641c\u7d22\u51fa\u6b63\u786e\u7b54\u6848\u5462? 1971 \u65af\u8482\u6587\u00b7\u8003\u514b \u7f8e\u56fd\u9ebb\u5dde\u7684\u514b\u96f7\uff08Clay\uff09\u6570\u5b66\u7814\u7a76\u6240\u4e8e2000\u5e745\u670824\u65e5\u5728\u5df4\u9ece\u6cd5\u5170\u897f\u5b66\u9662\u5ba3\u5e03\u4e86\u4e00\u4ef6\u88ab\u5a92\u4f53\u7092\u5f97\u706b\u70ed\u7684\u5927\u4e8b\uff1a\u5bf9\u4e03\u4e2a\u201c\u5343\u50d6\u5e74\u6570\u5b66\u96be\u9898\u201d\u7684\u6bcf\u4e00\u4e2a\u60ac\u8d4f\u4e00\u767e\u4e07\u7f8e\u5143\u3002 \u89e3\u51b3\u8fd9\u4e2a\u731c\u60f3\uff0c\u65e0\u975e\u4e24\u79cd\u53ef\u80fd\uff0c\u4e00\u79cd\u662f\u627e\u5230\u4e00\u4e2a\u8fd9\u6837\u7684\u7b97\u6cd5\uff0c\u53ea\u8981\u9488\u5bf9\u67d0\u4e2a\u7279\u5b9aNP\u5b8c\u5168\u95ee\u9898\u627e\u5230\u4e00\u4e2a\u7b97\u6cd5\uff0c\u6240\u6709\u8fd9\u7c7b\u95ee\u9898\u90fd\u53ef\u4ee5\u8fce\u5203\u800c\u89e3\u4e86\uff0c\u56e0\u4e3a\u4ed6\u4eec\u53ef\u4ee5\u8f6c\u5316\u4e3a\u540c\u4e00\u4e2a\u95ee\u9898\u3002\u53e6\u5916\u7684\u4e00\u79cd\u53ef\u80fd\uff0c\u5c31\u662f\u8fd9\u6837\u7684\u7b97\u6cd5\u662f\u4e0d\u5b58\u5728\u7684\u3002\u90a3\u4e48\u5c31\u8981\u4ece\u6570\u5b66\u7406\u8bba\u4e0a\u8bc1\u660e\u5b83\u4e3a\u4ec0\u4e48\u4e0d\u5b58\u5728\u3002","title":"\u76f8\u5173\u5b9a\u4e49"}]}